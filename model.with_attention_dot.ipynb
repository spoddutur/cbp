{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import import_ipynb\n",
    "#from model import *\n",
    "import numpy as np\n",
    "import itertools\n",
    "import glob\n",
    "import os\n",
    "import json\n",
    "import re\n",
    "import pickle\n",
    "import math\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from keras.models import Model\n",
    "from keras.backend import mean, sum, expand_dims, tanh\n",
    "from keras.layers import Dense, Input, Dropout, LSTM, Activation, GRU, Concatenate, Multiply, Reshape, RepeatVector, Dot, Softmax\n",
    "from keras.layers.embeddings import Embedding\n",
    "from keras.preprocessing import sequence\n",
    "from keras.initializers import glorot_uniform\n",
    "from keras.layers import Lambda\n",
    "from keras.optimizers import Adam\n",
    "np.random.seed(1)\n",
    "from keras.models import Sequential\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# given x (?,dim) always return (max_len, dim) by padding with zeros\n",
    "def padding(max_len, x, dim ):\n",
    "    x_len = x.shape[0]\n",
    "    # truncate if more than max_len else pad with zeros\n",
    "    if(x_len >= max_len):\n",
    "        return x[0:max_len]\n",
    "    else:   \n",
    "        padding = np.zeros((max_len-x_len, dim))     \n",
    "        if(len(x.shape) > 1):\n",
    "            assert dim == x.shape[1],\"dimensions didnt match in padding\"   \n",
    "            return np.concatenate((x, padding))\n",
    "        else:\n",
    "            return padding\n",
    "        \n",
    "# given 1D array x, we return array of shape (max_len, dim) by replicating each element dim times and apdding with zeros at end\n",
    "def reshape_mask(max_len, x, dim):\n",
    "    # mask is a 1D array so padd with dim == 1\n",
    "    padded_question_mask = np.squeeze(padding(max_len, x, 1))\n",
    "    final_question_mask = []\n",
    "    for qm in padded_question_mask:\n",
    "        # make each mask index into array of dimension dim\n",
    "        final_question_mask.append(np.array([qm]*dim))\n",
    "    return np.asarray(final_question_mask)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "s_DimOfQuestionVector = 300\n",
    "s_DimOfTripletVector  = 900\n",
    "s_DimOfMask           = 50\n",
    "s_QuestionMaxWords    = 60\n",
    "s_TripletsMaxNumbers  = 500"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X:/cs230/proj0/ned-graphs/data_wiki_encoded/train/train_8.ipwk\n"
     ]
    }
   ],
   "source": [
    "def prepare_data(data, \n",
    "                 question_max_words, \n",
    "                 triplets_max_numbers, \n",
    "                 dimOfQuestionVector, \n",
    "                 dimOfTripletVector, \n",
    "                 dimOfMask):\n",
    "    question_vectors = []\n",
    "    question_masks = []\n",
    "    triplet_vectors = []\n",
    "    Y = []\n",
    "    for elem in data:\n",
    "        item_question             = elem[\"question\"]\n",
    "        padded_item_question      = padding(question_max_words, item_question, dimOfQuestionVector)\n",
    "        item_question_mask        = np.reshape(elem[\"question_mask\"], (len(elem[\"question_mask\"]), 1) )\n",
    "        padded_item_question_mask = reshape_mask(question_max_words, item_question_mask, dimOfMask)\n",
    "        item_correct_triplets     = elem[\"correct_triplets\"]\n",
    "        item_wrong_triplets       = elem[\"wrong_triplets\"]\n",
    "        \n",
    "        # for triplets take mean of each S, P  and 0 to get 3,300 vectors which are then concatenated to dimOfTripletVector vector\n",
    "        item_correct_triplets_vectors = [] \n",
    "        for tr in item_correct_triplets: # There are triplets_max_numbers triplets\n",
    "            # Each tr has s, p and o. Each of the _s, _p and _o's are (num_tokens, dimOfTripletVector) size\n",
    "            _s = np.mean(tr[0], axis=0)\n",
    "            _p = np.mean(tr[1], axis=0)\n",
    "            _o = np.mean(tr[2], axis=0)\n",
    "            item_correct_triplets_vectors.append(np.concatenate((_s, _p, _o))) # adding (900,) vector for each triplet\n",
    "        #pad triplet vectors so we have (triplets_max_numbers, dimOfTripletVector)  encoding for all triplets\n",
    "        padded_item_triplets_vectors = padding(triplets_max_numbers, np.asarray(item_correct_triplets_vectors), dimOfTripletVector)\n",
    "        \n",
    "        triplet_vectors.append(padded_item_triplets_vectors)\n",
    "        question_vectors.append(padded_item_question)\n",
    "        question_masks.append(padded_item_question_mask)\n",
    "        Y.append(1)\n",
    "\n",
    "        # for wrong triplets\n",
    "        item_wrong_triplets_vectors = []\n",
    "        for tr in item_wrong_triplets:\n",
    "            _s = np.mean(tr[0], axis=0)\n",
    "            _p = np.mean(tr[1], axis=0)\n",
    "            _o = np.mean(tr[2], axis=0)\n",
    "            item_wrong_triplets_vectors.append(np.concatenate((_s, _p, _o)))\n",
    "        padded_item_wrong_triplets_vectors = padding(triplets_max_numbers, np.asarray(item_wrong_triplets_vectors), dimOfTripletVector)\n",
    "                \n",
    "        triplet_vectors.append(padded_item_wrong_triplets_vectors)\n",
    "        question_vectors.append(padded_item_question)\n",
    "        question_masks.append(padded_item_question_mask)\n",
    "        Y.append(0)\n",
    "        \n",
    "        \n",
    "        \n",
    "    question_vectors = np.asarray(question_vectors)\n",
    "    question_masks   = np.asarray(question_masks)\n",
    "    triplet_vectors  = np.asarray(triplet_vectors)\n",
    "    Y                = np.asarray(Y)\n",
    "    return question_vectors, question_masks, triplet_vectors, Y\n",
    "\n",
    "def generate_model_inputs():\n",
    "    file_list = glob.glob('X:/cs230/proj0/ned-graphs/data_wiki_encoded/train/train_8.ipwk')\n",
    "    data = []\n",
    "    num = 0\n",
    "    for inputFile in file_list:\n",
    "        print(inputFile)\n",
    "        f = open(inputFile, 'rb')\n",
    "        test = pickle.load(f)\n",
    "        data = np.append(data, test)\n",
    "        f.close()\n",
    "        num += 1\n",
    "        if num == 1:\n",
    "            break\n",
    "    \n",
    "    return prepare_data(data, \n",
    "                        question_max_words   = s_QuestionMaxWords, \n",
    "                        triplets_max_numbers = s_TripletsMaxNumbers, \n",
    "                        dimOfQuestionVector  = s_DimOfQuestionVector, \n",
    "                        dimOfTripletVector   = s_DimOfTripletVector, \n",
    "                        dimOfMask            = s_DimOfMask )\n",
    "\n",
    "question_vectors, question_masks, triplet_vectors, Y = generate_model_inputs()#prepare_data(data, question_max_words=60, triplets_max_numbers=500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(200, 60, 300)\n",
      "(200, 60, 50)\n",
      "(200, 500, 900)\n",
      "(200,)\n"
     ]
    }
   ],
   "source": [
    "print(question_vectors.shape)\n",
    "print(question_masks.shape)\n",
    "print(triplet_vectors.shape)\n",
    "print(Y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "questions_input_shape      = (s_QuestionMaxWords,   s_DimOfQuestionVector)\n",
    "questions_mask_input_shape = (s_QuestionMaxWords,   s_DimOfMask )\n",
    "triplets_input_shape       = (s_TripletsMaxNumbers, s_DimOfTripletVector )\n",
    "# question_vectors(, 60, 300), question_masks(, 60, 300), triplet_vectors (,500,900), Y\n",
    "\n",
    "gru_dimension = s_DimOfMask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "question_vectors_input (InputLa (None, 60, 300)      0                                            \n",
      "__________________________________________________________________________________________________\n",
      "Sentence_GRU1 (GRU)             (None, 60, 50)       52650       question_vectors_input[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "question_masks_input (InputLaye (None, 60, 50)       0                                            \n",
      "__________________________________________________________________________________________________\n",
      "Sentence_GRU2 (GRU)             (None, 60, 50)       15150       Sentence_GRU1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "triplets_input (InputLayer)     (None, 500, 900)     0                                            \n",
      "__________________________________________________________________________________________________\n",
      "multiply_9 (Multiply)           (None, 60, 50)       0           question_masks_input[0][0]       \n",
      "                                                                 Sentence_GRU2[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "TripletDense50T (Dense)         (None, 500, 50)      45050       triplets_input[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "SentenceMean (Lambda)           (None, 50)           0           multiply_9[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "Triplet_GRU1 (GRU)              (None, 500, 50)      15150       TripletDense50T[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "Triplet_GRU2 (GRU)              (None, 500, 50)      15150       Triplet_GRU1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "AttentionRepeat (RepeatVector)  (None, 500, 50)      0           SentenceMean[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "AttentionMultiply (Multiply)    (None, 500, 50)      0           Triplet_GRU2[0][0]               \n",
      "                                                                 AttentionRepeat[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "AttentionSum (Lambda)           (None, 500)          0           AttentionMultiply[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "AttentionSofMax (Softmax)       (None, 500)          0           AttentionSum[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "AttentionWeightedSum (Lambda)   (None, 50)           0           Triplet_GRU2[0][0]               \n",
      "                                                                 AttentionSofMax[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "SentenceTripletConcat (Concaten (None, 100)          0           SentenceMean[0][0]               \n",
      "                                                                 AttentionWeightedSum[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "Dense64 (Dense)                 (None, 64)           6464        SentenceTripletConcat[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "Dense1 (Dense)                  (None, 1)            65          Dense64[0][0]                    \n",
      "==================================================================================================\n",
      "Total params: 149,679\n",
      "Trainable params: 149,679\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "# question inputs\n",
    "question_vectors_input = Input(shape=questions_input_shape,      dtype='float32', name=\"question_vectors_input\")   \n",
    "question_masks_input   = Input(shape=questions_mask_input_shape, dtype='float32', name=\"question_masks_input\")\n",
    "\n",
    "# triplets input\n",
    "triplets_input = Input(shape=triplets_input_shape, dtype='float32', name=\"triplets_input\")  #(None, 500, 900)\n",
    "\n",
    "# layers\n",
    "# gru1 = Bidirectional(GRU( 50, return_sequences=True, name=\"Sentence_GRU1\"))\n",
    "# gru2 = Bidirectional(GRU( 50, return_sequences=False, name=\"Sentence_GRU2\"))\n",
    "# tgru1 = Bidirectional(GRU( 50, return_sequences=True, name=\"Triplet_GRU1\"))\n",
    "# tgru2 = Bidirectional(GRU( 50, return_sequences=False, name=\"Triplet_GRU2\"))\n",
    "\n",
    "gru1 =  (GRU( gru_dimension,  return_sequences=True,  name=\"Sentence_GRU1\"))\n",
    "gru2 =  (GRU( gru_dimension,  return_sequences=True,  name=\"Sentence_GRU2\"))\n",
    "tgru1 = (GRU( gru_dimension,  return_sequences=True,  name=\"Triplet_GRU1\"))\n",
    "tgru2 = (GRU( gru_dimension,  return_sequences=True, name=\"Triplet_GRU2\"))\n",
    "\n",
    "mean_layer = Lambda(lambda xin: mean(xin, axis=1), name=\"SentenceMean\")\n",
    "\n",
    "repeat_layer       = RepeatVector(triplets_input_shape[0], name=\"AttentionRepeat\")\n",
    "sum_layer          = Lambda(lambda xin: sum(xin, axis=-1), name=\"AttentionSum\")\n",
    "soft_max_layer     = Softmax(name=\"AttentionSofMax\")\n",
    "weighted_sum_layer = Lambda(lambda X: sum(X[0]*expand_dims(X[1],axis=-1), axis=1), name=\"AttentionWeightedSum\")\n",
    "\n",
    "X_question = gru2(gru1(question_vectors_input))             # (None, 3000, 50) -> (None, 60, 50)\n",
    "X_question = Multiply()([question_masks_input, X_question]) # (None, 60, 50)\n",
    "X_question = mean_layer(X_question)                         # (None, 60, 50) -> (None, 50)\n",
    "\n",
    "X_triplets = Dense(50, activation='relu', name=\"TripletDense50T\")(triplets_input)    # (None,500,900) -> (None,500,50)\n",
    "X_triplets = tgru2(tgru1(X_triplets))                                                # (None,500,50)  -> (None,500,50)\n",
    "\n",
    "X_attention = repeat_layer(X_question)\n",
    "# compute dot product X_triplets with X_question\n",
    "X_attention = Multiply(name=\"AttentionMultiply\")([X_triplets, X_attention])\n",
    "X_attention = sum_layer(X_attention)\n",
    "# compute softmax and get attention weights\n",
    "X_attention = soft_max_layer(X_attention)\n",
    "# weighted sum of triplets with attention weights\n",
    "X_triplets  = weighted_sum_layer([ X_triplets, X_attention])\n",
    "\n",
    "# concat sentence and triplet for final prediction\n",
    "X_concatenated = Concatenate(name=\"SentenceTripletConcat\")([X_question, X_triplets])                      # (None,100)\n",
    "X_concatenated = Dense(64, activation='relu', name=\"Dense64\")(X_concatenated) # (None,100) -> (None,64)        \n",
    "Y_pred = Dense(1, activation='sigmoid', name=\"Dense1\")(X_concatenated)        # (None,64)  -> sigmoid    \n",
    "\n",
    "model = Model(inputs=[question_vectors_input, question_masks_input, triplets_input], outputs=Y_pred)\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "#model.fit([question_vectors, question_masks, triplet_vectors], Y, epochs = 30, batch_size = 20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "459\n",
      "92\n"
     ]
    }
   ],
   "source": [
    "#TRAIN\n",
    "s_NumEpocs        = 5\n",
    "s_NumFilesInBatch = 5\n",
    "file_list         = glob.glob('X:/cs230/proj0/ned-graphs/data_wiki_encoded/train/train_*.ipwk')\n",
    "file_list_count   = len(file_list)\n",
    "file_batch_count  = math.ceil(( file_list_count / s_NumFilesInBatch ))\n",
    "\n",
    "print(file_list_count)\n",
    "print(file_batch_count)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training on Epoch  0 batch  5  Files [5] start  0 / 459\n",
      "Epoch 1/10\n",
      "1000/1000 [==============================] - 15s 15ms/step - loss: 0.6880 - acc: 0.5240\n",
      "Epoch 2/10\n",
      "1000/1000 [==============================] - 11s 11ms/step - loss: 0.6697 - acc: 0.5480\n",
      "Epoch 3/10\n",
      "1000/1000 [==============================] - 11s 11ms/step - loss: 0.6409 - acc: 0.6350\n",
      "Epoch 4/10\n",
      "1000/1000 [==============================] - 11s 11ms/step - loss: 0.6035 - acc: 0.7170\n",
      "Epoch 5/10\n",
      "1000/1000 [==============================] - 12s 12ms/step - loss: 0.5640 - acc: 0.7470\n",
      "Epoch 6/10\n",
      "1000/1000 [==============================] - 11s 11ms/step - loss: 0.5248 - acc: 0.7860\n",
      "Epoch 7/10\n",
      "1000/1000 [==============================] - 11s 11ms/step - loss: 0.4776 - acc: 0.8130\n",
      "Epoch 8/10\n",
      "1000/1000 [==============================] - 11s 11ms/step - loss: 0.4412 - acc: 0.8170\n",
      "Epoch 9/10\n",
      "1000/1000 [==============================] - 11s 11ms/step - loss: 0.4122 - acc: 0.8320\n",
      "Epoch 10/10\n",
      "1000/1000 [==============================] - 11s 11ms/step - loss: 0.3742 - acc: 0.8410\n",
      "Training on Epoch  0 batch  5  Files [5] start  5 / 459\n",
      "Epoch 1/10\n",
      "1000/1000 [==============================] - 17s 17ms/step - loss: 0.5107 - acc: 0.8190\n",
      "Epoch 2/10\n",
      "1000/1000 [==============================] - 17s 17ms/step - loss: 0.4636 - acc: 0.8260\n",
      "Epoch 3/10\n",
      "1000/1000 [==============================] - 17s 17ms/step - loss: 0.4187 - acc: 0.8400\n",
      "Epoch 4/10\n",
      "1000/1000 [==============================] - 17s 17ms/step - loss: 0.3871 - acc: 0.8450\n",
      "Epoch 5/10\n",
      "1000/1000 [==============================] - 18s 18ms/step - loss: 0.3459 - acc: 0.8740\n",
      "Epoch 6/10\n",
      "1000/1000 [==============================] - 18s 18ms/step - loss: 0.3236 - acc: 0.8760\n",
      "Epoch 7/10\n",
      "1000/1000 [==============================] - 18s 18ms/step - loss: 0.3145 - acc: 0.8840\n",
      "Epoch 8/10\n",
      "1000/1000 [==============================] - 19s 19ms/step - loss: 0.2919 - acc: 0.8940\n",
      "Epoch 9/10\n",
      "1000/1000 [==============================] - 19s 19ms/step - loss: 0.2884 - acc: 0.8890\n",
      "Epoch 10/10\n",
      "1000/1000 [==============================] - 18s 18ms/step - loss: 0.2772 - acc: 0.8930\n",
      "Training on Epoch  0 batch  5  Files [5] start  10 / 459\n",
      "Epoch 1/10\n",
      "1000/1000 [==============================] - 16s 16ms/step - loss: 0.5598 - acc: 0.8010\n",
      "Epoch 2/10\n",
      "1000/1000 [==============================] - 17s 17ms/step - loss: 0.4456 - acc: 0.8260\n",
      "Epoch 3/10\n",
      "1000/1000 [==============================] - 17s 17ms/step - loss: 0.4080 - acc: 0.8330\n",
      "Epoch 4/10\n",
      "1000/1000 [==============================] - 17s 17ms/step - loss: 0.3813 - acc: 0.8460\n",
      "Epoch 5/10\n",
      "1000/1000 [==============================] - 18s 18ms/step - loss: 0.3624 - acc: 0.8630\n",
      "Epoch 6/10\n",
      "1000/1000 [==============================] - 18s 18ms/step - loss: 0.3394 - acc: 0.8670\n",
      "Epoch 7/10\n",
      "1000/1000 [==============================] - 18s 18ms/step - loss: 0.3142 - acc: 0.8720\n",
      "Epoch 8/10\n",
      "1000/1000 [==============================] - 18s 18ms/step - loss: 0.2907 - acc: 0.8870\n",
      "Epoch 9/10\n",
      "1000/1000 [==============================] - 18s 18ms/step - loss: 0.2844 - acc: 0.8810\n",
      "Epoch 10/10\n",
      "1000/1000 [==============================] - 18s 18ms/step - loss: 0.2525 - acc: 0.9010\n",
      "Training on Epoch  0 batch  5  Files [5] start  15 / 459\n",
      "Epoch 1/10\n",
      "1000/1000 [==============================] - 20s 20ms/step - loss: 0.4554 - acc: 0.8300\n",
      "Epoch 2/10\n",
      "1000/1000 [==============================] - 20s 20ms/step - loss: 0.3988 - acc: 0.8440\n",
      "Epoch 3/10\n",
      "1000/1000 [==============================] - 20s 20ms/step - loss: 0.3740 - acc: 0.8540\n",
      "Epoch 4/10\n",
      "1000/1000 [==============================] - 21s 21ms/step - loss: 0.3504 - acc: 0.8640\n",
      "Epoch 5/10\n",
      "1000/1000 [==============================] - 21s 21ms/step - loss: 0.3231 - acc: 0.8770\n",
      "Epoch 6/10\n",
      "1000/1000 [==============================] - 21s 21ms/step - loss: 0.3082 - acc: 0.8820\n",
      "Epoch 7/10\n",
      "1000/1000 [==============================] - 21s 21ms/step - loss: 0.2927 - acc: 0.8840\n",
      "Epoch 8/10\n",
      "1000/1000 [==============================] - 21s 21ms/step - loss: 0.2652 - acc: 0.8960\n",
      "Epoch 9/10\n",
      "1000/1000 [==============================] - 21s 21ms/step - loss: 0.2492 - acc: 0.8940\n",
      "Epoch 10/10\n",
      "1000/1000 [==============================] - 21s 21ms/step - loss: 0.2295 - acc: 0.9050\n",
      "Training on Epoch  0 batch  5  Files [5] start  20 / 459\n",
      "Epoch 1/10\n",
      "1000/1000 [==============================] - 19s 19ms/step - loss: 0.4571 - acc: 0.8200\n",
      "Epoch 2/10\n",
      "1000/1000 [==============================] - 20s 20ms/step - loss: 0.4203 - acc: 0.8190\n",
      "Epoch 3/10\n",
      "1000/1000 [==============================] - 21s 21ms/step - loss: 0.3858 - acc: 0.8370\n",
      "Epoch 4/10\n",
      "1000/1000 [==============================] - 20s 20ms/step - loss: 0.3535 - acc: 0.8490\n",
      "Epoch 5/10\n",
      "1000/1000 [==============================] - 20s 20ms/step - loss: 0.3180 - acc: 0.8690\n",
      "Epoch 6/10\n",
      "1000/1000 [==============================] - 20s 20ms/step - loss: 0.2895 - acc: 0.8850\n",
      "Epoch 7/10\n",
      "1000/1000 [==============================] - 20s 20ms/step - loss: 0.2783 - acc: 0.8810\n",
      "Epoch 8/10\n",
      "1000/1000 [==============================] - 20s 20ms/step - loss: 0.2539 - acc: 0.9050\n",
      "Epoch 9/10\n",
      "1000/1000 [==============================] - 20s 20ms/step - loss: 0.2389 - acc: 0.9070\n",
      "Epoch 10/10\n",
      "1000/1000 [==============================] - 20s 20ms/step - loss: 0.2235 - acc: 0.9080\n",
      "Training on Epoch  0 batch  5  Files [5] start  25 / 459\n",
      "Epoch 1/10\n",
      "1000/1000 [==============================] - 25s 25ms/step - loss: 0.4948 - acc: 0.8030\n",
      "Epoch 2/10\n",
      "1000/1000 [==============================] - 25s 25ms/step - loss: 0.4367 - acc: 0.8050\n",
      "Epoch 3/10\n",
      "1000/1000 [==============================] - 25s 25ms/step - loss: 0.4195 - acc: 0.8130\n",
      "Epoch 4/10\n",
      "1000/1000 [==============================] - 26s 26ms/step - loss: 0.3892 - acc: 0.8260\n",
      "Epoch 5/10\n",
      "1000/1000 [==============================] - 27s 27ms/step - loss: 0.3647 - acc: 0.8420\n",
      "Epoch 6/10\n",
      "1000/1000 [==============================] - 27s 27ms/step - loss: 0.3493 - acc: 0.8480\n",
      "Epoch 7/10\n",
      "1000/1000 [==============================] - 27s 27ms/step - loss: 0.3333 - acc: 0.8540\n",
      "Epoch 8/10\n",
      "1000/1000 [==============================] - 27s 27ms/step - loss: 0.3202 - acc: 0.8570\n",
      "Epoch 9/10\n",
      "1000/1000 [==============================] - 28s 28ms/step - loss: 0.3206 - acc: 0.8560\n",
      "Epoch 10/10\n",
      "1000/1000 [==============================] - 27s 27ms/step - loss: 0.3061 - acc: 0.8620\n",
      "Training on Epoch  0 batch  5  Files [5] start  30 / 459\n",
      "Epoch 1/10\n",
      "1000/1000 [==============================] - 25s 25ms/step - loss: 0.4233 - acc: 0.8210\n",
      "Epoch 2/10\n",
      "1000/1000 [==============================] - 25s 25ms/step - loss: 0.3963 - acc: 0.8370\n",
      "Epoch 3/10\n",
      "1000/1000 [==============================] - 26s 26ms/step - loss: 0.3778 - acc: 0.8450\n",
      "Epoch 4/10\n",
      "1000/1000 [==============================] - 26s 26ms/step - loss: 0.3547 - acc: 0.8570\n",
      "Epoch 5/10\n",
      "1000/1000 [==============================] - 27s 27ms/step - loss: 0.3377 - acc: 0.8650\n",
      "Epoch 6/10\n",
      "1000/1000 [==============================] - 26s 26ms/step - loss: 0.3189 - acc: 0.8730\n",
      "Epoch 7/10\n",
      "1000/1000 [==============================] - 26s 26ms/step - loss: 0.3048 - acc: 0.8800\n",
      "Epoch 8/10\n",
      "1000/1000 [==============================] - 26s 26ms/step - loss: 0.2867 - acc: 0.8880\n",
      "Epoch 9/10\n",
      "1000/1000 [==============================] - 26s 26ms/step - loss: 0.2716 - acc: 0.8900\n",
      "Epoch 10/10\n",
      "1000/1000 [==============================] - 27s 27ms/step - loss: 0.2541 - acc: 0.9030\n",
      "Training on Epoch  0 batch  5  Files [5] start  35 / 459\n",
      "Epoch 1/10\n",
      "1000/1000 [==============================] - 28s 28ms/step - loss: 0.3983 - acc: 0.8310\n",
      "Epoch 2/10\n",
      "1000/1000 [==============================] - 28s 28ms/step - loss: 0.3504 - acc: 0.8510\n",
      "Epoch 3/10\n",
      "1000/1000 [==============================] - 29s 29ms/step - loss: 0.3404 - acc: 0.8640\n",
      "Epoch 4/10\n",
      "1000/1000 [==============================] - 29s 29ms/step - loss: 0.3043 - acc: 0.8720\n",
      "Epoch 5/10\n",
      "1000/1000 [==============================] - 29s 29ms/step - loss: 0.3004 - acc: 0.8730\n",
      "Epoch 6/10\n",
      "1000/1000 [==============================] - 28s 28ms/step - loss: 0.2916 - acc: 0.8790\n",
      "Epoch 7/10\n",
      "1000/1000 [==============================] - 28s 28ms/step - loss: 0.2613 - acc: 0.8870\n",
      "Epoch 8/10\n",
      "1000/1000 [==============================] - 28s 28ms/step - loss: 0.2422 - acc: 0.9040\n",
      "Epoch 9/10\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000/1000 [==============================] - 29s 29ms/step - loss: 0.2217 - acc: 0.9040\n",
      "Epoch 10/10\n",
      "1000/1000 [==============================] - 29s 29ms/step - loss: 0.2135 - acc: 0.9050\n",
      "Training on Epoch  0 batch  5  Files [5] start  40 / 459\n",
      "Epoch 1/10\n",
      "1000/1000 [==============================] - 33s 33ms/step - loss: 0.3722 - acc: 0.8530\n",
      "Epoch 2/10\n",
      "1000/1000 [==============================] - 33s 33ms/step - loss: 0.3336 - acc: 0.8640\n",
      "Epoch 3/10\n",
      "1000/1000 [==============================] - 40s 40ms/step - loss: 0.3145 - acc: 0.8850\n",
      "Epoch 4/10\n",
      "1000/1000 [==============================] - 44s 44ms/step - loss: 0.2950 - acc: 0.8860\n",
      "Epoch 5/10\n",
      "1000/1000 [==============================] - 44s 44ms/step - loss: 0.2741 - acc: 0.8950\n",
      "Epoch 6/10\n",
      "1000/1000 [==============================] - 45s 45ms/step - loss: 0.2624 - acc: 0.9020\n",
      "Epoch 7/10\n",
      "1000/1000 [==============================] - 44s 44ms/step - loss: 0.2566 - acc: 0.9030\n",
      "Epoch 8/10\n",
      "1000/1000 [==============================] - 45s 45ms/step - loss: 0.2418 - acc: 0.9060\n",
      "Epoch 9/10\n",
      "1000/1000 [==============================] - 45s 45ms/step - loss: 0.2351 - acc: 0.9080\n",
      "Epoch 10/10\n",
      "1000/1000 [==============================] - 46s 46ms/step - loss: 0.2220 - acc: 0.9190\n",
      "Training on Epoch  0 batch  5  Files [5] start  45 / 459\n",
      "Epoch 1/10\n",
      "1000/1000 [==============================] - 43s 43ms/step - loss: 0.4188 - acc: 0.8180\n",
      "Epoch 2/10\n",
      "1000/1000 [==============================] - 45s 45ms/step - loss: 0.3656 - acc: 0.8380\n",
      "Epoch 3/10\n",
      "1000/1000 [==============================] - 44s 44ms/step - loss: 0.3564 - acc: 0.8490\n",
      "Epoch 4/10\n",
      "1000/1000 [==============================] - 46s 46ms/step - loss: 0.3262 - acc: 0.8600\n",
      "Epoch 5/10\n",
      "1000/1000 [==============================] - 45s 45ms/step - loss: 0.3188 - acc: 0.8600\n",
      "Epoch 6/10\n",
      "1000/1000 [==============================] - 46s 46ms/step - loss: 0.2952 - acc: 0.8750\n",
      "Epoch 7/10\n",
      "1000/1000 [==============================] - 45s 45ms/step - loss: 0.2775 - acc: 0.8870\n",
      "Epoch 8/10\n",
      "1000/1000 [==============================] - 46s 46ms/step - loss: 0.3030 - acc: 0.8810\n",
      "Epoch 9/10\n",
      "1000/1000 [==============================] - 46s 46ms/step - loss: 0.3013 - acc: 0.8850\n",
      "Epoch 10/10\n",
      "1000/1000 [==============================] - 46s 46ms/step - loss: 0.2824 - acc: 0.8820\n",
      "Training on Epoch  0 batch  5  Files [5] start  50 / 459\n",
      "Epoch 1/10\n",
      "1000/1000 [==============================] - 48s 48ms/step - loss: 0.3964 - acc: 0.8380\n",
      "Epoch 2/10\n",
      "1000/1000 [==============================] - 49s 49ms/step - loss: 0.3700 - acc: 0.8460\n",
      "Epoch 3/10\n",
      "1000/1000 [==============================] - 49s 49ms/step - loss: 0.3307 - acc: 0.8550\n",
      "Epoch 4/10\n",
      "1000/1000 [==============================] - 49s 49ms/step - loss: 0.3112 - acc: 0.8640\n",
      "Epoch 5/10\n",
      "1000/1000 [==============================] - 50s 50ms/step - loss: 0.3081 - acc: 0.8850\n",
      "Epoch 6/10\n",
      "1000/1000 [==============================] - 50s 50ms/step - loss: 0.2813 - acc: 0.8810\n",
      "Epoch 7/10\n",
      "1000/1000 [==============================] - 49s 49ms/step - loss: 0.2719 - acc: 0.8880\n",
      "Epoch 8/10\n",
      "1000/1000 [==============================] - 50s 50ms/step - loss: 0.2556 - acc: 0.9010\n",
      "Epoch 9/10\n",
      "1000/1000 [==============================] - 49s 49ms/step - loss: 0.2413 - acc: 0.9100\n",
      "Epoch 10/10\n",
      "1000/1000 [==============================] - 49s 49ms/step - loss: 0.2297 - acc: 0.9130\n",
      "Training on Epoch  0 batch  5  Files [5] start  55 / 459\n",
      "Epoch 1/10\n",
      "1000/1000 [==============================] - 45s 45ms/step - loss: 0.3986 - acc: 0.8400\n",
      "Epoch 2/10\n",
      "1000/1000 [==============================] - 46s 46ms/step - loss: 0.3593 - acc: 0.8460\n",
      "Epoch 3/10\n",
      "1000/1000 [==============================] - 46s 46ms/step - loss: 0.3352 - acc: 0.8620\n",
      "Epoch 4/10\n",
      "1000/1000 [==============================] - 46s 46ms/step - loss: 0.3155 - acc: 0.8770\n",
      "Epoch 5/10\n",
      "1000/1000 [==============================] - 47s 47ms/step - loss: 0.2993 - acc: 0.8900\n",
      "Epoch 6/10\n",
      "1000/1000 [==============================] - 46s 46ms/step - loss: 0.2772 - acc: 0.9010\n",
      "Epoch 7/10\n",
      "1000/1000 [==============================] - 46s 46ms/step - loss: 0.2640 - acc: 0.8990\n",
      "Epoch 8/10\n",
      "1000/1000 [==============================] - 47s 47ms/step - loss: 0.2569 - acc: 0.8970\n",
      "Epoch 9/10\n",
      "1000/1000 [==============================] - 46s 46ms/step - loss: 0.2551 - acc: 0.9030\n",
      "Epoch 10/10\n",
      "1000/1000 [==============================] - 46s 46ms/step - loss: 0.2584 - acc: 0.8970\n",
      "Training on Epoch  0 batch  5  Files [5] start  60 / 459\n",
      "Epoch 1/10\n",
      "1000/1000 [==============================] - 36s 36ms/step - loss: 0.4176 - acc: 0.8170\n",
      "Epoch 2/10\n",
      "1000/1000 [==============================] - 37s 37ms/step - loss: 0.3609 - acc: 0.8340\n",
      "Epoch 3/10\n",
      "1000/1000 [==============================] - 37s 37ms/step - loss: 0.3305 - acc: 0.8500\n",
      "Epoch 4/10\n",
      "1000/1000 [==============================] - 37s 37ms/step - loss: 0.3107 - acc: 0.8640\n",
      "Epoch 5/10\n",
      "1000/1000 [==============================] - 37s 37ms/step - loss: 0.3149 - acc: 0.8530\n",
      "Epoch 6/10\n",
      "1000/1000 [==============================] - 37s 37ms/step - loss: 0.3720 - acc: 0.8210\n",
      "Epoch 7/10\n",
      "1000/1000 [==============================] - 38s 38ms/step - loss: 0.3825 - acc: 0.8340\n",
      "Epoch 8/10\n",
      "1000/1000 [==============================] - 37s 37ms/step - loss: 0.3502 - acc: 0.8400\n",
      "Epoch 9/10\n",
      "1000/1000 [==============================] - 37s 37ms/step - loss: 0.3230 - acc: 0.8560\n",
      "Epoch 10/10\n",
      "1000/1000 [==============================] - 37s 37ms/step - loss: 0.3000 - acc: 0.8580\n",
      "Training on Epoch  0 batch  5  Files [5] start  65 / 459\n",
      "Epoch 1/10\n",
      "1000/1000 [==============================] - 44s 44ms/step - loss: 0.3974 - acc: 0.8290\n",
      "Epoch 2/10\n",
      "1000/1000 [==============================] - 46s 46ms/step - loss: 0.3765 - acc: 0.8340\n",
      "Epoch 3/10\n",
      "1000/1000 [==============================] - 45s 45ms/step - loss: 0.3508 - acc: 0.8470\n",
      "Epoch 4/10\n",
      "1000/1000 [==============================] - 45s 45ms/step - loss: 0.3342 - acc: 0.8640\n",
      "Epoch 5/10\n",
      "1000/1000 [==============================] - 45s 45ms/step - loss: 0.3236 - acc: 0.8640\n",
      "Epoch 6/10\n",
      "1000/1000 [==============================] - 45s 45ms/step - loss: 0.3033 - acc: 0.8780\n",
      "Epoch 7/10\n",
      "1000/1000 [==============================] - 45s 45ms/step - loss: 0.2911 - acc: 0.8880\n",
      "Epoch 8/10\n",
      "1000/1000 [==============================] - 45s 45ms/step - loss: 0.2806 - acc: 0.8890\n",
      "Epoch 9/10\n",
      "1000/1000 [==============================] - 45s 45ms/step - loss: 0.2684 - acc: 0.8910\n",
      "Epoch 10/10\n",
      "1000/1000 [==============================] - 44s 44ms/step - loss: 0.2590 - acc: 0.8900\n",
      "Training on Epoch  0 batch  5  Files [5] start  70 / 459\n",
      "Epoch 1/10\n",
      "1000/1000 [==============================] - 43s 43ms/step - loss: 0.3722 - acc: 0.8320\n",
      "Epoch 2/10\n",
      "1000/1000 [==============================] - 44s 44ms/step - loss: 0.3495 - acc: 0.8520\n",
      "Epoch 3/10\n",
      "1000/1000 [==============================] - 44s 44ms/step - loss: 0.3231 - acc: 0.8640\n",
      "Epoch 4/10\n",
      "1000/1000 [==============================] - 44s 44ms/step - loss: 0.3031 - acc: 0.8720\n",
      "Epoch 5/10\n",
      "1000/1000 [==============================] - 44s 44ms/step - loss: 0.2840 - acc: 0.9010\n",
      "Epoch 6/10\n",
      "1000/1000 [==============================] - 45s 45ms/step - loss: 0.2589 - acc: 0.9040\n",
      "Epoch 7/10\n",
      "1000/1000 [==============================] - 45s 45ms/step - loss: 0.2479 - acc: 0.9030\n",
      "Epoch 8/10\n",
      "1000/1000 [==============================] - 46s 46ms/step - loss: 0.2321 - acc: 0.9210\n",
      "Epoch 9/10\n",
      "1000/1000 [==============================] - 45s 45ms/step - loss: 0.2183 - acc: 0.9250\n",
      "Epoch 10/10\n",
      "1000/1000 [==============================] - 45s 45ms/step - loss: 0.2022 - acc: 0.9290\n",
      "Training on Epoch  0 batch  5  Files [5] start  75 / 459\n",
      "Epoch 1/10\n",
      "1000/1000 [==============================] - 44s 44ms/step - loss: 0.5011 - acc: 0.8070\n",
      "Epoch 2/10\n",
      "1000/1000 [==============================] - 45s 45ms/step - loss: 0.3986 - acc: 0.8260\n",
      "Epoch 3/10\n",
      "1000/1000 [==============================] - 45s 45ms/step - loss: 0.3718 - acc: 0.8440\n",
      "Epoch 4/10\n",
      "1000/1000 [==============================] - 45s 45ms/step - loss: 0.3766 - acc: 0.8310\n",
      "Epoch 5/10\n",
      "1000/1000 [==============================] - 45s 45ms/step - loss: 0.3482 - acc: 0.8460\n",
      "Epoch 6/10\n",
      "1000/1000 [==============================] - 45s 45ms/step - loss: 0.3348 - acc: 0.8480\n",
      "Epoch 7/10\n",
      "1000/1000 [==============================] - 46s 46ms/step - loss: 0.3182 - acc: 0.8540\n",
      "Epoch 8/10\n",
      "1000/1000 [==============================] - 46s 46ms/step - loss: 0.2992 - acc: 0.8610\n",
      "Epoch 9/10\n",
      "1000/1000 [==============================] - 46s 46ms/step - loss: 0.2818 - acc: 0.8740\n",
      "Epoch 10/10\n",
      "1000/1000 [==============================] - 45s 45ms/step - loss: 0.2712 - acc: 0.8810\n",
      "Training on Epoch  0 batch  5  Files [5] start  80 / 459\n",
      "Epoch 1/10\n",
      "1000/1000 [==============================] - 46s 46ms/step - loss: 0.4856 - acc: 0.7940\n",
      "Epoch 2/10\n",
      "1000/1000 [==============================] - 47s 47ms/step - loss: 0.4438 - acc: 0.8010\n",
      "Epoch 3/10\n",
      "1000/1000 [==============================] - 47s 47ms/step - loss: 0.4066 - acc: 0.8110\n",
      "Epoch 4/10\n",
      "1000/1000 [==============================] - 47s 47ms/step - loss: 0.3811 - acc: 0.8290\n",
      "Epoch 5/10\n",
      "1000/1000 [==============================] - 48s 48ms/step - loss: 0.3623 - acc: 0.8390\n",
      "Epoch 6/10\n",
      "1000/1000 [==============================] - 48s 48ms/step - loss: 0.3435 - acc: 0.8510\n",
      "Epoch 7/10\n",
      "1000/1000 [==============================] - 47s 47ms/step - loss: 0.3298 - acc: 0.8660\n",
      "Epoch 8/10\n",
      "1000/1000 [==============================] - 47s 47ms/step - loss: 0.3315 - acc: 0.8530\n",
      "Epoch 9/10\n",
      "1000/1000 [==============================] - 46s 46ms/step - loss: 0.3235 - acc: 0.8570\n",
      "Epoch 10/10\n",
      "1000/1000 [==============================] - 47s 47ms/step - loss: 0.3031 - acc: 0.8750\n",
      "Training on Epoch  0 batch  5  Files [5] start  85 / 459\n",
      "Epoch 1/10\n",
      "1000/1000 [==============================] - 39s 39ms/step - loss: 0.4193 - acc: 0.8350\n",
      "Epoch 2/10\n",
      "1000/1000 [==============================] - 39s 39ms/step - loss: 0.3885 - acc: 0.8510\n",
      "Epoch 3/10\n",
      "1000/1000 [==============================] - 40s 40ms/step - loss: 0.3584 - acc: 0.8570\n",
      "Epoch 4/10\n",
      "1000/1000 [==============================] - 40s 40ms/step - loss: 0.3318 - acc: 0.8700\n",
      "Epoch 5/10\n",
      "1000/1000 [==============================] - 41s 41ms/step - loss: 0.3248 - acc: 0.8560\n",
      "Epoch 6/10\n",
      "1000/1000 [==============================] - 39s 39ms/step - loss: 0.3045 - acc: 0.8830\n",
      "Epoch 7/10\n",
      "1000/1000 [==============================] - 39s 39ms/step - loss: 0.2852 - acc: 0.8820\n",
      "Epoch 8/10\n",
      "1000/1000 [==============================] - 40s 40ms/step - loss: 0.2652 - acc: 0.8960\n",
      "Epoch 9/10\n",
      "1000/1000 [==============================] - 40s 40ms/step - loss: 0.2494 - acc: 0.9040\n",
      "Epoch 10/10\n",
      "1000/1000 [==============================] - 40s 40ms/step - loss: 0.2465 - acc: 0.9050\n",
      "Training on Epoch  0 batch  5  Files [5] start  90 / 459\n",
      "Epoch 1/10\n",
      "1000/1000 [==============================] - 40s 40ms/step - loss: 0.3938 - acc: 0.8520\n",
      "Epoch 2/10\n",
      "1000/1000 [==============================] - 40s 40ms/step - loss: 0.3590 - acc: 0.8620\n",
      "Epoch 3/10\n",
      "1000/1000 [==============================] - 40s 40ms/step - loss: 0.3239 - acc: 0.8710\n",
      "Epoch 4/10\n",
      "1000/1000 [==============================] - 40s 40ms/step - loss: 0.3025 - acc: 0.8850\n",
      "Epoch 5/10\n",
      "1000/1000 [==============================] - 40s 40ms/step - loss: 0.2842 - acc: 0.8940\n",
      "Epoch 6/10\n",
      "1000/1000 [==============================] - 39s 39ms/step - loss: 0.2670 - acc: 0.8980\n",
      "Epoch 7/10\n",
      "1000/1000 [==============================] - 39s 39ms/step - loss: 0.2519 - acc: 0.9080\n",
      "Epoch 8/10\n",
      "1000/1000 [==============================] - 40s 40ms/step - loss: 0.2373 - acc: 0.9110\n",
      "Epoch 9/10\n",
      "1000/1000 [==============================] - 40s 40ms/step - loss: 0.2221 - acc: 0.9220\n",
      "Epoch 10/10\n",
      "1000/1000 [==============================] - 40s 40ms/step - loss: 0.2114 - acc: 0.9200\n",
      "Training on Epoch  0 batch  5  Files [5] start  95 / 459\n",
      "Epoch 1/10\n",
      "1000/1000 [==============================] - 43s 43ms/step - loss: 0.4048 - acc: 0.8370\n",
      "Epoch 2/10\n",
      "1000/1000 [==============================] - 44s 44ms/step - loss: 0.3409 - acc: 0.8610\n",
      "Epoch 3/10\n",
      "1000/1000 [==============================] - 44s 44ms/step - loss: 0.3174 - acc: 0.8760\n",
      "Epoch 4/10\n",
      "1000/1000 [==============================] - 44s 44ms/step - loss: 0.2929 - acc: 0.8760\n",
      "Epoch 5/10\n",
      "1000/1000 [==============================] - 43s 43ms/step - loss: 0.2764 - acc: 0.8850\n",
      "Epoch 6/10\n",
      "1000/1000 [==============================] - 43s 43ms/step - loss: 0.2652 - acc: 0.9020\n",
      "Epoch 7/10\n",
      "1000/1000 [==============================] - 43s 43ms/step - loss: 0.2449 - acc: 0.9020\n",
      "Epoch 8/10\n",
      "1000/1000 [==============================] - 44s 44ms/step - loss: 0.2319 - acc: 0.9140\n",
      "Epoch 9/10\n",
      "1000/1000 [==============================] - 44s 44ms/step - loss: 0.2130 - acc: 0.9160\n",
      "Epoch 10/10\n",
      "1000/1000 [==============================] - 44s 44ms/step - loss: 0.2027 - acc: 0.9220\n",
      "Training on Epoch  0 batch  5  Files [5] start  100 / 459\n",
      "Epoch 1/10\n",
      "1000/1000 [==============================] - 43s 43ms/step - loss: 0.3876 - acc: 0.8540\n",
      "Epoch 2/10\n",
      "1000/1000 [==============================] - 43s 43ms/step - loss: 0.3365 - acc: 0.8760\n",
      "Epoch 3/10\n",
      "1000/1000 [==============================] - 43s 43ms/step - loss: 0.2948 - acc: 0.8860\n",
      "Epoch 4/10\n",
      "1000/1000 [==============================] - 43s 43ms/step - loss: 0.2688 - acc: 0.8940\n",
      "Epoch 5/10\n",
      "1000/1000 [==============================] - 44s 44ms/step - loss: 0.2464 - acc: 0.8980\n",
      "Epoch 6/10\n",
      "1000/1000 [==============================] - 44s 44ms/step - loss: 0.2146 - acc: 0.9150\n",
      "Epoch 7/10\n",
      "1000/1000 [==============================] - 44s 44ms/step - loss: 0.1966 - acc: 0.9200\n",
      "Epoch 8/10\n",
      "1000/1000 [==============================] - 43s 43ms/step - loss: 0.1878 - acc: 0.9250\n",
      "Epoch 9/10\n",
      "1000/1000 [==============================] - 44s 44ms/step - loss: 0.1737 - acc: 0.9360\n",
      "Epoch 10/10\n",
      "1000/1000 [==============================] - 45s 45ms/step - loss: 0.1578 - acc: 0.9430\n",
      "Training on Epoch  0 batch  5  Files [5] start  105 / 459\n",
      "Epoch 1/10\n",
      "1000/1000 [==============================] - 41s 41ms/step - loss: 0.3872 - acc: 0.8580\n",
      "Epoch 2/10\n",
      "1000/1000 [==============================] - 41s 41ms/step - loss: 0.3474 - acc: 0.8730\n",
      "Epoch 3/10\n",
      "1000/1000 [==============================] - 41s 41ms/step - loss: 0.2878 - acc: 0.8860\n",
      "Epoch 4/10\n",
      "1000/1000 [==============================] - 43s 43ms/step - loss: 0.2600 - acc: 0.8940\n",
      "Epoch 5/10\n",
      "1000/1000 [==============================] - 42s 42ms/step - loss: 0.2498 - acc: 0.8970\n",
      "Epoch 6/10\n",
      "1000/1000 [==============================] - 42s 42ms/step - loss: 0.2343 - acc: 0.9030\n",
      "Epoch 7/10\n",
      "1000/1000 [==============================] - 42s 42ms/step - loss: 0.2191 - acc: 0.9140\n",
      "Epoch 8/10\n",
      "1000/1000 [==============================] - 43s 43ms/step - loss: 0.1989 - acc: 0.9250\n",
      "Epoch 9/10\n",
      "1000/1000 [==============================] - 42s 42ms/step - loss: 0.1857 - acc: 0.9280\n",
      "Epoch 10/10\n",
      "1000/1000 [==============================] - 41s 41ms/step - loss: 0.1913 - acc: 0.9260\n",
      "Training on Epoch  0 batch  5  Files [5] start  110 / 459\n",
      "Epoch 1/10\n",
      "1000/1000 [==============================] - 50s 50ms/step - loss: 0.4680 - acc: 0.8120\n",
      "Epoch 2/10\n",
      "1000/1000 [==============================] - 50s 50ms/step - loss: 0.4218 - acc: 0.8160\n",
      "Epoch 3/10\n",
      "1000/1000 [==============================] - 50s 50ms/step - loss: 0.3416 - acc: 0.8520\n",
      "Epoch 4/10\n",
      "1000/1000 [==============================] - 50s 50ms/step - loss: 0.3245 - acc: 0.8650\n",
      "Epoch 5/10\n",
      "1000/1000 [==============================] - 49s 49ms/step - loss: 0.2979 - acc: 0.8880\n",
      "Epoch 6/10\n",
      "1000/1000 [==============================] - 50s 50ms/step - loss: 0.2678 - acc: 0.9050\n",
      "Epoch 7/10\n",
      "1000/1000 [==============================] - 49s 49ms/step - loss: 0.2486 - acc: 0.9020\n",
      "Epoch 8/10\n",
      "1000/1000 [==============================] - 50s 50ms/step - loss: 0.2289 - acc: 0.9110\n",
      "Epoch 9/10\n",
      "1000/1000 [==============================] - 49s 49ms/step - loss: 0.2099 - acc: 0.9260\n",
      "Epoch 10/10\n",
      "1000/1000 [==============================] - 49s 49ms/step - loss: 0.1952 - acc: 0.9280\n",
      "Training on Epoch  0 batch  5  Files [5] start  115 / 459\n",
      "Epoch 1/10\n",
      "1000/1000 [==============================] - 49s 49ms/step - loss: 0.4438 - acc: 0.8170\n",
      "Epoch 2/10\n",
      "1000/1000 [==============================] - 50s 50ms/step - loss: 0.3703 - acc: 0.8430\n",
      "Epoch 3/10\n",
      "1000/1000 [==============================] - 49s 49ms/step - loss: 0.3643 - acc: 0.8400\n",
      "Epoch 4/10\n",
      "1000/1000 [==============================] - 51s 51ms/step - loss: 0.3461 - acc: 0.8370\n",
      "Epoch 5/10\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000/1000 [==============================] - 50s 50ms/step - loss: 0.3179 - acc: 0.8610\n",
      "Epoch 6/10\n",
      "1000/1000 [==============================] - 52s 52ms/step - loss: 0.3024 - acc: 0.8730\n",
      "Epoch 7/10\n",
      "1000/1000 [==============================] - 53s 53ms/step - loss: 0.2850 - acc: 0.8890\n",
      "Epoch 8/10\n",
      "1000/1000 [==============================] - 53s 53ms/step - loss: 0.2778 - acc: 0.8830\n",
      "Epoch 9/10\n",
      "1000/1000 [==============================] - 52s 52ms/step - loss: 0.2532 - acc: 0.8910\n",
      "Epoch 10/10\n",
      "1000/1000 [==============================] - 53s 53ms/step - loss: 0.2426 - acc: 0.8990\n",
      "Training on Epoch  0 batch  5  Files [5] start  120 / 459\n",
      "Epoch 1/10\n",
      "1000/1000 [==============================] - 48s 48ms/step - loss: 0.3534 - acc: 0.8460\n",
      "Epoch 2/10\n",
      "1000/1000 [==============================] - 49s 49ms/step - loss: 0.3286 - acc: 0.8570\n",
      "Epoch 3/10\n",
      "1000/1000 [==============================] - 49s 49ms/step - loss: 0.3018 - acc: 0.8740\n",
      "Epoch 4/10\n",
      "1000/1000 [==============================] - 50s 50ms/step - loss: 0.2880 - acc: 0.8800\n",
      "Epoch 5/10\n",
      "1000/1000 [==============================] - 49s 49ms/step - loss: 0.2771 - acc: 0.8890\n",
      "Epoch 6/10\n",
      "1000/1000 [==============================] - 49s 49ms/step - loss: 0.2619 - acc: 0.8790\n",
      "Epoch 7/10\n",
      "1000/1000 [==============================] - 49s 49ms/step - loss: 0.2438 - acc: 0.8980\n",
      "Epoch 8/10\n",
      "1000/1000 [==============================] - 50s 50ms/step - loss: 0.2360 - acc: 0.8980\n",
      "Epoch 9/10\n",
      "1000/1000 [==============================] - 54s 54ms/step - loss: 0.2203 - acc: 0.9060\n",
      "Epoch 10/10\n",
      "1000/1000 [==============================] - 54s 54ms/step - loss: 0.2141 - acc: 0.9040\n",
      "Training on Epoch  0 batch  5  Files [5] start  125 / 459\n",
      "Epoch 1/10\n",
      "1000/1000 [==============================] - 54s 54ms/step - loss: 0.4595 - acc: 0.8310\n",
      "Epoch 2/10\n",
      "1000/1000 [==============================] - 55s 55ms/step - loss: 0.3813 - acc: 0.8420\n",
      "Epoch 3/10\n",
      "1000/1000 [==============================] - 56s 56ms/step - loss: 0.3426 - acc: 0.8470\n",
      "Epoch 4/10\n",
      "1000/1000 [==============================] - 56s 56ms/step - loss: 0.3250 - acc: 0.8600\n",
      "Epoch 5/10\n",
      "1000/1000 [==============================] - 56s 56ms/step - loss: 0.3081 - acc: 0.8640\n",
      "Epoch 6/10\n",
      "1000/1000 [==============================] - 56s 56ms/step - loss: 0.2921 - acc: 0.8680\n",
      "Epoch 7/10\n",
      "1000/1000 [==============================] - 56s 56ms/step - loss: 0.2816 - acc: 0.8780\n",
      "Epoch 8/10\n",
      "1000/1000 [==============================] - 56s 56ms/step - loss: 0.2702 - acc: 0.8890\n",
      "Epoch 9/10\n",
      "1000/1000 [==============================] - 56s 56ms/step - loss: 0.2587 - acc: 0.8890\n",
      "Epoch 10/10\n",
      "1000/1000 [==============================] - 56s 56ms/step - loss: 0.2480 - acc: 0.8940\n",
      "Training on Epoch  0 batch  5  Files [5] start  130 / 459\n",
      "Epoch 1/10\n",
      "1000/1000 [==============================] - 51s 51ms/step - loss: 0.4204 - acc: 0.8220\n",
      "Epoch 2/10\n",
      "1000/1000 [==============================] - 54s 54ms/step - loss: 0.3832 - acc: 0.8360\n",
      "Epoch 3/10\n",
      "1000/1000 [==============================] - 54s 54ms/step - loss: 0.3605 - acc: 0.8530\n",
      "Epoch 4/10\n",
      "1000/1000 [==============================] - 54s 54ms/step - loss: 0.3311 - acc: 0.8610\n",
      "Epoch 5/10\n",
      "1000/1000 [==============================] - 54s 54ms/step - loss: 0.3112 - acc: 0.8730\n",
      "Epoch 6/10\n",
      "1000/1000 [==============================] - 54s 54ms/step - loss: 0.2984 - acc: 0.8640\n",
      "Epoch 7/10\n",
      "1000/1000 [==============================] - 53s 53ms/step - loss: 0.3019 - acc: 0.8650\n",
      "Epoch 8/10\n",
      "1000/1000 [==============================] - 54s 54ms/step - loss: 0.2812 - acc: 0.8840\n",
      "Epoch 9/10\n",
      "1000/1000 [==============================] - 54s 54ms/step - loss: 0.2877 - acc: 0.8620\n",
      "Epoch 10/10\n",
      "1000/1000 [==============================] - 54s 54ms/step - loss: 0.2689 - acc: 0.8790\n",
      "Training on Epoch  0 batch  5  Files [5] start  135 / 459\n",
      "Epoch 1/10\n",
      "1000/1000 [==============================] - 51s 51ms/step - loss: 0.4008 - acc: 0.8280\n",
      "Epoch 2/10\n",
      "1000/1000 [==============================] - 53s 53ms/step - loss: 0.3649 - acc: 0.8360\n",
      "Epoch 3/10\n",
      "1000/1000 [==============================] - 53s 53ms/step - loss: 0.3386 - acc: 0.8600\n",
      "Epoch 4/10\n",
      "1000/1000 [==============================] - 52s 52ms/step - loss: 0.3552 - acc: 0.8400\n",
      "Epoch 5/10\n",
      "1000/1000 [==============================] - 53s 53ms/step - loss: 0.3472 - acc: 0.8470\n",
      "Epoch 6/10\n",
      "1000/1000 [==============================] - 52s 52ms/step - loss: 0.3246 - acc: 0.8620\n",
      "Epoch 7/10\n",
      "1000/1000 [==============================] - 53s 53ms/step - loss: 0.3158 - acc: 0.8610\n",
      "Epoch 8/10\n",
      "1000/1000 [==============================] - 53s 53ms/step - loss: 0.2967 - acc: 0.8690\n",
      "Epoch 9/10\n",
      "1000/1000 [==============================] - 53s 53ms/step - loss: 0.2807 - acc: 0.8770\n",
      "Epoch 10/10\n",
      "1000/1000 [==============================] - 53s 53ms/step - loss: 0.2821 - acc: 0.8800\n",
      "Training on Epoch  0 batch  5  Files [5] start  140 / 459\n",
      "Epoch 1/10\n",
      "1000/1000 [==============================] - 51s 51ms/step - loss: 0.3935 - acc: 0.8400\n",
      "Epoch 2/10\n",
      "1000/1000 [==============================] - 54s 54ms/step - loss: 0.3567 - acc: 0.8440\n",
      "Epoch 3/10\n",
      "1000/1000 [==============================] - 53s 53ms/step - loss: 0.3276 - acc: 0.8540\n",
      "Epoch 4/10\n",
      "1000/1000 [==============================] - 54s 54ms/step - loss: 0.2984 - acc: 0.8760\n",
      "Epoch 5/10\n",
      "1000/1000 [==============================] - 54s 54ms/step - loss: 0.2844 - acc: 0.8920\n",
      "Epoch 6/10\n",
      "1000/1000 [==============================] - 53s 53ms/step - loss: 0.2762 - acc: 0.8840\n",
      "Epoch 7/10\n",
      "1000/1000 [==============================] - 54s 54ms/step - loss: 0.2597 - acc: 0.8950\n",
      "Epoch 8/10\n",
      "1000/1000 [==============================] - 54s 54ms/step - loss: 0.2504 - acc: 0.9000\n",
      "Epoch 9/10\n",
      "1000/1000 [==============================] - 54s 54ms/step - loss: 0.2436 - acc: 0.8950\n",
      "Epoch 10/10\n",
      "1000/1000 [==============================] - 54s 54ms/step - loss: 0.2286 - acc: 0.9050\n",
      "Training on Epoch  0 batch  5  Files [5] start  145 / 459\n",
      "Epoch 1/10\n",
      "1000/1000 [==============================] - 43s 43ms/step - loss: 0.3967 - acc: 0.8430\n",
      "Epoch 2/10\n",
      "1000/1000 [==============================] - 44s 44ms/step - loss: 0.3442 - acc: 0.8670\n",
      "Epoch 3/10\n",
      "1000/1000 [==============================] - 44s 44ms/step - loss: 0.2996 - acc: 0.8840\n",
      "Epoch 4/10\n",
      "1000/1000 [==============================] - 44s 44ms/step - loss: 0.2691 - acc: 0.9040\n",
      "Epoch 5/10\n",
      "1000/1000 [==============================] - 44s 44ms/step - loss: 0.2417 - acc: 0.9100\n",
      "Epoch 6/10\n",
      "1000/1000 [==============================] - 44s 44ms/step - loss: 0.2350 - acc: 0.9130\n",
      "Epoch 7/10\n",
      "1000/1000 [==============================] - 44s 44ms/step - loss: 0.2585 - acc: 0.8930\n",
      "Epoch 8/10\n",
      "1000/1000 [==============================] - 44s 44ms/step - loss: 0.2462 - acc: 0.9090\n",
      "Epoch 9/10\n",
      "1000/1000 [==============================] - 44s 44ms/step - loss: 0.2029 - acc: 0.9270\n",
      "Epoch 10/10\n",
      "1000/1000 [==============================] - 44s 44ms/step - loss: 0.1771 - acc: 0.9340\n",
      "Training on Epoch  0 batch  5  Files [5] start  150 / 459\n",
      "Epoch 1/10\n",
      "1000/1000 [==============================] - 56s 56ms/step - loss: 0.4396 - acc: 0.8350\n",
      "Epoch 2/10\n",
      "1000/1000 [==============================] - 57s 57ms/step - loss: 0.4094 - acc: 0.8420\n",
      "Epoch 3/10\n",
      "1000/1000 [==============================] - 57s 57ms/step - loss: 0.3607 - acc: 0.8350\n",
      "Epoch 4/10\n",
      "1000/1000 [==============================] - 57s 57ms/step - loss: 0.3188 - acc: 0.8710\n",
      "Epoch 5/10\n",
      "1000/1000 [==============================] - 57s 57ms/step - loss: 0.3094 - acc: 0.8710\n",
      "Epoch 6/10\n",
      "1000/1000 [==============================] - 58s 58ms/step - loss: 0.2827 - acc: 0.8940\n",
      "Epoch 7/10\n",
      "1000/1000 [==============================] - 57s 57ms/step - loss: 0.2650 - acc: 0.8960\n",
      "Epoch 8/10\n",
      "1000/1000 [==============================] - 58s 58ms/step - loss: 0.2461 - acc: 0.9080\n",
      "Epoch 9/10\n",
      "1000/1000 [==============================] - 58s 58ms/step - loss: 0.2344 - acc: 0.9130\n",
      "Epoch 10/10\n",
      "1000/1000 [==============================] - 58s 58ms/step - loss: 0.2209 - acc: 0.9120\n",
      "Training on Epoch  0 batch  5  Files [5] start  155 / 459\n",
      "Epoch 1/10\n",
      "1000/1000 [==============================] - 53s 53ms/step - loss: 0.2826 - acc: 0.8840\n",
      "Epoch 2/10\n",
      "1000/1000 [==============================] - 52s 52ms/step - loss: 0.2529 - acc: 0.8950\n",
      "Epoch 3/10\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000/1000 [==============================] - 53s 53ms/step - loss: 0.2264 - acc: 0.9060\n",
      "Epoch 4/10\n",
      "1000/1000 [==============================] - 53s 53ms/step - loss: 0.2075 - acc: 0.9170\n",
      "Epoch 5/10\n",
      "1000/1000 [==============================] - 53s 53ms/step - loss: 0.1942 - acc: 0.9210\n",
      "Epoch 6/10\n",
      "1000/1000 [==============================] - 53s 53ms/step - loss: 0.1815 - acc: 0.9290\n",
      "Epoch 7/10\n",
      "1000/1000 [==============================] - 52s 52ms/step - loss: 0.1686 - acc: 0.9370\n",
      "Epoch 8/10\n",
      "1000/1000 [==============================] - 53s 53ms/step - loss: 0.1595 - acc: 0.9400\n",
      "Epoch 9/10\n",
      "1000/1000 [==============================] - 53s 53ms/step - loss: 0.1495 - acc: 0.9450\n",
      "Epoch 10/10\n",
      "1000/1000 [==============================] - 53s 53ms/step - loss: 0.1350 - acc: 0.9520\n",
      "Training on Epoch  0 batch  5  Files [5] start  160 / 459\n",
      "Epoch 1/10\n",
      "1000/1000 [==============================] - 50s 50ms/step - loss: 0.2942 - acc: 0.8820\n",
      "Epoch 2/10\n",
      "1000/1000 [==============================] - 51s 51ms/step - loss: 0.2519 - acc: 0.8950\n",
      "Epoch 3/10\n",
      "1000/1000 [==============================] - 51s 51ms/step - loss: 0.2256 - acc: 0.9030\n",
      "Epoch 4/10\n",
      "1000/1000 [==============================] - 51s 51ms/step - loss: 0.2086 - acc: 0.9090\n",
      "Epoch 5/10\n",
      "1000/1000 [==============================] - 51s 51ms/step - loss: 0.1866 - acc: 0.9250\n",
      "Epoch 6/10\n",
      "1000/1000 [==============================] - 50s 50ms/step - loss: 0.1702 - acc: 0.9380\n",
      "Epoch 7/10\n",
      "1000/1000 [==============================] - 51s 51ms/step - loss: 0.1595 - acc: 0.9390\n",
      "Epoch 8/10\n",
      "1000/1000 [==============================] - 51s 51ms/step - loss: 0.1501 - acc: 0.9460\n",
      "Epoch 9/10\n",
      "1000/1000 [==============================] - 51s 51ms/step - loss: 0.1383 - acc: 0.9550\n",
      "Epoch 10/10\n",
      "1000/1000 [==============================] - 51s 51ms/step - loss: 0.1281 - acc: 0.9550\n",
      "Training on Epoch  0 batch  5  Files [5] start  165 / 459\n",
      "Epoch 1/10\n",
      "1000/1000 [==============================] - 55s 55ms/step - loss: 0.2580 - acc: 0.8870\n",
      "Epoch 2/10\n",
      "1000/1000 [==============================] - 55s 55ms/step - loss: 0.2192 - acc: 0.9080\n",
      "Epoch 3/10\n",
      "1000/1000 [==============================] - 55s 55ms/step - loss: 0.2015 - acc: 0.9080\n",
      "Epoch 4/10\n",
      "1000/1000 [==============================] - 55s 55ms/step - loss: 0.1861 - acc: 0.9190\n",
      "Epoch 5/10\n",
      "1000/1000 [==============================] - 56s 56ms/step - loss: 0.1787 - acc: 0.9230\n",
      "Epoch 6/10\n",
      "1000/1000 [==============================] - 56s 56ms/step - loss: 0.1612 - acc: 0.9280\n",
      "Epoch 7/10\n",
      "1000/1000 [==============================] - 56s 56ms/step - loss: 0.1546 - acc: 0.9400\n",
      "Epoch 8/10\n",
      "1000/1000 [==============================] - 56s 56ms/step - loss: 0.1441 - acc: 0.9420\n",
      "Epoch 9/10\n",
      "1000/1000 [==============================] - 56s 56ms/step - loss: 0.1344 - acc: 0.9430\n",
      "Epoch 10/10\n",
      "1000/1000 [==============================] - 56s 56ms/step - loss: 0.1296 - acc: 0.9430\n",
      "Training on Epoch  0 batch  5  Files [5] start  170 / 459\n",
      "Epoch 1/10\n",
      "1000/1000 [==============================] - 57s 57ms/step - loss: 0.2514 - acc: 0.9060\n",
      "Epoch 2/10\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 0.2089 - acc: 0.9220\n",
      "Epoch 3/10\n",
      "1000/1000 [==============================] - 57s 57ms/step - loss: 0.1886 - acc: 0.9290\n",
      "Epoch 4/10\n",
      "1000/1000 [==============================] - 58s 58ms/step - loss: 0.1717 - acc: 0.9350\n",
      "Epoch 5/10\n",
      "1000/1000 [==============================] - 58s 58ms/step - loss: 0.1543 - acc: 0.9470\n",
      "Epoch 6/10\n",
      "1000/1000 [==============================] - 58s 58ms/step - loss: 0.1516 - acc: 0.9430\n",
      "Epoch 7/10\n",
      "1000/1000 [==============================] - 58s 58ms/step - loss: 0.1461 - acc: 0.9380\n",
      "Epoch 8/10\n",
      "1000/1000 [==============================] - 58s 58ms/step - loss: 0.1312 - acc: 0.9530\n",
      "Epoch 9/10\n",
      "1000/1000 [==============================] - 58s 58ms/step - loss: 0.1232 - acc: 0.9550\n",
      "Epoch 10/10\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 0.1176 - acc: 0.9560\n",
      "Training on Epoch  0 batch  5  Files [5] start  175 / 459\n",
      "Epoch 1/10\n",
      "1000/1000 [==============================] - 57s 57ms/step - loss: 0.2285 - acc: 0.8940\n",
      "Epoch 2/10\n",
      "1000/1000 [==============================] - 57s 57ms/step - loss: 0.1937 - acc: 0.9120\n",
      "Epoch 3/10\n",
      "1000/1000 [==============================] - 57s 57ms/step - loss: 0.1711 - acc: 0.9280\n",
      "Epoch 4/10\n",
      "1000/1000 [==============================] - 57s 57ms/step - loss: 0.1734 - acc: 0.9280\n",
      "Epoch 5/10\n",
      "1000/1000 [==============================] - 57s 57ms/step - loss: 0.1636 - acc: 0.9200\n",
      "Epoch 6/10\n",
      "1000/1000 [==============================] - 57s 57ms/step - loss: 0.1421 - acc: 0.9380\n",
      "Epoch 7/10\n",
      "1000/1000 [==============================] - 57s 57ms/step - loss: 0.1254 - acc: 0.9500\n",
      "Epoch 8/10\n",
      "1000/1000 [==============================] - 53s 53ms/step - loss: 0.1146 - acc: 0.9540\n",
      "Epoch 9/10\n",
      "1000/1000 [==============================] - 51s 51ms/step - loss: 0.1107 - acc: 0.9550\n",
      "Epoch 10/10\n",
      "1000/1000 [==============================] - 52s 52ms/step - loss: 0.1029 - acc: 0.9600\n",
      "Training on Epoch  0 batch  5  Files [5] start  180 / 459\n",
      "Epoch 1/10\n",
      "1000/1000 [==============================] - 50s 50ms/step - loss: 0.1716 - acc: 0.9310\n",
      "Epoch 2/10\n",
      "1000/1000 [==============================] - 51s 51ms/step - loss: 0.1544 - acc: 0.9340\n",
      "Epoch 3/10\n",
      "1000/1000 [==============================] - 50s 50ms/step - loss: 0.1272 - acc: 0.9470\n",
      "Epoch 4/10\n",
      "1000/1000 [==============================] - 51s 51ms/step - loss: 0.1200 - acc: 0.9490\n",
      "Epoch 5/10\n",
      "1000/1000 [==============================] - 51s 51ms/step - loss: 0.1053 - acc: 0.9600\n",
      "Epoch 6/10\n",
      "1000/1000 [==============================] - 51s 51ms/step - loss: 0.0967 - acc: 0.9570\n",
      "Epoch 7/10\n",
      "1000/1000 [==============================] - 51s 51ms/step - loss: 0.0904 - acc: 0.9610\n",
      "Epoch 8/10\n",
      "1000/1000 [==============================] - 51s 51ms/step - loss: 0.0836 - acc: 0.9640\n",
      "Epoch 9/10\n",
      "1000/1000 [==============================] - 51s 51ms/step - loss: 0.0795 - acc: 0.9650\n",
      "Epoch 10/10\n",
      "1000/1000 [==============================] - 51s 51ms/step - loss: 0.0751 - acc: 0.9680\n",
      "Training on Epoch  0 batch  5  Files [5] start  185 / 459\n",
      "Epoch 1/10\n",
      "1000/1000 [==============================] - 53s 53ms/step - loss: 0.2042 - acc: 0.9010\n",
      "Epoch 2/10\n",
      "1000/1000 [==============================] - 53s 53ms/step - loss: 0.1809 - acc: 0.9070\n",
      "Epoch 3/10\n",
      "1000/1000 [==============================] - 53s 53ms/step - loss: 0.1596 - acc: 0.9160\n",
      "Epoch 4/10\n",
      "1000/1000 [==============================] - 53s 53ms/step - loss: 0.1485 - acc: 0.9270\n",
      "Epoch 5/10\n",
      "1000/1000 [==============================] - 53s 53ms/step - loss: 0.1449 - acc: 0.9310\n",
      "Epoch 6/10\n",
      "1000/1000 [==============================] - 53s 53ms/step - loss: 0.1365 - acc: 0.9320\n",
      "Epoch 7/10\n",
      "1000/1000 [==============================] - 53s 53ms/step - loss: 0.1303 - acc: 0.9370\n",
      "Epoch 8/10\n",
      "1000/1000 [==============================] - 53s 53ms/step - loss: 0.1261 - acc: 0.9370\n",
      "Epoch 9/10\n",
      "1000/1000 [==============================] - 53s 53ms/step - loss: 0.1236 - acc: 0.9370\n",
      "Epoch 10/10\n",
      "1000/1000 [==============================] - 53s 53ms/step - loss: 0.1223 - acc: 0.9420\n",
      "Training on Epoch  0 batch  5  Files [5] start  190 / 459\n",
      "Epoch 1/10\n",
      "1000/1000 [==============================] - 47s 47ms/step - loss: 0.2570 - acc: 0.8950\n",
      "Epoch 2/10\n",
      "1000/1000 [==============================] - 47s 47ms/step - loss: 0.2096 - acc: 0.9100\n",
      "Epoch 3/10\n",
      "1000/1000 [==============================] - 47s 47ms/step - loss: 0.1840 - acc: 0.9090\n",
      "Epoch 4/10\n",
      "1000/1000 [==============================] - 48s 48ms/step - loss: 0.1638 - acc: 0.9220\n",
      "Epoch 5/10\n",
      "1000/1000 [==============================] - 47s 47ms/step - loss: 0.1566 - acc: 0.9370\n",
      "Epoch 6/10\n",
      "1000/1000 [==============================] - 48s 48ms/step - loss: 0.1474 - acc: 0.9290\n",
      "Epoch 7/10\n",
      "1000/1000 [==============================] - 48s 48ms/step - loss: 0.1378 - acc: 0.9420\n",
      "Epoch 8/10\n",
      "1000/1000 [==============================] - 48s 48ms/step - loss: 0.1296 - acc: 0.9410\n",
      "Epoch 9/10\n",
      "1000/1000 [==============================] - 48s 48ms/step - loss: 0.1236 - acc: 0.9440\n",
      "Epoch 10/10\n",
      "1000/1000 [==============================] - 48s 48ms/step - loss: 0.1194 - acc: 0.9440\n",
      "Training on Epoch  0 batch  5  Files [5] start  195 / 459\n",
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000/1000 [==============================] - 55s 55ms/step - loss: 0.2790 - acc: 0.8830\n",
      "Epoch 2/10\n",
      "1000/1000 [==============================] - 56s 56ms/step - loss: 0.2399 - acc: 0.8940\n",
      "Epoch 3/10\n",
      "1000/1000 [==============================] - 55s 55ms/step - loss: 0.2188 - acc: 0.8960\n",
      "Epoch 4/10\n",
      "1000/1000 [==============================] - 56s 56ms/step - loss: 0.2128 - acc: 0.9040\n",
      "Epoch 5/10\n",
      "1000/1000 [==============================] - 56s 56ms/step - loss: 0.2043 - acc: 0.8930\n",
      "Epoch 6/10\n",
      "1000/1000 [==============================] - 56s 56ms/step - loss: 0.1815 - acc: 0.9120\n",
      "Epoch 7/10\n",
      "1000/1000 [==============================] - 56s 56ms/step - loss: 0.1762 - acc: 0.9140\n",
      "Epoch 8/10\n",
      "1000/1000 [==============================] - 56s 56ms/step - loss: 0.1656 - acc: 0.9270\n",
      "Epoch 9/10\n",
      "1000/1000 [==============================] - 56s 56ms/step - loss: 0.1601 - acc: 0.9210\n",
      "Epoch 10/10\n",
      "1000/1000 [==============================] - 57s 57ms/step - loss: 0.1525 - acc: 0.9320\n",
      "Training on Epoch  0 batch  5  Files [5] start  200 / 459\n",
      "Epoch 1/10\n",
      "1000/1000 [==============================] - 52s 52ms/step - loss: 0.2927 - acc: 0.8580\n",
      "Epoch 2/10\n",
      "1000/1000 [==============================] - 53s 53ms/step - loss: 0.2532 - acc: 0.8790\n",
      "Epoch 3/10\n",
      "1000/1000 [==============================] - 52s 52ms/step - loss: 0.2234 - acc: 0.8850\n",
      "Epoch 4/10\n",
      "1000/1000 [==============================] - 52s 52ms/step - loss: 0.1984 - acc: 0.9030\n",
      "Epoch 5/10\n",
      "1000/1000 [==============================] - 52s 52ms/step - loss: 0.1824 - acc: 0.9100\n",
      "Epoch 6/10\n",
      "1000/1000 [==============================] - 52s 52ms/step - loss: 0.1711 - acc: 0.9160\n",
      "Epoch 7/10\n",
      "1000/1000 [==============================] - 53s 53ms/step - loss: 0.1589 - acc: 0.9230\n",
      "Epoch 8/10\n",
      "1000/1000 [==============================] - 52s 52ms/step - loss: 0.1519 - acc: 0.9260\n",
      "Epoch 9/10\n",
      "1000/1000 [==============================] - 52s 52ms/step - loss: 0.1452 - acc: 0.9290\n",
      "Epoch 10/10\n",
      "1000/1000 [==============================] - 52s 52ms/step - loss: 0.1370 - acc: 0.9310\n",
      "Training on Epoch  0 batch  5  Files [5] start  205 / 459\n",
      "Epoch 1/10\n",
      "1000/1000 [==============================] - 54s 54ms/step - loss: 0.1957 - acc: 0.9060\n",
      "Epoch 2/10\n",
      "1000/1000 [==============================] - 53s 53ms/step - loss: 0.1792 - acc: 0.9000\n",
      "Epoch 3/10\n",
      "1000/1000 [==============================] - 3901s 4s/step - loss: 0.1629 - acc: 0.9110\n",
      "Epoch 4/10\n",
      "1000/1000 [==============================] - 57s 57ms/step - loss: 0.1560 - acc: 0.9220\n",
      "Epoch 5/10\n",
      "1000/1000 [==============================] - 56s 56ms/step - loss: 0.1445 - acc: 0.9150\n",
      "Epoch 6/10\n",
      "1000/1000 [==============================] - 56s 56ms/step - loss: 0.1389 - acc: 0.9260\n",
      "Epoch 7/10\n",
      "1000/1000 [==============================] - 56s 56ms/step - loss: 0.1359 - acc: 0.9310\n",
      "Epoch 8/10\n",
      "1000/1000 [==============================] - 57s 57ms/step - loss: 0.1321 - acc: 0.9260\n",
      "Epoch 9/10\n",
      "1000/1000 [==============================] - 56s 56ms/step - loss: 0.1287 - acc: 0.9330\n",
      "Epoch 10/10\n",
      "1000/1000 [==============================] - 58s 58ms/step - loss: 0.1212 - acc: 0.9330\n",
      "Training on Epoch  0 batch  5  Files [5] start  210 / 459\n",
      "Epoch 1/10\n",
      "1000/1000 [==============================] - 49s 49ms/step - loss: 0.2390 - acc: 0.9030\n",
      "Epoch 2/10\n",
      "1000/1000 [==============================] - 49s 49ms/step - loss: 0.1841 - acc: 0.9160\n",
      "Epoch 3/10\n",
      "1000/1000 [==============================] - 49s 49ms/step - loss: 0.1498 - acc: 0.9400\n",
      "Epoch 4/10\n",
      "1000/1000 [==============================] - 49s 49ms/step - loss: 0.1303 - acc: 0.9560\n",
      "Epoch 5/10\n",
      "1000/1000 [==============================] - 50s 50ms/step - loss: 0.1127 - acc: 0.9580\n",
      "Epoch 6/10\n",
      "1000/1000 [==============================] - 49s 49ms/step - loss: 0.1024 - acc: 0.9610\n",
      "Epoch 7/10\n",
      "1000/1000 [==============================] - 50s 50ms/step - loss: 0.0948 - acc: 0.9660\n",
      "Epoch 8/10\n",
      "1000/1000 [==============================] - 50s 50ms/step - loss: 0.0855 - acc: 0.9690\n",
      "Epoch 9/10\n",
      "1000/1000 [==============================] - 49s 49ms/step - loss: 0.0771 - acc: 0.9700\n",
      "Epoch 10/10\n",
      "1000/1000 [==============================] - 50s 50ms/step - loss: 0.0712 - acc: 0.9740\n",
      "Training on Epoch  0 batch  5  Files [5] start  215 / 459\n",
      "Epoch 1/10\n",
      "1000/1000 [==============================] - 50s 50ms/step - loss: 0.3124 - acc: 0.8740\n",
      "Epoch 2/10\n",
      "1000/1000 [==============================] - 51s 51ms/step - loss: 0.2369 - acc: 0.8980\n",
      "Epoch 3/10\n",
      "1000/1000 [==============================] - 51s 51ms/step - loss: 0.2093 - acc: 0.9100\n",
      "Epoch 4/10\n",
      "1000/1000 [==============================] - 50s 50ms/step - loss: 0.1981 - acc: 0.9150\n",
      "Epoch 5/10\n",
      "1000/1000 [==============================] - 51s 51ms/step - loss: 0.1939 - acc: 0.9130\n",
      "Epoch 6/10\n",
      "1000/1000 [==============================] - 51s 51ms/step - loss: 0.1921 - acc: 0.9190\n",
      "Epoch 7/10\n",
      "1000/1000 [==============================] - 51s 51ms/step - loss: 0.1823 - acc: 0.9220\n",
      "Epoch 8/10\n",
      "1000/1000 [==============================] - 52s 52ms/step - loss: 0.1732 - acc: 0.9210\n",
      "Epoch 9/10\n",
      "1000/1000 [==============================] - 51s 51ms/step - loss: 0.1643 - acc: 0.9280\n",
      "Epoch 10/10\n",
      "1000/1000 [==============================] - 51s 51ms/step - loss: 0.1584 - acc: 0.9270\n",
      "Training on Epoch  0 batch  5  Files [5] start  220 / 459\n",
      "Epoch 1/10\n",
      "1000/1000 [==============================] - 51s 51ms/step - loss: 0.3093 - acc: 0.8800\n",
      "Epoch 2/10\n",
      "1000/1000 [==============================] - 50s 50ms/step - loss: 0.2725 - acc: 0.8920\n",
      "Epoch 3/10\n",
      "1000/1000 [==============================] - 51s 51ms/step - loss: 0.2412 - acc: 0.9050\n",
      "Epoch 4/10\n",
      "1000/1000 [==============================] - 49s 49ms/step - loss: 0.2222 - acc: 0.9020\n",
      "Epoch 5/10\n",
      "1000/1000 [==============================] - 50s 50ms/step - loss: 0.2055 - acc: 0.9130\n",
      "Epoch 6/10\n",
      "1000/1000 [==============================] - 51s 51ms/step - loss: 0.1885 - acc: 0.9210\n",
      "Epoch 7/10\n",
      "1000/1000 [==============================] - 51s 51ms/step - loss: 0.1754 - acc: 0.9270\n",
      "Epoch 8/10\n",
      "1000/1000 [==============================] - 51s 51ms/step - loss: 0.1652 - acc: 0.9360\n",
      "Epoch 9/10\n",
      "1000/1000 [==============================] - 50s 50ms/step - loss: 0.1593 - acc: 0.9360\n",
      "Epoch 10/10\n",
      "1000/1000 [==============================] - 51s 51ms/step - loss: 0.1588 - acc: 0.9360\n",
      "Training on Epoch  0 batch  5  Files [5] start  225 / 459\n",
      "Epoch 1/10\n",
      "1000/1000 [==============================] - 55s 55ms/step - loss: 0.1899 - acc: 0.9200\n",
      "Epoch 2/10\n",
      "1000/1000 [==============================] - 55s 55ms/step - loss: 0.1711 - acc: 0.9250\n",
      "Epoch 3/10\n",
      "1000/1000 [==============================] - 56s 56ms/step - loss: 0.1493 - acc: 0.9310\n",
      "Epoch 4/10\n",
      "1000/1000 [==============================] - 58s 58ms/step - loss: 0.1376 - acc: 0.9380\n",
      "Epoch 5/10\n",
      "1000/1000 [==============================] - 56s 56ms/step - loss: 0.1263 - acc: 0.9390\n",
      "Epoch 6/10\n",
      "1000/1000 [==============================] - 56s 56ms/step - loss: 0.1169 - acc: 0.9450\n",
      "Epoch 7/10\n",
      "1000/1000 [==============================] - 57s 57ms/step - loss: 0.1022 - acc: 0.9530\n",
      "Epoch 8/10\n",
      "1000/1000 [==============================] - 57s 57ms/step - loss: 0.0956 - acc: 0.9590\n",
      "Epoch 9/10\n",
      "1000/1000 [==============================] - 57s 57ms/step - loss: 0.1041 - acc: 0.9560\n",
      "Epoch 10/10\n",
      "1000/1000 [==============================] - 57s 57ms/step - loss: 0.0978 - acc: 0.9580\n",
      "Training on Epoch  0 batch  5  Files [5] start  230 / 459\n",
      "Epoch 1/10\n",
      "1000/1000 [==============================] - 52s 52ms/step - loss: 0.1786 - acc: 0.9200\n",
      "Epoch 2/10\n",
      "1000/1000 [==============================] - 49s 49ms/step - loss: 0.1434 - acc: 0.9370\n",
      "Epoch 3/10\n",
      "1000/1000 [==============================] - 50s 50ms/step - loss: 0.1126 - acc: 0.9420\n",
      "Epoch 4/10\n",
      "1000/1000 [==============================] - 49s 49ms/step - loss: 0.1134 - acc: 0.9460\n",
      "Epoch 5/10\n",
      "1000/1000 [==============================] - 50s 50ms/step - loss: 0.1024 - acc: 0.9580\n",
      "Epoch 6/10\n",
      "1000/1000 [==============================] - 49s 49ms/step - loss: 0.0977 - acc: 0.9550\n",
      "Epoch 7/10\n",
      "1000/1000 [==============================] - 50s 50ms/step - loss: 0.0933 - acc: 0.9550\n",
      "Epoch 8/10\n",
      "1000/1000 [==============================] - 50s 50ms/step - loss: 0.0893 - acc: 0.9620\n",
      "Epoch 9/10\n",
      "1000/1000 [==============================] - 49s 49ms/step - loss: 0.0867 - acc: 0.9630\n",
      "Epoch 10/10\n",
      "1000/1000 [==============================] - 50s 50ms/step - loss: 0.0828 - acc: 0.9630\n",
      "Training on Epoch  0 batch  5  Files [5] start  235 / 459\n",
      "Epoch 1/10\n",
      "1000/1000 [==============================] - 48s 48ms/step - loss: 0.1639 - acc: 0.9200\n",
      "Epoch 2/10\n",
      "1000/1000 [==============================] - 49s 49ms/step - loss: 0.1403 - acc: 0.9240\n",
      "Epoch 3/10\n",
      "1000/1000 [==============================] - 48s 48ms/step - loss: 0.1237 - acc: 0.9370\n",
      "Epoch 4/10\n",
      "1000/1000 [==============================] - 49s 49ms/step - loss: 0.1139 - acc: 0.9490\n",
      "Epoch 5/10\n",
      "1000/1000 [==============================] - 48s 48ms/step - loss: 0.1055 - acc: 0.9490\n",
      "Epoch 6/10\n",
      "1000/1000 [==============================] - 49s 49ms/step - loss: 0.0976 - acc: 0.9520\n",
      "Epoch 7/10\n",
      "1000/1000 [==============================] - 49s 49ms/step - loss: 0.0905 - acc: 0.9530\n",
      "Epoch 8/10\n",
      "1000/1000 [==============================] - 48s 48ms/step - loss: 0.0832 - acc: 0.9540\n",
      "Epoch 9/10\n",
      "1000/1000 [==============================] - 48s 48ms/step - loss: 0.0791 - acc: 0.9590\n",
      "Epoch 10/10\n",
      "1000/1000 [==============================] - 49s 49ms/step - loss: 0.0737 - acc: 0.9650\n",
      "Training on Epoch  0 batch  5  Files [5] start  240 / 459\n",
      "Epoch 1/10\n",
      "1000/1000 [==============================] - 48s 48ms/step - loss: 0.1274 - acc: 0.9420\n",
      "Epoch 2/10\n",
      "1000/1000 [==============================] - 49s 49ms/step - loss: 0.1065 - acc: 0.9520\n",
      "Epoch 3/10\n",
      "1000/1000 [==============================] - 49s 49ms/step - loss: 0.0921 - acc: 0.9590\n",
      "Epoch 4/10\n",
      "1000/1000 [==============================] - 49s 49ms/step - loss: 0.0792 - acc: 0.9640\n",
      "Epoch 5/10\n",
      "1000/1000 [==============================] - 49s 49ms/step - loss: 0.0729 - acc: 0.9650\n",
      "Epoch 6/10\n",
      "1000/1000 [==============================] - 48s 48ms/step - loss: 0.0662 - acc: 0.9680\n",
      "Epoch 7/10\n",
      "1000/1000 [==============================] - 48s 48ms/step - loss: 0.0628 - acc: 0.9690\n",
      "Epoch 8/10\n",
      "1000/1000 [==============================] - 48s 48ms/step - loss: 0.0588 - acc: 0.9710\n",
      "Epoch 9/10\n",
      "1000/1000 [==============================] - 48s 48ms/step - loss: 0.0554 - acc: 0.9760\n",
      "Epoch 10/10\n",
      "1000/1000 [==============================] - 48s 48ms/step - loss: 0.0517 - acc: 0.9770\n",
      "Training on Epoch  0 batch  5  Files [5] start  245 / 459\n",
      "Epoch 1/10\n",
      "1000/1000 [==============================] - 53s 53ms/step - loss: 0.2673 - acc: 0.9130\n",
      "Epoch 2/10\n",
      "1000/1000 [==============================] - 53s 53ms/step - loss: 0.2081 - acc: 0.9170\n",
      "Epoch 3/10\n",
      "1000/1000 [==============================] - 51s 51ms/step - loss: 0.1641 - acc: 0.9260\n",
      "Epoch 4/10\n",
      "1000/1000 [==============================] - 50s 50ms/step - loss: 0.1494 - acc: 0.9320\n",
      "Epoch 5/10\n",
      "1000/1000 [==============================] - 50s 50ms/step - loss: 0.1340 - acc: 0.9400\n",
      "Epoch 6/10\n",
      "1000/1000 [==============================] - 50s 50ms/step - loss: 0.1205 - acc: 0.9490\n",
      "Epoch 7/10\n",
      "1000/1000 [==============================] - 50s 50ms/step - loss: 0.1130 - acc: 0.9480\n",
      "Epoch 8/10\n",
      "1000/1000 [==============================] - 50s 50ms/step - loss: 0.1056 - acc: 0.9490\n",
      "Epoch 9/10\n",
      "1000/1000 [==============================] - 50s 50ms/step - loss: 0.1004 - acc: 0.9530\n",
      "Epoch 10/10\n",
      "1000/1000 [==============================] - 50s 50ms/step - loss: 0.0943 - acc: 0.9580\n",
      "Training on Epoch  0 batch  5  Files [5] start  250 / 459\n",
      "Epoch 1/10\n",
      "1000/1000 [==============================] - 54s 54ms/step - loss: 0.2128 - acc: 0.9020\n",
      "Epoch 2/10\n",
      "1000/1000 [==============================] - 55s 55ms/step - loss: 0.1807 - acc: 0.9190\n",
      "Epoch 3/10\n",
      "1000/1000 [==============================] - 55s 55ms/step - loss: 0.1574 - acc: 0.9280\n",
      "Epoch 4/10\n",
      "1000/1000 [==============================] - 55s 55ms/step - loss: 0.1453 - acc: 0.9300\n",
      "Epoch 5/10\n",
      "1000/1000 [==============================] - 56s 56ms/step - loss: 0.1359 - acc: 0.9340\n",
      "Epoch 6/10\n",
      "1000/1000 [==============================] - 55s 55ms/step - loss: 0.1266 - acc: 0.9400\n",
      "Epoch 7/10\n",
      "1000/1000 [==============================] - 55s 55ms/step - loss: 0.1202 - acc: 0.9420\n",
      "Epoch 8/10\n",
      "1000/1000 [==============================] - 55s 55ms/step - loss: 0.1143 - acc: 0.9490\n",
      "Epoch 9/10\n",
      "1000/1000 [==============================] - 55s 55ms/step - loss: 0.1133 - acc: 0.9410\n",
      "Epoch 10/10\n",
      "1000/1000 [==============================] - 55s 55ms/step - loss: 0.1105 - acc: 0.9460\n",
      "Training on Epoch  0 batch  5  Files [5] start  255 / 459\n",
      "Epoch 1/10\n",
      "1000/1000 [==============================] - 53s 53ms/step - loss: 0.1805 - acc: 0.9170\n",
      "Epoch 2/10\n",
      "1000/1000 [==============================] - 52s 52ms/step - loss: 0.1512 - acc: 0.9280\n",
      "Epoch 3/10\n",
      "1000/1000 [==============================] - 53s 53ms/step - loss: 0.1384 - acc: 0.9340\n",
      "Epoch 4/10\n",
      "1000/1000 [==============================] - 52s 52ms/step - loss: 0.1212 - acc: 0.9410\n",
      "Epoch 5/10\n",
      "1000/1000 [==============================] - 52s 52ms/step - loss: 0.1126 - acc: 0.9470\n",
      "Epoch 6/10\n",
      "1000/1000 [==============================] - 52s 52ms/step - loss: 0.1093 - acc: 0.9420\n",
      "Epoch 7/10\n",
      "1000/1000 [==============================] - 53s 53ms/step - loss: 0.1002 - acc: 0.9510\n",
      "Epoch 8/10\n",
      "1000/1000 [==============================] - 53s 53ms/step - loss: 0.0931 - acc: 0.9530\n",
      "Epoch 9/10\n",
      "1000/1000 [==============================] - 52s 52ms/step - loss: 0.0899 - acc: 0.9600\n",
      "Epoch 10/10\n",
      "1000/1000 [==============================] - 52s 52ms/step - loss: 0.0878 - acc: 0.9540\n",
      "Training on Epoch  0 batch  5  Files [5] start  260 / 459\n",
      "Epoch 1/10\n",
      "1000/1000 [==============================] - 56s 56ms/step - loss: 0.2564 - acc: 0.8900\n",
      "Epoch 2/10\n",
      "1000/1000 [==============================] - 57s 57ms/step - loss: 0.2022 - acc: 0.9190\n",
      "Epoch 3/10\n",
      "1000/1000 [==============================] - 56s 56ms/step - loss: 0.1645 - acc: 0.9270\n",
      "Epoch 4/10\n",
      "1000/1000 [==============================] - 57s 57ms/step - loss: 0.1450 - acc: 0.9330\n",
      "Epoch 5/10\n",
      "1000/1000 [==============================] - 57s 57ms/step - loss: 0.1363 - acc: 0.9450\n",
      "Epoch 6/10\n",
      "1000/1000 [==============================] - 58s 58ms/step - loss: 0.1281 - acc: 0.9460\n",
      "Epoch 7/10\n",
      "1000/1000 [==============================] - 57s 57ms/step - loss: 0.1208 - acc: 0.9520\n",
      "Epoch 8/10\n",
      "1000/1000 [==============================] - 58s 58ms/step - loss: 0.1153 - acc: 0.9510\n",
      "Epoch 9/10\n",
      "1000/1000 [==============================] - 58s 58ms/step - loss: 0.1107 - acc: 0.9550\n",
      "Epoch 10/10\n",
      "1000/1000 [==============================] - 58s 58ms/step - loss: 0.1045 - acc: 0.9550\n",
      "Training on Epoch  0 batch  5  Files [5] start  265 / 459\n",
      "Epoch 1/10\n",
      "1000/1000 [==============================] - 53s 53ms/step - loss: 0.2481 - acc: 0.8890\n",
      "Epoch 2/10\n",
      "1000/1000 [==============================] - 54s 54ms/step - loss: 0.1967 - acc: 0.9120\n",
      "Epoch 3/10\n",
      "1000/1000 [==============================] - 55s 55ms/step - loss: 0.1569 - acc: 0.9320\n",
      "Epoch 4/10\n",
      "1000/1000 [==============================] - 55s 55ms/step - loss: 0.1432 - acc: 0.9390\n",
      "Epoch 5/10\n",
      "1000/1000 [==============================] - 56s 56ms/step - loss: 0.1222 - acc: 0.9490\n",
      "Epoch 6/10\n",
      "1000/1000 [==============================] - 55s 55ms/step - loss: 0.1098 - acc: 0.9550\n",
      "Epoch 7/10\n",
      "1000/1000 [==============================] - 55s 55ms/step - loss: 0.1019 - acc: 0.9600\n",
      "Epoch 8/10\n",
      "1000/1000 [==============================] - 54s 54ms/step - loss: 0.0915 - acc: 0.9650\n",
      "Epoch 9/10\n",
      "1000/1000 [==============================] - 55s 55ms/step - loss: 0.0849 - acc: 0.9660\n",
      "Epoch 10/10\n",
      "1000/1000 [==============================] - 54s 54ms/step - loss: 0.0779 - acc: 0.9680\n",
      "Training on Epoch  0 batch  5  Files [5] start  270 / 459\n",
      "Epoch 1/10\n",
      "1000/1000 [==============================] - 62s 62ms/step - loss: 0.2058 - acc: 0.9090\n",
      "Epoch 2/10\n",
      "1000/1000 [==============================] - 63s 63ms/step - loss: 0.1781 - acc: 0.9210\n",
      "Epoch 3/10\n",
      "1000/1000 [==============================] - 63s 63ms/step - loss: 0.1537 - acc: 0.9290\n",
      "Epoch 4/10\n",
      "1000/1000 [==============================] - 63s 63ms/step - loss: 0.1408 - acc: 0.9310\n",
      "Epoch 5/10\n",
      "1000/1000 [==============================] - 62s 62ms/step - loss: 0.1333 - acc: 0.9340\n",
      "Epoch 6/10\n",
      "1000/1000 [==============================] - 62s 62ms/step - loss: 0.1240 - acc: 0.9390\n",
      "Epoch 7/10\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000/1000 [==============================] - 62s 62ms/step - loss: 0.1170 - acc: 0.9470\n",
      "Epoch 8/10\n",
      "1000/1000 [==============================] - 62s 62ms/step - loss: 0.1153 - acc: 0.9430\n",
      "Epoch 9/10\n",
      "1000/1000 [==============================] - 63s 63ms/step - loss: 0.1131 - acc: 0.9470\n",
      "Epoch 10/10\n",
      "1000/1000 [==============================] - 62s 62ms/step - loss: 0.1068 - acc: 0.9500\n",
      "Training on Epoch  0 batch  5  Files [5] start  275 / 459\n",
      "Epoch 1/10\n",
      "1000/1000 [==============================] - 54s 54ms/step - loss: 0.2098 - acc: 0.9190\n",
      "Epoch 2/10\n",
      "1000/1000 [==============================] - 55s 55ms/step - loss: 0.1659 - acc: 0.9390\n",
      "Epoch 3/10\n",
      "1000/1000 [==============================] - 55s 55ms/step - loss: 0.1662 - acc: 0.9270\n",
      "Epoch 4/10\n",
      "1000/1000 [==============================] - 55s 55ms/step - loss: 0.1370 - acc: 0.9390\n",
      "Epoch 5/10\n",
      "1000/1000 [==============================] - 55s 55ms/step - loss: 0.1368 - acc: 0.9490\n",
      "Epoch 6/10\n",
      "1000/1000 [==============================] - 55s 55ms/step - loss: 0.1240 - acc: 0.9520\n",
      "Epoch 7/10\n",
      "1000/1000 [==============================] - 55s 55ms/step - loss: 0.1154 - acc: 0.9500\n",
      "Epoch 8/10\n",
      "1000/1000 [==============================] - 55s 55ms/step - loss: 0.1030 - acc: 0.9540\n",
      "Epoch 9/10\n",
      "1000/1000 [==============================] - 56s 56ms/step - loss: 0.0930 - acc: 0.9630\n",
      "Epoch 10/10\n",
      "1000/1000 [==============================] - 55s 55ms/step - loss: 0.0863 - acc: 0.9670\n",
      "Training on Epoch  0 batch  5  Files [5] start  280 / 459\n",
      "Epoch 1/10\n",
      "1000/1000 [==============================] - 49s 49ms/step - loss: 0.1938 - acc: 0.9170\n",
      "Epoch 2/10\n",
      "1000/1000 [==============================] - 49s 49ms/step - loss: 0.1669 - acc: 0.9300\n",
      "Epoch 3/10\n",
      "1000/1000 [==============================] - 49s 49ms/step - loss: 0.1492 - acc: 0.9300\n",
      "Epoch 4/10\n",
      "1000/1000 [==============================] - 49s 49ms/step - loss: 0.1224 - acc: 0.9530\n",
      "Epoch 5/10\n",
      "1000/1000 [==============================] - 49s 49ms/step - loss: 0.1158 - acc: 0.9460\n",
      "Epoch 6/10\n",
      "1000/1000 [==============================] - 50s 50ms/step - loss: 0.1081 - acc: 0.9470\n",
      "Epoch 7/10\n",
      "1000/1000 [==============================] - 49s 49ms/step - loss: 0.0982 - acc: 0.9580\n",
      "Epoch 8/10\n",
      "1000/1000 [==============================] - 49s 49ms/step - loss: 0.0912 - acc: 0.9570\n",
      "Epoch 9/10\n",
      "1000/1000 [==============================] - 49s 49ms/step - loss: 0.0860 - acc: 0.9580\n",
      "Epoch 10/10\n",
      "1000/1000 [==============================] - 49s 49ms/step - loss: 0.0827 - acc: 0.9610\n",
      "Training on Epoch  0 batch  5  Files [5] start  285 / 459\n",
      "Epoch 1/10\n",
      "1000/1000 [==============================] - 51s 51ms/step - loss: 0.2263 - acc: 0.8980\n",
      "Epoch 2/10\n",
      "1000/1000 [==============================] - 51s 51ms/step - loss: 0.1870 - acc: 0.9020\n",
      "Epoch 3/10\n",
      "1000/1000 [==============================] - 51s 51ms/step - loss: 0.1644 - acc: 0.9190\n",
      "Epoch 4/10\n",
      "1000/1000 [==============================] - 51s 51ms/step - loss: 0.1511 - acc: 0.9250\n",
      "Epoch 5/10\n",
      "1000/1000 [==============================] - 51s 51ms/step - loss: 0.1425 - acc: 0.9330\n",
      "Epoch 6/10\n",
      "1000/1000 [==============================] - 52s 52ms/step - loss: 0.1347 - acc: 0.9340\n",
      "Epoch 7/10\n",
      "1000/1000 [==============================] - 51s 51ms/step - loss: 0.1286 - acc: 0.9340\n",
      "Epoch 8/10\n",
      "1000/1000 [==============================] - 52s 52ms/step - loss: 0.1230 - acc: 0.9370\n",
      "Epoch 9/10\n",
      "1000/1000 [==============================] - 52s 52ms/step - loss: 0.1183 - acc: 0.9410\n",
      "Epoch 10/10\n",
      "1000/1000 [==============================] - 52s 52ms/step - loss: 0.1143 - acc: 0.9420\n",
      "Training on Epoch  0 batch  5  Files [5] start  290 / 459\n",
      "Epoch 1/10\n",
      "1000/1000 [==============================] - 53s 53ms/step - loss: 0.2612 - acc: 0.8930\n",
      "Epoch 2/10\n",
      "1000/1000 [==============================] - 54s 54ms/step - loss: 0.2190 - acc: 0.9010\n",
      "Epoch 3/10\n",
      "1000/1000 [==============================] - 53s 53ms/step - loss: 0.1952 - acc: 0.9100\n",
      "Epoch 4/10\n",
      "1000/1000 [==============================] - 53s 53ms/step - loss: 0.1939 - acc: 0.9100\n",
      "Epoch 5/10\n",
      "1000/1000 [==============================] - 53s 53ms/step - loss: 0.1876 - acc: 0.9100\n",
      "Epoch 6/10\n",
      "1000/1000 [==============================] - 53s 53ms/step - loss: 0.1611 - acc: 0.9240\n",
      "Epoch 7/10\n",
      "1000/1000 [==============================] - 53s 53ms/step - loss: 0.1500 - acc: 0.9360\n",
      "Epoch 8/10\n",
      "1000/1000 [==============================] - 53s 53ms/step - loss: 0.1405 - acc: 0.9390\n",
      "Epoch 9/10\n",
      "1000/1000 [==============================] - 53s 53ms/step - loss: 0.1292 - acc: 0.9450\n",
      "Epoch 10/10\n",
      "1000/1000 [==============================] - 53s 53ms/step - loss: 0.1229 - acc: 0.9430\n",
      "Training on Epoch  0 batch  5  Files [5] start  295 / 459\n",
      "Epoch 1/10\n",
      "1000/1000 [==============================] - 50s 50ms/step - loss: 0.1480 - acc: 0.9370\n",
      "Epoch 2/10\n",
      "1000/1000 [==============================] - 50s 50ms/step - loss: 0.1108 - acc: 0.9560\n",
      "Epoch 3/10\n",
      "1000/1000 [==============================] - 50s 50ms/step - loss: 0.0997 - acc: 0.9560\n",
      "Epoch 4/10\n",
      "1000/1000 [==============================] - 50s 50ms/step - loss: 0.0924 - acc: 0.9610\n",
      "Epoch 5/10\n",
      "1000/1000 [==============================] - 51s 51ms/step - loss: 0.0844 - acc: 0.9630\n",
      "Epoch 6/10\n",
      "1000/1000 [==============================] - 50s 50ms/step - loss: 0.0762 - acc: 0.9680\n",
      "Epoch 7/10\n",
      "1000/1000 [==============================] - 50s 50ms/step - loss: 0.0689 - acc: 0.9670\n",
      "Epoch 8/10\n",
      "1000/1000 [==============================] - 50s 50ms/step - loss: 0.0657 - acc: 0.9750\n",
      "Epoch 9/10\n",
      "1000/1000 [==============================] - 51s 51ms/step - loss: 0.0657 - acc: 0.9700\n",
      "Epoch 10/10\n",
      "1000/1000 [==============================] - 50s 50ms/step - loss: 0.0617 - acc: 0.9760\n",
      "Training on Epoch  0 batch  5  Files [5] start  300 / 459\n",
      "Epoch 1/10\n",
      "1000/1000 [==============================] - 50s 50ms/step - loss: 0.3124 - acc: 0.8820\n",
      "Epoch 2/10\n",
      "1000/1000 [==============================] - 50s 50ms/step - loss: 0.2275 - acc: 0.9060\n",
      "Epoch 3/10\n",
      "1000/1000 [==============================] - 51s 51ms/step - loss: 0.2034 - acc: 0.9140\n",
      "Epoch 4/10\n",
      "1000/1000 [==============================] - 50s 50ms/step - loss: 0.2001 - acc: 0.9150\n",
      "Epoch 5/10\n",
      "1000/1000 [==============================] - 51s 51ms/step - loss: 0.1952 - acc: 0.9170\n",
      "Epoch 6/10\n",
      "1000/1000 [==============================] - 50s 50ms/step - loss: 0.1784 - acc: 0.9240\n",
      "Epoch 7/10\n",
      "1000/1000 [==============================] - 50s 50ms/step - loss: 0.1725 - acc: 0.9240\n",
      "Epoch 8/10\n",
      "1000/1000 [==============================] - 50s 50ms/step - loss: 0.1613 - acc: 0.9290\n",
      "Epoch 9/10\n",
      "1000/1000 [==============================] - 50s 50ms/step - loss: 0.1477 - acc: 0.9410\n",
      "Epoch 10/10\n",
      "1000/1000 [==============================] - 51s 51ms/step - loss: 0.1328 - acc: 0.9450\n",
      "Training on Epoch  0 batch  5  Files [5] start  305 / 459\n",
      "Epoch 1/10\n",
      "1000/1000 [==============================] - 52s 52ms/step - loss: 0.1685 - acc: 0.9190\n",
      "Epoch 2/10\n",
      "1000/1000 [==============================] - 52s 52ms/step - loss: 0.1376 - acc: 0.9360\n",
      "Epoch 3/10\n",
      "1000/1000 [==============================] - 52s 52ms/step - loss: 0.1201 - acc: 0.9520\n",
      "Epoch 4/10\n",
      "1000/1000 [==============================] - 52s 52ms/step - loss: 0.1079 - acc: 0.9540\n",
      "Epoch 5/10\n",
      "1000/1000 [==============================] - 52s 52ms/step - loss: 0.0986 - acc: 0.9580\n",
      "Epoch 6/10\n",
      "1000/1000 [==============================] - 52s 52ms/step - loss: 0.0891 - acc: 0.9600\n",
      "Epoch 7/10\n",
      "1000/1000 [==============================] - 53s 53ms/step - loss: 0.0843 - acc: 0.9590\n",
      "Epoch 8/10\n",
      "1000/1000 [==============================] - 53s 53ms/step - loss: 0.0778 - acc: 0.9620\n",
      "Epoch 9/10\n",
      "1000/1000 [==============================] - 52s 52ms/step - loss: 0.0730 - acc: 0.9610\n",
      "Epoch 10/10\n",
      "1000/1000 [==============================] - 52s 52ms/step - loss: 0.0699 - acc: 0.9700\n",
      "Training on Epoch  0 batch  5  Files [5] start  310 / 459\n",
      "Epoch 1/10\n",
      "1000/1000 [==============================] - 51s 51ms/step - loss: 0.2405 - acc: 0.9070\n",
      "Epoch 2/10\n",
      "1000/1000 [==============================] - 51s 51ms/step - loss: 0.1916 - acc: 0.9220\n",
      "Epoch 3/10\n",
      "1000/1000 [==============================] - 51s 51ms/step - loss: 0.1716 - acc: 0.9200\n",
      "Epoch 4/10\n",
      "1000/1000 [==============================] - 51s 51ms/step - loss: 0.1553 - acc: 0.9340\n",
      "Epoch 5/10\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000/1000 [==============================] - 52s 52ms/step - loss: 0.1379 - acc: 0.9400\n",
      "Epoch 6/10\n",
      "1000/1000 [==============================] - 51s 51ms/step - loss: 0.1308 - acc: 0.9380\n",
      "Epoch 7/10\n",
      "1000/1000 [==============================] - 52s 52ms/step - loss: 0.1244 - acc: 0.9470\n",
      "Epoch 8/10\n",
      "1000/1000 [==============================] - 51s 51ms/step - loss: 0.1175 - acc: 0.9480\n",
      "Epoch 9/10\n",
      "1000/1000 [==============================] - 51s 51ms/step - loss: 0.1103 - acc: 0.9540\n",
      "Epoch 10/10\n",
      "1000/1000 [==============================] - 51s 51ms/step - loss: 0.1042 - acc: 0.9560\n",
      "Training on Epoch  0 batch  5  Files [5] start  315 / 459\n",
      "Epoch 1/10\n",
      "1000/1000 [==============================] - 53s 53ms/step - loss: 0.1968 - acc: 0.9120\n",
      "Epoch 2/10\n",
      "1000/1000 [==============================] - 54s 54ms/step - loss: 0.1615 - acc: 0.9220\n",
      "Epoch 3/10\n",
      "1000/1000 [==============================] - 54s 54ms/step - loss: 0.1298 - acc: 0.9350\n",
      "Epoch 4/10\n",
      "1000/1000 [==============================] - 53s 53ms/step - loss: 0.1214 - acc: 0.9400\n",
      "Epoch 5/10\n",
      "1000/1000 [==============================] - 54s 54ms/step - loss: 0.1136 - acc: 0.9440\n",
      "Epoch 6/10\n",
      "1000/1000 [==============================] - 53s 53ms/step - loss: 0.1080 - acc: 0.9460\n",
      "Epoch 7/10\n",
      "1000/1000 [==============================] - 54s 54ms/step - loss: 0.1043 - acc: 0.9410\n",
      "Epoch 8/10\n",
      "1000/1000 [==============================] - 53s 53ms/step - loss: 0.1006 - acc: 0.9460\n",
      "Epoch 9/10\n",
      "1000/1000 [==============================] - 54s 54ms/step - loss: 0.0973 - acc: 0.9460\n",
      "Epoch 10/10\n",
      "1000/1000 [==============================] - 53s 53ms/step - loss: 0.0951 - acc: 0.9490\n",
      "Training on Epoch  0 batch  5  Files [5] start  320 / 459\n",
      "Epoch 1/10\n",
      "1000/1000 [==============================] - 54s 54ms/step - loss: 0.2335 - acc: 0.9070\n",
      "Epoch 2/10\n",
      "1000/1000 [==============================] - 54s 54ms/step - loss: 0.1793 - acc: 0.9280\n",
      "Epoch 3/10\n",
      "1000/1000 [==============================] - 54s 54ms/step - loss: 0.1536 - acc: 0.9360\n",
      "Epoch 4/10\n",
      "1000/1000 [==============================] - 54s 54ms/step - loss: 0.1401 - acc: 0.9470\n",
      "Epoch 5/10\n",
      "1000/1000 [==============================] - 54s 54ms/step - loss: 0.1542 - acc: 0.9420\n",
      "Epoch 6/10\n",
      "1000/1000 [==============================] - 54s 54ms/step - loss: 0.1510 - acc: 0.9410\n",
      "Epoch 7/10\n",
      "1000/1000 [==============================] - 54s 54ms/step - loss: 0.1368 - acc: 0.9430\n",
      "Epoch 8/10\n",
      "1000/1000 [==============================] - 54s 54ms/step - loss: 0.1169 - acc: 0.9520\n",
      "Epoch 9/10\n",
      "1000/1000 [==============================] - 54s 54ms/step - loss: 0.1068 - acc: 0.9580\n",
      "Epoch 10/10\n",
      "1000/1000 [==============================] - 54s 54ms/step - loss: 0.0991 - acc: 0.9630\n",
      "Training on Epoch  0 batch  5  Files [5] start  325 / 459\n",
      "Epoch 1/10\n",
      "1000/1000 [==============================] - 54s 54ms/step - loss: 0.1745 - acc: 0.9260\n",
      "Epoch 2/10\n",
      "1000/1000 [==============================] - 54s 54ms/step - loss: 0.1416 - acc: 0.9350\n",
      "Epoch 3/10\n",
      "1000/1000 [==============================] - 54s 54ms/step - loss: 0.1514 - acc: 0.9280\n",
      "Epoch 4/10\n",
      "1000/1000 [==============================] - 54s 54ms/step - loss: 0.1694 - acc: 0.9220\n",
      "Epoch 5/10\n",
      "1000/1000 [==============================] - 54s 54ms/step - loss: 0.1585 - acc: 0.9220\n",
      "Epoch 6/10\n",
      "1000/1000 [==============================] - 54s 54ms/step - loss: 0.1343 - acc: 0.9370\n",
      "Epoch 7/10\n",
      "1000/1000 [==============================] - 54s 54ms/step - loss: 0.1222 - acc: 0.9400\n",
      "Epoch 8/10\n",
      "1000/1000 [==============================] - 55s 55ms/step - loss: 0.1098 - acc: 0.9480\n",
      "Epoch 9/10\n",
      "1000/1000 [==============================] - 54s 54ms/step - loss: 0.1022 - acc: 0.9510\n",
      "Epoch 10/10\n",
      "1000/1000 [==============================] - 54s 54ms/step - loss: 0.0938 - acc: 0.9560\n",
      "Training on Epoch  0 batch  5  Files [5] start  330 / 459\n",
      "Epoch 1/10\n",
      "1000/1000 [==============================] - 58s 58ms/step - loss: 0.2775 - acc: 0.8880\n",
      "Epoch 2/10\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 0.2411 - acc: 0.9050\n",
      "Epoch 3/10\n",
      "1000/1000 [==============================] - 60s 60ms/step - loss: 0.2144 - acc: 0.9040\n",
      "Epoch 4/10\n",
      "1000/1000 [==============================] - 60s 60ms/step - loss: 0.1908 - acc: 0.9180\n",
      "Epoch 5/10\n",
      "1000/1000 [==============================] - 61s 61ms/step - loss: 0.1714 - acc: 0.9250\n",
      "Epoch 6/10\n",
      "1000/1000 [==============================] - 60s 60ms/step - loss: 0.1586 - acc: 0.9360\n",
      "Epoch 7/10\n",
      "1000/1000 [==============================] - 60s 60ms/step - loss: 0.1483 - acc: 0.9390\n",
      "Epoch 8/10\n",
      "1000/1000 [==============================] - 61s 61ms/step - loss: 0.1379 - acc: 0.9430\n",
      "Epoch 9/10\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 0.1312 - acc: 0.9510\n",
      "Epoch 10/10\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 0.1232 - acc: 0.9550\n",
      "Training on Epoch  0 batch  5  Files [5] start  335 / 459\n",
      "Epoch 1/10\n",
      "1000/1000 [==============================] - 55s 55ms/step - loss: 0.2118 - acc: 0.8920\n",
      "Epoch 2/10\n",
      "1000/1000 [==============================] - 54s 54ms/step - loss: 0.2007 - acc: 0.8980\n",
      "Epoch 3/10\n",
      "1000/1000 [==============================] - 55s 55ms/step - loss: 0.1801 - acc: 0.9130\n",
      "Epoch 4/10\n",
      "1000/1000 [==============================] - 55s 55ms/step - loss: 0.1650 - acc: 0.9200\n",
      "Epoch 5/10\n",
      "1000/1000 [==============================] - 56s 56ms/step - loss: 0.1541 - acc: 0.9200\n",
      "Epoch 6/10\n",
      "1000/1000 [==============================] - 55s 55ms/step - loss: 0.1446 - acc: 0.9340\n",
      "Epoch 7/10\n",
      "1000/1000 [==============================] - 56s 56ms/step - loss: 0.1353 - acc: 0.9350\n",
      "Epoch 8/10\n",
      "1000/1000 [==============================] - 54s 54ms/step - loss: 0.1314 - acc: 0.9390\n",
      "Epoch 9/10\n",
      "1000/1000 [==============================] - 55s 55ms/step - loss: 0.1227 - acc: 0.9500\n",
      "Epoch 10/10\n",
      "1000/1000 [==============================] - 54s 54ms/step - loss: 0.1184 - acc: 0.9500\n",
      "Training on Epoch  0 batch  5  Files [5] start  340 / 459\n",
      "Epoch 1/10\n",
      "1000/1000 [==============================] - 52s 52ms/step - loss: 0.1087 - acc: 0.9420\n",
      "Epoch 2/10\n",
      "1000/1000 [==============================] - 52s 52ms/step - loss: 0.0934 - acc: 0.9490\n",
      "Epoch 3/10\n",
      "1000/1000 [==============================] - 51s 51ms/step - loss: 0.0837 - acc: 0.9600\n",
      "Epoch 4/10\n",
      "1000/1000 [==============================] - 52s 52ms/step - loss: 0.0783 - acc: 0.9600\n",
      "Epoch 5/10\n",
      "1000/1000 [==============================] - 51s 51ms/step - loss: 0.0742 - acc: 0.9620\n",
      "Epoch 6/10\n",
      "1000/1000 [==============================] - 52s 52ms/step - loss: 0.0717 - acc: 0.9640\n",
      "Epoch 7/10\n",
      "1000/1000 [==============================] - 51s 51ms/step - loss: 0.0711 - acc: 0.9640\n",
      "Epoch 8/10\n",
      "1000/1000 [==============================] - 51s 51ms/step - loss: 0.0661 - acc: 0.9690\n",
      "Epoch 9/10\n",
      "1000/1000 [==============================] - 51s 51ms/step - loss: 0.0645 - acc: 0.9700\n",
      "Epoch 10/10\n",
      "1000/1000 [==============================] - 51s 51ms/step - loss: 0.0634 - acc: 0.9700\n",
      "Training on Epoch  0 batch  5  Files [5] start  345 / 459\n",
      "Epoch 1/10\n",
      "1000/1000 [==============================] - 51s 51ms/step - loss: 0.3409 - acc: 0.8750\n",
      "Epoch 2/10\n",
      "1000/1000 [==============================] - 53s 53ms/step - loss: 0.2396 - acc: 0.8950\n",
      "Epoch 3/10\n",
      "1000/1000 [==============================] - 52s 52ms/step - loss: 0.1961 - acc: 0.9060\n",
      "Epoch 4/10\n",
      "1000/1000 [==============================] - 52s 52ms/step - loss: 0.2008 - acc: 0.9020\n",
      "Epoch 5/10\n",
      "1000/1000 [==============================] - 52s 52ms/step - loss: 0.1904 - acc: 0.9090\n",
      "Epoch 6/10\n",
      "1000/1000 [==============================] - 52s 52ms/step - loss: 0.1658 - acc: 0.9240\n",
      "Epoch 7/10\n",
      "1000/1000 [==============================] - 53s 53ms/step - loss: 0.1393 - acc: 0.9460\n",
      "Epoch 8/10\n",
      "1000/1000 [==============================] - 53s 53ms/step - loss: 0.1282 - acc: 0.9480\n",
      "Epoch 9/10\n",
      "1000/1000 [==============================] - 53s 53ms/step - loss: 0.1159 - acc: 0.9510\n",
      "Epoch 10/10\n",
      "1000/1000 [==============================] - 52s 52ms/step - loss: 0.1052 - acc: 0.9550\n",
      "Training on Epoch  0 batch  5  Files [5] start  350 / 459\n",
      "Epoch 1/10\n",
      "1000/1000 [==============================] - 53s 53ms/step - loss: 0.4287 - acc: 0.8370\n",
      "Epoch 2/10\n",
      "1000/1000 [==============================] - 51s 51ms/step - loss: 0.3331 - acc: 0.8680\n",
      "Epoch 3/10\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000/1000 [==============================] - 50s 50ms/step - loss: 0.2925 - acc: 0.8830\n",
      "Epoch 4/10\n",
      "1000/1000 [==============================] - 50s 50ms/step - loss: 0.2625 - acc: 0.8920\n",
      "Epoch 5/10\n",
      "1000/1000 [==============================] - 50s 50ms/step - loss: 0.2441 - acc: 0.8980\n",
      "Epoch 6/10\n",
      "1000/1000 [==============================] - 50s 50ms/step - loss: 0.2313 - acc: 0.8980\n",
      "Epoch 7/10\n",
      "1000/1000 [==============================] - 51s 51ms/step - loss: 0.2044 - acc: 0.9170\n",
      "Epoch 8/10\n",
      "1000/1000 [==============================] - 50s 50ms/step - loss: 0.1796 - acc: 0.9320\n",
      "Epoch 9/10\n",
      "1000/1000 [==============================] - 50s 50ms/step - loss: 0.1664 - acc: 0.9330\n",
      "Epoch 10/10\n",
      "1000/1000 [==============================] - 51s 51ms/step - loss: 0.1523 - acc: 0.9440\n",
      "Training on Epoch  0 batch  5  Files [5] start  355 / 459\n",
      "Epoch 1/10\n",
      "1000/1000 [==============================] - 48s 48ms/step - loss: 0.4003 - acc: 0.8480\n",
      "Epoch 2/10\n",
      "1000/1000 [==============================] - 48s 48ms/step - loss: 0.3234 - acc: 0.8740\n",
      "Epoch 3/10\n",
      "1000/1000 [==============================] - 49s 49ms/step - loss: 0.2684 - acc: 0.8940\n",
      "Epoch 4/10\n",
      "1000/1000 [==============================] - 49s 49ms/step - loss: 0.2480 - acc: 0.8940\n",
      "Epoch 5/10\n",
      "1000/1000 [==============================] - 49s 49ms/step - loss: 0.2232 - acc: 0.9090\n",
      "Epoch 6/10\n",
      "1000/1000 [==============================] - 49s 49ms/step - loss: 0.2005 - acc: 0.9290\n",
      "Epoch 7/10\n",
      "1000/1000 [==============================] - 49s 49ms/step - loss: 0.1793 - acc: 0.9350\n",
      "Epoch 8/10\n",
      "1000/1000 [==============================] - 49s 49ms/step - loss: 0.1658 - acc: 0.9420\n",
      "Epoch 9/10\n",
      "1000/1000 [==============================] - 48s 48ms/step - loss: 0.1510 - acc: 0.9460\n",
      "Epoch 10/10\n",
      "1000/1000 [==============================] - 49s 49ms/step - loss: 0.1370 - acc: 0.9530\n",
      "Training on Epoch  0 batch  5  Files [5] start  360 / 459\n",
      "Epoch 1/10\n",
      "1000/1000 [==============================] - 52s 52ms/step - loss: 0.3552 - acc: 0.8590\n",
      "Epoch 2/10\n",
      "1000/1000 [==============================] - 53s 53ms/step - loss: 0.2865 - acc: 0.8930\n",
      "Epoch 3/10\n",
      "1000/1000 [==============================] - 52s 52ms/step - loss: 0.2345 - acc: 0.9110\n",
      "Epoch 4/10\n",
      "1000/1000 [==============================] - 52s 52ms/step - loss: 0.2103 - acc: 0.9180\n",
      "Epoch 5/10\n",
      "1000/1000 [==============================] - 54s 54ms/step - loss: 0.1865 - acc: 0.9320\n",
      "Epoch 6/10\n",
      "1000/1000 [==============================] - 54s 54ms/step - loss: 0.1668 - acc: 0.9350\n",
      "Epoch 7/10\n",
      "1000/1000 [==============================] - 53s 53ms/step - loss: 0.1630 - acc: 0.9370\n",
      "Epoch 8/10\n",
      "1000/1000 [==============================] - 54s 54ms/step - loss: 0.1371 - acc: 0.9500\n",
      "Epoch 9/10\n",
      "1000/1000 [==============================] - 52s 52ms/step - loss: 0.1177 - acc: 0.9580\n",
      "Epoch 10/10\n",
      "1000/1000 [==============================] - 52s 52ms/step - loss: 0.0997 - acc: 0.9660\n",
      "Training on Epoch  0 batch  5  Files [5] start  365 / 459\n",
      "Epoch 1/10\n",
      "1000/1000 [==============================] - 50s 50ms/step - loss: 0.4837 - acc: 0.8350\n",
      "Epoch 2/10\n",
      "1000/1000 [==============================] - 51s 51ms/step - loss: 0.3452 - acc: 0.8650\n",
      "Epoch 3/10\n",
      "1000/1000 [==============================] - 50s 50ms/step - loss: 0.2876 - acc: 0.8730\n",
      "Epoch 4/10\n",
      "1000/1000 [==============================] - 50s 50ms/step - loss: 0.2450 - acc: 0.8970\n",
      "Epoch 5/10\n",
      "1000/1000 [==============================] - 51s 51ms/step - loss: 0.2173 - acc: 0.9080\n",
      "Epoch 6/10\n",
      "1000/1000 [==============================] - 50s 50ms/step - loss: 0.1976 - acc: 0.9210\n",
      "Epoch 7/10\n",
      "1000/1000 [==============================] - 51s 51ms/step - loss: 0.1737 - acc: 0.9370\n",
      "Epoch 8/10\n",
      "1000/1000 [==============================] - 51s 51ms/step - loss: 0.1546 - acc: 0.9420\n",
      "Epoch 9/10\n",
      "1000/1000 [==============================] - 51s 51ms/step - loss: 0.1434 - acc: 0.9490\n",
      "Epoch 10/10\n",
      "1000/1000 [==============================] - 50s 50ms/step - loss: 0.1306 - acc: 0.9530\n",
      "Training on Epoch  0 batch  5  Files [5] start  370 / 459\n",
      "Epoch 1/10\n",
      "1000/1000 [==============================] - 51s 51ms/step - loss: 0.3064 - acc: 0.8870\n",
      "Epoch 2/10\n",
      "1000/1000 [==============================] - 50s 50ms/step - loss: 0.2390 - acc: 0.8940\n",
      "Epoch 3/10\n",
      "1000/1000 [==============================] - 50s 50ms/step - loss: 0.2127 - acc: 0.8950\n",
      "Epoch 4/10\n",
      "1000/1000 [==============================] - 50s 50ms/step - loss: 0.1860 - acc: 0.9230\n",
      "Epoch 5/10\n",
      "1000/1000 [==============================] - 50s 50ms/step - loss: 0.1652 - acc: 0.9190\n",
      "Epoch 6/10\n",
      "1000/1000 [==============================] - 50s 50ms/step - loss: 0.1481 - acc: 0.9370\n",
      "Epoch 7/10\n",
      "1000/1000 [==============================] - 51s 51ms/step - loss: 0.1343 - acc: 0.9460\n",
      "Epoch 8/10\n",
      "1000/1000 [==============================] - 50s 50ms/step - loss: 0.1283 - acc: 0.9390\n",
      "Epoch 9/10\n",
      "1000/1000 [==============================] - 50s 50ms/step - loss: 0.1173 - acc: 0.9490\n",
      "Epoch 10/10\n",
      "1000/1000 [==============================] - 51s 51ms/step - loss: 0.1093 - acc: 0.9520\n",
      "Training on Epoch  0 batch  5  Files [5] start  375 / 459\n",
      "Epoch 1/10\n",
      "1000/1000 [==============================] - 54s 54ms/step - loss: 0.4197 - acc: 0.8480\n",
      "Epoch 2/10\n",
      "1000/1000 [==============================] - 54s 54ms/step - loss: 0.3277 - acc: 0.8710\n",
      "Epoch 3/10\n",
      "1000/1000 [==============================] - 54s 54ms/step - loss: 0.2737 - acc: 0.8870\n",
      "Epoch 4/10\n",
      "1000/1000 [==============================] - 54s 54ms/step - loss: 0.2310 - acc: 0.9130\n",
      "Epoch 5/10\n",
      "1000/1000 [==============================] - 54s 54ms/step - loss: 0.1988 - acc: 0.9230\n",
      "Epoch 6/10\n",
      "1000/1000 [==============================] - 54s 54ms/step - loss: 0.1735 - acc: 0.9310\n",
      "Epoch 7/10\n",
      "1000/1000 [==============================] - 54s 54ms/step - loss: 0.1573 - acc: 0.9400\n",
      "Epoch 8/10\n",
      "1000/1000 [==============================] - 55s 55ms/step - loss: 0.1434 - acc: 0.9470\n",
      "Epoch 9/10\n",
      "1000/1000 [==============================] - 55s 55ms/step - loss: 0.1231 - acc: 0.9610\n",
      "Epoch 10/10\n",
      "1000/1000 [==============================] - 55s 55ms/step - loss: 0.1070 - acc: 0.9690\n",
      "Training on Epoch  0 batch  5  Files [5] start  380 / 459\n",
      "Epoch 1/10\n",
      "1000/1000 [==============================] - 51s 51ms/step - loss: 0.3685 - acc: 0.8670\n",
      "Epoch 2/10\n",
      "1000/1000 [==============================] - 51s 51ms/step - loss: 0.2738 - acc: 0.8820\n",
      "Epoch 3/10\n",
      "1000/1000 [==============================] - 50s 50ms/step - loss: 0.2215 - acc: 0.9070\n",
      "Epoch 4/10\n",
      "1000/1000 [==============================] - 51s 51ms/step - loss: 0.1907 - acc: 0.9310\n",
      "Epoch 5/10\n",
      "1000/1000 [==============================] - 51s 51ms/step - loss: 0.1594 - acc: 0.9420\n",
      "Epoch 6/10\n",
      "1000/1000 [==============================] - 50s 50ms/step - loss: 0.1428 - acc: 0.9440\n",
      "Epoch 7/10\n",
      "1000/1000 [==============================] - 50s 50ms/step - loss: 0.1218 - acc: 0.9570\n",
      "Epoch 8/10\n",
      "1000/1000 [==============================] - 51s 51ms/step - loss: 0.1075 - acc: 0.9630\n",
      "Epoch 9/10\n",
      "1000/1000 [==============================] - 51s 51ms/step - loss: 0.0964 - acc: 0.9700\n",
      "Epoch 10/10\n",
      "1000/1000 [==============================] - 51s 51ms/step - loss: 0.0876 - acc: 0.9760\n",
      "Training on Epoch  0 batch  5  Files [5] start  385 / 459\n",
      "Epoch 1/10\n",
      "1000/1000 [==============================] - 53s 53ms/step - loss: 0.3661 - acc: 0.8660\n",
      "Epoch 2/10\n",
      "1000/1000 [==============================] - 54s 54ms/step - loss: 0.2820 - acc: 0.8910\n",
      "Epoch 3/10\n",
      "1000/1000 [==============================] - 53s 53ms/step - loss: 0.2297 - acc: 0.9130\n",
      "Epoch 4/10\n",
      "1000/1000 [==============================] - 53s 53ms/step - loss: 0.1981 - acc: 0.9260\n",
      "Epoch 5/10\n",
      "1000/1000 [==============================] - 53s 53ms/step - loss: 0.1783 - acc: 0.9300\n",
      "Epoch 6/10\n",
      "1000/1000 [==============================] - 53s 53ms/step - loss: 0.1680 - acc: 0.9450\n",
      "Epoch 7/10\n",
      "1000/1000 [==============================] - 53s 53ms/step - loss: 0.1408 - acc: 0.9550\n",
      "Epoch 8/10\n",
      "1000/1000 [==============================] - 53s 53ms/step - loss: 0.1268 - acc: 0.9530\n",
      "Epoch 9/10\n",
      "1000/1000 [==============================] - 52s 52ms/step - loss: 0.1133 - acc: 0.9620\n",
      "Epoch 10/10\n",
      "1000/1000 [==============================] - 53s 53ms/step - loss: 0.1037 - acc: 0.9690\n",
      "Training on Epoch  0 batch  5  Files [5] start  390 / 459\n",
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000/1000 [==============================] - 53s 53ms/step - loss: 0.4209 - acc: 0.8410\n",
      "Epoch 2/10\n",
      "1000/1000 [==============================] - 52s 52ms/step - loss: 0.3292 - acc: 0.8650\n",
      "Epoch 3/10\n",
      "1000/1000 [==============================] - 52s 52ms/step - loss: 0.2519 - acc: 0.9050\n",
      "Epoch 4/10\n",
      "1000/1000 [==============================] - 52s 52ms/step - loss: 0.2138 - acc: 0.9250\n",
      "Epoch 5/10\n",
      "1000/1000 [==============================] - 52s 52ms/step - loss: 0.1865 - acc: 0.9300\n",
      "Epoch 6/10\n",
      "1000/1000 [==============================] - 51s 51ms/step - loss: 0.1649 - acc: 0.9450\n",
      "Epoch 7/10\n",
      "1000/1000 [==============================] - 52s 52ms/step - loss: 0.1432 - acc: 0.9540\n",
      "Epoch 8/10\n",
      "1000/1000 [==============================] - 52s 52ms/step - loss: 0.1277 - acc: 0.9590\n",
      "Epoch 9/10\n",
      "1000/1000 [==============================] - 53s 53ms/step - loss: 0.1149 - acc: 0.9650\n",
      "Epoch 10/10\n",
      "1000/1000 [==============================] - 52s 52ms/step - loss: 0.1036 - acc: 0.9710\n",
      "Training on Epoch  0 batch  5  Files [5] start  395 / 459\n",
      "Epoch 1/10\n",
      "1000/1000 [==============================] - 51s 51ms/step - loss: 0.3694 - acc: 0.8630\n",
      "Epoch 2/10\n",
      "1000/1000 [==============================] - 52s 52ms/step - loss: 0.2917 - acc: 0.8930\n",
      "Epoch 3/10\n",
      "1000/1000 [==============================] - 52s 52ms/step - loss: 0.2420 - acc: 0.9060\n",
      "Epoch 4/10\n",
      "1000/1000 [==============================] - 52s 52ms/step - loss: 0.2071 - acc: 0.9170\n",
      "Epoch 5/10\n",
      "1000/1000 [==============================] - 52s 52ms/step - loss: 0.1746 - acc: 0.9340\n",
      "Epoch 6/10\n",
      "1000/1000 [==============================] - 52s 52ms/step - loss: 0.1581 - acc: 0.9440\n",
      "Epoch 7/10\n",
      "1000/1000 [==============================] - 52s 52ms/step - loss: 0.1350 - acc: 0.9540\n",
      "Epoch 8/10\n",
      "1000/1000 [==============================] - 52s 52ms/step - loss: 0.1203 - acc: 0.9590\n",
      "Epoch 9/10\n",
      "1000/1000 [==============================] - 52s 52ms/step - loss: 0.1072 - acc: 0.9650\n",
      "Epoch 10/10\n",
      "1000/1000 [==============================] - 52s 52ms/step - loss: 0.0957 - acc: 0.9680\n",
      "Training on Epoch  0 batch  5  Files [5] start  400 / 459\n",
      "Epoch 1/10\n",
      "1000/1000 [==============================] - 53s 53ms/step - loss: 0.3710 - acc: 0.8740\n",
      "Epoch 2/10\n",
      "1000/1000 [==============================] - 53s 53ms/step - loss: 0.2857 - acc: 0.8980\n",
      "Epoch 3/10\n",
      "1000/1000 [==============================] - 53s 53ms/step - loss: 0.2338 - acc: 0.9140\n",
      "Epoch 4/10\n",
      "1000/1000 [==============================] - 53s 53ms/step - loss: 0.1883 - acc: 0.9280\n",
      "Epoch 5/10\n",
      "1000/1000 [==============================] - 53s 53ms/step - loss: 0.1696 - acc: 0.9370\n",
      "Epoch 6/10\n",
      "1000/1000 [==============================] - 53s 53ms/step - loss: 0.1486 - acc: 0.9450\n",
      "Epoch 7/10\n",
      "1000/1000 [==============================] - 53s 53ms/step - loss: 0.1300 - acc: 0.9540\n",
      "Epoch 8/10\n",
      "1000/1000 [==============================] - 53s 53ms/step - loss: 0.1172 - acc: 0.9620\n",
      "Epoch 9/10\n",
      "1000/1000 [==============================] - 53s 53ms/step - loss: 0.1044 - acc: 0.9670\n",
      "Epoch 10/10\n",
      "1000/1000 [==============================] - 53s 53ms/step - loss: 0.0972 - acc: 0.9670\n",
      "Training on Epoch  0 batch  5  Files [5] start  405 / 459\n",
      "Epoch 1/10\n",
      "1000/1000 [==============================] - 53s 53ms/step - loss: 0.3457 - acc: 0.8800\n",
      "Epoch 2/10\n",
      "1000/1000 [==============================] - 53s 53ms/step - loss: 0.2475 - acc: 0.9070\n",
      "Epoch 3/10\n",
      "1000/1000 [==============================] - 53s 53ms/step - loss: 0.1962 - acc: 0.9260\n",
      "Epoch 4/10\n",
      "1000/1000 [==============================] - 53s 53ms/step - loss: 0.1612 - acc: 0.9380\n",
      "Epoch 5/10\n",
      "1000/1000 [==============================] - 53s 53ms/step - loss: 0.1389 - acc: 0.9530\n",
      "Epoch 6/10\n",
      "1000/1000 [==============================] - 54s 54ms/step - loss: 0.1204 - acc: 0.9570\n",
      "Epoch 7/10\n",
      "1000/1000 [==============================] - 53s 53ms/step - loss: 0.1000 - acc: 0.9690\n",
      "Epoch 8/10\n",
      "1000/1000 [==============================] - 53s 53ms/step - loss: 0.0883 - acc: 0.9770\n",
      "Epoch 9/10\n",
      "1000/1000 [==============================] - 53s 53ms/step - loss: 0.0786 - acc: 0.9770\n",
      "Epoch 10/10\n",
      "1000/1000 [==============================] - 54s 54ms/step - loss: 0.0708 - acc: 0.9800\n",
      "Training on Epoch  0 batch  5  Files [5] start  410 / 459\n",
      "Epoch 1/10\n",
      "1000/1000 [==============================] - 48s 48ms/step - loss: 0.3937 - acc: 0.8690\n",
      "Epoch 2/10\n",
      "1000/1000 [==============================] - 49s 49ms/step - loss: 0.2837 - acc: 0.8880\n",
      "Epoch 3/10\n",
      "1000/1000 [==============================] - 49s 49ms/step - loss: 0.2369 - acc: 0.8980\n",
      "Epoch 4/10\n",
      "1000/1000 [==============================] - 49s 49ms/step - loss: 0.2057 - acc: 0.9150\n",
      "Epoch 5/10\n",
      "1000/1000 [==============================] - 49s 49ms/step - loss: 0.1756 - acc: 0.9360\n",
      "Epoch 6/10\n",
      "1000/1000 [==============================] - 48s 48ms/step - loss: 0.1535 - acc: 0.9380\n",
      "Epoch 7/10\n",
      "1000/1000 [==============================] - 48s 48ms/step - loss: 0.1347 - acc: 0.9440\n",
      "Epoch 8/10\n",
      "1000/1000 [==============================] - 49s 49ms/step - loss: 0.1215 - acc: 0.9560\n",
      "Epoch 9/10\n",
      "1000/1000 [==============================] - 49s 49ms/step - loss: 0.1089 - acc: 0.9600\n",
      "Epoch 10/10\n",
      "1000/1000 [==============================] - 48s 48ms/step - loss: 0.0964 - acc: 0.9680\n",
      "Training on Epoch  0 batch  5  Files [5] start  415 / 459\n",
      "Epoch 1/10\n",
      "1000/1000 [==============================] - 48s 48ms/step - loss: 0.4323 - acc: 0.8590\n",
      "Epoch 2/10\n",
      "1000/1000 [==============================] - 49s 49ms/step - loss: 0.3379 - acc: 0.8780\n",
      "Epoch 3/10\n",
      "1000/1000 [==============================] - 49s 49ms/step - loss: 0.2839 - acc: 0.8820\n",
      "Epoch 4/10\n",
      "1000/1000 [==============================] - 51s 51ms/step - loss: 0.2348 - acc: 0.9160\n",
      "Epoch 5/10\n",
      "1000/1000 [==============================] - 49s 49ms/step - loss: 0.1999 - acc: 0.9210\n",
      "Epoch 6/10\n",
      "1000/1000 [==============================] - 49s 49ms/step - loss: 0.1795 - acc: 0.9350\n",
      "Epoch 7/10\n",
      "1000/1000 [==============================] - 49s 49ms/step - loss: 0.1593 - acc: 0.9420\n",
      "Epoch 8/10\n",
      "1000/1000 [==============================] - 49s 49ms/step - loss: 0.1397 - acc: 0.9500\n",
      "Epoch 9/10\n",
      "1000/1000 [==============================] - 49s 49ms/step - loss: 0.1231 - acc: 0.9560\n",
      "Epoch 10/10\n",
      "1000/1000 [==============================] - 49s 49ms/step - loss: 0.1175 - acc: 0.9570\n",
      "Training on Epoch  0 batch  5  Files [5] start  420 / 459\n",
      "Epoch 1/10\n",
      "1000/1000 [==============================] - 52s 52ms/step - loss: 0.3661 - acc: 0.8590\n",
      "Epoch 2/10\n",
      "1000/1000 [==============================] - 52s 52ms/step - loss: 0.2757 - acc: 0.8900\n",
      "Epoch 3/10\n",
      "1000/1000 [==============================] - 52s 52ms/step - loss: 0.2240 - acc: 0.9100\n",
      "Epoch 4/10\n",
      "1000/1000 [==============================] - 52s 52ms/step - loss: 0.1910 - acc: 0.9240\n",
      "Epoch 5/10\n",
      "1000/1000 [==============================] - 52s 52ms/step - loss: 0.1656 - acc: 0.9350\n",
      "Epoch 6/10\n",
      "1000/1000 [==============================] - 53s 53ms/step - loss: 0.1412 - acc: 0.9440\n",
      "Epoch 7/10\n",
      "1000/1000 [==============================] - 53s 53ms/step - loss: 0.1239 - acc: 0.9530\n",
      "Epoch 8/10\n",
      "1000/1000 [==============================] - 52s 52ms/step - loss: 0.1080 - acc: 0.9590\n",
      "Epoch 9/10\n",
      "1000/1000 [==============================] - 52s 52ms/step - loss: 0.0954 - acc: 0.9680\n",
      "Epoch 10/10\n",
      "1000/1000 [==============================] - 53s 53ms/step - loss: 0.0868 - acc: 0.9710\n",
      "Training on Epoch  0 batch  5  Files [5] start  425 / 459\n",
      "Epoch 1/10\n",
      "1000/1000 [==============================] - 50s 50ms/step - loss: 0.4062 - acc: 0.8550\n",
      "Epoch 2/10\n",
      "1000/1000 [==============================] - 50s 50ms/step - loss: 0.2910 - acc: 0.8830\n",
      "Epoch 3/10\n",
      "1000/1000 [==============================] - 50s 50ms/step - loss: 0.2400 - acc: 0.9010\n",
      "Epoch 4/10\n",
      "1000/1000 [==============================] - 49s 49ms/step - loss: 0.2038 - acc: 0.9150\n",
      "Epoch 5/10\n",
      "1000/1000 [==============================] - 50s 50ms/step - loss: 0.1801 - acc: 0.9270\n",
      "Epoch 6/10\n",
      "1000/1000 [==============================] - 49s 49ms/step - loss: 0.1606 - acc: 0.9350\n",
      "Epoch 7/10\n",
      "1000/1000 [==============================] - 50s 50ms/step - loss: 0.1439 - acc: 0.9410\n",
      "Epoch 8/10\n",
      "1000/1000 [==============================] - 50s 50ms/step - loss: 0.1252 - acc: 0.9520\n",
      "Epoch 9/10\n",
      "1000/1000 [==============================] - 50s 50ms/step - loss: 0.1152 - acc: 0.9570\n",
      "Epoch 10/10\n",
      "1000/1000 [==============================] - 50s 50ms/step - loss: 0.1016 - acc: 0.9630\n",
      "Training on Epoch  0 batch  5  Files [5] start  430 / 459\n",
      "Epoch 1/10\n",
      "1000/1000 [==============================] - 51s 51ms/step - loss: 0.3836 - acc: 0.8640\n",
      "Epoch 2/10\n",
      "1000/1000 [==============================] - 52s 52ms/step - loss: 0.2855 - acc: 0.8880\n",
      "Epoch 3/10\n",
      "1000/1000 [==============================] - 52s 52ms/step - loss: 0.2237 - acc: 0.9190\n",
      "Epoch 4/10\n",
      "1000/1000 [==============================] - 53s 53ms/step - loss: 0.1872 - acc: 0.9310\n",
      "Epoch 5/10\n",
      "1000/1000 [==============================] - 52s 52ms/step - loss: 0.1624 - acc: 0.9390\n",
      "Epoch 6/10\n",
      "1000/1000 [==============================] - 52s 52ms/step - loss: 0.1358 - acc: 0.9540\n",
      "Epoch 7/10\n",
      "1000/1000 [==============================] - 51s 51ms/step - loss: 0.1196 - acc: 0.9540\n",
      "Epoch 8/10\n",
      "1000/1000 [==============================] - 51s 51ms/step - loss: 0.1054 - acc: 0.9590\n",
      "Epoch 9/10\n",
      "1000/1000 [==============================] - 51s 51ms/step - loss: 0.0948 - acc: 0.9670\n",
      "Epoch 10/10\n",
      "1000/1000 [==============================] - 51s 51ms/step - loss: 0.0816 - acc: 0.9760\n",
      "Training on Epoch  0 batch  5  Files [5] start  435 / 459\n",
      "Epoch 1/10\n",
      "1000/1000 [==============================] - 49s 49ms/step - loss: 0.3885 - acc: 0.8760\n",
      "Epoch 2/10\n",
      "1000/1000 [==============================] - 50s 50ms/step - loss: 0.2918 - acc: 0.8920\n",
      "Epoch 3/10\n",
      "1000/1000 [==============================] - 50s 50ms/step - loss: 0.2413 - acc: 0.8980\n",
      "Epoch 4/10\n",
      "1000/1000 [==============================] - 49s 49ms/step - loss: 0.2017 - acc: 0.9290\n",
      "Epoch 5/10\n",
      "1000/1000 [==============================] - 50s 50ms/step - loss: 0.1670 - acc: 0.9350\n",
      "Epoch 6/10\n",
      "1000/1000 [==============================] - 49s 49ms/step - loss: 0.1460 - acc: 0.9400\n",
      "Epoch 7/10\n",
      "1000/1000 [==============================] - 49s 49ms/step - loss: 0.1301 - acc: 0.9480\n",
      "Epoch 8/10\n",
      "1000/1000 [==============================] - 49s 49ms/step - loss: 0.1154 - acc: 0.9550\n",
      "Epoch 9/10\n",
      "1000/1000 [==============================] - 49s 49ms/step - loss: 0.1025 - acc: 0.9610\n",
      "Epoch 10/10\n",
      "1000/1000 [==============================] - 49s 49ms/step - loss: 0.0912 - acc: 0.9670\n",
      "Training on Epoch  0 batch  5  Files [5] start  440 / 459\n",
      "Epoch 1/10\n",
      "1000/1000 [==============================] - 52s 52ms/step - loss: 0.2266 - acc: 0.9180\n",
      "Epoch 2/10\n",
      "1000/1000 [==============================] - 52s 52ms/step - loss: 0.1649 - acc: 0.9390\n",
      "Epoch 3/10\n",
      "1000/1000 [==============================] - 52s 52ms/step - loss: 0.1236 - acc: 0.9590\n",
      "Epoch 4/10\n",
      "1000/1000 [==============================] - 52s 52ms/step - loss: 0.0972 - acc: 0.9630\n",
      "Epoch 5/10\n",
      "1000/1000 [==============================] - 53s 53ms/step - loss: 0.0721 - acc: 0.9770\n",
      "Epoch 6/10\n",
      "1000/1000 [==============================] - 53s 53ms/step - loss: 0.0566 - acc: 0.9850\n",
      "Epoch 7/10\n",
      "1000/1000 [==============================] - 53s 53ms/step - loss: 0.0454 - acc: 0.9900\n",
      "Epoch 8/10\n",
      "1000/1000 [==============================] - 53s 53ms/step - loss: 0.0393 - acc: 0.9900\n",
      "Epoch 9/10\n",
      "1000/1000 [==============================] - 53s 53ms/step - loss: 0.0339 - acc: 0.9890\n",
      "Epoch 10/10\n",
      "1000/1000 [==============================] - 53s 53ms/step - loss: 0.0302 - acc: 0.9920\n",
      "Training on Epoch  0 batch  5  Files [5] start  445 / 459\n",
      "Epoch 1/10\n",
      "1000/1000 [==============================] - 49s 49ms/step - loss: 0.2652 - acc: 0.9140\n",
      "Epoch 2/10\n",
      "1000/1000 [==============================] - 49s 49ms/step - loss: 0.1742 - acc: 0.9350\n",
      "Epoch 3/10\n",
      "1000/1000 [==============================] - 49s 49ms/step - loss: 0.1308 - acc: 0.9420\n",
      "Epoch 4/10\n",
      "1000/1000 [==============================] - 10595s 11s/step - loss: 0.1034 - acc: 0.9600\n",
      "Epoch 5/10\n",
      "1000/1000 [==============================] - 51s 51ms/step - loss: 0.0832 - acc: 0.9690\n",
      "Epoch 6/10\n",
      "1000/1000 [==============================] - 49s 49ms/step - loss: 0.0702 - acc: 0.9750\n",
      "Epoch 7/10\n",
      "1000/1000 [==============================] - 49s 49ms/step - loss: 0.0598 - acc: 0.9820\n",
      "Epoch 8/10\n",
      "1000/1000 [==============================] - 49s 49ms/step - loss: 0.0515 - acc: 0.9830\n",
      "Epoch 9/10\n",
      "1000/1000 [==============================] - 51s 51ms/step - loss: 0.0433 - acc: 0.9900\n",
      "Epoch 10/10\n",
      "1000/1000 [==============================] - 50s 50ms/step - loss: 0.0368 - acc: 0.9910\n",
      "Training on Epoch  0 batch  5  Files [5] start  450 / 459\n",
      "Epoch 1/10\n",
      "1000/1000 [==============================] - 53s 53ms/step - loss: 0.3482 - acc: 0.8870\n",
      "Epoch 2/10\n",
      "1000/1000 [==============================] - 54s 54ms/step - loss: 0.2332 - acc: 0.9120\n",
      "Epoch 3/10\n",
      "1000/1000 [==============================] - 54s 54ms/step - loss: 0.1746 - acc: 0.9340\n",
      "Epoch 4/10\n",
      "1000/1000 [==============================] - 54s 54ms/step - loss: 0.1446 - acc: 0.9490\n",
      "Epoch 5/10\n",
      "1000/1000 [==============================] - 54s 54ms/step - loss: 0.1193 - acc: 0.9640\n",
      "Epoch 6/10\n",
      "1000/1000 [==============================] - 54s 54ms/step - loss: 0.1010 - acc: 0.9690\n",
      "Epoch 7/10\n",
      "1000/1000 [==============================] - 54s 54ms/step - loss: 0.0881 - acc: 0.9710\n",
      "Epoch 8/10\n",
      "1000/1000 [==============================] - 54s 54ms/step - loss: 0.0779 - acc: 0.9720\n",
      "Epoch 9/10\n",
      "1000/1000 [==============================] - 54s 54ms/step - loss: 0.0697 - acc: 0.9760\n",
      "Epoch 10/10\n",
      "1000/1000 [==============================] - 54s 54ms/step - loss: 0.0616 - acc: 0.9760\n",
      "Training on Epoch  0 batch  4  Files [5] start  455 / 459\n",
      "Epoch 1/10\n",
      "800/800 [==============================] - 48s 60ms/step - loss: 0.3336 - acc: 0.9012\n",
      "Epoch 2/10\n",
      "800/800 [==============================] - 48s 60ms/step - loss: 0.2625 - acc: 0.9262\n",
      "Epoch 3/10\n",
      "800/800 [==============================] - 48s 60ms/step - loss: 0.2038 - acc: 0.9300\n",
      "Epoch 4/10\n",
      "800/800 [==============================] - 48s 60ms/step - loss: 0.1586 - acc: 0.9488\n",
      "Epoch 5/10\n",
      "800/800 [==============================] - 48s 60ms/step - loss: 0.1309 - acc: 0.9600\n",
      "Epoch 6/10\n",
      "800/800 [==============================] - 48s 60ms/step - loss: 0.1092 - acc: 0.9700\n",
      "Epoch 7/10\n",
      "800/800 [==============================] - 48s 60ms/step - loss: 0.0986 - acc: 0.9725\n",
      "Epoch 8/10\n",
      "800/800 [==============================] - 48s 60ms/step - loss: 0.0867 - acc: 0.9750\n",
      "Epoch 9/10\n",
      "800/800 [==============================] - 48s 59ms/step - loss: 0.0770 - acc: 0.9800\n",
      "Epoch 10/10\n",
      "800/800 [==============================] - 48s 60ms/step - loss: 0.0690 - acc: 0.9825\n",
      "Training on Epoch  1 batch  5  Files [5] start  0 / 459\n",
      "Epoch 1/10\n",
      "1000/1000 [==============================] - 48s 48ms/step - loss: 0.3368 - acc: 0.8770\n",
      "Epoch 2/10\n",
      "1000/1000 [==============================] - 49s 49ms/step - loss: 0.2442 - acc: 0.9000\n",
      "Epoch 3/10\n",
      "1000/1000 [==============================] - 48s 48ms/step - loss: 0.1894 - acc: 0.9270\n",
      "Epoch 4/10\n",
      "1000/1000 [==============================] - 49s 49ms/step - loss: 0.1589 - acc: 0.9370\n",
      "Epoch 5/10\n",
      "1000/1000 [==============================] - 48s 48ms/step - loss: 0.1336 - acc: 0.9480\n",
      "Epoch 6/10\n",
      "1000/1000 [==============================] - 48s 48ms/step - loss: 0.1188 - acc: 0.9540\n",
      "Epoch 7/10\n",
      "1000/1000 [==============================] - 49s 49ms/step - loss: 0.1041 - acc: 0.9660\n",
      "Epoch 8/10\n",
      "1000/1000 [==============================] - 48s 48ms/step - loss: 0.0921 - acc: 0.9680\n",
      "Epoch 9/10\n",
      "1000/1000 [==============================] - 49s 49ms/step - loss: 0.0824 - acc: 0.9780\n",
      "Epoch 10/10\n",
      "1000/1000 [==============================] - 49s 49ms/step - loss: 0.0730 - acc: 0.9790\n",
      "Training on Epoch  1 batch  5  Files [5] start  5 / 459\n",
      "Epoch 1/10\n",
      "1000/1000 [==============================] - 48s 48ms/step - loss: 0.3240 - acc: 0.8890\n",
      "Epoch 2/10\n",
      "1000/1000 [==============================] - 48s 48ms/step - loss: 0.2565 - acc: 0.9090\n",
      "Epoch 3/10\n",
      "1000/1000 [==============================] - 49s 49ms/step - loss: 0.1933 - acc: 0.9340\n",
      "Epoch 4/10\n",
      "1000/1000 [==============================] - 48s 48ms/step - loss: 0.1631 - acc: 0.9520\n",
      "Epoch 5/10\n",
      "1000/1000 [==============================] - 48s 48ms/step - loss: 0.1414 - acc: 0.9630\n",
      "Epoch 6/10\n",
      "1000/1000 [==============================] - 49s 49ms/step - loss: 0.1244 - acc: 0.9660\n",
      "Epoch 7/10\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000/1000 [==============================] - 48s 48ms/step - loss: 0.1093 - acc: 0.9700\n",
      "Epoch 8/10\n",
      "1000/1000 [==============================] - 48s 48ms/step - loss: 0.0961 - acc: 0.9730\n",
      "Epoch 9/10\n",
      "1000/1000 [==============================] - 48s 48ms/step - loss: 0.0855 - acc: 0.9760\n",
      "Epoch 10/10\n",
      "1000/1000 [==============================] - 48s 48ms/step - loss: 0.0751 - acc: 0.9760\n",
      "Training on Epoch  1 batch  5  Files [5] start  10 / 459\n",
      "Epoch 1/10\n",
      "1000/1000 [==============================] - 52s 52ms/step - loss: 0.4213 - acc: 0.8580\n",
      "Epoch 2/10\n",
      "1000/1000 [==============================] - 52s 52ms/step - loss: 0.2930 - acc: 0.8790\n",
      "Epoch 3/10\n",
      "1000/1000 [==============================] - 52s 52ms/step - loss: 0.2169 - acc: 0.9130\n",
      "Epoch 4/10\n",
      "1000/1000 [==============================] - 52s 52ms/step - loss: 0.1817 - acc: 0.9290\n",
      "Epoch 5/10\n",
      "1000/1000 [==============================] - 52s 52ms/step - loss: 0.1528 - acc: 0.9450\n",
      "Epoch 6/10\n",
      "1000/1000 [==============================] - 52s 52ms/step - loss: 0.1260 - acc: 0.9580\n",
      "Epoch 7/10\n",
      "1000/1000 [==============================] - 52s 52ms/step - loss: 0.1094 - acc: 0.9660\n",
      "Epoch 8/10\n",
      "1000/1000 [==============================] - 52s 52ms/step - loss: 0.0975 - acc: 0.9660\n",
      "Epoch 9/10\n",
      "1000/1000 [==============================] - 52s 52ms/step - loss: 0.0840 - acc: 0.9740\n",
      "Epoch 10/10\n",
      "1000/1000 [==============================] - 52s 52ms/step - loss: 0.0733 - acc: 0.9780\n",
      "Training on Epoch  1 batch  5  Files [5] start  15 / 459\n",
      "Epoch 1/10\n",
      "1000/1000 [==============================] - 52s 52ms/step - loss: 0.3313 - acc: 0.8870\n",
      "Epoch 2/10\n",
      "1000/1000 [==============================] - 53s 53ms/step - loss: 0.2497 - acc: 0.9110\n",
      "Epoch 3/10\n",
      "1000/1000 [==============================] - 53s 53ms/step - loss: 0.1941 - acc: 0.9270\n",
      "Epoch 4/10\n",
      "1000/1000 [==============================] - 53s 53ms/step - loss: 0.1636 - acc: 0.9340\n",
      "Epoch 5/10\n",
      "1000/1000 [==============================] - 53s 53ms/step - loss: 0.1359 - acc: 0.9530\n",
      "Epoch 6/10\n",
      "1000/1000 [==============================] - 54s 54ms/step - loss: 0.1205 - acc: 0.9610\n",
      "Epoch 7/10\n",
      "1000/1000 [==============================] - 54s 54ms/step - loss: 0.1109 - acc: 0.9600\n",
      "Epoch 8/10\n",
      "1000/1000 [==============================] - 53s 53ms/step - loss: 0.0996 - acc: 0.9650\n",
      "Epoch 9/10\n",
      "1000/1000 [==============================] - 54s 54ms/step - loss: 0.0925 - acc: 0.9730\n",
      "Epoch 10/10\n",
      "1000/1000 [==============================] - 53s 53ms/step - loss: 0.0830 - acc: 0.9760\n",
      "Training on Epoch  1 batch  5  Files [5] start  20 / 459\n",
      "Epoch 1/10\n",
      "1000/1000 [==============================] - 48s 48ms/step - loss: 0.3572 - acc: 0.8860\n",
      "Epoch 2/10\n",
      "1000/1000 [==============================] - 49s 49ms/step - loss: 0.2718 - acc: 0.9000\n",
      "Epoch 3/10\n",
      "1000/1000 [==============================] - 49s 49ms/step - loss: 0.2087 - acc: 0.9200\n",
      "Epoch 4/10\n",
      "1000/1000 [==============================] - 49s 49ms/step - loss: 0.1739 - acc: 0.9440\n",
      "Epoch 5/10\n",
      "1000/1000 [==============================] - 49s 49ms/step - loss: 0.1513 - acc: 0.9480\n",
      "Epoch 6/10\n",
      "1000/1000 [==============================] - 49s 49ms/step - loss: 0.1261 - acc: 0.9560\n",
      "Epoch 7/10\n",
      "1000/1000 [==============================] - 49s 49ms/step - loss: 0.1107 - acc: 0.9600\n",
      "Epoch 8/10\n",
      "1000/1000 [==============================] - 49s 49ms/step - loss: 0.0949 - acc: 0.9710\n",
      "Epoch 9/10\n",
      "1000/1000 [==============================] - 49s 49ms/step - loss: 0.0875 - acc: 0.9700\n",
      "Epoch 10/10\n",
      "1000/1000 [==============================] - 49s 49ms/step - loss: 0.0839 - acc: 0.9720\n",
      "Training on Epoch  1 batch  5  Files [5] start  25 / 459\n",
      "Epoch 1/10\n",
      "1000/1000 [==============================] - 51s 51ms/step - loss: 0.3895 - acc: 0.8620\n",
      "Epoch 2/10\n",
      "1000/1000 [==============================] - 51s 51ms/step - loss: 0.3004 - acc: 0.8840\n",
      "Epoch 3/10\n",
      "1000/1000 [==============================] - 51s 51ms/step - loss: 0.2451 - acc: 0.9000\n",
      "Epoch 4/10\n",
      "1000/1000 [==============================] - 51s 51ms/step - loss: 0.2062 - acc: 0.9210\n",
      "Epoch 5/10\n",
      "1000/1000 [==============================] - 52s 52ms/step - loss: 0.1801 - acc: 0.9270\n",
      "Epoch 6/10\n",
      "1000/1000 [==============================] - 52s 52ms/step - loss: 0.1564 - acc: 0.9470\n",
      "Epoch 7/10\n",
      "1000/1000 [==============================] - 51s 51ms/step - loss: 0.1375 - acc: 0.9520\n",
      "Epoch 8/10\n",
      "1000/1000 [==============================] - 52s 52ms/step - loss: 0.1233 - acc: 0.9510\n",
      "Epoch 9/10\n",
      "1000/1000 [==============================] - 52s 52ms/step - loss: 0.1113 - acc: 0.9580\n",
      "Epoch 10/10\n",
      "1000/1000 [==============================] - 52s 52ms/step - loss: 0.1021 - acc: 0.9630\n",
      "Training on Epoch  1 batch  5  Files [5] start  30 / 459\n",
      "Epoch 1/10\n",
      "1000/1000 [==============================] - 50s 50ms/step - loss: 0.3293 - acc: 0.8750\n",
      "Epoch 2/10\n",
      "1000/1000 [==============================] - 50s 50ms/step - loss: 0.2508 - acc: 0.9100\n",
      "Epoch 3/10\n",
      "1000/1000 [==============================] - 50s 50ms/step - loss: 0.2046 - acc: 0.9210\n",
      "Epoch 4/10\n",
      "1000/1000 [==============================] - 51s 51ms/step - loss: 0.1739 - acc: 0.9380\n",
      "Epoch 5/10\n",
      "1000/1000 [==============================] - 50s 50ms/step - loss: 0.1492 - acc: 0.9590\n",
      "Epoch 6/10\n",
      "1000/1000 [==============================] - 50s 50ms/step - loss: 0.1320 - acc: 0.9590\n",
      "Epoch 7/10\n",
      "1000/1000 [==============================] - 50s 50ms/step - loss: 0.1173 - acc: 0.9650\n",
      "Epoch 8/10\n",
      "1000/1000 [==============================] - 50s 50ms/step - loss: 0.1083 - acc: 0.9630\n",
      "Epoch 9/10\n",
      "1000/1000 [==============================] - 50s 50ms/step - loss: 0.0968 - acc: 0.9670\n",
      "Epoch 10/10\n",
      "1000/1000 [==============================] - 50s 50ms/step - loss: 0.0864 - acc: 0.9730\n",
      "Training on Epoch  1 batch  5  Files [5] start  35 / 459\n",
      "Epoch 1/10\n",
      "1000/1000 [==============================] - 49s 49ms/step - loss: 0.3244 - acc: 0.8800\n",
      "Epoch 2/10\n",
      "1000/1000 [==============================] - 49s 49ms/step - loss: 0.2326 - acc: 0.9070\n",
      "Epoch 3/10\n",
      "1000/1000 [==============================] - 49s 49ms/step - loss: 0.1860 - acc: 0.9260\n",
      "Epoch 4/10\n",
      "1000/1000 [==============================] - 49s 49ms/step - loss: 0.1584 - acc: 0.9390\n",
      "Epoch 5/10\n",
      "1000/1000 [==============================] - 49s 49ms/step - loss: 0.1403 - acc: 0.9490\n",
      "Epoch 6/10\n",
      "1000/1000 [==============================] - 49s 49ms/step - loss: 0.1240 - acc: 0.9540\n",
      "Epoch 7/10\n",
      "1000/1000 [==============================] - 49s 49ms/step - loss: 0.1110 - acc: 0.9600\n",
      "Epoch 8/10\n",
      "1000/1000 [==============================] - 49s 49ms/step - loss: 0.0971 - acc: 0.9660\n",
      "Epoch 9/10\n",
      "1000/1000 [==============================] - 49s 49ms/step - loss: 0.0882 - acc: 0.9670\n",
      "Epoch 10/10\n",
      "1000/1000 [==============================] - 49s 49ms/step - loss: 0.0803 - acc: 0.9680\n",
      "Training on Epoch  1 batch  5  Files [5] start  40 / 459\n",
      "Epoch 1/10\n",
      "1000/1000 [==============================] - 52s 52ms/step - loss: 0.2896 - acc: 0.8940\n",
      "Epoch 2/10\n",
      "1000/1000 [==============================] - 54s 54ms/step - loss: 0.2135 - acc: 0.9140\n",
      "Epoch 3/10\n",
      "1000/1000 [==============================] - 53s 53ms/step - loss: 0.1746 - acc: 0.9290\n",
      "Epoch 4/10\n",
      "1000/1000 [==============================] - 53s 53ms/step - loss: 0.1513 - acc: 0.9410\n",
      "Epoch 5/10\n",
      "1000/1000 [==============================] - 53s 53ms/step - loss: 0.1281 - acc: 0.9520\n",
      "Epoch 6/10\n",
      "1000/1000 [==============================] - 53s 53ms/step - loss: 0.1043 - acc: 0.9620\n",
      "Epoch 7/10\n",
      "1000/1000 [==============================] - 54s 54ms/step - loss: 0.0792 - acc: 0.9650\n",
      "Epoch 8/10\n",
      "1000/1000 [==============================] - 54s 54ms/step - loss: 0.0673 - acc: 0.9750\n",
      "Epoch 9/10\n",
      "1000/1000 [==============================] - 54s 54ms/step - loss: 0.0587 - acc: 0.9760\n",
      "Epoch 10/10\n",
      "1000/1000 [==============================] - 52s 52ms/step - loss: 0.0502 - acc: 0.9820\n",
      "Training on Epoch  1 batch  5  Files [5] start  45 / 459\n",
      "Epoch 1/10\n",
      "1000/1000 [==============================] - 48s 48ms/step - loss: 0.3848 - acc: 0.8800\n",
      "Epoch 2/10\n",
      "1000/1000 [==============================] - 49s 49ms/step - loss: 0.2783 - acc: 0.9030\n",
      "Epoch 3/10\n",
      "1000/1000 [==============================] - 49s 49ms/step - loss: 0.2076 - acc: 0.9250\n",
      "Epoch 4/10\n",
      "1000/1000 [==============================] - 50s 50ms/step - loss: 0.1806 - acc: 0.9360\n",
      "Epoch 5/10\n",
      "1000/1000 [==============================] - 49s 49ms/step - loss: 0.1512 - acc: 0.9470\n",
      "Epoch 6/10\n",
      "1000/1000 [==============================] - 50s 50ms/step - loss: 0.1308 - acc: 0.9540\n",
      "Epoch 7/10\n",
      "1000/1000 [==============================] - 49s 49ms/step - loss: 0.1135 - acc: 0.9550\n",
      "Epoch 8/10\n",
      "1000/1000 [==============================] - 50s 50ms/step - loss: 0.1029 - acc: 0.9590\n",
      "Epoch 9/10\n",
      "1000/1000 [==============================] - 49s 49ms/step - loss: 0.0923 - acc: 0.9630\n",
      "Epoch 10/10\n",
      "1000/1000 [==============================] - 49s 49ms/step - loss: 0.0820 - acc: 0.9690\n",
      "Training on Epoch  1 batch  5  Files [5] start  50 / 459\n",
      "Epoch 1/10\n",
      "1000/1000 [==============================] - 54s 54ms/step - loss: 0.3789 - acc: 0.8780\n",
      "Epoch 2/10\n",
      "1000/1000 [==============================] - 56s 56ms/step - loss: 0.2834 - acc: 0.9020\n",
      "Epoch 3/10\n",
      "1000/1000 [==============================] - 55s 55ms/step - loss: 0.2121 - acc: 0.9230\n",
      "Epoch 4/10\n",
      "1000/1000 [==============================] - 55s 55ms/step - loss: 0.1759 - acc: 0.9410\n",
      "Epoch 5/10\n",
      "1000/1000 [==============================] - 55s 55ms/step - loss: 0.1517 - acc: 0.9490\n",
      "Epoch 6/10\n",
      "1000/1000 [==============================] - 55s 55ms/step - loss: 0.1349 - acc: 0.9540\n",
      "Epoch 7/10\n",
      "1000/1000 [==============================] - 56s 56ms/step - loss: 0.1198 - acc: 0.9650\n",
      "Epoch 8/10\n",
      "1000/1000 [==============================] - 55s 55ms/step - loss: 0.1084 - acc: 0.9680\n",
      "Epoch 9/10\n",
      "1000/1000 [==============================] - 55s 55ms/step - loss: 0.0993 - acc: 0.9680\n",
      "Epoch 10/10\n",
      "1000/1000 [==============================] - 55s 55ms/step - loss: 0.0925 - acc: 0.9740\n",
      "Training on Epoch  1 batch  5  Files [5] start  55 / 459\n",
      "Epoch 1/10\n",
      "1000/1000 [==============================] - 52s 52ms/step - loss: 0.3281 - acc: 0.8810\n",
      "Epoch 2/10\n",
      "1000/1000 [==============================] - 53s 53ms/step - loss: 0.2530 - acc: 0.9040\n",
      "Epoch 3/10\n",
      "1000/1000 [==============================] - 53s 53ms/step - loss: 0.2167 - acc: 0.9090\n",
      "Epoch 4/10\n",
      "1000/1000 [==============================] - 53s 53ms/step - loss: 0.1797 - acc: 0.9340\n",
      "Epoch 5/10\n",
      "1000/1000 [==============================] - 53s 53ms/step - loss: 0.1523 - acc: 0.9470\n",
      "Epoch 6/10\n",
      "1000/1000 [==============================] - 53s 53ms/step - loss: 0.1355 - acc: 0.9490\n",
      "Epoch 7/10\n",
      "1000/1000 [==============================] - 53s 53ms/step - loss: 0.1178 - acc: 0.9590\n",
      "Epoch 8/10\n",
      "1000/1000 [==============================] - 55s 55ms/step - loss: 0.1051 - acc: 0.9660\n",
      "Epoch 9/10\n",
      "1000/1000 [==============================] - 54s 54ms/step - loss: 0.0955 - acc: 0.9670\n",
      "Epoch 10/10\n",
      "1000/1000 [==============================] - 55s 55ms/step - loss: 0.0869 - acc: 0.9680\n",
      "Training on Epoch  1 batch  5  Files [5] start  60 / 459\n",
      "Epoch 1/10\n",
      "1000/1000 [==============================] - 47s 47ms/step - loss: 0.3427 - acc: 0.8650\n",
      "Epoch 2/10\n",
      "1000/1000 [==============================] - 49s 49ms/step - loss: 0.2502 - acc: 0.8950\n",
      "Epoch 3/10\n",
      "1000/1000 [==============================] - 48s 48ms/step - loss: 0.2028 - acc: 0.9110\n",
      "Epoch 4/10\n",
      "1000/1000 [==============================] - 48s 48ms/step - loss: 0.1684 - acc: 0.9370\n",
      "Epoch 5/10\n",
      "1000/1000 [==============================] - 48s 48ms/step - loss: 0.1481 - acc: 0.9410\n",
      "Epoch 6/10\n",
      "1000/1000 [==============================] - 49s 49ms/step - loss: 0.1351 - acc: 0.9460\n",
      "Epoch 7/10\n",
      "1000/1000 [==============================] - 48s 48ms/step - loss: 0.1217 - acc: 0.9490\n",
      "Epoch 8/10\n",
      "1000/1000 [==============================] - 48s 48ms/step - loss: 0.1121 - acc: 0.9510\n",
      "Epoch 9/10\n",
      "1000/1000 [==============================] - 48s 48ms/step - loss: 0.1064 - acc: 0.9540\n",
      "Epoch 10/10\n",
      "1000/1000 [==============================] - 48s 48ms/step - loss: 0.0982 - acc: 0.9570\n",
      "Training on Epoch  1 batch  5  Files [5] start  65 / 459\n",
      "Epoch 1/10\n",
      "1000/1000 [==============================] - 52s 52ms/step - loss: 0.3638 - acc: 0.8730\n",
      "Epoch 2/10\n",
      "1000/1000 [==============================] - 52s 52ms/step - loss: 0.2674 - acc: 0.8920\n",
      "Epoch 3/10\n",
      "1000/1000 [==============================] - 52s 52ms/step - loss: 0.1977 - acc: 0.9230\n",
      "Epoch 4/10\n",
      "1000/1000 [==============================] - 52s 52ms/step - loss: 0.1592 - acc: 0.9430\n",
      "Epoch 5/10\n",
      "1000/1000 [==============================] - 51s 51ms/step - loss: 0.1370 - acc: 0.9470\n",
      "Epoch 6/10\n",
      "1000/1000 [==============================] - 52s 52ms/step - loss: 0.1200 - acc: 0.9530\n",
      "Epoch 7/10\n",
      "1000/1000 [==============================] - 53s 53ms/step - loss: 0.1068 - acc: 0.9570\n",
      "Epoch 8/10\n",
      "1000/1000 [==============================] - 51s 51ms/step - loss: 0.0932 - acc: 0.9620\n",
      "Epoch 9/10\n",
      "1000/1000 [==============================] - 52s 52ms/step - loss: 0.0828 - acc: 0.9680\n",
      "Epoch 10/10\n",
      "1000/1000 [==============================] - 51s 51ms/step - loss: 0.0779 - acc: 0.9670\n",
      "Training on Epoch  1 batch  5  Files [5] start  70 / 459\n",
      "Epoch 1/10\n",
      "1000/1000 [==============================] - 52s 52ms/step - loss: 0.3962 - acc: 0.8690\n",
      "Epoch 2/10\n",
      "1000/1000 [==============================] - 51s 51ms/step - loss: 0.2887 - acc: 0.8970\n",
      "Epoch 3/10\n",
      "1000/1000 [==============================] - 51s 51ms/step - loss: 0.2282 - acc: 0.9130\n",
      "Epoch 4/10\n",
      "1000/1000 [==============================] - 52s 52ms/step - loss: 0.1825 - acc: 0.9360\n",
      "Epoch 5/10\n",
      "1000/1000 [==============================] - 52s 52ms/step - loss: 0.1572 - acc: 0.9450\n",
      "Epoch 6/10\n",
      "1000/1000 [==============================] - 51s 51ms/step - loss: 0.1380 - acc: 0.9560\n",
      "Epoch 7/10\n",
      "1000/1000 [==============================] - 52s 52ms/step - loss: 0.1208 - acc: 0.9590\n",
      "Epoch 8/10\n",
      "1000/1000 [==============================] - 51s 51ms/step - loss: 0.1039 - acc: 0.9630\n",
      "Epoch 9/10\n",
      "1000/1000 [==============================] - 52s 52ms/step - loss: 0.0935 - acc: 0.9690\n",
      "Epoch 10/10\n",
      "1000/1000 [==============================] - 52s 52ms/step - loss: 0.0829 - acc: 0.9720\n",
      "Training on Epoch  1 batch  5  Files [5] start  75 / 459\n",
      "Epoch 1/10\n",
      "1000/1000 [==============================] - 58s 58ms/step - loss: 0.4003 - acc: 0.8490\n",
      "Epoch 2/10\n",
      "1000/1000 [==============================] - 58s 58ms/step - loss: 0.3162 - acc: 0.8670\n",
      "Epoch 3/10\n",
      "1000/1000 [==============================] - 58s 58ms/step - loss: 0.2538 - acc: 0.8860\n",
      "Epoch 4/10\n",
      "1000/1000 [==============================] - 58s 58ms/step - loss: 0.2320 - acc: 0.8950\n",
      "Epoch 5/10\n",
      "1000/1000 [==============================] - 58s 58ms/step - loss: 0.1977 - acc: 0.9070\n",
      "Epoch 6/10\n",
      "1000/1000 [==============================] - 58s 58ms/step - loss: 0.1766 - acc: 0.9250\n",
      "Epoch 7/10\n",
      "1000/1000 [==============================] - 58s 58ms/step - loss: 0.1601 - acc: 0.9380\n",
      "Epoch 8/10\n",
      "1000/1000 [==============================] - 58s 58ms/step - loss: 0.1436 - acc: 0.9450\n",
      "Epoch 9/10\n",
      "1000/1000 [==============================] - 58s 58ms/step - loss: 0.1321 - acc: 0.9470\n",
      "Epoch 10/10\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 0.1265 - acc: 0.9510\n",
      "Training on Epoch  1 batch  5  Files [5] start  80 / 459\n",
      "Epoch 1/10\n",
      "1000/1000 [==============================] - 57s 57ms/step - loss: 0.4073 - acc: 0.8530\n",
      "Epoch 2/10\n",
      "1000/1000 [==============================] - 57s 57ms/step - loss: 0.3171 - acc: 0.8610\n",
      "Epoch 3/10\n",
      "1000/1000 [==============================] - 58s 58ms/step - loss: 0.2530 - acc: 0.8960\n",
      "Epoch 4/10\n",
      "1000/1000 [==============================] - 58s 58ms/step - loss: 0.2077 - acc: 0.9130\n",
      "Epoch 5/10\n",
      "1000/1000 [==============================] - 58s 58ms/step - loss: 0.1775 - acc: 0.9220\n",
      "Epoch 6/10\n",
      "1000/1000 [==============================] - 58s 58ms/step - loss: 0.1577 - acc: 0.9310\n",
      "Epoch 7/10\n",
      "1000/1000 [==============================] - 57s 57ms/step - loss: 0.1477 - acc: 0.9390\n",
      "Epoch 8/10\n",
      "1000/1000 [==============================] - 57s 57ms/step - loss: 0.1353 - acc: 0.9550\n",
      "Epoch 9/10\n",
      "1000/1000 [==============================] - 57s 57ms/step - loss: 0.1154 - acc: 0.9550\n",
      "Epoch 10/10\n",
      "1000/1000 [==============================] - 57s 57ms/step - loss: 0.1044 - acc: 0.9610\n",
      "Training on Epoch  1 batch  5  Files [5] start  85 / 459\n",
      "Epoch 1/10\n",
      "1000/1000 [==============================] - 51s 51ms/step - loss: 0.3778 - acc: 0.8530\n",
      "Epoch 2/10\n",
      "1000/1000 [==============================] - 51s 51ms/step - loss: 0.2918 - acc: 0.8810\n",
      "Epoch 3/10\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000/1000 [==============================] - 51s 51ms/step - loss: 0.2363 - acc: 0.9030\n",
      "Epoch 4/10\n",
      "1000/1000 [==============================] - 51s 51ms/step - loss: 0.1970 - acc: 0.9260\n",
      "Epoch 5/10\n",
      "1000/1000 [==============================] - 51s 51ms/step - loss: 0.1715 - acc: 0.9380\n",
      "Epoch 6/10\n",
      "1000/1000 [==============================] - 51s 51ms/step - loss: 0.1499 - acc: 0.9430\n",
      "Epoch 7/10\n",
      "1000/1000 [==============================] - 51s 51ms/step - loss: 0.1374 - acc: 0.9450\n",
      "Epoch 8/10\n",
      "1000/1000 [==============================] - 51s 51ms/step - loss: 0.1266 - acc: 0.9490\n",
      "Epoch 9/10\n",
      "1000/1000 [==============================] - 51s 51ms/step - loss: 0.1124 - acc: 0.9530\n",
      "Epoch 10/10\n",
      "1000/1000 [==============================] - 51s 51ms/step - loss: 0.1019 - acc: 0.9620\n",
      "Training on Epoch  1 batch  5  Files [5] start  90 / 459\n",
      "Epoch 1/10\n",
      "1000/1000 [==============================] - 46s 46ms/step - loss: 0.3652 - acc: 0.8670\n",
      "Epoch 2/10\n",
      "1000/1000 [==============================] - 50s 50ms/step - loss: 0.2671 - acc: 0.8870\n",
      "Epoch 3/10\n",
      "1000/1000 [==============================] - 49s 49ms/step - loss: 0.2146 - acc: 0.9110\n",
      "Epoch 4/10\n",
      "1000/1000 [==============================] - 53s 53ms/step - loss: 0.1815 - acc: 0.9380\n",
      "Epoch 5/10\n",
      "1000/1000 [==============================] - 49s 49ms/step - loss: 0.1542 - acc: 0.9440\n",
      "Epoch 6/10\n",
      "1000/1000 [==============================] - 47s 47ms/step - loss: 0.1370 - acc: 0.9570\n",
      "Epoch 7/10\n",
      "1000/1000 [==============================] - 48s 48ms/step - loss: 0.1232 - acc: 0.9580\n",
      "Epoch 8/10\n",
      "1000/1000 [==============================] - 48s 48ms/step - loss: 0.1118 - acc: 0.9640\n",
      "Epoch 9/10\n",
      "1000/1000 [==============================] - 47s 47ms/step - loss: 0.1058 - acc: 0.9640\n",
      "Epoch 10/10\n",
      "1000/1000 [==============================] - 47s 47ms/step - loss: 0.0972 - acc: 0.9670\n",
      "Training on Epoch  1 batch  5  Files [5] start  95 / 459\n",
      "Epoch 1/10\n",
      "1000/1000 [==============================] - 57s 57ms/step - loss: 0.3542 - acc: 0.8590\n",
      "Epoch 2/10\n",
      "1000/1000 [==============================] - 54s 54ms/step - loss: 0.2633 - acc: 0.8950\n",
      "Epoch 3/10\n",
      "1000/1000 [==============================] - 55s 55ms/step - loss: 0.2163 - acc: 0.9190\n",
      "Epoch 4/10\n",
      "1000/1000 [==============================] - 56s 56ms/step - loss: 0.1992 - acc: 0.9190\n",
      "Epoch 5/10\n",
      "1000/1000 [==============================] - 55s 55ms/step - loss: 0.1667 - acc: 0.9300\n",
      "Epoch 6/10\n",
      "1000/1000 [==============================] - 54s 54ms/step - loss: 0.1455 - acc: 0.9380\n",
      "Epoch 7/10\n",
      "1000/1000 [==============================] - 54s 54ms/step - loss: 0.1281 - acc: 0.9470\n",
      "Epoch 8/10\n",
      "1000/1000 [==============================] - 56s 56ms/step - loss: 0.1083 - acc: 0.9570\n",
      "Epoch 9/10\n",
      "1000/1000 [==============================] - 61s 61ms/step - loss: 0.0995 - acc: 0.9580\n",
      "Epoch 10/10\n",
      "1000/1000 [==============================] - 62s 62ms/step - loss: 0.0923 - acc: 0.9580\n",
      "Training on Epoch  1 batch  5  Files [5] start  100 / 459\n",
      "Epoch 1/10\n",
      "1000/1000 [==============================] - 55s 55ms/step - loss: 0.3865 - acc: 0.8670\n",
      "Epoch 2/10\n",
      "1000/1000 [==============================] - 52s 52ms/step - loss: 0.2898 - acc: 0.8740\n",
      "Epoch 3/10\n",
      "1000/1000 [==============================] - 52s 52ms/step - loss: 0.2348 - acc: 0.9020\n",
      "Epoch 4/10\n",
      "1000/1000 [==============================] - 52s 52ms/step - loss: 0.1811 - acc: 0.9330\n",
      "Epoch 5/10\n",
      "1000/1000 [==============================] - 53s 53ms/step - loss: 0.1522 - acc: 0.9390\n",
      "Epoch 6/10\n",
      "1000/1000 [==============================] - 52s 52ms/step - loss: 0.1353 - acc: 0.9470\n",
      "Epoch 7/10\n",
      "1000/1000 [==============================] - 52s 52ms/step - loss: 0.1175 - acc: 0.9570\n",
      "Epoch 8/10\n",
      "1000/1000 [==============================] - 53s 53ms/step - loss: 0.1003 - acc: 0.9690\n",
      "Epoch 9/10\n",
      "1000/1000 [==============================] - 52s 52ms/step - loss: 0.0886 - acc: 0.9750\n",
      "Epoch 10/10\n",
      "1000/1000 [==============================] - 52s 52ms/step - loss: 0.0805 - acc: 0.9760\n",
      "Training on Epoch  1 batch  5  Files [5] start  105 / 459\n",
      "Epoch 1/10\n",
      "1000/1000 [==============================] - 56s 56ms/step - loss: 0.3240 - acc: 0.8780\n",
      "Epoch 2/10\n",
      "1000/1000 [==============================] - 57s 57ms/step - loss: 0.2578 - acc: 0.8890\n",
      "Epoch 3/10\n",
      "1000/1000 [==============================] - 57s 57ms/step - loss: 0.1854 - acc: 0.9260\n",
      "Epoch 4/10\n",
      "1000/1000 [==============================] - 57s 57ms/step - loss: 0.1567 - acc: 0.9420\n",
      "Epoch 5/10\n",
      "1000/1000 [==============================] - 57s 57ms/step - loss: 0.1309 - acc: 0.9550\n",
      "Epoch 6/10\n",
      "1000/1000 [==============================] - 57s 57ms/step - loss: 0.1118 - acc: 0.9580\n",
      "Epoch 7/10\n",
      "1000/1000 [==============================] - 57s 57ms/step - loss: 0.0961 - acc: 0.9610\n",
      "Epoch 8/10\n",
      "1000/1000 [==============================] - 61s 61ms/step - loss: 0.0844 - acc: 0.9710\n",
      "Epoch 9/10\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 0.0770 - acc: 0.9740\n",
      "Epoch 10/10\n",
      "1000/1000 [==============================] - 61s 61ms/step - loss: 0.0713 - acc: 0.9770\n",
      "Training on Epoch  1 batch  5  Files [5] start  110 / 459\n",
      "Epoch 1/10\n",
      "1000/1000 [==============================] - 69s 69ms/step - loss: 0.4077 - acc: 0.8510\n",
      "Epoch 2/10\n",
      "1000/1000 [==============================] - 72s 72ms/step - loss: 0.3061 - acc: 0.8780\n",
      "Epoch 3/10\n",
      "1000/1000 [==============================] - 73s 73ms/step - loss: 0.2335 - acc: 0.9080\n",
      "Epoch 4/10\n",
      "1000/1000 [==============================] - 70s 70ms/step - loss: 0.1924 - acc: 0.9250\n",
      "Epoch 5/10\n",
      "1000/1000 [==============================] - 72s 72ms/step - loss: 0.1616 - acc: 0.9420\n",
      "Epoch 6/10\n",
      "1000/1000 [==============================] - 70s 70ms/step - loss: 0.1423 - acc: 0.9490\n",
      "Epoch 7/10\n",
      "1000/1000 [==============================] - 67s 67ms/step - loss: 0.1276 - acc: 0.9470\n",
      "Epoch 8/10\n",
      "1000/1000 [==============================] - 66s 66ms/step - loss: 0.1122 - acc: 0.9570\n",
      "Epoch 9/10\n",
      "1000/1000 [==============================] - 66s 66ms/step - loss: 0.1012 - acc: 0.9600\n",
      "Epoch 10/10\n",
      "1000/1000 [==============================] - 64s 64ms/step - loss: 0.0924 - acc: 0.9700\n",
      "Training on Epoch  1 batch  5  Files [5] start  115 / 459\n",
      "Epoch 1/10\n",
      "1000/1000 [==============================] - 62s 62ms/step - loss: 0.4040 - acc: 0.8460\n",
      "Epoch 2/10\n",
      "1000/1000 [==============================] - 62s 62ms/step - loss: 0.2927 - acc: 0.8770\n",
      "Epoch 3/10\n",
      "1000/1000 [==============================] - 63s 63ms/step - loss: 0.2624 - acc: 0.8950\n",
      "Epoch 4/10\n",
      "1000/1000 [==============================] - 63s 63ms/step - loss: 0.2287 - acc: 0.9040\n",
      "Epoch 5/10\n",
      "1000/1000 [==============================] - 64s 64ms/step - loss: 0.2057 - acc: 0.9130\n",
      "Epoch 6/10\n",
      "1000/1000 [==============================] - 67s 67ms/step - loss: 0.1853 - acc: 0.9190\n",
      "Epoch 7/10\n",
      "1000/1000 [==============================] - 63s 63ms/step - loss: 0.1649 - acc: 0.9310\n",
      "Epoch 8/10\n",
      "1000/1000 [==============================] - 69s 69ms/step - loss: 0.1523 - acc: 0.9380\n",
      "Epoch 9/10\n",
      "1000/1000 [==============================] - 71s 71ms/step - loss: 0.1437 - acc: 0.9460\n",
      "Epoch 10/10\n",
      "1000/1000 [==============================] - 70s 70ms/step - loss: 0.1352 - acc: 0.9440\n",
      "Training on Epoch  1 batch  5  Files [5] start  120 / 459\n",
      "Epoch 1/10\n",
      "1000/1000 [==============================] - 68s 68ms/step - loss: 0.3379 - acc: 0.8610\n",
      "Epoch 2/10\n",
      "1000/1000 [==============================] - 73s 73ms/step - loss: 0.2770 - acc: 0.8680\n",
      "Epoch 3/10\n",
      "1000/1000 [==============================] - 72s 72ms/step - loss: 0.2406 - acc: 0.8900\n",
      "Epoch 4/10\n",
      "1000/1000 [==============================] - 72s 72ms/step - loss: 0.2218 - acc: 0.8980\n",
      "Epoch 5/10\n",
      "1000/1000 [==============================] - 71s 71ms/step - loss: 0.2053 - acc: 0.9100\n",
      "Epoch 6/10\n",
      "1000/1000 [==============================] - 70s 70ms/step - loss: 0.1955 - acc: 0.9170\n",
      "Epoch 7/10\n",
      "1000/1000 [==============================] - 70s 70ms/step - loss: 0.1872 - acc: 0.9180\n",
      "Epoch 8/10\n",
      "1000/1000 [==============================] - 71s 71ms/step - loss: 0.1808 - acc: 0.9200\n",
      "Epoch 9/10\n",
      "1000/1000 [==============================] - 70s 70ms/step - loss: 0.1813 - acc: 0.9210\n",
      "Epoch 10/10\n",
      "1000/1000 [==============================] - 75s 75ms/step - loss: 0.1730 - acc: 0.9220\n",
      "Training on Epoch  1 batch  5  Files [5] start  125 / 459\n",
      "Epoch 1/10\n",
      "1000/1000 [==============================] - 68s 68ms/step - loss: 0.3802 - acc: 0.8430\n",
      "Epoch 2/10\n",
      "1000/1000 [==============================] - 70s 70ms/step - loss: 0.3128 - acc: 0.8650\n",
      "Epoch 3/10\n",
      "1000/1000 [==============================] - 65s 65ms/step - loss: 0.2661 - acc: 0.8820\n",
      "Epoch 4/10\n",
      "1000/1000 [==============================] - 63s 63ms/step - loss: 0.2417 - acc: 0.8950\n",
      "Epoch 5/10\n",
      "1000/1000 [==============================] - 61s 61ms/step - loss: 0.2219 - acc: 0.9050\n",
      "Epoch 6/10\n",
      "1000/1000 [==============================] - 62s 62ms/step - loss: 0.2065 - acc: 0.9080\n",
      "Epoch 7/10\n",
      "1000/1000 [==============================] - 62s 62ms/step - loss: 0.1978 - acc: 0.9080\n",
      "Epoch 8/10\n",
      "1000/1000 [==============================] - 63s 63ms/step - loss: 0.1845 - acc: 0.9100\n",
      "Epoch 9/10\n",
      "1000/1000 [==============================] - 62s 62ms/step - loss: 0.1774 - acc: 0.9150\n",
      "Epoch 10/10\n",
      "1000/1000 [==============================] - 63s 63ms/step - loss: 0.1701 - acc: 0.9190\n",
      "Training on Epoch  1 batch  5  Files [5] start  130 / 459\n",
      "Epoch 1/10\n",
      "1000/1000 [==============================] - 65s 65ms/step - loss: 0.4054 - acc: 0.8360\n",
      "Epoch 2/10\n",
      "1000/1000 [==============================] - 65s 65ms/step - loss: 0.3362 - acc: 0.8500\n",
      "Epoch 3/10\n",
      "1000/1000 [==============================] - 65s 65ms/step - loss: 0.2952 - acc: 0.8800\n",
      "Epoch 4/10\n",
      "1000/1000 [==============================] - 71s 71ms/step - loss: 0.2707 - acc: 0.8880\n",
      "Epoch 5/10\n",
      "1000/1000 [==============================] - 70s 70ms/step - loss: 0.2503 - acc: 0.8930\n",
      "Epoch 6/10\n",
      "1000/1000 [==============================] - 71s 71ms/step - loss: 0.2304 - acc: 0.9020\n",
      "Epoch 7/10\n",
      "1000/1000 [==============================] - 66s 66ms/step - loss: 0.2178 - acc: 0.9100\n",
      "Epoch 8/10\n",
      "1000/1000 [==============================] - 66s 66ms/step - loss: 0.2068 - acc: 0.9120\n",
      "Epoch 9/10\n",
      "1000/1000 [==============================] - 67s 67ms/step - loss: 0.1975 - acc: 0.9200\n",
      "Epoch 10/10\n",
      "1000/1000 [==============================] - 70s 70ms/step - loss: 0.1897 - acc: 0.9230\n",
      "Training on Epoch  1 batch  5  Files [5] start  135 / 459\n",
      "Epoch 1/10\n",
      "1000/1000 [==============================] - 68s 68ms/step - loss: 0.3439 - acc: 0.8510\n",
      "Epoch 2/10\n",
      "1000/1000 [==============================] - 73s 73ms/step - loss: 0.2967 - acc: 0.8610\n",
      "Epoch 3/10\n",
      "1000/1000 [==============================] - 71s 71ms/step - loss: 0.2740 - acc: 0.8670\n",
      "Epoch 4/10\n",
      "1000/1000 [==============================] - 74s 74ms/step - loss: 0.2535 - acc: 0.8800\n",
      "Epoch 5/10\n",
      "1000/1000 [==============================] - 70s 70ms/step - loss: 0.2461 - acc: 0.8850\n",
      "Epoch 6/10\n",
      "1000/1000 [==============================] - 71s 71ms/step - loss: 0.2342 - acc: 0.8900\n",
      "Epoch 7/10\n",
      "1000/1000 [==============================] - 73s 73ms/step - loss: 0.2221 - acc: 0.8940\n",
      "Epoch 8/10\n",
      "1000/1000 [==============================] - 70s 70ms/step - loss: 0.2146 - acc: 0.8980\n",
      "Epoch 9/10\n",
      "1000/1000 [==============================] - 73s 73ms/step - loss: 0.2062 - acc: 0.9040\n",
      "Epoch 10/10\n",
      "1000/1000 [==============================] - 71s 71ms/step - loss: 0.2024 - acc: 0.9040\n",
      "Training on Epoch  1 batch  5  Files [5] start  140 / 459\n",
      "Epoch 1/10\n",
      "1000/1000 [==============================] - 65s 65ms/step - loss: 0.4059 - acc: 0.8600\n",
      "Epoch 2/10\n",
      "1000/1000 [==============================] - 60s 60ms/step - loss: 0.3062 - acc: 0.8730\n",
      "Epoch 3/10\n",
      "1000/1000 [==============================] - 62s 62ms/step - loss: 0.2566 - acc: 0.8840\n",
      "Epoch 4/10\n",
      "1000/1000 [==============================] - 64s 64ms/step - loss: 0.2151 - acc: 0.9050\n",
      "Epoch 5/10\n",
      "1000/1000 [==============================] - 61s 61ms/step - loss: 0.1881 - acc: 0.9150\n",
      "Epoch 6/10\n",
      "1000/1000 [==============================] - 61s 61ms/step - loss: 0.1668 - acc: 0.9220\n",
      "Epoch 7/10\n",
      "1000/1000 [==============================] - 60s 60ms/step - loss: 0.1663 - acc: 0.9230\n",
      "Epoch 8/10\n",
      "1000/1000 [==============================] - 60s 60ms/step - loss: 0.1589 - acc: 0.9320\n",
      "Epoch 9/10\n",
      "1000/1000 [==============================] - 60s 60ms/step - loss: 0.1438 - acc: 0.9410\n",
      "Epoch 10/10\n",
      "1000/1000 [==============================] - 65s 65ms/step - loss: 0.1450 - acc: 0.9310\n",
      "Training on Epoch  1 batch  5  Files [5] start  145 / 459\n",
      "Epoch 1/10\n",
      "1000/1000 [==============================] - 63s 63ms/step - loss: 0.3549 - acc: 0.8710\n",
      "Epoch 2/10\n",
      "1000/1000 [==============================] - 61s 61ms/step - loss: 0.2936 - acc: 0.8890\n",
      "Epoch 3/10\n",
      "1000/1000 [==============================] - 63s 63ms/step - loss: 0.2490 - acc: 0.8980\n",
      "Epoch 4/10\n",
      "1000/1000 [==============================] - 62s 62ms/step - loss: 0.2066 - acc: 0.9120\n",
      "Epoch 5/10\n",
      "1000/1000 [==============================] - 62s 62ms/step - loss: 0.1812 - acc: 0.9250\n",
      "Epoch 6/10\n",
      "1000/1000 [==============================] - 62s 62ms/step - loss: 0.1517 - acc: 0.9330\n",
      "Epoch 7/10\n",
      "1000/1000 [==============================] - 61s 61ms/step - loss: 0.1331 - acc: 0.9510\n",
      "Epoch 8/10\n",
      "1000/1000 [==============================] - 60s 60ms/step - loss: 0.1185 - acc: 0.9560\n",
      "Epoch 9/10\n",
      "1000/1000 [==============================] - 61s 61ms/step - loss: 0.1041 - acc: 0.9620\n",
      "Epoch 10/10\n",
      "1000/1000 [==============================] - 64s 64ms/step - loss: 0.0964 - acc: 0.9660\n",
      "Training on Epoch  1 batch  5  Files [5] start  150 / 459\n",
      "Epoch 1/10\n",
      "1000/1000 [==============================] - 67s 67ms/step - loss: 0.4020 - acc: 0.8450\n",
      "Epoch 2/10\n",
      "1000/1000 [==============================] - 69s 69ms/step - loss: 0.3015 - acc: 0.8830\n",
      "Epoch 3/10\n",
      "1000/1000 [==============================] - 68s 68ms/step - loss: 0.2498 - acc: 0.9040\n",
      "Epoch 4/10\n",
      "1000/1000 [==============================] - 61s 61ms/step - loss: 0.2091 - acc: 0.9180\n",
      "Epoch 5/10\n",
      "1000/1000 [==============================] - 61s 61ms/step - loss: 0.1822 - acc: 0.9340\n",
      "Epoch 6/10\n",
      "1000/1000 [==============================] - 61s 61ms/step - loss: 0.1606 - acc: 0.9400\n",
      "Epoch 7/10\n",
      "1000/1000 [==============================] - 61s 61ms/step - loss: 0.1429 - acc: 0.9470\n",
      "Epoch 8/10\n",
      "1000/1000 [==============================] - 60s 60ms/step - loss: 0.1278 - acc: 0.9500\n",
      "Epoch 9/10\n",
      "1000/1000 [==============================] - 61s 61ms/step - loss: 0.1226 - acc: 0.9530\n",
      "Epoch 10/10\n",
      "1000/1000 [==============================] - 61s 61ms/step - loss: 0.1117 - acc: 0.9550\n",
      "Training on Epoch  1 batch  5  Files [5] start  155 / 459\n",
      "Epoch 1/10\n",
      "1000/1000 [==============================] - 60s 60ms/step - loss: 0.2444 - acc: 0.8970\n",
      "Epoch 2/10\n",
      "1000/1000 [==============================] - 60s 60ms/step - loss: 0.1897 - acc: 0.9140\n",
      "Epoch 3/10\n",
      "1000/1000 [==============================] - 58s 58ms/step - loss: 0.1528 - acc: 0.9280\n",
      "Epoch 4/10\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 0.1271 - acc: 0.9430\n",
      "Epoch 5/10\n",
      "1000/1000 [==============================] - 58s 58ms/step - loss: 0.1150 - acc: 0.9510\n",
      "Epoch 6/10\n",
      "1000/1000 [==============================] - 58s 58ms/step - loss: 0.1037 - acc: 0.9560\n",
      "Epoch 7/10\n",
      "1000/1000 [==============================] - 58s 58ms/step - loss: 0.0941 - acc: 0.9580\n",
      "Epoch 8/10\n",
      "1000/1000 [==============================] - 58s 58ms/step - loss: 0.0877 - acc: 0.9590\n",
      "Epoch 9/10\n",
      "1000/1000 [==============================] - 58s 58ms/step - loss: 0.0813 - acc: 0.9630\n",
      "Epoch 10/10\n",
      "1000/1000 [==============================] - 58s 58ms/step - loss: 0.0766 - acc: 0.9640\n",
      "Training on Epoch  1 batch  5  Files [5] start  160 / 459\n",
      "Epoch 1/10\n",
      "1000/1000 [==============================] - 62s 62ms/step - loss: 0.2566 - acc: 0.9070\n",
      "Epoch 2/10\n",
      "1000/1000 [==============================] - 62s 62ms/step - loss: 0.1760 - acc: 0.9190\n",
      "Epoch 3/10\n",
      "1000/1000 [==============================] - 62s 62ms/step - loss: 0.1421 - acc: 0.9430\n",
      "Epoch 4/10\n",
      "1000/1000 [==============================] - 62s 62ms/step - loss: 0.1194 - acc: 0.9560\n",
      "Epoch 5/10\n",
      "1000/1000 [==============================] - 62s 62ms/step - loss: 0.1010 - acc: 0.9600\n",
      "Epoch 6/10\n",
      "1000/1000 [==============================] - 62s 62ms/step - loss: 0.0930 - acc: 0.9590\n",
      "Epoch 7/10\n",
      "1000/1000 [==============================] - 62s 62ms/step - loss: 0.0822 - acc: 0.9650\n",
      "Epoch 8/10\n",
      "1000/1000 [==============================] - 62s 62ms/step - loss: 0.0781 - acc: 0.9680\n",
      "Epoch 9/10\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000/1000 [==============================] - 62s 62ms/step - loss: 0.0738 - acc: 0.9720\n",
      "Epoch 10/10\n",
      "1000/1000 [==============================] - 61s 61ms/step - loss: 0.0671 - acc: 0.9720\n",
      "Training on Epoch  1 batch  5  Files [5] start  165 / 459\n",
      "Epoch 1/10\n",
      "1000/1000 [==============================] - 61s 61ms/step - loss: 0.2216 - acc: 0.8910\n",
      "Epoch 2/10\n",
      "1000/1000 [==============================] - 60s 60ms/step - loss: 0.1901 - acc: 0.9050\n",
      "Epoch 3/10\n",
      "1000/1000 [==============================] - 60s 60ms/step - loss: 0.1499 - acc: 0.9200\n",
      "Epoch 4/10\n",
      "1000/1000 [==============================] - 61s 61ms/step - loss: 0.1320 - acc: 0.9340\n",
      "Epoch 5/10\n",
      "1000/1000 [==============================] - 61s 61ms/step - loss: 0.1188 - acc: 0.9410\n",
      "Epoch 6/10\n",
      "1000/1000 [==============================] - 60s 60ms/step - loss: 0.1112 - acc: 0.9360\n",
      "Epoch 7/10\n",
      "1000/1000 [==============================] - 61s 61ms/step - loss: 0.1056 - acc: 0.9480\n",
      "Epoch 8/10\n",
      "1000/1000 [==============================] - 61s 61ms/step - loss: 0.0974 - acc: 0.9500\n",
      "Epoch 9/10\n",
      "1000/1000 [==============================] - 61s 61ms/step - loss: 0.0961 - acc: 0.9470\n",
      "Epoch 10/10\n",
      "1000/1000 [==============================] - 61s 61ms/step - loss: 0.0954 - acc: 0.9500\n",
      "Training on Epoch  1 batch  5  Files [5] start  170 / 459\n",
      "Epoch 1/10\n",
      "1000/1000 [==============================] - 60s 60ms/step - loss: 0.2109 - acc: 0.9180\n",
      "Epoch 2/10\n",
      "1000/1000 [==============================] - 62s 62ms/step - loss: 0.1941 - acc: 0.9090\n",
      "Epoch 3/10\n",
      "1000/1000 [==============================] - 61s 61ms/step - loss: 0.1753 - acc: 0.9230\n",
      "Epoch 4/10\n",
      "1000/1000 [==============================] - 62s 62ms/step - loss: 0.1536 - acc: 0.9360\n",
      "Epoch 5/10\n",
      "1000/1000 [==============================] - 63s 63ms/step - loss: 0.1306 - acc: 0.9450\n",
      "Epoch 6/10\n",
      "1000/1000 [==============================] - 62s 62ms/step - loss: 0.1102 - acc: 0.9560\n",
      "Epoch 7/10\n",
      "1000/1000 [==============================] - 61s 61ms/step - loss: 0.1016 - acc: 0.9570\n",
      "Epoch 8/10\n",
      "1000/1000 [==============================] - 62s 62ms/step - loss: 0.0955 - acc: 0.9600\n",
      "Epoch 9/10\n",
      "1000/1000 [==============================] - 63s 63ms/step - loss: 0.0871 - acc: 0.9640\n",
      "Epoch 10/10\n",
      "1000/1000 [==============================] - 62s 62ms/step - loss: 0.0790 - acc: 0.9660\n",
      "Training on Epoch  1 batch  5  Files [5] start  175 / 459\n",
      "Epoch 1/10\n",
      "1000/1000 [==============================] - 60s 60ms/step - loss: 0.2932 - acc: 0.8980\n",
      "Epoch 2/10\n",
      "1000/1000 [==============================] - 61s 61ms/step - loss: 0.2056 - acc: 0.9170\n",
      "Epoch 3/10\n",
      "1000/1000 [==============================] - 61s 61ms/step - loss: 0.1758 - acc: 0.9180\n",
      "Epoch 4/10\n",
      "1000/1000 [==============================] - 61s 61ms/step - loss: 0.1436 - acc: 0.9410\n",
      "Epoch 5/10\n",
      "1000/1000 [==============================] - 61s 61ms/step - loss: 0.1320 - acc: 0.9530\n",
      "Epoch 6/10\n",
      "1000/1000 [==============================] - 61s 61ms/step - loss: 0.1145 - acc: 0.9530\n",
      "Epoch 7/10\n",
      "1000/1000 [==============================] - 61s 61ms/step - loss: 0.1020 - acc: 0.9610\n",
      "Epoch 8/10\n",
      "1000/1000 [==============================] - 61s 61ms/step - loss: 0.0948 - acc: 0.9610\n",
      "Epoch 9/10\n",
      "1000/1000 [==============================] - 61s 61ms/step - loss: 0.0867 - acc: 0.9660\n",
      "Epoch 10/10\n",
      "1000/1000 [==============================] - 61s 61ms/step - loss: 0.0802 - acc: 0.9700\n",
      "Training on Epoch  1 batch  5  Files [5] start  180 / 459\n",
      "Epoch 1/10\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 0.1679 - acc: 0.9270\n",
      "Epoch 2/10\n",
      "1000/1000 [==============================] - 60s 60ms/step - loss: 0.1387 - acc: 0.9410\n",
      "Epoch 3/10\n",
      "1000/1000 [==============================] - 60s 60ms/step - loss: 0.1227 - acc: 0.9470\n",
      "Epoch 4/10\n",
      "1000/1000 [==============================] - 60s 60ms/step - loss: 0.1037 - acc: 0.9530\n",
      "Epoch 5/10\n",
      "1000/1000 [==============================] - 60s 60ms/step - loss: 0.0939 - acc: 0.9510\n",
      "Epoch 6/10\n",
      "1000/1000 [==============================] - 60s 60ms/step - loss: 0.0855 - acc: 0.9600\n",
      "Epoch 7/10\n",
      "1000/1000 [==============================] - 60s 60ms/step - loss: 0.0805 - acc: 0.9610\n",
      "Epoch 8/10\n",
      "1000/1000 [==============================] - 61s 61ms/step - loss: 0.0754 - acc: 0.9620\n",
      "Epoch 9/10\n",
      "1000/1000 [==============================] - 60s 60ms/step - loss: 0.0699 - acc: 0.9660\n",
      "Epoch 10/10\n",
      "1000/1000 [==============================] - 60s 60ms/step - loss: 0.0661 - acc: 0.9660\n",
      "Training on Epoch  1 batch  5  Files [5] start  185 / 459\n",
      "Epoch 1/10\n",
      "1000/1000 [==============================] - 61s 61ms/step - loss: 0.1832 - acc: 0.9140\n",
      "Epoch 2/10\n",
      "1000/1000 [==============================] - 62s 62ms/step - loss: 0.1549 - acc: 0.9260\n",
      "Epoch 3/10\n",
      "1000/1000 [==============================] - 62s 62ms/step - loss: 0.1394 - acc: 0.9260\n",
      "Epoch 4/10\n",
      "1000/1000 [==============================] - 62s 62ms/step - loss: 0.1318 - acc: 0.9310\n",
      "Epoch 5/10\n",
      "1000/1000 [==============================] - 63s 63ms/step - loss: 0.1242 - acc: 0.9330\n",
      "Epoch 6/10\n",
      "1000/1000 [==============================] - 62s 62ms/step - loss: 0.1197 - acc: 0.9370\n",
      "Epoch 7/10\n",
      "1000/1000 [==============================] - 62s 62ms/step - loss: 0.1145 - acc: 0.9320\n",
      "Epoch 8/10\n",
      "1000/1000 [==============================] - 62s 62ms/step - loss: 0.1104 - acc: 0.9400\n",
      "Epoch 9/10\n",
      "1000/1000 [==============================] - 62s 62ms/step - loss: 0.1075 - acc: 0.9400\n",
      "Epoch 10/10\n",
      "1000/1000 [==============================] - 62s 62ms/step - loss: 0.1047 - acc: 0.9390\n",
      "Training on Epoch  1 batch  5  Files [5] start  190 / 459\n",
      "Epoch 1/10\n",
      "1000/1000 [==============================] - 60s 60ms/step - loss: 0.2361 - acc: 0.9010\n",
      "Epoch 2/10\n",
      "1000/1000 [==============================] - 62s 62ms/step - loss: 0.1873 - acc: 0.9140\n",
      "Epoch 3/10\n",
      "1000/1000 [==============================] - 61s 61ms/step - loss: 0.1477 - acc: 0.9280\n",
      "Epoch 4/10\n",
      "1000/1000 [==============================] - 62s 62ms/step - loss: 0.1367 - acc: 0.9300\n",
      "Epoch 5/10\n",
      "1000/1000 [==============================] - 61s 61ms/step - loss: 0.1247 - acc: 0.9380\n",
      "Epoch 6/10\n",
      "1000/1000 [==============================] - 61s 61ms/step - loss: 0.1183 - acc: 0.9430\n",
      "Epoch 7/10\n",
      "1000/1000 [==============================] - 61s 61ms/step - loss: 0.1136 - acc: 0.9490\n",
      "Epoch 8/10\n",
      "1000/1000 [==============================] - 61s 61ms/step - loss: 0.1093 - acc: 0.9500\n",
      "Epoch 9/10\n",
      "1000/1000 [==============================] - 61s 61ms/step - loss: 0.1041 - acc: 0.9490\n",
      "Epoch 10/10\n",
      "1000/1000 [==============================] - 61s 61ms/step - loss: 0.1080 - acc: 0.9510\n",
      "Training on Epoch  1 batch  5  Files [5] start  195 / 459\n",
      "Epoch 1/10\n",
      "1000/1000 [==============================] - 63s 63ms/step - loss: 0.2406 - acc: 0.8870\n",
      "Epoch 2/10\n",
      "1000/1000 [==============================] - 63s 63ms/step - loss: 0.2047 - acc: 0.8990\n",
      "Epoch 3/10\n",
      "1000/1000 [==============================] - 63s 63ms/step - loss: 0.1855 - acc: 0.9070\n",
      "Epoch 4/10\n",
      "1000/1000 [==============================] - 63s 63ms/step - loss: 0.1731 - acc: 0.9140\n",
      "Epoch 5/10\n",
      "1000/1000 [==============================] - 63s 63ms/step - loss: 0.1632 - acc: 0.9220\n",
      "Epoch 6/10\n",
      "1000/1000 [==============================] - 63s 63ms/step - loss: 0.1553 - acc: 0.9180\n",
      "Epoch 7/10\n",
      "1000/1000 [==============================] - 63s 63ms/step - loss: 0.1482 - acc: 0.9230\n",
      "Epoch 8/10\n",
      "1000/1000 [==============================] - 63s 63ms/step - loss: 0.1435 - acc: 0.9230\n",
      "Epoch 9/10\n",
      "1000/1000 [==============================] - 63s 63ms/step - loss: 0.1372 - acc: 0.9260\n",
      "Epoch 10/10\n",
      "1000/1000 [==============================] - 64s 64ms/step - loss: 0.1334 - acc: 0.9290\n",
      "Training on Epoch  1 batch  5  Files [5] start  200 / 459\n",
      "Epoch 1/10\n",
      "1000/1000 [==============================] - 62s 62ms/step - loss: 0.2646 - acc: 0.8810\n",
      "Epoch 2/10\n",
      "1000/1000 [==============================] - 63s 63ms/step - loss: 0.2128 - acc: 0.9030\n",
      "Epoch 3/10\n",
      "1000/1000 [==============================] - 63s 63ms/step - loss: 0.1785 - acc: 0.9120\n",
      "Epoch 4/10\n",
      "1000/1000 [==============================] - 62s 62ms/step - loss: 0.1536 - acc: 0.9200\n",
      "Epoch 5/10\n",
      "1000/1000 [==============================] - 62s 62ms/step - loss: 0.1393 - acc: 0.9300\n",
      "Epoch 6/10\n",
      "1000/1000 [==============================] - 62s 62ms/step - loss: 0.1325 - acc: 0.9330\n",
      "Epoch 7/10\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000/1000 [==============================] - 62s 62ms/step - loss: 0.1242 - acc: 0.9390\n",
      "Epoch 8/10\n",
      "1000/1000 [==============================] - 63s 63ms/step - loss: 0.1183 - acc: 0.9380\n",
      "Epoch 9/10\n",
      "1000/1000 [==============================] - 62s 62ms/step - loss: 0.1141 - acc: 0.9430\n",
      "Epoch 10/10\n",
      "1000/1000 [==============================] - 63s 63ms/step - loss: 0.1095 - acc: 0.9480\n",
      "Training on Epoch  1 batch  5  Files [5] start  205 / 459\n",
      "Epoch 1/10\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 0.1745 - acc: 0.9080\n",
      "Epoch 2/10\n",
      "1000/1000 [==============================] - 60s 60ms/step - loss: 0.1511 - acc: 0.9120\n",
      "Epoch 3/10\n",
      "1000/1000 [==============================] - 61s 61ms/step - loss: 0.1379 - acc: 0.9260\n",
      "Epoch 4/10\n",
      "1000/1000 [==============================] - 60s 60ms/step - loss: 0.1271 - acc: 0.9390\n",
      "Epoch 5/10\n",
      "1000/1000 [==============================] - 61s 61ms/step - loss: 0.1201 - acc: 0.9430\n",
      "Epoch 6/10\n",
      "1000/1000 [==============================] - 61s 61ms/step - loss: 0.1147 - acc: 0.9460\n",
      "Epoch 7/10\n",
      "1000/1000 [==============================] - 60s 60ms/step - loss: 0.1108 - acc: 0.9470\n",
      "Epoch 8/10\n",
      "1000/1000 [==============================] - 60s 60ms/step - loss: 0.1068 - acc: 0.9470\n",
      "Epoch 9/10\n",
      "1000/1000 [==============================] - 60s 60ms/step - loss: 0.1040 - acc: 0.9530\n",
      "Epoch 10/10\n",
      "1000/1000 [==============================] - 60s 60ms/step - loss: 0.1027 - acc: 0.9520\n",
      "Training on Epoch  1 batch  5  Files [5] start  210 / 459\n",
      "Epoch 1/10\n",
      "1000/1000 [==============================] - 61s 61ms/step - loss: 0.2346 - acc: 0.9050\n",
      "Epoch 2/10\n",
      "1000/1000 [==============================] - 61s 61ms/step - loss: 0.1576 - acc: 0.9240\n",
      "Epoch 3/10\n",
      "1000/1000 [==============================] - 62s 62ms/step - loss: 0.1372 - acc: 0.9360\n",
      "Epoch 4/10\n",
      "1000/1000 [==============================] - 60s 60ms/step - loss: 0.1082 - acc: 0.9590\n",
      "Epoch 5/10\n",
      "1000/1000 [==============================] - 60s 60ms/step - loss: 0.0976 - acc: 0.9650\n",
      "Epoch 6/10\n",
      "1000/1000 [==============================] - 62s 62ms/step - loss: 0.0870 - acc: 0.9680\n",
      "Epoch 7/10\n",
      "1000/1000 [==============================] - 63s 63ms/step - loss: 0.0799 - acc: 0.9700\n",
      "Epoch 8/10\n",
      "1000/1000 [==============================] - 63s 63ms/step - loss: 0.0723 - acc: 0.9750\n",
      "Epoch 9/10\n",
      "1000/1000 [==============================] - 63s 63ms/step - loss: 0.0662 - acc: 0.9770\n",
      "Epoch 10/10\n",
      "1000/1000 [==============================] - 62s 62ms/step - loss: 0.0610 - acc: 0.9800\n",
      "Training on Epoch  1 batch  5  Files [5] start  215 / 459\n",
      "Epoch 1/10\n",
      "1000/1000 [==============================] - 63s 63ms/step - loss: 0.2406 - acc: 0.8910\n",
      "Epoch 2/10\n",
      "1000/1000 [==============================] - 63s 63ms/step - loss: 0.2034 - acc: 0.8970\n",
      "Epoch 3/10\n",
      "1000/1000 [==============================] - 63s 63ms/step - loss: 0.1829 - acc: 0.9060\n",
      "Epoch 4/10\n",
      "1000/1000 [==============================] - 63s 63ms/step - loss: 0.1618 - acc: 0.9210\n",
      "Epoch 5/10\n",
      "1000/1000 [==============================] - 63s 63ms/step - loss: 0.1541 - acc: 0.9240\n",
      "Epoch 6/10\n",
      "1000/1000 [==============================] - 63s 63ms/step - loss: 0.1464 - acc: 0.9300\n",
      "Epoch 7/10\n",
      "1000/1000 [==============================] - 63s 63ms/step - loss: 0.1390 - acc: 0.9330\n",
      "Epoch 8/10\n",
      "1000/1000 [==============================] - 63s 63ms/step - loss: 0.1322 - acc: 0.9370\n",
      "Epoch 9/10\n",
      "1000/1000 [==============================] - 63s 63ms/step - loss: 0.1300 - acc: 0.9400\n",
      "Epoch 10/10\n",
      "1000/1000 [==============================] - 63s 63ms/step - loss: 0.1292 - acc: 0.9330\n",
      "Training on Epoch  1 batch  5  Files [5] start  220 / 459\n",
      "Epoch 1/10\n",
      "1000/1000 [==============================] - 63s 63ms/step - loss: 0.3432 - acc: 0.8780\n",
      "Epoch 2/10\n",
      "1000/1000 [==============================] - 62s 62ms/step - loss: 0.2767 - acc: 0.8880\n",
      "Epoch 3/10\n",
      "1000/1000 [==============================] - 63s 63ms/step - loss: 0.2000 - acc: 0.9030\n",
      "Epoch 4/10\n",
      "1000/1000 [==============================] - 62s 62ms/step - loss: 0.1849 - acc: 0.9040\n",
      "Epoch 5/10\n",
      "1000/1000 [==============================] - 62s 62ms/step - loss: 0.1574 - acc: 0.9350\n",
      "Epoch 6/10\n",
      "1000/1000 [==============================] - 62s 62ms/step - loss: 0.1418 - acc: 0.9440\n",
      "Epoch 7/10\n",
      "1000/1000 [==============================] - 62s 62ms/step - loss: 0.1309 - acc: 0.9440\n",
      "Epoch 8/10\n",
      "1000/1000 [==============================] - 61s 61ms/step - loss: 0.1187 - acc: 0.9480\n",
      "Epoch 9/10\n",
      "1000/1000 [==============================] - 62s 62ms/step - loss: 0.1082 - acc: 0.9560\n",
      "Epoch 10/10\n",
      "1000/1000 [==============================] - 62s 62ms/step - loss: 0.1003 - acc: 0.9580\n",
      "Training on Epoch  1 batch  5  Files [5] start  225 / 459\n",
      "Epoch 1/10\n",
      "1000/1000 [==============================] - 62s 62ms/step - loss: 0.1795 - acc: 0.9180\n",
      "Epoch 2/10\n",
      "1000/1000 [==============================] - 63s 63ms/step - loss: 0.1501 - acc: 0.9310\n",
      "Epoch 3/10\n",
      "1000/1000 [==============================] - 63s 63ms/step - loss: 0.1285 - acc: 0.9320\n",
      "Epoch 4/10\n",
      "1000/1000 [==============================] - 63s 63ms/step - loss: 0.1089 - acc: 0.9480\n",
      "Epoch 5/10\n",
      "1000/1000 [==============================] - 63s 63ms/step - loss: 0.0975 - acc: 0.9610\n",
      "Epoch 6/10\n",
      "1000/1000 [==============================] - 63s 63ms/step - loss: 0.0861 - acc: 0.9690\n",
      "Epoch 7/10\n",
      "1000/1000 [==============================] - 63s 63ms/step - loss: 0.0802 - acc: 0.9710\n",
      "Epoch 8/10\n",
      "1000/1000 [==============================] - 63s 63ms/step - loss: 0.0742 - acc: 0.9750\n",
      "Epoch 9/10\n",
      "1000/1000 [==============================] - 63s 63ms/step - loss: 0.0701 - acc: 0.9740\n",
      "Epoch 10/10\n",
      "1000/1000 [==============================] - 62s 62ms/step - loss: 0.0661 - acc: 0.9760\n",
      "Training on Epoch  1 batch  5  Files [5] start  230 / 459\n",
      "Epoch 1/10\n",
      "1000/1000 [==============================] - 60s 60ms/step - loss: 0.1357 - acc: 0.9270\n",
      "Epoch 2/10\n",
      "1000/1000 [==============================] - 61s 61ms/step - loss: 0.1222 - acc: 0.9280\n",
      "Epoch 3/10\n",
      "1000/1000 [==============================] - 61s 61ms/step - loss: 0.1124 - acc: 0.9340\n",
      "Epoch 4/10\n",
      "1000/1000 [==============================] - 60s 60ms/step - loss: 0.1068 - acc: 0.9420\n",
      "Epoch 5/10\n",
      "1000/1000 [==============================] - 63s 63ms/step - loss: 0.1004 - acc: 0.9430\n",
      "Epoch 6/10\n",
      "1000/1000 [==============================] - 61s 61ms/step - loss: 0.0969 - acc: 0.9460\n",
      "Epoch 7/10\n",
      "1000/1000 [==============================] - 60s 60ms/step - loss: 0.0939 - acc: 0.9500\n",
      "Epoch 8/10\n",
      "1000/1000 [==============================] - 60s 60ms/step - loss: 0.0903 - acc: 0.9550\n",
      "Epoch 9/10\n",
      "1000/1000 [==============================] - 60s 60ms/step - loss: 0.0888 - acc: 0.9540\n",
      "Epoch 10/10\n",
      "1000/1000 [==============================] - 61s 61ms/step - loss: 0.0856 - acc: 0.9540\n",
      "Training on Epoch  1 batch  5  Files [5] start  235 / 459\n",
      "Epoch 1/10\n",
      "1000/1000 [==============================] - 57s 57ms/step - loss: 0.1626 - acc: 0.9210\n",
      "Epoch 2/10\n",
      "1000/1000 [==============================] - 57s 57ms/step - loss: 0.1346 - acc: 0.9330\n",
      "Epoch 3/10\n",
      "1000/1000 [==============================] - 57s 57ms/step - loss: 0.1200 - acc: 0.9400\n",
      "Epoch 4/10\n",
      "1000/1000 [==============================] - 57s 57ms/step - loss: 0.1068 - acc: 0.9490\n",
      "Epoch 5/10\n",
      "1000/1000 [==============================] - 57s 57ms/step - loss: 0.0980 - acc: 0.9570\n",
      "Epoch 6/10\n",
      "1000/1000 [==============================] - 56s 56ms/step - loss: 0.0909 - acc: 0.9590\n",
      "Epoch 7/10\n",
      "1000/1000 [==============================] - 56s 56ms/step - loss: 0.0866 - acc: 0.9620\n",
      "Epoch 8/10\n",
      "1000/1000 [==============================] - 57s 57ms/step - loss: 0.0818 - acc: 0.9610\n",
      "Epoch 9/10\n",
      "1000/1000 [==============================] - 57s 57ms/step - loss: 0.0775 - acc: 0.9630\n",
      "Epoch 10/10\n",
      "1000/1000 [==============================] - 57s 57ms/step - loss: 0.0738 - acc: 0.9650\n",
      "Training on Epoch  1 batch  5  Files [5] start  240 / 459\n",
      "Epoch 1/10\n",
      "1000/1000 [==============================] - 56s 56ms/step - loss: 0.1304 - acc: 0.9370\n",
      "Epoch 2/10\n",
      "1000/1000 [==============================] - 56s 56ms/step - loss: 0.1035 - acc: 0.9510\n",
      "Epoch 3/10\n",
      "1000/1000 [==============================] - 56s 56ms/step - loss: 0.0881 - acc: 0.9560\n",
      "Epoch 4/10\n",
      "1000/1000 [==============================] - 56s 56ms/step - loss: 0.0791 - acc: 0.9620\n",
      "Epoch 5/10\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000/1000 [==============================] - 57s 57ms/step - loss: 0.0738 - acc: 0.9680\n",
      "Epoch 6/10\n",
      "1000/1000 [==============================] - 56s 56ms/step - loss: 0.0688 - acc: 0.9720\n",
      "Epoch 7/10\n",
      "1000/1000 [==============================] - 56s 56ms/step - loss: 0.0662 - acc: 0.9740\n",
      "Epoch 8/10\n",
      "1000/1000 [==============================] - 57s 57ms/step - loss: 0.0627 - acc: 0.9740\n",
      "Epoch 9/10\n",
      "1000/1000 [==============================] - 56s 56ms/step - loss: 0.0620 - acc: 0.9770\n",
      "Epoch 10/10\n",
      "1000/1000 [==============================] - 56s 56ms/step - loss: 0.0586 - acc: 0.9760\n",
      "Training on Epoch  1 batch  5  Files [5] start  245 / 459\n",
      "Epoch 1/10\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 0.1685 - acc: 0.9220\n",
      "Epoch 2/10\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 0.1251 - acc: 0.9340\n",
      "Epoch 3/10\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 0.1066 - acc: 0.9440\n",
      "Epoch 4/10\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 0.1002 - acc: 0.9440\n",
      "Epoch 5/10\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 0.0905 - acc: 0.9480\n",
      "Epoch 6/10\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 0.0835 - acc: 0.9540\n",
      "Epoch 7/10\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 0.0801 - acc: 0.9540\n",
      "Epoch 8/10\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 0.0764 - acc: 0.9540\n",
      "Epoch 9/10\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 0.0728 - acc: 0.9570\n",
      "Epoch 10/10\n",
      "1000/1000 [==============================] - 60s 60ms/step - loss: 0.0709 - acc: 0.9590\n",
      "Training on Epoch  1 batch  5  Files [5] start  250 / 459\n",
      "Epoch 1/10\n",
      "1000/1000 [==============================] - 62s 62ms/step - loss: 0.1781 - acc: 0.8900\n",
      "Epoch 2/10\n",
      "1000/1000 [==============================] - 61s 61ms/step - loss: 0.1477 - acc: 0.9080\n",
      "Epoch 3/10\n",
      "1000/1000 [==============================] - 62s 62ms/step - loss: 0.1267 - acc: 0.9340\n",
      "Epoch 4/10\n",
      "1000/1000 [==============================] - 62s 62ms/step - loss: 0.1150 - acc: 0.9420\n",
      "Epoch 5/10\n",
      "1000/1000 [==============================] - 62s 62ms/step - loss: 0.1081 - acc: 0.9460\n",
      "Epoch 6/10\n",
      "1000/1000 [==============================] - 62s 62ms/step - loss: 0.1037 - acc: 0.9510\n",
      "Epoch 7/10\n",
      "1000/1000 [==============================] - 62s 62ms/step - loss: 0.0995 - acc: 0.9510\n",
      "Epoch 8/10\n",
      "1000/1000 [==============================] - 62s 62ms/step - loss: 0.0962 - acc: 0.9560\n",
      "Epoch 9/10\n",
      "1000/1000 [==============================] - 62s 62ms/step - loss: 0.0926 - acc: 0.9560\n",
      "Epoch 10/10\n",
      "1000/1000 [==============================] - 62s 62ms/step - loss: 0.0911 - acc: 0.9560\n",
      "Training on Epoch  1 batch  5  Files [5] start  255 / 459\n",
      "Epoch 1/10\n",
      "1000/1000 [==============================] - 62s 62ms/step - loss: 0.1816 - acc: 0.9270\n",
      "Epoch 2/10\n",
      "1000/1000 [==============================] - 62s 62ms/step - loss: 0.1210 - acc: 0.9440\n",
      "Epoch 3/10\n",
      "1000/1000 [==============================] - 63s 63ms/step - loss: 0.1051 - acc: 0.9510\n",
      "Epoch 4/10\n",
      "1000/1000 [==============================] - 62s 62ms/step - loss: 0.0942 - acc: 0.9540\n",
      "Epoch 5/10\n",
      "1000/1000 [==============================] - 62s 62ms/step - loss: 0.0871 - acc: 0.9600\n",
      "Epoch 6/10\n",
      "1000/1000 [==============================] - 62s 62ms/step - loss: 0.0820 - acc: 0.9630\n",
      "Epoch 7/10\n",
      "1000/1000 [==============================] - 62s 62ms/step - loss: 0.0773 - acc: 0.9640\n",
      "Epoch 8/10\n",
      "1000/1000 [==============================] - 63s 63ms/step - loss: 0.0751 - acc: 0.9670\n",
      "Epoch 9/10\n",
      "1000/1000 [==============================] - 63s 63ms/step - loss: 0.0729 - acc: 0.9660\n",
      "Epoch 10/10\n",
      "1000/1000 [==============================] - 62s 62ms/step - loss: 0.0706 - acc: 0.9660\n",
      "Training on Epoch  1 batch  5  Files [5] start  260 / 459\n",
      "Epoch 1/10\n",
      "1000/1000 [==============================] - 63s 63ms/step - loss: 0.2440 - acc: 0.8960\n",
      "Epoch 2/10\n",
      "1000/1000 [==============================] - 64s 64ms/step - loss: 0.1939 - acc: 0.9090\n",
      "Epoch 3/10\n",
      "1000/1000 [==============================] - 64s 64ms/step - loss: 0.1564 - acc: 0.9270\n",
      "Epoch 4/10\n",
      "1000/1000 [==============================] - 64s 64ms/step - loss: 0.1276 - acc: 0.9330\n",
      "Epoch 5/10\n",
      "1000/1000 [==============================] - 65s 65ms/step - loss: 0.1030 - acc: 0.9520\n",
      "Epoch 6/10\n",
      "1000/1000 [==============================] - 65s 65ms/step - loss: 0.0965 - acc: 0.9550\n",
      "Epoch 7/10\n",
      "1000/1000 [==============================] - 66s 66ms/step - loss: 0.0882 - acc: 0.9580\n",
      "Epoch 8/10\n",
      "1000/1000 [==============================] - 66s 66ms/step - loss: 0.0839 - acc: 0.9570\n",
      "Epoch 9/10\n",
      "1000/1000 [==============================] - 66s 66ms/step - loss: 0.0805 - acc: 0.9620\n",
      "Epoch 10/10\n",
      "1000/1000 [==============================] - 66s 66ms/step - loss: 0.0767 - acc: 0.9640\n",
      "Training on Epoch  1 batch  5  Files [5] start  265 / 459\n",
      "Epoch 1/10\n",
      "1000/1000 [==============================] - 61s 61ms/step - loss: 0.2309 - acc: 0.9160\n",
      "Epoch 2/10\n",
      "1000/1000 [==============================] - 62s 62ms/step - loss: 0.1740 - acc: 0.9370\n",
      "Epoch 3/10\n",
      "1000/1000 [==============================] - 61s 61ms/step - loss: 0.1422 - acc: 0.9470\n",
      "Epoch 4/10\n",
      "1000/1000 [==============================] - 61s 61ms/step - loss: 0.1248 - acc: 0.9520\n",
      "Epoch 5/10\n",
      "1000/1000 [==============================] - 62s 62ms/step - loss: 0.1081 - acc: 0.9590\n",
      "Epoch 6/10\n",
      "1000/1000 [==============================] - 61s 61ms/step - loss: 0.0937 - acc: 0.9650\n",
      "Epoch 7/10\n",
      "1000/1000 [==============================] - 62s 62ms/step - loss: 0.0871 - acc: 0.9680\n",
      "Epoch 8/10\n",
      "1000/1000 [==============================] - 62s 62ms/step - loss: 0.0815 - acc: 0.9680\n",
      "Epoch 9/10\n",
      "1000/1000 [==============================] - 62s 62ms/step - loss: 0.0764 - acc: 0.9720\n",
      "Epoch 10/10\n",
      "1000/1000 [==============================] - 62s 62ms/step - loss: 0.0726 - acc: 0.9720\n",
      "Training on Epoch  1 batch  5  Files [5] start  270 / 459\n",
      "Epoch 1/10\n",
      "1000/1000 [==============================] - 68s 68ms/step - loss: 0.2196 - acc: 0.9130\n",
      "Epoch 2/10\n",
      "1000/1000 [==============================] - 69s 69ms/step - loss: 0.1794 - acc: 0.9290\n",
      "Epoch 3/10\n",
      "1000/1000 [==============================] - 69s 69ms/step - loss: 0.1592 - acc: 0.9260\n",
      "Epoch 4/10\n",
      "1000/1000 [==============================] - 70s 70ms/step - loss: 0.1390 - acc: 0.9350\n",
      "Epoch 5/10\n",
      "1000/1000 [==============================] - 69s 69ms/step - loss: 0.1256 - acc: 0.9430\n",
      "Epoch 6/10\n",
      "1000/1000 [==============================] - 69s 69ms/step - loss: 0.1164 - acc: 0.9470\n",
      "Epoch 7/10\n",
      "1000/1000 [==============================] - 69s 69ms/step - loss: 0.1064 - acc: 0.9500\n",
      "Epoch 8/10\n",
      "1000/1000 [==============================] - 69s 69ms/step - loss: 0.1016 - acc: 0.9580\n",
      "Epoch 9/10\n",
      "1000/1000 [==============================] - 69s 69ms/step - loss: 0.0954 - acc: 0.9550\n",
      "Epoch 10/10\n",
      "1000/1000 [==============================] - 69s 69ms/step - loss: 0.0904 - acc: 0.9590\n",
      "Training on Epoch  1 batch  5  Files [5] start  275 / 459\n",
      "Epoch 1/10\n",
      "1000/1000 [==============================] - 63s 63ms/step - loss: 0.1830 - acc: 0.9240\n",
      "Epoch 2/10\n",
      "1000/1000 [==============================] - 64s 64ms/step - loss: 0.1475 - acc: 0.9350\n",
      "Epoch 3/10\n",
      "1000/1000 [==============================] - 64s 64ms/step - loss: 0.1163 - acc: 0.9450\n",
      "Epoch 4/10\n",
      "1000/1000 [==============================] - 64s 64ms/step - loss: 0.1029 - acc: 0.9540\n",
      "Epoch 5/10\n",
      "1000/1000 [==============================] - 64s 64ms/step - loss: 0.0906 - acc: 0.9590\n",
      "Epoch 6/10\n",
      "1000/1000 [==============================] - 64s 64ms/step - loss: 0.0850 - acc: 0.9640\n",
      "Epoch 7/10\n",
      "1000/1000 [==============================] - 64s 64ms/step - loss: 0.0787 - acc: 0.9630\n",
      "Epoch 8/10\n",
      "1000/1000 [==============================] - 63s 63ms/step - loss: 0.0763 - acc: 0.9660\n",
      "Epoch 9/10\n",
      "1000/1000 [==============================] - 64s 64ms/step - loss: 0.0733 - acc: 0.9680\n",
      "Epoch 10/10\n",
      "1000/1000 [==============================] - 64s 64ms/step - loss: 0.0665 - acc: 0.9730\n",
      "Training on Epoch  1 batch  5  Files [5] start  280 / 459\n",
      "Epoch 1/10\n",
      "1000/1000 [==============================] - 58s 58ms/step - loss: 0.1599 - acc: 0.9230\n",
      "Epoch 2/10\n",
      "1000/1000 [==============================] - 58s 58ms/step - loss: 0.1235 - acc: 0.9450\n",
      "Epoch 3/10\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000/1000 [==============================] - 58s 58ms/step - loss: 0.1055 - acc: 0.9410\n",
      "Epoch 4/10\n",
      "1000/1000 [==============================] - 58s 58ms/step - loss: 0.0924 - acc: 0.9530\n",
      "Epoch 5/10\n",
      "1000/1000 [==============================] - 58s 58ms/step - loss: 0.1001 - acc: 0.9530\n",
      "Epoch 6/10\n",
      "1000/1000 [==============================] - 58s 58ms/step - loss: 0.0842 - acc: 0.9600\n",
      "Epoch 7/10\n",
      "1000/1000 [==============================] - 58s 58ms/step - loss: 0.0782 - acc: 0.9610\n",
      "Epoch 8/10\n",
      "1000/1000 [==============================] - 58s 58ms/step - loss: 0.0737 - acc: 0.9630\n",
      "Epoch 9/10\n",
      "1000/1000 [==============================] - 58s 58ms/step - loss: 0.0700 - acc: 0.9670\n",
      "Epoch 10/10\n",
      "1000/1000 [==============================] - 58s 58ms/step - loss: 0.0667 - acc: 0.9700\n",
      "Training on Epoch  1 batch  5  Files [5] start  285 / 459\n",
      "Epoch 1/10\n",
      "1000/1000 [==============================] - 63s 63ms/step - loss: 0.2062 - acc: 0.9000\n",
      "Epoch 2/10\n",
      "1000/1000 [==============================] - 62s 62ms/step - loss: 0.1700 - acc: 0.9150\n",
      "Epoch 3/10\n",
      "1000/1000 [==============================] - 62s 62ms/step - loss: 0.1466 - acc: 0.9230\n",
      "Epoch 4/10\n",
      "1000/1000 [==============================] - 63s 63ms/step - loss: 0.1417 - acc: 0.9260\n",
      "Epoch 5/10\n",
      "1000/1000 [==============================] - 63s 63ms/step - loss: 0.1394 - acc: 0.9330\n",
      "Epoch 6/10\n",
      "1000/1000 [==============================] - 63s 63ms/step - loss: 0.1311 - acc: 0.9310\n",
      "Epoch 7/10\n",
      "1000/1000 [==============================] - 63s 63ms/step - loss: 0.1228 - acc: 0.9400\n",
      "Epoch 8/10\n",
      "1000/1000 [==============================] - 63s 63ms/step - loss: 0.1165 - acc: 0.9400\n",
      "Epoch 9/10\n",
      "1000/1000 [==============================] - 63s 63ms/step - loss: 0.1171 - acc: 0.9410\n",
      "Epoch 10/10\n",
      "1000/1000 [==============================] - 64s 64ms/step - loss: 0.1132 - acc: 0.9430\n",
      "Training on Epoch  1 batch  5  Files [5] start  290 / 459\n",
      "Epoch 1/10\n",
      "1000/1000 [==============================] - 62s 62ms/step - loss: 0.2370 - acc: 0.9080\n",
      "Epoch 2/10\n",
      "1000/1000 [==============================] - 63s 63ms/step - loss: 0.1869 - acc: 0.9160\n",
      "Epoch 3/10\n",
      "1000/1000 [==============================] - 63s 63ms/step - loss: 0.1600 - acc: 0.9190\n",
      "Epoch 4/10\n",
      "1000/1000 [==============================] - 63s 63ms/step - loss: 0.1357 - acc: 0.9320\n",
      "Epoch 5/10\n",
      "1000/1000 [==============================] - 63s 63ms/step - loss: 0.1295 - acc: 0.9330\n",
      "Epoch 6/10\n",
      "1000/1000 [==============================] - 63s 63ms/step - loss: 0.1181 - acc: 0.9370\n",
      "Epoch 7/10\n",
      "1000/1000 [==============================] - 64s 64ms/step - loss: 0.1132 - acc: 0.9410\n",
      "Epoch 8/10\n",
      "1000/1000 [==============================] - 64s 64ms/step - loss: 0.1102 - acc: 0.9450\n",
      "Epoch 9/10\n",
      "1000/1000 [==============================] - 63s 63ms/step - loss: 0.1050 - acc: 0.9480\n",
      "Epoch 10/10\n",
      "1000/1000 [==============================] - 64s 64ms/step - loss: 0.1019 - acc: 0.9510\n",
      "Training on Epoch  1 batch  5  Files [5] start  295 / 459\n",
      "Epoch 1/10\n",
      "1000/1000 [==============================] - 58s 58ms/step - loss: 0.1256 - acc: 0.9360\n",
      "Epoch 2/10\n",
      "1000/1000 [==============================] - 58s 58ms/step - loss: 0.1011 - acc: 0.9570\n",
      "Epoch 3/10\n",
      "1000/1000 [==============================] - 58s 58ms/step - loss: 0.0926 - acc: 0.9630\n",
      "Epoch 4/10\n",
      "1000/1000 [==============================] - 57s 57ms/step - loss: 0.0954 - acc: 0.9520\n",
      "Epoch 5/10\n",
      "1000/1000 [==============================] - 58s 58ms/step - loss: 0.0862 - acc: 0.9670\n",
      "Epoch 6/10\n",
      "1000/1000 [==============================] - 58s 58ms/step - loss: 0.0745 - acc: 0.9740\n",
      "Epoch 7/10\n",
      "1000/1000 [==============================] - 58s 58ms/step - loss: 0.0719 - acc: 0.9740\n",
      "Epoch 8/10\n",
      "1000/1000 [==============================] - 58s 58ms/step - loss: 0.0685 - acc: 0.9670\n",
      "Epoch 9/10\n",
      "1000/1000 [==============================] - 58s 58ms/step - loss: 0.0646 - acc: 0.9680\n",
      "Epoch 10/10\n",
      "1000/1000 [==============================] - 58s 58ms/step - loss: 0.0615 - acc: 0.9710\n",
      "Training on Epoch  1 batch  5  Files [5] start  300 / 459\n",
      "Epoch 1/10\n",
      "1000/1000 [==============================] - 61s 61ms/step - loss: 0.2292 - acc: 0.9090\n",
      "Epoch 2/10\n",
      "1000/1000 [==============================] - 61s 61ms/step - loss: 0.1788 - acc: 0.9250\n",
      "Epoch 3/10\n",
      "1000/1000 [==============================] - 61s 61ms/step - loss: 0.1506 - acc: 0.9390\n",
      "Epoch 4/10\n",
      "1000/1000 [==============================] - 61s 61ms/step - loss: 0.1319 - acc: 0.9490\n",
      "Epoch 5/10\n",
      "1000/1000 [==============================] - 61s 61ms/step - loss: 0.1195 - acc: 0.9430\n",
      "Epoch 6/10\n",
      "1000/1000 [==============================] - 61s 61ms/step - loss: 0.1081 - acc: 0.9540\n",
      "Epoch 7/10\n",
      "1000/1000 [==============================] - 61s 61ms/step - loss: 0.1006 - acc: 0.9600\n",
      "Epoch 8/10\n",
      "1000/1000 [==============================] - 61s 61ms/step - loss: 0.0938 - acc: 0.9590\n",
      "Epoch 9/10\n",
      "1000/1000 [==============================] - 62s 62ms/step - loss: 0.0892 - acc: 0.9650\n",
      "Epoch 10/10\n",
      "1000/1000 [==============================] - 61s 61ms/step - loss: 0.0846 - acc: 0.9650\n",
      "Training on Epoch  1 batch  5  Files [5] start  305 / 459\n",
      "Epoch 1/10\n",
      "1000/1000 [==============================] - 62s 62ms/step - loss: 0.1783 - acc: 0.9270\n",
      "Epoch 2/10\n",
      "1000/1000 [==============================] - 62s 62ms/step - loss: 0.1281 - acc: 0.9430\n",
      "Epoch 3/10\n",
      "1000/1000 [==============================] - 62s 62ms/step - loss: 0.1004 - acc: 0.9540\n",
      "Epoch 4/10\n",
      "1000/1000 [==============================] - 62s 62ms/step - loss: 0.0882 - acc: 0.9610\n",
      "Epoch 5/10\n",
      "1000/1000 [==============================] - 62s 62ms/step - loss: 0.0797 - acc: 0.9660\n",
      "Epoch 6/10\n",
      "1000/1000 [==============================] - 63s 63ms/step - loss: 0.0740 - acc: 0.9730\n",
      "Epoch 7/10\n",
      "1000/1000 [==============================] - 62s 62ms/step - loss: 0.0697 - acc: 0.9740\n",
      "Epoch 8/10\n",
      "1000/1000 [==============================] - 62s 62ms/step - loss: 0.0655 - acc: 0.9730\n",
      "Epoch 9/10\n",
      "1000/1000 [==============================] - 62s 62ms/step - loss: 0.0613 - acc: 0.9750\n",
      "Epoch 10/10\n",
      "1000/1000 [==============================] - 62s 62ms/step - loss: 0.0586 - acc: 0.9770\n",
      "Training on Epoch  1 batch  5  Files [5] start  310 / 459\n",
      "Epoch 1/10\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 0.2469 - acc: 0.9110\n",
      "Epoch 2/10\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 0.1730 - acc: 0.9210\n",
      "Epoch 3/10\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 0.1403 - acc: 0.9440\n",
      "Epoch 4/10\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 0.1257 - acc: 0.9400\n",
      "Epoch 5/10\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 0.1103 - acc: 0.9550\n",
      "Epoch 6/10\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 0.1005 - acc: 0.9580\n",
      "Epoch 7/10\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 0.0929 - acc: 0.9590\n",
      "Epoch 8/10\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 0.0858 - acc: 0.9600\n",
      "Epoch 9/10\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 0.0812 - acc: 0.9660\n",
      "Epoch 10/10\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 0.0768 - acc: 0.9660\n",
      "Training on Epoch  1 batch  5  Files [5] start  315 / 459\n",
      "Epoch 1/10\n",
      "1000/1000 [==============================] - 64s 64ms/step - loss: 0.1695 - acc: 0.9250\n",
      "Epoch 2/10\n",
      "1000/1000 [==============================] - 63s 63ms/step - loss: 0.1439 - acc: 0.9410\n",
      "Epoch 3/10\n",
      "1000/1000 [==============================] - 64s 64ms/step - loss: 0.1302 - acc: 0.9340\n",
      "Epoch 4/10\n",
      "1000/1000 [==============================] - 64s 64ms/step - loss: 0.1197 - acc: 0.9440\n",
      "Epoch 5/10\n",
      "1000/1000 [==============================] - 64s 64ms/step - loss: 0.1151 - acc: 0.9440\n",
      "Epoch 6/10\n",
      "1000/1000 [==============================] - 63s 63ms/step - loss: 0.1041 - acc: 0.9460\n",
      "Epoch 7/10\n",
      "1000/1000 [==============================] - 64s 64ms/step - loss: 0.1006 - acc: 0.9490\n",
      "Epoch 8/10\n",
      "1000/1000 [==============================] - 64s 64ms/step - loss: 0.0944 - acc: 0.9520\n",
      "Epoch 9/10\n",
      "1000/1000 [==============================] - 65s 65ms/step - loss: 0.0931 - acc: 0.9540\n",
      "Epoch 10/10\n",
      "1000/1000 [==============================] - 63s 63ms/step - loss: 0.0896 - acc: 0.9550\n",
      "Training on Epoch  1 batch  5  Files [5] start  320 / 459\n",
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000/1000 [==============================] - 60s 60ms/step - loss: 0.1834 - acc: 0.9260\n",
      "Epoch 2/10\n",
      "1000/1000 [==============================] - 60s 60ms/step - loss: 0.1554 - acc: 0.9290\n",
      "Epoch 3/10\n",
      "1000/1000 [==============================] - 60s 60ms/step - loss: 0.1202 - acc: 0.9470\n",
      "Epoch 4/10\n",
      "1000/1000 [==============================] - 60s 60ms/step - loss: 0.1041 - acc: 0.9590\n",
      "Epoch 5/10\n",
      "1000/1000 [==============================] - 60s 60ms/step - loss: 0.0905 - acc: 0.9610\n",
      "Epoch 6/10\n",
      "1000/1000 [==============================] - 60s 60ms/step - loss: 0.0826 - acc: 0.9610\n",
      "Epoch 7/10\n",
      "1000/1000 [==============================] - 60s 60ms/step - loss: 0.0738 - acc: 0.9640\n",
      "Epoch 8/10\n",
      "1000/1000 [==============================] - 61s 61ms/step - loss: 0.0665 - acc: 0.9680\n",
      "Epoch 9/10\n",
      "1000/1000 [==============================] - 60s 60ms/step - loss: 0.0619 - acc: 0.9710\n",
      "Epoch 10/10\n",
      "1000/1000 [==============================] - 61s 61ms/step - loss: 0.0574 - acc: 0.9740\n",
      "Training on Epoch  1 batch  5  Files [5] start  325 / 459\n",
      "Epoch 1/10\n",
      "1000/1000 [==============================] - 63s 63ms/step - loss: 0.1436 - acc: 0.9330\n",
      "Epoch 2/10\n",
      "1000/1000 [==============================] - 63s 63ms/step - loss: 0.1119 - acc: 0.9470\n",
      "Epoch 3/10\n",
      "1000/1000 [==============================] - 63s 63ms/step - loss: 0.0939 - acc: 0.9530\n",
      "Epoch 4/10\n",
      "1000/1000 [==============================] - 63s 63ms/step - loss: 0.0838 - acc: 0.9650\n",
      "Epoch 5/10\n",
      "1000/1000 [==============================] - 64s 64ms/step - loss: 0.0780 - acc: 0.9610\n",
      "Epoch 6/10\n",
      "1000/1000 [==============================] - 63s 63ms/step - loss: 0.0709 - acc: 0.9690\n",
      "Epoch 7/10\n",
      "1000/1000 [==============================] - 63s 63ms/step - loss: 0.0648 - acc: 0.9700\n",
      "Epoch 8/10\n",
      "1000/1000 [==============================] - 64s 64ms/step - loss: 0.0608 - acc: 0.9710\n",
      "Epoch 9/10\n",
      "1000/1000 [==============================] - 64s 64ms/step - loss: 0.0557 - acc: 0.9750\n",
      "Epoch 10/10\n",
      "1000/1000 [==============================] - 64s 64ms/step - loss: 0.0533 - acc: 0.9740\n",
      "Training on Epoch  1 batch  5  Files [5] start  330 / 459\n",
      "Epoch 1/10\n",
      "1000/1000 [==============================] - 66s 66ms/step - loss: 0.2646 - acc: 0.9010\n",
      "Epoch 2/10\n",
      "1000/1000 [==============================] - 66s 66ms/step - loss: 0.1781 - acc: 0.9190\n",
      "Epoch 3/10\n",
      "1000/1000 [==============================] - 66s 66ms/step - loss: 0.1408 - acc: 0.9270\n",
      "Epoch 4/10\n",
      "1000/1000 [==============================] - 66s 66ms/step - loss: 0.1153 - acc: 0.9490\n",
      "Epoch 5/10\n",
      "1000/1000 [==============================] - 67s 67ms/step - loss: 0.1024 - acc: 0.9520\n",
      "Epoch 6/10\n",
      "1000/1000 [==============================] - 66s 66ms/step - loss: 0.0909 - acc: 0.9530\n",
      "Epoch 7/10\n",
      "1000/1000 [==============================] - 66s 66ms/step - loss: 0.0850 - acc: 0.9570\n",
      "Epoch 8/10\n",
      "1000/1000 [==============================] - 66s 66ms/step - loss: 0.0801 - acc: 0.9660\n",
      "Epoch 9/10\n",
      "1000/1000 [==============================] - 66s 66ms/step - loss: 0.0763 - acc: 0.9690\n",
      "Epoch 10/10\n",
      "1000/1000 [==============================] - 66s 66ms/step - loss: 0.0720 - acc: 0.9690\n",
      "Training on Epoch  1 batch  5  Files [5] start  335 / 459\n",
      "Epoch 1/10\n",
      "1000/1000 [==============================] - 62s 62ms/step - loss: 0.2170 - acc: 0.9050\n",
      "Epoch 2/10\n",
      "1000/1000 [==============================] - 63s 63ms/step - loss: 0.1725 - acc: 0.9140\n",
      "Epoch 3/10\n",
      "1000/1000 [==============================] - 62s 62ms/step - loss: 0.1468 - acc: 0.9300\n",
      "Epoch 4/10\n",
      "1000/1000 [==============================] - 62s 62ms/step - loss: 0.1305 - acc: 0.9320\n",
      "Epoch 5/10\n",
      "1000/1000 [==============================] - 63s 63ms/step - loss: 0.1195 - acc: 0.9350\n",
      "Epoch 6/10\n",
      "1000/1000 [==============================] - 63s 63ms/step - loss: 0.1125 - acc: 0.9370\n",
      "Epoch 7/10\n",
      "1000/1000 [==============================] - 63s 63ms/step - loss: 0.1082 - acc: 0.9410\n",
      "Epoch 8/10\n",
      "1000/1000 [==============================] - 62s 62ms/step - loss: 0.1026 - acc: 0.9420\n",
      "Epoch 9/10\n",
      "1000/1000 [==============================] - 63s 63ms/step - loss: 0.0997 - acc: 0.9450\n",
      "Epoch 10/10\n",
      "1000/1000 [==============================] - 63s 63ms/step - loss: 0.0959 - acc: 0.9490\n",
      "Training on Epoch  1 batch  5  Files [5] start  340 / 459\n",
      "Epoch 1/10\n",
      "1000/1000 [==============================] - 61s 61ms/step - loss: 0.1091 - acc: 0.9470\n",
      "Epoch 2/10\n",
      "1000/1000 [==============================] - 60s 60ms/step - loss: 0.0887 - acc: 0.9450\n",
      "Epoch 3/10\n",
      "1000/1000 [==============================] - 61s 61ms/step - loss: 0.0751 - acc: 0.9530\n",
      "Epoch 4/10\n",
      "1000/1000 [==============================] - 61s 61ms/step - loss: 0.0700 - acc: 0.9590\n",
      "Epoch 5/10\n",
      "1000/1000 [==============================] - 60s 60ms/step - loss: 0.0665 - acc: 0.9640\n",
      "Epoch 6/10\n",
      "1000/1000 [==============================] - 61s 61ms/step - loss: 0.0656 - acc: 0.9670\n",
      "Epoch 7/10\n",
      "1000/1000 [==============================] - 61s 61ms/step - loss: 0.0636 - acc: 0.9690\n",
      "Epoch 8/10\n",
      "1000/1000 [==============================] - 60s 60ms/step - loss: 0.0613 - acc: 0.9680\n",
      "Epoch 9/10\n",
      "1000/1000 [==============================] - 60s 60ms/step - loss: 0.0597 - acc: 0.9700\n",
      "Epoch 10/10\n",
      "1000/1000 [==============================] - 60s 60ms/step - loss: 0.0580 - acc: 0.9700\n",
      "Training on Epoch  1 batch  5  Files [5] start  345 / 459\n",
      "Epoch 1/10\n",
      "1000/1000 [==============================] - 64s 64ms/step - loss: 0.2976 - acc: 0.8940\n",
      "Epoch 2/10\n",
      "1000/1000 [==============================] - 64s 64ms/step - loss: 0.1823 - acc: 0.9120\n",
      "Epoch 3/10\n",
      " 200/1000 [=====>........................] - ETA: 52s - loss: 0.1531 - acc: 0.9200"
     ]
    }
   ],
   "source": [
    "for ep in range(0,s_NumEpocs):\n",
    "    if ep != 0:\n",
    "        file_name = \"train_epoch_dot_attention_\" + str(ep-1) + \".save\"\n",
    "        model.load_weights(file_name)\n",
    "    \n",
    "    file_index       = 0\n",
    "    batch_file_index = 0\n",
    "    \n",
    "    data = []\n",
    "    # train on batches of files\n",
    "    for file_index in range(0, file_list_count) :\n",
    "        inputFile = file_list[file_index]\n",
    "        file_index       += 1\n",
    "        batch_file_index += 1\n",
    "        # print(inputFile)\n",
    "        f = open(inputFile, 'rb')\n",
    "        test = pickle.load(f)\n",
    "        data = np.append(data, test)\n",
    "        f.close()\n",
    "    \n",
    "        if batch_file_index == s_NumFilesInBatch or file_index == file_list_count:\n",
    "            print(\"Training on Epoch \", str(ep), \"batch \", str(batch_file_index), \" Files [\" + str(s_NumFilesInBatch) + \"] start \", str(file_index - batch_file_index), \"/\", str(file_list_count) )\n",
    "            question_vectors, question_masks, triplet_vectors, Y = prepare_data(data, \n",
    "                                                                                question_max_words   = s_QuestionMaxWords, \n",
    "                                                                                triplets_max_numbers = s_TripletsMaxNumbers, \n",
    "                                                                                dimOfQuestionVector  = s_DimOfQuestionVector, \n",
    "                                                                                dimOfTripletVector   = s_DimOfTripletVector, \n",
    "                                                                                dimOfMask            = s_DimOfMask )\n",
    "            # train on this batch\n",
    "            model.fit([question_vectors, question_masks, triplet_vectors], Y, epochs = 10, batch_size = 200, shuffle=True)\n",
    "            # rest for next batch\n",
    "            batch_file_index = 0;\n",
    "            data = []\n",
    "            \n",
    "    # save the mode for the epoch\n",
    "    file_name = \"train_epoch_dot_attention_\" + str(ep) + \".save\"\n",
    "    model.save_weights(file_name)\n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from keras.layers import Dense, Input, Dropout, LSTM, Activation, SimpleRNN, GRU, Concatenate, Multiply, Reshape, Flatten, Bidirectional\n",
    "\n",
    "# # layers\n",
    "# s1_bilstm = Bidirectional(GRU(128, return_sequences = True), name = \"s1_bilstm\")\n",
    "# s2_bilstm = Bidirectional(GRU(128, return_sequences = False), name = \"s2_bilstm\")\n",
    "# t_bilstm = Bidirectional(GRU(128, return_sequences = False), name = \"t_bilstm\")\n",
    "# embedding_layer = pretrained_embedding_layer(word_to_vec_map, words_to_index)\n",
    "# unstack_layer = Lambda(lambda xin: myUnstack(xin), name=\"AUnstackLayer\")\n",
    "\n",
    "# # sentence inputs\n",
    "# sentence_indices = Input(shape=(maxWordsPerSentence,), dtype='int32', name=\"sentence_indices\")   \n",
    "# sentence_masks = Input(shape=(2*lstm_dim,), dtype='float32', name=\"sentence_masks\")\n",
    "\n",
    "# # sentence embeddings\n",
    "# sentence_embeddings = embedding_layer(sentence_indices)       \n",
    "# # X_sentence = Reshape((maxWordsPerSentence, -1), name=\"s_reshape\")(sentence_embeddings)\n",
    "# X_sentence = s1_bilstm(sentence_embeddings)\n",
    "# X_sentence = Multiply()([sentence_masks, X_sentence]) # (None, 60, 256)\n",
    "# X_sentence = s2_bilstm(X_sentence)\n",
    "\n",
    "# # triplets\n",
    "# triplets_input = Input(shape=(maxTriplets, maxWordsPerSentence,), dtype='int32', name=\"tripletz\") \n",
    "# triplet_embeddings = embedding_layer(triplets_input)\n",
    "\n",
    "# X_triplets = Reshape((maxTriplets, -1))(triplet_embeddings)\n",
    "# X_triplets = t_bilstm(X_triplets)\n",
    "\n",
    "# X_concatenated = Concatenate()([X_sentence, X_triplets])\n",
    "# X_concatenated = Dense(256, activation='relu', name=\"Dense256\")(X_concatenated)\n",
    "# X_concatenated = Dense(64, activation='relu', name=\"Dense64\")(X_concatenated)\n",
    "# Y_pred = Dense(1, activation='sigmoid', name=\"Dense1\")(X_concatenated)\n",
    "\n",
    "# m.v2 = Model(inputs=[sentence_indices, sentence_masks, triplets_input], outputs=X_concatenated)\n",
    "# print(m.v2.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
