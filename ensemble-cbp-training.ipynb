{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from pandas.io.json import json_normalize\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "import pickle\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore') #action='once')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "# save the model to disk\n",
    "def save_model(filename, model):\n",
    "    pickle.dump(model, open(filename, 'wb'))    \n",
    "\n",
    "# load the model from disk\n",
    "def load_model(filename):\n",
    "    return pickle.load(open(filename, 'rb'))\n",
    "\n",
    "def save_series(filename, series):\n",
    "    save_model(filename, str(series.to_dict()))\n",
    "\n",
    "def load_series(filename):\n",
    "    import yaml\n",
    "    a = load_model(filename)\n",
    "    a_dict = yaml.load(a)\n",
    "    return pd.Series(a_dict) \n",
    "\n",
    "def score(model, x, y):\n",
    "    y_pred = model.predict(x)\n",
    "    # print(confusion_matrix(np.asarray(y['isGold']==1.0), np.asarray(y_pred > 0.5)))\n",
    "    print(classification_report(np.asarray(y['isGold']==1.0), np.asarray(y_pred > 0.5)))\n",
    "    return np.asarray(y_pred > 0.5).reshape(y_pred.shape[0], 1)\n",
    "    \n",
    "def load_and_score(filename, x, y):\n",
    "    loaded_model = load_model(filename)\n",
    "    return score(loaded_model, x, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "tm1 = load_model(\"train_mean1.p\")\n",
    "tm2 = load_model(\"train_mean2.p\")\n",
    "tm3 = load_model(\"train_mean3.p\")\n",
    "tm4 = load_model(\"train_mean4.p\")\n",
    "tm5 = load_model(\"train_mean5.p\")\n",
    "tm6 = load_model(\"train_mean6.p\")\n",
    "\n",
    "tstd1 = load_model(\"train_std1.p\")\n",
    "tstd2 = load_model(\"train_std2.p\")\n",
    "tstd3 = load_model(\"train_std3.p\")\n",
    "tstd4 = load_model(\"train_std4.p\")\n",
    "tstd5 = load_model(\"train_std5.p\")\n",
    "tstd6 = load_model(\"train_std6.p\")\n",
    "\n",
    "save_model(\"train_mean1_as_dict.p\", str(tm1.to_dict()))\n",
    "save_model(\"train_mean2_as_dict.p\", str(tm2.to_dict()))\n",
    "save_model(\"train_mean3_as_dict.p\", str(tm3.to_dict()))\n",
    "save_model(\"train_mean4_as_dict.p\", str(tm4.to_dict()))\n",
    "save_model(\"train_mean5_as_dict.p\", str(tm5.to_dict()))\n",
    "save_model(\"train_mean6_as_dict.p\", str(tm6.to_dict()))\n",
    "\n",
    "save_model(\"train_std1_as_dict.p\", str(tstd1.to_dict()))\n",
    "save_model(\"train_std2_as_dict.p\", str(tstd2.to_dict()))\n",
    "save_model(\"train_std3_as_dict.p\", str(tstd3.to_dict()))\n",
    "save_model(\"train_std4_as_dict.p\", str(tstd4.to_dict()))\n",
    "save_model(\"train_std5_as_dict.p\", str(tstd5.to_dict()))\n",
    "save_model(\"train_std6_as_dict.p\", str(tstd6.to_dict()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = load_model(\"train_mean1_as_dict.p\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "import yaml\n",
    "a = load_model(\"train_mean1_as_dict.p\")\n",
    "a_dict = yaml.load(a)\n",
    "a_series = pd.Series(a_dict) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3638.9431524547804"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a_dict['articleLength']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "a_series = pd.Series(a_dict) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3638.9431524547804"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a_series['articleLength']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3638.943152</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5.619121</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3.150904</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.147287</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.159690</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1.041860</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.045478</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.282507</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.055451</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.076762</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.039327</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>16671.832041</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0.331783</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>2.332300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>0.063049</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>0.373127</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>0.137984</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>0.193282</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>0.026873</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>0.220135</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>41.783979</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>0.073385</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>7.112842</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               0\n",
       "0    3638.943152\n",
       "1       5.619121\n",
       "2       3.150904\n",
       "3       0.147287\n",
       "4       0.159690\n",
       "5       1.041860\n",
       "6       0.045478\n",
       "7       0.282507\n",
       "8       0.055451\n",
       "9       0.076762\n",
       "10      0.039327\n",
       "11  16671.832041\n",
       "12      0.331783\n",
       "13      2.332300\n",
       "14      0.063049\n",
       "15      0.373127\n",
       "16      0.137984\n",
       "17      0.193282\n",
       "18      0.026873\n",
       "19      0.220135\n",
       "20     41.783979\n",
       "21      0.073385\n",
       "22      7.112842"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tm11"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3638.9431524547804                             Unnamed: 0             0\n",
      "0                        articleLength   3638.943152\n",
      "1              countOfDistinctIndustry      5.619121\n",
      "2                     countOfOccurence      3.150904\n",
      "3            countOfOccurenceOfAliases      0.147287\n",
      "4   countOfOccurenceOfNamePreserveList      0.159690\n",
      "5            countOfSignificantStrings      1.041860\n",
      "6                      countOfUrlMatch      0.045478\n",
      "7           countryMatchByOverlapScore      0.282507\n",
      "8                 directCityMatchScore      0.055451\n",
      "9              directCountryMatchScore      0.076762\n",
      "10               directStateMatchScore      0.039327\n",
      "11                            empCount  16671.832041\n",
      "12                          exactMatch      0.331783\n",
      "13                          fieldMatch      2.332300\n",
      "14                          isIndustry      0.063049\n",
      "15                 isProminentByItself      0.373127\n",
      "16                 isProminentByParent      0.137984\n",
      "17                            isPublic      0.193282\n",
      "18                        isUrlMatched      0.026873\n",
      "19            stateMatchByOverlapScore      0.220135\n",
      "20                       sumOfIndustry     41.783979\n",
      "21                         tickerMatch      0.073385\n",
      "22                            w2vScore      7.112842\n"
     ]
    }
   ],
   "source": [
    "print(tm1['articleLength'], tm11)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(23, 1)                          articleLength  3638.9431524547804\n",
      "0              countOfDistinctIndustry            5.619121\n",
      "1                     countOfOccurence            3.150904\n",
      "2            countOfOccurenceOfAliases            0.147287\n",
      "3   countOfOccurenceOfNamePreserveList            0.159690\n",
      "4            countOfSignificantStrings            1.041860\n",
      "5                      countOfUrlMatch            0.045478\n",
      "6           countryMatchByOverlapScore            0.282507\n",
      "7                 directCityMatchScore            0.055451\n",
      "8              directCountryMatchScore            0.076762\n",
      "9                directStateMatchScore            0.039327\n",
      "10                            empCount        16671.832041\n",
      "11                          exactMatch            0.331783\n",
      "12                          fieldMatch            2.332300\n",
      "13                          isIndustry            0.063049\n",
      "14                 isProminentByItself            0.373127\n",
      "15                 isProminentByParent            0.137984\n",
      "16                            isPublic            0.193282\n",
      "17                        isUrlMatched            0.026873\n",
      "18            stateMatchByOverlapScore            0.220135\n",
      "19                       sumOfIndustry           41.783979\n",
      "20                         tickerMatch            0.073385\n",
      "21                            w2vScore            7.112842\n"
     ]
    }
   ],
   "source": [
    "print(tm1.to_frame().shape, tm11)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "tm_pkl = pd.read_pickle('train_mean1.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "articleLength                          3638.943152\n",
       "countOfDistinctIndustry                   5.619121\n",
       "countOfOccurence                          3.150904\n",
       "countOfOccurenceOfAliases                 0.147287\n",
       "countOfOccurenceOfNamePreserveList        0.159690\n",
       "countOfSignificantStrings                 1.041860\n",
       "countOfUrlMatch                           0.045478\n",
       "countryMatchByOverlapScore                0.282507\n",
       "directCityMatchScore                      0.055451\n",
       "directCountryMatchScore                   0.076762\n",
       "directStateMatchScore                     0.039327\n",
       "empCount                              16671.832041\n",
       "exactMatch                                0.331783\n",
       "fieldMatch                                2.332300\n",
       "isIndustry                                0.063049\n",
       "isProminentByItself                       0.373127\n",
       "isProminentByParent                       0.137984\n",
       "isPublic                                  0.193282\n",
       "isUrlMatched                              0.026873\n",
       "stateMatchByOverlapScore                  0.220135\n",
       "sumOfIndustry                            41.783979\n",
       "tickerMatch                               0.073385\n",
       "w2vScore                                  7.112842\n",
       "dtype: float64"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tm_pkl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 346,
   "metadata": {},
   "outputs": [],
   "source": [
    "d = open(\"/Users/surthi/Downloads/cbp-apr-17-2019/ensembleData/set1.json\").read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 347,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data10 = open(\"/Users/surthi/Documents/cs230project/data/triplets/nonsingles10RecordsPerMentionAid/part-00000-6d8d4860-b569-41a7-94c6-4016af8cf4d3.json\").read()\n",
    "bool_cols = ['exactMatch', 'fieldMatch', 'isIndustry', \"tickerMatch\", 'isPublic', 'isProminentByItself', 'isProminentByParent', 'isUrlMatched','isGold'] # 'isSingleCompanyMatch'\n",
    "na_cols = ['articleLength', 'countOfDistinctIndustry',\n",
    "          'countOfOccurence', 'countOfOccurenceOfAliases',\n",
    "          'countOfOccurenceOfNamePreserveList', 'countOfSignificantStrings',\n",
    "          'countOfUrlMatch', 'countryMatchByOverlapScore', 'directCityMatchScore',\n",
    "          'directCountryMatchScore', 'directStateMatchScore', 'exactMatch',\n",
    "          'fieldMatch', 'isIndustry', \"isTickerMatch\", \"personScore\",\n",
    "          'isProminentByItself', 'isProminentByParent', 'isSingleCompanyMatch',\n",
    "           'isUrlMatched', 'stateMatchByOverlapScore', 'sumOfIndustry', 'w2vScore'] # 'personScore', \n",
    "\n",
    "def read(path):\n",
    "    d = open(path).read()\n",
    "    json_data = [json.loads(str(item)) for item in d.strip().split('\\n')]\n",
    "    df0 = json_normalize(json_data).drop(columns=[\"isCommon\", \"personScore\", \"isTickerMatch\", \"popularity\", \"isFortune\"])\n",
    "    df = df0[df0[\"isSingleCompanyMatch\"] == 0.0].drop(columns=['isSingleCompanyMatch'])\n",
    "    preprocess_nas(df)\n",
    "    return df\n",
    "    \n",
    "def preprocess_nas(df):\n",
    "    for k, v in df.iteritems():\n",
    "        if k in bool_cols:\n",
    "            v *= 1.0\n",
    "        if k in na_cols:\n",
    "            v[v == -1000.0] = np.nan\n",
    "\n",
    "s1 = read(\"/Users/surthi/Downloads/cbp-apr-17-2019/ensembleData/set1.json\")\n",
    "s2 = read(\"/Users/surthi/Downloads/cbp-apr-17-2019/ensembleData/set2.json\")\n",
    "s3 = read(\"/Users/surthi/Downloads/cbp-apr-17-2019/ensembleData/set3.json\")\n",
    "s4 = read(\"/Users/surthi/Downloads/cbp-apr-17-2019/ensembleData/set4.json\")\n",
    "s5 = read(\"/Users/surthi/Downloads/cbp-apr-17-2019/ensembleData/set5.json\")\n",
    "s6 = read(\"/Users/surthi/Downloads/cbp-apr-17-2019/ensembleData/set6.json\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 348,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>articleId</th>\n",
       "      <th>articleLength</th>\n",
       "      <th>companyId</th>\n",
       "      <th>countOfDistinctIndustry</th>\n",
       "      <th>countOfOccurence</th>\n",
       "      <th>countOfOccurenceOfAliases</th>\n",
       "      <th>countOfOccurenceOfNamePreserveList</th>\n",
       "      <th>countOfSignificantStrings</th>\n",
       "      <th>countOfUrlMatch</th>\n",
       "      <th>countryMatchByOverlapScore</th>\n",
       "      <th>...</th>\n",
       "      <th>isIndustry</th>\n",
       "      <th>isProminentByItself</th>\n",
       "      <th>isProminentByParent</th>\n",
       "      <th>isPublic</th>\n",
       "      <th>isUrlMatched</th>\n",
       "      <th>mentionMatched</th>\n",
       "      <th>stateMatchByOverlapScore</th>\n",
       "      <th>sumOfIndustry</th>\n",
       "      <th>tickerMatch</th>\n",
       "      <th>w2vScore</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>37348838595</td>\n",
       "      <td>12271</td>\n",
       "      <td>17748243</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>stifel</td>\n",
       "      <td>0.7</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>33454213472</td>\n",
       "      <td>763</td>\n",
       "      <td>547738</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>liberty mutual insurance</td>\n",
       "      <td>0.7</td>\n",
       "      <td>3</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>37270698700</td>\n",
       "      <td>4618</td>\n",
       "      <td>861034</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>clariant</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>37294269525</td>\n",
       "      <td>2153</td>\n",
       "      <td>8515257</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>motion media</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>37348500112</td>\n",
       "      <td>2591</td>\n",
       "      <td>811824</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>panasonic</td>\n",
       "      <td>0.0</td>\n",
       "      <td>11</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.939327</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 27 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     articleId  articleLength companyId  countOfDistinctIndustry  \\\n",
       "0  37348838595          12271  17748243                        0   \n",
       "1  33454213472            763    547738                        1   \n",
       "2  37270698700           4618    861034                        0   \n",
       "3  37294269525           2153   8515257                        2   \n",
       "4  37348500112           2591    811824                        4   \n",
       "\n",
       "   countOfOccurence  countOfOccurenceOfAliases  \\\n",
       "0                 1                          0   \n",
       "1                 1                          0   \n",
       "2                 3                          0   \n",
       "3                 1                          0   \n",
       "4                 4                          1   \n",
       "\n",
       "   countOfOccurenceOfNamePreserveList  countOfSignificantStrings  \\\n",
       "0                                   0                          0   \n",
       "1                                   0                          1   \n",
       "2                                   0                          0   \n",
       "3                                   0                          0   \n",
       "4                                   1                          1   \n",
       "\n",
       "   countOfUrlMatch  countryMatchByOverlapScore  ...  isIndustry  \\\n",
       "0                0                         0.5  ...         0.0   \n",
       "1                0                         0.5  ...         0.0   \n",
       "2                0                         0.0  ...         0.0   \n",
       "3                0                         0.0  ...         0.0   \n",
       "4                1                         0.0  ...         0.0   \n",
       "\n",
       "   isProminentByItself  isProminentByParent  isPublic  isUrlMatched  \\\n",
       "0                  0.0                  1.0       0.0           0.0   \n",
       "1                  1.0                  0.0       0.0           0.0   \n",
       "2                  1.0                  0.0       1.0           0.0   \n",
       "3                  0.0                  0.0       0.0           0.0   \n",
       "4                  1.0                  1.0       1.0           1.0   \n",
       "\n",
       "             mentionMatched  stateMatchByOverlapScore  sumOfIndustry  \\\n",
       "0                    stifel                       0.7              0   \n",
       "1  liberty mutual insurance                       0.7              3   \n",
       "2                  clariant                       NaN              0   \n",
       "3              motion media                       0.0              7   \n",
       "4                 panasonic                       0.0             11   \n",
       "\n",
       "   tickerMatch  w2vScore  \n",
       "0          0.0  0.000000  \n",
       "1          0.0  0.000000  \n",
       "2          0.0  0.000000  \n",
       "3          0.0  0.000000  \n",
       "4          0.0  0.939327  \n",
       "\n",
       "[5 rows x 27 columns]"
      ]
     },
     "execution_count": 348,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# s1.isnull().any()\n",
    "s1.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 349,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1219 1200\n"
     ]
    }
   ],
   "source": [
    "print(s2[s2['isGold']==1.0].loc[:, 'isGold'].count(), s2[s2['isGold']==0.0].loc[:, 'isGold'].count())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 350,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_and_normalize_data(df, cols_to_normalize):\n",
    "    train, test = train_test_split(df, test_size=0.2, random_state=42)\n",
    "    y_train = train.loc[:, train.columns == 'isGold']\n",
    "    x_train = train[train.columns.difference(['isGold', 'articleId', 'mentionMatched', 'companyId'])]\n",
    "    ids_train = train[['isGold', 'articleId', 'mentionMatched', 'companyId']]\n",
    "    y_test = test.loc[:, test.columns == 'isGold']\n",
    "    x_test = test[test.columns.difference(['isGold', 'articleId', 'mentionMatched', 'companyId'])]\n",
    "    ids_test = test[['isGold', 'articleId', 'mentionMatched', 'companyId']]\n",
    "    \n",
    "    print(len(train),\": Gold-\", len(train[train[\"isGold\"]==1]), \": NonGold-\", len(train[train[\"isGold\"]==0]))\n",
    "    print(len(test),\": Gold-\", len(test[test[\"isGold\"]==1]), \": NonGold-\", len(test[test[\"isGold\"]==0]))\n",
    "\n",
    "    train_mean = x_train.mean()\n",
    "    train_std = x_train.std()\n",
    "    \n",
    "#     print(x_train[bool_cols].isnull().values.any())\n",
    "    \n",
    "    for col in cols_to_normalize:\n",
    "        x_train.loc[:, col] = (x_train.loc[:, col] - train_mean[col])/train_std[col]\n",
    "#         x_test.loc[:, col] = (x_test.loc[:, col] - train_mean[col])/train_std[col]\n",
    "    \n",
    "    from sklearn.preprocessing import Imputer\n",
    "    imputer = Imputer(missing_values = \"NaN\", strategy = \"mean\", axis = 0) \n",
    "    imputer = imputer.fit(x_train) \n",
    "    imputed_x_train = pd.DataFrame(imputer.transform(x_train))\n",
    "    imputed_x_train.columns = x_train.columns\n",
    "    imputed_x_train.index = x_train.index\n",
    "\n",
    "#     imputer1 = Imputer(missing_values = \"NaN\", strategy = \"mean\", axis = 0) \n",
    "#     imputer1 = imputer1.fit(x_test) \n",
    "#     imputed_x_test = pd.DataFrame(imputer.transform(x_test))\n",
    "#     imputed_x_test.columns = x_test.columns\n",
    "#     imputed_x_test.index = x_test.index\n",
    "    \n",
    "    return (imputed_x_train, y_train, x_test, y_test, imputer, train_mean, train_std)\n",
    "\n",
    "def normalize(x_test, train_mean, train_std, imputer, cols_to_normalize):\n",
    "    imputed_x_test = x_test.copy(deep=True)\n",
    "    for col in cols_to_normalize:\n",
    "        imputed_x_test.loc[:, col] = (imputed_x_test.loc[:, col] - train_mean[col])/train_std[col]\n",
    "    imputed_x_test = pd.DataFrame(imputer.transform(imputed_x_test))\n",
    "    imputed_x_test.columns = x_test.columns\n",
    "    imputed_x_test.index = x_test.index\n",
    "    return imputed_x_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 351,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1935 : Gold- 964 : NonGold- 971\n",
      "484 : Gold- 255 : NonGold- 229\n",
      "1935 : Gold- 964 : NonGold- 971\n",
      "484 : Gold- 255 : NonGold- 229\n",
      "1935 : Gold- 964 : NonGold- 971\n",
      "484 : Gold- 255 : NonGold- 229\n",
      "1935 : Gold- 964 : NonGold- 971\n",
      "484 : Gold- 255 : NonGold- 229\n",
      "1935 : Gold- 964 : NonGold- 971\n",
      "484 : Gold- 255 : NonGold- 229\n",
      "1935 : Gold- 964 : NonGold- 971\n",
      "484 : Gold- 255 : NonGold- 229\n"
     ]
    }
   ],
   "source": [
    "cols = ['articleId', 'mentionMatched', 'companyId', 'exactMatch', 'fieldMatch', 'isIndustry', \"tickerMatch\", 'isPublic', 'isProminentByItself', 'isProminentByParent', 'isUrlMatched','isGold'] # 'isSingleCompanyMatch'\n",
    "cols_to_normalize = [item for item in s1.columns.tolist() if item not in cols]\n",
    "\n",
    "imputed_x_train1, y_train1, x_test1, y_test1, imputer1, train_mean1, train_std1 = split_and_normalize_data(s1, cols_to_normalize)\n",
    "imputed_x_train2, y_train2, x_test2, y_test2, imputer2, train_mean2, train_std2 = split_and_normalize_data(s2, cols_to_normalize)\n",
    "imputed_x_train3, y_train3, x_test3, y_test3, imputer3, train_mean3, train_std3 = split_and_normalize_data(s3, cols_to_normalize)\n",
    "imputed_x_train4, y_train4, x_test4, y_test4, imputer4, train_mean4, train_std4 = split_and_normalize_data(s4, cols_to_normalize)\n",
    "imputed_x_train5, y_train5, x_test5, y_test5, imputer5, train_mean5, train_std5 = split_and_normalize_data(s5, cols_to_normalize)\n",
    "imputed_x_train6, y_train6, x_test6, y_test6, imputer6, train_mean6, train_std6 = split_and_normalize_data(s6, cols_to_normalize)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 478,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['articleLength',\n",
       " 'countOfDistinctIndustry',\n",
       " 'countOfOccurence',\n",
       " 'countOfOccurenceOfAliases',\n",
       " 'countOfOccurenceOfNamePreserveList',\n",
       " 'countOfSignificantStrings',\n",
       " 'countOfUrlMatch',\n",
       " 'countryMatchByOverlapScore',\n",
       " 'directCityMatchScore',\n",
       " 'directCountryMatchScore',\n",
       " 'directStateMatchScore',\n",
       " 'empCount',\n",
       " 'stateMatchByOverlapScore',\n",
       " 'sumOfIndustry',\n",
       " 'w2vScore']"
      ]
     },
     "execution_count": 478,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cols_to_normalize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 352,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC, SVR \n",
    "################## SIMPLE RBF KERNEL ###################\n",
    "# svclassifier = SVR(kernel='rbf')  \n",
    "# svclassifier.fit(imputed_x_train, y_train) \n",
    "# y_pred = svclassifier.predict(imputed_x_test)  \n",
    "#######################################################\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import StratifiedShuffleSplit\n",
    "\n",
    "def train(train_x, train_y):\n",
    "    svr = SVR(kernel='rbf')\n",
    "    C_range = np.logspace(-3, 3, 7)\n",
    "    gamma_range = np.logspace(-3, 3, 7)\n",
    "    param_grid = dict( C=C_range, gamma=gamma_range)\n",
    "    cv = StratifiedShuffleSplit(n_splits=5, test_size=0.2, random_state=0)\n",
    "    grid = GridSearchCV(svr, param_grid=param_grid, cv=cv)\n",
    "    grid.fit(imputed_x_train1, y_train1)\n",
    "    print(\"DONE\")\n",
    "    return grid\n",
    "\n",
    "# train(imputed_x_train1,  y_train1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 353,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DONE\n",
      "DONE\n",
      "DONE\n",
      "DONE\n",
      "DONE\n",
      "DONE\n"
     ]
    }
   ],
   "source": [
    "m1 = train(imputed_x_train1,  y_train1)\n",
    "a1 = normalize(x_test1, train_mean1, train_std1, imputer1, cols_to_normalize)\n",
    "m2 = train(imputed_x_train2,  y_train2)\n",
    "a2 = normalize(x_test2, train_mean2, train_std2, imputer2, cols_to_normalize)\n",
    "m3 = train(imputed_x_train3,  y_train3)\n",
    "a3 = normalize(x_test3, train_mean3, train_std3, imputer3, cols_to_normalize)\n",
    "m4 = train(imputed_x_train4,  y_train4)\n",
    "a4 = normalize(x_test4, train_mean4, train_std4, imputer4, cols_to_normalize)\n",
    "m5 = train(imputed_x_train5,  y_train5)\n",
    "a5 = normalize(x_test5, train_mean5, train_std5, imputer5, cols_to_normalize)\n",
    "m6 = train(imputed_x_train6,  y_train6)\n",
    "a6 = normalize(x_test6, train_mean6, train_std6, imputer6, cols_to_normalize)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 393,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "       False       0.84      0.86      0.85       229\n",
      "        True       0.87      0.86      0.86       255\n",
      "\n",
      "   micro avg       0.86      0.86      0.86       484\n",
      "   macro avg       0.86      0.86      0.86       484\n",
      "weighted avg       0.86      0.86      0.86       484\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       False       0.84      0.86      0.85       229\n",
      "        True       0.87      0.86      0.86       255\n",
      "\n",
      "   micro avg       0.86      0.86      0.86       484\n",
      "   macro avg       0.86      0.86      0.86       484\n",
      "weighted avg       0.86      0.86      0.86       484\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       False       0.84      0.84      0.84       229\n",
      "        True       0.86      0.85      0.85       255\n",
      "\n",
      "   micro avg       0.85      0.85      0.85       484\n",
      "   macro avg       0.85      0.85      0.85       484\n",
      "weighted avg       0.85      0.85      0.85       484\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       False       0.84      0.84      0.84       229\n",
      "        True       0.86      0.85      0.85       255\n",
      "\n",
      "   micro avg       0.85      0.85      0.85       484\n",
      "   macro avg       0.85      0.85      0.85       484\n",
      "weighted avg       0.85      0.85      0.85       484\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       False       0.84      0.84      0.84       229\n",
      "        True       0.86      0.86      0.86       255\n",
      "\n",
      "   micro avg       0.85      0.85      0.85       484\n",
      "   macro avg       0.85      0.85      0.85       484\n",
      "weighted avg       0.85      0.85      0.85       484\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       False       0.84      0.84      0.84       229\n",
      "        True       0.86      0.86      0.86       255\n",
      "\n",
      "   micro avg       0.85      0.85      0.85       484\n",
      "   macro avg       0.85      0.85      0.85       484\n",
      "weighted avg       0.85      0.85      0.85       484\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       False       0.85      0.85      0.85       229\n",
      "        True       0.86      0.86      0.86       255\n",
      "\n",
      "   micro avg       0.86      0.86      0.86       484\n",
      "   macro avg       0.85      0.85      0.85       484\n",
      "weighted avg       0.86      0.86      0.86       484\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       False       0.85      0.85      0.85       229\n",
      "        True       0.86      0.86      0.86       255\n",
      "\n",
      "   micro avg       0.86      0.86      0.86       484\n",
      "   macro avg       0.85      0.85      0.85       484\n",
      "weighted avg       0.86      0.86      0.86       484\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       False       0.85      0.83      0.84       229\n",
      "        True       0.85      0.87      0.86       255\n",
      "\n",
      "   micro avg       0.85      0.85      0.85       484\n",
      "   macro avg       0.85      0.85      0.85       484\n",
      "weighted avg       0.85      0.85      0.85       484\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       False       0.85      0.83      0.84       229\n",
      "        True       0.85      0.87      0.86       255\n",
      "\n",
      "   micro avg       0.85      0.85      0.85       484\n",
      "   macro avg       0.85      0.85      0.85       484\n",
      "weighted avg       0.85      0.85      0.85       484\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       False       0.84      0.83      0.83       229\n",
      "        True       0.85      0.86      0.85       255\n",
      "\n",
      "   micro avg       0.85      0.85      0.85       484\n",
      "   macro avg       0.84      0.84      0.84       484\n",
      "weighted avg       0.85      0.85      0.84       484\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       False       0.84      0.83      0.83       229\n",
      "        True       0.85      0.86      0.85       255\n",
      "\n",
      "   micro avg       0.85      0.85      0.85       484\n",
      "   macro avg       0.84      0.84      0.84       484\n",
      "weighted avg       0.85      0.85      0.84       484\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[0.20211464],\n",
       "       [0.8607759 ],\n",
       "       [0.11552421],\n",
       "       [0.63927054],\n",
       "       [0.10105118],\n",
       "       [0.97424371],\n",
       "       [0.91581304],\n",
       "       [0.08272832],\n",
       "       [0.11482554],\n",
       "       [0.60269566],\n",
       "       [0.87167776],\n",
       "       [0.09296842],\n",
       "       [0.68867904],\n",
       "       [0.96186617],\n",
       "       [0.15761837],\n",
       "       [0.48883799],\n",
       "       [0.07892882],\n",
       "       [0.10493217],\n",
       "       [0.0869492 ],\n",
       "       [0.58836851],\n",
       "       [0.57445919],\n",
       "       [0.09981029],\n",
       "       [0.34603428],\n",
       "       [0.84931218],\n",
       "       [0.11075107],\n",
       "       [0.52042796],\n",
       "       [0.37851535],\n",
       "       [1.11921164],\n",
       "       [0.49328915],\n",
       "       [0.08704605],\n",
       "       [0.15030983],\n",
       "       [1.01087762],\n",
       "       [1.06114279],\n",
       "       [0.77307768],\n",
       "       [0.89823787],\n",
       "       [0.64977087],\n",
       "       [0.86952761],\n",
       "       [0.10943039],\n",
       "       [1.0609463 ],\n",
       "       [0.25867975],\n",
       "       [0.1149837 ],\n",
       "       [0.76203484],\n",
       "       [0.97170957],\n",
       "       [0.52376798],\n",
       "       [0.123073  ],\n",
       "       [0.90357867],\n",
       "       [0.94427351],\n",
       "       [0.33825217],\n",
       "       [0.09794923],\n",
       "       [0.96011335],\n",
       "       [0.80765249],\n",
       "       [0.09711327],\n",
       "       [0.77262406],\n",
       "       [0.84946681],\n",
       "       [0.35624505],\n",
       "       [0.97349579],\n",
       "       [0.39550003],\n",
       "       [0.26538162],\n",
       "       [0.26447457],\n",
       "       [0.2354792 ],\n",
       "       [0.07318275],\n",
       "       [0.11512308],\n",
       "       [0.86865438],\n",
       "       [0.99527818],\n",
       "       [0.81232077],\n",
       "       [0.10574563],\n",
       "       [0.0891557 ],\n",
       "       [0.28817752],\n",
       "       [0.17267684],\n",
       "       [0.11297631],\n",
       "       [0.10544174],\n",
       "       [0.90879765],\n",
       "       [0.27593678],\n",
       "       [0.83464817],\n",
       "       [0.54871211],\n",
       "       [0.08222521],\n",
       "       [1.09860271],\n",
       "       [0.10421245],\n",
       "       [0.12393825],\n",
       "       [0.1178948 ],\n",
       "       [0.10240982],\n",
       "       [0.16345447],\n",
       "       [0.49167191],\n",
       "       [0.75453465],\n",
       "       [1.02524977],\n",
       "       [0.0818508 ],\n",
       "       [0.53749816],\n",
       "       [0.10593243],\n",
       "       [0.10110379],\n",
       "       [0.11905715],\n",
       "       [0.90799163],\n",
       "       [0.94516744],\n",
       "       [0.48497745],\n",
       "       [0.34146982],\n",
       "       [0.37550007],\n",
       "       [0.05942871],\n",
       "       [0.8810899 ],\n",
       "       [0.97974779],\n",
       "       [0.81772292],\n",
       "       [0.79160204],\n",
       "       [0.20540126],\n",
       "       [0.75498168],\n",
       "       [0.91522495],\n",
       "       [0.07505423],\n",
       "       [0.93189505],\n",
       "       [0.65269719],\n",
       "       [0.1442022 ],\n",
       "       [0.75999078],\n",
       "       [1.04200471],\n",
       "       [0.04796052],\n",
       "       [0.1329866 ],\n",
       "       [0.89200207],\n",
       "       [0.44184866],\n",
       "       [1.06414089],\n",
       "       [0.67415313],\n",
       "       [0.05412849],\n",
       "       [0.91791362],\n",
       "       [0.09330969],\n",
       "       [0.9376902 ],\n",
       "       [0.86951876],\n",
       "       [0.94160014],\n",
       "       [0.10156883],\n",
       "       [0.51390663],\n",
       "       [0.09329914],\n",
       "       [0.73519941],\n",
       "       [0.50537244],\n",
       "       [0.69398187],\n",
       "       [1.08467888],\n",
       "       [0.09836325],\n",
       "       [0.87083832],\n",
       "       [0.76749837],\n",
       "       [0.60082271],\n",
       "       [0.07197887],\n",
       "       [0.1347069 ],\n",
       "       [0.881478  ],\n",
       "       [0.96379482],\n",
       "       [0.87583555],\n",
       "       [0.09358   ],\n",
       "       [0.9026025 ],\n",
       "       [0.53749816],\n",
       "       [1.07520231],\n",
       "       [0.94636281],\n",
       "       [0.41655455],\n",
       "       [1.08330062],\n",
       "       [0.93943417],\n",
       "       [0.30749595],\n",
       "       [0.34487737],\n",
       "       [0.92109157],\n",
       "       [0.78003346],\n",
       "       [0.6576498 ],\n",
       "       [0.10413973],\n",
       "       [0.09771481],\n",
       "       [0.9036528 ],\n",
       "       [0.86851545],\n",
       "       [0.10908922],\n",
       "       [0.12471063],\n",
       "       [0.93411481],\n",
       "       [0.82686874],\n",
       "       [0.11133495],\n",
       "       [0.89425224],\n",
       "       [0.48792953],\n",
       "       [0.99155904],\n",
       "       [0.670042  ],\n",
       "       [1.05170934],\n",
       "       [0.07278816],\n",
       "       [0.16964078],\n",
       "       [0.14908702],\n",
       "       [0.10458318],\n",
       "       [0.12279811],\n",
       "       [0.73759398],\n",
       "       [0.13732894],\n",
       "       [0.98534367],\n",
       "       [0.90594664],\n",
       "       [0.77412373],\n",
       "       [0.12540087],\n",
       "       [0.03287274],\n",
       "       [1.08802464],\n",
       "       [1.08281407],\n",
       "       [1.05027869],\n",
       "       [0.84525977],\n",
       "       [0.75867175],\n",
       "       [0.94895917],\n",
       "       [1.0864535 ],\n",
       "       [0.12114314],\n",
       "       [0.77526683],\n",
       "       [0.05804082],\n",
       "       [1.01400343],\n",
       "       [0.5079666 ],\n",
       "       [0.90431161],\n",
       "       [0.92704113],\n",
       "       [0.98753345],\n",
       "       [0.11359776],\n",
       "       [0.31678686],\n",
       "       [0.11778415],\n",
       "       [1.1085562 ],\n",
       "       [0.15539791],\n",
       "       [1.07892915],\n",
       "       [1.04168918],\n",
       "       [0.59860563],\n",
       "       [0.11277861],\n",
       "       [0.9565206 ],\n",
       "       [0.10486003],\n",
       "       [0.54739095],\n",
       "       [0.53542358],\n",
       "       [0.81653135],\n",
       "       [0.91033386],\n",
       "       [0.13848853],\n",
       "       [0.1110029 ],\n",
       "       [0.86037197],\n",
       "       [1.04299558],\n",
       "       [0.4837925 ],\n",
       "       [0.78587848],\n",
       "       [1.00911898],\n",
       "       [0.10521655],\n",
       "       [0.11075107],\n",
       "       [0.45168515],\n",
       "       [1.06646486],\n",
       "       [0.09995389],\n",
       "       [0.09508161],\n",
       "       [0.17425988],\n",
       "       [0.15545648],\n",
       "       [0.38446375],\n",
       "       [1.00559405],\n",
       "       [1.06290747],\n",
       "       [0.60256116],\n",
       "       [1.03537433],\n",
       "       [0.54668416],\n",
       "       [0.07964886],\n",
       "       [1.07825121],\n",
       "       [0.82071307],\n",
       "       [0.11018892],\n",
       "       [0.75332297],\n",
       "       [0.97558326],\n",
       "       [1.02370762],\n",
       "       [0.68174965],\n",
       "       [0.12108371],\n",
       "       [1.06809514],\n",
       "       [0.99725239],\n",
       "       [0.18222384],\n",
       "       [0.01305802],\n",
       "       [1.01301369],\n",
       "       [0.91082183],\n",
       "       [0.49263499],\n",
       "       [0.20279067],\n",
       "       [0.92806951],\n",
       "       [1.07399271],\n",
       "       [0.1110029 ],\n",
       "       [0.6778459 ],\n",
       "       [0.1010928 ],\n",
       "       [1.00354736],\n",
       "       [0.88168992],\n",
       "       [0.67007603],\n",
       "       [0.07049618],\n",
       "       [0.91348129],\n",
       "       [0.33456032],\n",
       "       [0.09084117],\n",
       "       [0.93177639],\n",
       "       [0.82877654],\n",
       "       [0.33676121],\n",
       "       [0.37314633],\n",
       "       [1.10595065],\n",
       "       [0.11333068],\n",
       "       [0.10231748],\n",
       "       [0.10805173],\n",
       "       [0.11088317],\n",
       "       [0.7922874 ],\n",
       "       [0.92899899],\n",
       "       [0.12305741],\n",
       "       [0.06719938],\n",
       "       [0.48914703],\n",
       "       [0.09881827],\n",
       "       [0.89408151],\n",
       "       [0.03160098],\n",
       "       [1.0979045 ],\n",
       "       [0.87993039],\n",
       "       [0.94601583],\n",
       "       [0.22171227],\n",
       "       [0.90350814],\n",
       "       [0.11340929],\n",
       "       [0.05633123],\n",
       "       [0.0831482 ],\n",
       "       [0.11243924],\n",
       "       [0.88945893],\n",
       "       [0.49577794],\n",
       "       [0.10491282],\n",
       "       [0.80906958],\n",
       "       [0.88244876],\n",
       "       [0.94727855],\n",
       "       [0.13780306],\n",
       "       [0.93567828],\n",
       "       [1.05059623],\n",
       "       [0.11611026],\n",
       "       [1.02149587],\n",
       "       [0.20909851],\n",
       "       [0.09249196],\n",
       "       [0.75075759],\n",
       "       [0.79782361],\n",
       "       [0.62520606],\n",
       "       [0.66148463],\n",
       "       [0.1098001 ],\n",
       "       [0.87209329],\n",
       "       [0.50079884],\n",
       "       [0.09622966],\n",
       "       [1.03005614],\n",
       "       [0.73853675],\n",
       "       [0.24275137],\n",
       "       [0.33073731],\n",
       "       [0.09195512],\n",
       "       [0.09296842],\n",
       "       [0.86117541],\n",
       "       [1.13597029],\n",
       "       [0.12010366],\n",
       "       [1.03480814],\n",
       "       [0.06885015],\n",
       "       [1.05011441],\n",
       "       [0.5622727 ],\n",
       "       [0.88643079],\n",
       "       [0.78824028],\n",
       "       [0.11042614],\n",
       "       [0.09698759],\n",
       "       [0.11140112],\n",
       "       [0.1119011 ],\n",
       "       [0.12638073],\n",
       "       [0.54459641],\n",
       "       [0.89815131],\n",
       "       [0.1056039 ],\n",
       "       [0.55209538],\n",
       "       [0.28468428],\n",
       "       [0.10541147],\n",
       "       [0.47057297],\n",
       "       [0.9532445 ],\n",
       "       [0.60780933],\n",
       "       [0.78649532],\n",
       "       [1.00445437],\n",
       "       [0.64854055],\n",
       "       [0.12256508],\n",
       "       [0.13432297],\n",
       "       [0.10906261],\n",
       "       [0.10078388],\n",
       "       [0.60082271],\n",
       "       [0.23700944],\n",
       "       [0.11052919],\n",
       "       [0.89694697],\n",
       "       [1.00843621],\n",
       "       [0.91473147],\n",
       "       [0.10766578],\n",
       "       [0.13323363],\n",
       "       [0.24924796],\n",
       "       [0.11657452],\n",
       "       [1.03882953],\n",
       "       [0.06546715],\n",
       "       [0.9207    ],\n",
       "       [0.88369918],\n",
       "       [0.93589482],\n",
       "       [0.87238407],\n",
       "       [0.8483195 ],\n",
       "       [0.10803061],\n",
       "       [1.11098804],\n",
       "       [0.92437031],\n",
       "       [0.42284309],\n",
       "       [0.8735466 ],\n",
       "       [0.8011177 ],\n",
       "       [0.93886925],\n",
       "       [0.07913974],\n",
       "       [0.93753343],\n",
       "       [0.66343488],\n",
       "       [0.07146639],\n",
       "       [0.98562735],\n",
       "       [0.81997453],\n",
       "       [0.89944954],\n",
       "       [0.47039195],\n",
       "       [0.09143455],\n",
       "       [0.73644149],\n",
       "       [0.0650019 ],\n",
       "       [0.40442501],\n",
       "       [0.86678524],\n",
       "       [0.22193606],\n",
       "       [0.36247509],\n",
       "       [0.08892187],\n",
       "       [0.91716026],\n",
       "       [0.4529582 ],\n",
       "       [0.91647436],\n",
       "       [0.93633382],\n",
       "       [0.09343172],\n",
       "       [0.08735688],\n",
       "       [0.89583896],\n",
       "       [0.78604821],\n",
       "       [0.07886687],\n",
       "       [0.60361179],\n",
       "       [0.08735688],\n",
       "       [0.22120616],\n",
       "       [0.08381953],\n",
       "       [0.19737267],\n",
       "       [0.09957924],\n",
       "       [0.30766442],\n",
       "       [0.13549102],\n",
       "       [0.93455609],\n",
       "       [0.93447918],\n",
       "       [1.00418512],\n",
       "       [0.30749595],\n",
       "       [1.08806616],\n",
       "       [0.89322633],\n",
       "       [0.10688417],\n",
       "       [0.676878  ],\n",
       "       [0.81265829],\n",
       "       [0.83500383],\n",
       "       [0.10749468],\n",
       "       [0.91647436],\n",
       "       [0.10545314],\n",
       "       [0.92543319],\n",
       "       [0.9574357 ],\n",
       "       [0.11328996],\n",
       "       [0.91959378],\n",
       "       [0.10250057],\n",
       "       [0.09711327],\n",
       "       [0.07414874],\n",
       "       [1.03067113],\n",
       "       [0.97178773],\n",
       "       [0.82451613],\n",
       "       [0.22572337],\n",
       "       [0.76044724],\n",
       "       [0.83013409],\n",
       "       [0.13342517],\n",
       "       [0.98337624],\n",
       "       [0.61835262],\n",
       "       [0.93477958],\n",
       "       [0.09573568],\n",
       "       [0.63342113],\n",
       "       [1.04869612],\n",
       "       [0.11026321],\n",
       "       [0.10521025],\n",
       "       [0.12467018],\n",
       "       [0.12523587],\n",
       "       [0.87184444],\n",
       "       [0.40815499],\n",
       "       [0.87514328],\n",
       "       [1.02335889],\n",
       "       [0.1171771 ],\n",
       "       [1.05370269],\n",
       "       [0.11610508],\n",
       "       [0.97539468],\n",
       "       [0.922424  ],\n",
       "       [0.98861442],\n",
       "       [0.10143231],\n",
       "       [0.92919341],\n",
       "       [0.10447824],\n",
       "       [0.10753965],\n",
       "       [0.87701165],\n",
       "       [0.09749177],\n",
       "       [0.91108714],\n",
       "       [0.2885538 ],\n",
       "       [0.26938634],\n",
       "       [1.00834576],\n",
       "       [0.99174587],\n",
       "       [0.82577546],\n",
       "       [0.1710788 ],\n",
       "       [0.97539599],\n",
       "       [0.1107202 ],\n",
       "       [1.02922832],\n",
       "       [0.49046482],\n",
       "       [0.11530548],\n",
       "       [0.11044883],\n",
       "       [0.86426893],\n",
       "       [0.87906057],\n",
       "       [0.57998547],\n",
       "       [0.93154669],\n",
       "       [1.03082861],\n",
       "       [0.74618935],\n",
       "       [0.79648669],\n",
       "       [0.66372028],\n",
       "       [0.10897974],\n",
       "       [0.93226904],\n",
       "       [0.37017008],\n",
       "       [0.86884195],\n",
       "       [0.11905715],\n",
       "       [0.81836838],\n",
       "       [0.08690352],\n",
       "       [0.10458318],\n",
       "       [1.01364262],\n",
       "       [0.07760998],\n",
       "       [0.76750971],\n",
       "       [0.87697128],\n",
       "       [0.82917958],\n",
       "       [0.14607424]])"
      ]
     },
     "execution_count": 393,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "score(m1, a1, y_test1)\n",
    "save_model('m1.sav', m1)\n",
    "load_and_score('m1.sav', a1, y_test1)\n",
    "\n",
    "score(m2, a2, y_test2)\n",
    "save_model('m2.sav', m2)\n",
    "load_and_score('m2.sav', a2, y_test2)\n",
    "\n",
    "score(m3, a3, y_test3)\n",
    "save_model('m3.sav', m3)\n",
    "load_and_score('m3.sav', a3, y_test3)\n",
    "\n",
    "score(m4, a4, y_test4)\n",
    "save_model('m4.sav', m4)\n",
    "load_and_score('m4.sav', a4, y_test4)\n",
    "\n",
    "score(m5, a5, y_test5)\n",
    "save_model('m5.sav', m5)\n",
    "load_and_score('m5.sav', a5, y_test5)\n",
    "\n",
    "score(m6, a6, y_test6)\n",
    "save_model('m6.sav', m6)\n",
    "load_and_score('m6.sav', a6, y_test6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 484,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Expected 2D array, got 1D array instead:\narray=[ 0.04833786  0.16671975  2.17873791 -0.17518793 -0.18038709 -0.07188621\n -0.131307    0.87719359 -0.24221646 -0.38292294 -0.22729915 -0.27360081\n  0.          2.          0.          0.          0.          0.\n  0.          1.4759416  -0.22690903  0.         -0.63220201].\nReshape your data either using array.reshape(-1, 1) if your data has a single feature or array.reshape(1, -1) if it contains a single sample.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-484-d17c07d37032>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# y6_1 = score(m1, a6_1, y_test6)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mq\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma6_1\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mm1\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mq\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/Documents/mygitrepo/cs230-code-examples/tensorflow/nlp/cs230/lib/python3.6/site-packages/sklearn/utils/metaestimators.py\u001b[0m in \u001b[0;36m<lambda>\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    116\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    117\u001b[0m         \u001b[0;31m# lambda, but not partial, allows help() to work with update_wrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 118\u001b[0;31m         \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mlambda\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    119\u001b[0m         \u001b[0;31m# update the docstring of the returned function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    120\u001b[0m         \u001b[0mupdate_wrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documents/mygitrepo/cs230-code-examples/tensorflow/nlp/cs230/lib/python3.6/site-packages/sklearn/model_selection/_search.py\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m    489\u001b[0m         \"\"\"\n\u001b[1;32m    490\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_check_is_fitted\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'predict'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 491\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbest_estimator_\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    492\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    493\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mif_delegate_has_method\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdelegate\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'best_estimator_'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'estimator'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documents/mygitrepo/cs230-code-examples/tensorflow/nlp/cs230/lib/python3.6/site-packages/sklearn/svm/base.py\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m    323\u001b[0m         \u001b[0my_pred\u001b[0m \u001b[0;34m:\u001b[0m \u001b[0marray\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshape\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mn_samples\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    324\u001b[0m         \"\"\"\n\u001b[0;32m--> 325\u001b[0;31m         \u001b[0mX\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_validate_for_predict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    326\u001b[0m         \u001b[0mpredict\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sparse_predict\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sparse\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dense_predict\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    327\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documents/mygitrepo/cs230-code-examples/tensorflow/nlp/cs230/lib/python3.6/site-packages/sklearn/svm/base.py\u001b[0m in \u001b[0;36m_validate_for_predict\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m    456\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    457\u001b[0m         X = check_array(X, accept_sparse='csr', dtype=np.float64, order=\"C\",\n\u001b[0;32m--> 458\u001b[0;31m                         accept_large_sparse=False)\n\u001b[0m\u001b[1;32m    459\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sparse\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0msp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0misspmatrix\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    460\u001b[0m             \u001b[0mX\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcsr_matrix\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documents/mygitrepo/cs230-code-examples/tensorflow/nlp/cs230/lib/python3.6/site-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36mcheck_array\u001b[0;34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, warn_on_dtype, estimator)\u001b[0m\n\u001b[1;32m    550\u001b[0m                     \u001b[0;34m\"Reshape your data either using array.reshape(-1, 1) if \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    551\u001b[0m                     \u001b[0;34m\"your data has a single feature or array.reshape(1, -1) \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 552\u001b[0;31m                     \"if it contains a single sample.\".format(array))\n\u001b[0m\u001b[1;32m    553\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    554\u001b[0m         \u001b[0;31m# in the future np.flexible dtypes will be handled like object dtypes\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Expected 2D array, got 1D array instead:\narray=[ 0.04833786  0.16671975  2.17873791 -0.17518793 -0.18038709 -0.07188621\n -0.131307    0.87719359 -0.24221646 -0.38292294 -0.22729915 -0.27360081\n  0.          2.          0.          0.          0.          0.\n  0.          1.4759416  -0.22690903  0.         -0.63220201].\nReshape your data either using array.reshape(-1, 1) if your data has a single feature or array.reshape(1, -1) if it contains a single sample."
     ]
    }
   ],
   "source": [
    "# y6_1 = score(m1, a6_1, y_test6)\n",
    "q = np.asarray(a6_1.iloc[0,:])\n",
    "m1.predict(q)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 319,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>articleLength</th>\n",
       "      <th>countOfDistinctIndustry</th>\n",
       "      <th>countOfOccurence</th>\n",
       "      <th>countOfOccurenceOfAliases</th>\n",
       "      <th>countOfOccurenceOfNamePreserveList</th>\n",
       "      <th>countOfSignificantStrings</th>\n",
       "      <th>countOfUrlMatch</th>\n",
       "      <th>countryMatchByOverlapScore</th>\n",
       "      <th>directCityMatchScore</th>\n",
       "      <th>directCountryMatchScore</th>\n",
       "      <th>...</th>\n",
       "      <th>fieldMatch</th>\n",
       "      <th>isIndustry</th>\n",
       "      <th>isProminentByItself</th>\n",
       "      <th>isProminentByParent</th>\n",
       "      <th>isPublic</th>\n",
       "      <th>isUrlMatched</th>\n",
       "      <th>stateMatchByOverlapScore</th>\n",
       "      <th>sumOfIndustry</th>\n",
       "      <th>tickerMatch</th>\n",
       "      <th>w2vScore</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>484.000000</td>\n",
       "      <td>484.000000</td>\n",
       "      <td>484.000000</td>\n",
       "      <td>484.000000</td>\n",
       "      <td>484.000000</td>\n",
       "      <td>484.000000</td>\n",
       "      <td>484.000000</td>\n",
       "      <td>482.000000</td>\n",
       "      <td>379.000000</td>\n",
       "      <td>482.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>484.000000</td>\n",
       "      <td>484.000000</td>\n",
       "      <td>484.000000</td>\n",
       "      <td>484.000000</td>\n",
       "      <td>484.000000</td>\n",
       "      <td>484.000000</td>\n",
       "      <td>366.000000</td>\n",
       "      <td>484.000000</td>\n",
       "      <td>484.000000</td>\n",
       "      <td>475.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>3834.252066</td>\n",
       "      <td>6.396694</td>\n",
       "      <td>3.206612</td>\n",
       "      <td>0.146694</td>\n",
       "      <td>0.154959</td>\n",
       "      <td>0.380165</td>\n",
       "      <td>0.041322</td>\n",
       "      <td>0.293568</td>\n",
       "      <td>0.058047</td>\n",
       "      <td>0.085892</td>\n",
       "      <td>...</td>\n",
       "      <td>2.324380</td>\n",
       "      <td>0.086777</td>\n",
       "      <td>0.425620</td>\n",
       "      <td>0.154959</td>\n",
       "      <td>0.214876</td>\n",
       "      <td>0.033058</td>\n",
       "      <td>0.258197</td>\n",
       "      <td>46.431818</td>\n",
       "      <td>0.070248</td>\n",
       "      <td>7.253997</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>5258.457925</td>\n",
       "      <td>8.930121</td>\n",
       "      <td>3.919305</td>\n",
       "      <td>0.770288</td>\n",
       "      <td>0.795143</td>\n",
       "      <td>1.372647</td>\n",
       "      <td>0.237192</td>\n",
       "      <td>0.246430</td>\n",
       "      <td>0.234142</td>\n",
       "      <td>0.210356</td>\n",
       "      <td>...</td>\n",
       "      <td>0.468627</td>\n",
       "      <td>0.281799</td>\n",
       "      <td>0.494948</td>\n",
       "      <td>0.362240</td>\n",
       "      <td>0.411161</td>\n",
       "      <td>0.178973</td>\n",
       "      <td>0.338208</td>\n",
       "      <td>200.806071</td>\n",
       "      <td>0.255829</td>\n",
       "      <td>11.470067</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>39.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>1933.250000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>2821.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.264328</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>4462.500000</td>\n",
       "      <td>9.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.700000</td>\n",
       "      <td>20.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>11.308431</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>53140.000000</td>\n",
       "      <td>72.000000</td>\n",
       "      <td>24.000000</td>\n",
       "      <td>13.000000</td>\n",
       "      <td>13.000000</td>\n",
       "      <td>13.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.600000</td>\n",
       "      <td>...</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.700000</td>\n",
       "      <td>3997.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>66.375770</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows × 23 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       articleLength  countOfDistinctIndustry  countOfOccurence  \\\n",
       "count     484.000000               484.000000        484.000000   \n",
       "mean     3834.252066                 6.396694          3.206612   \n",
       "std      5258.457925                 8.930121          3.919305   \n",
       "min        39.000000                 0.000000          1.000000   \n",
       "25%      1933.250000                 1.000000          1.000000   \n",
       "50%      2821.000000                 3.000000          2.000000   \n",
       "75%      4462.500000                 9.000000          4.000000   \n",
       "max     53140.000000                72.000000         24.000000   \n",
       "\n",
       "       countOfOccurenceOfAliases  countOfOccurenceOfNamePreserveList  \\\n",
       "count                 484.000000                          484.000000   \n",
       "mean                    0.146694                            0.154959   \n",
       "std                     0.770288                            0.795143   \n",
       "min                     0.000000                            0.000000   \n",
       "25%                     0.000000                            0.000000   \n",
       "50%                     0.000000                            0.000000   \n",
       "75%                     0.000000                            0.000000   \n",
       "max                    13.000000                           13.000000   \n",
       "\n",
       "       countOfSignificantStrings  countOfUrlMatch  countryMatchByOverlapScore  \\\n",
       "count                 484.000000       484.000000                  482.000000   \n",
       "mean                    0.380165         0.041322                    0.293568   \n",
       "std                     1.372647         0.237192                    0.246430   \n",
       "min                     0.000000         0.000000                    0.000000   \n",
       "25%                     0.000000         0.000000                    0.000000   \n",
       "50%                     0.000000         0.000000                    0.500000   \n",
       "75%                     0.000000         0.000000                    0.500000   \n",
       "max                    13.000000         2.000000                    0.500000   \n",
       "\n",
       "       directCityMatchScore  directCountryMatchScore  ...  fieldMatch  \\\n",
       "count            379.000000               482.000000  ...  484.000000   \n",
       "mean               0.058047                 0.085892  ...    2.324380   \n",
       "std                0.234142                 0.210356  ...    0.468627   \n",
       "min                0.000000                 0.000000  ...    2.000000   \n",
       "25%                0.000000                 0.000000  ...    2.000000   \n",
       "50%                0.000000                 0.000000  ...    2.000000   \n",
       "75%                0.000000                 0.000000  ...    3.000000   \n",
       "max                1.000000                 0.600000  ...    3.000000   \n",
       "\n",
       "       isIndustry  isProminentByItself  isProminentByParent    isPublic  \\\n",
       "count  484.000000           484.000000           484.000000  484.000000   \n",
       "mean     0.086777             0.425620             0.154959    0.214876   \n",
       "std      0.281799             0.494948             0.362240    0.411161   \n",
       "min      0.000000             0.000000             0.000000    0.000000   \n",
       "25%      0.000000             0.000000             0.000000    0.000000   \n",
       "50%      0.000000             0.000000             0.000000    0.000000   \n",
       "75%      0.000000             1.000000             0.000000    0.000000   \n",
       "max      1.000000             1.000000             1.000000    1.000000   \n",
       "\n",
       "       isUrlMatched  stateMatchByOverlapScore  sumOfIndustry  tickerMatch  \\\n",
       "count    484.000000                366.000000     484.000000   484.000000   \n",
       "mean       0.033058                  0.258197      46.431818     0.070248   \n",
       "std        0.178973                  0.338208     200.806071     0.255829   \n",
       "min        0.000000                  0.000000       0.000000     0.000000   \n",
       "25%        0.000000                  0.000000       1.000000     0.000000   \n",
       "50%        0.000000                  0.000000       6.000000     0.000000   \n",
       "75%        0.000000                  0.700000      20.000000     0.000000   \n",
       "max        1.000000                  0.700000    3997.000000     1.000000   \n",
       "\n",
       "         w2vScore  \n",
       "count  475.000000  \n",
       "mean     7.253997  \n",
       "std     11.470067  \n",
       "min      0.000000  \n",
       "25%      0.000000  \n",
       "50%      0.264328  \n",
       "75%     11.308431  \n",
       "max     66.375770  \n",
       "\n",
       "[8 rows x 23 columns]"
      ]
     },
     "execution_count": 319,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_test1.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 424,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "       False       0.84      0.86      0.85       229\n",
      "        True       0.87      0.86      0.86       255\n",
      "\n",
      "   micro avg       0.86      0.86      0.86       484\n",
      "   macro avg       0.86      0.86      0.86       484\n",
      "weighted avg       0.86      0.86      0.86       484\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       False       0.84      0.86      0.85       229\n",
      "        True       0.87      0.85      0.86       255\n",
      "\n",
      "   micro avg       0.86      0.86      0.86       484\n",
      "   macro avg       0.85      0.86      0.86       484\n",
      "weighted avg       0.86      0.86      0.86       484\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       False       0.85      0.86      0.85       229\n",
      "        True       0.87      0.86      0.87       255\n",
      "\n",
      "   micro avg       0.86      0.86      0.86       484\n",
      "   macro avg       0.86      0.86      0.86       484\n",
      "weighted avg       0.86      0.86      0.86       484\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       False       0.85      0.85      0.85       229\n",
      "        True       0.87      0.86      0.86       255\n",
      "\n",
      "   micro avg       0.86      0.86      0.86       484\n",
      "   macro avg       0.86      0.86      0.86       484\n",
      "weighted avg       0.86      0.86      0.86       484\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       False       0.85      0.84      0.85       229\n",
      "        True       0.86      0.87      0.86       255\n",
      "\n",
      "   micro avg       0.86      0.86      0.86       484\n",
      "   macro avg       0.86      0.85      0.85       484\n",
      "weighted avg       0.86      0.86      0.86       484\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       False       0.85      0.85      0.85       229\n",
      "        True       0.87      0.86      0.86       255\n",
      "\n",
      "   micro avg       0.86      0.86      0.86       484\n",
      "   macro avg       0.86      0.86      0.86       484\n",
      "weighted avg       0.86      0.86      0.86       484\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       False       0.84      0.86      0.85       229\n",
      "        True       0.87      0.86      0.86       255\n",
      "\n",
      "   micro avg       0.86      0.86      0.86       484\n",
      "   macro avg       0.86      0.86      0.86       484\n",
      "weighted avg       0.86      0.86      0.86       484\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       False       0.84      0.84      0.84       229\n",
      "        True       0.86      0.85      0.85       255\n",
      "\n",
      "   micro avg       0.85      0.85      0.85       484\n",
      "   macro avg       0.85      0.85      0.85       484\n",
      "weighted avg       0.85      0.85      0.85       484\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       False       0.84      0.85      0.85       229\n",
      "        True       0.86      0.86      0.86       255\n",
      "\n",
      "   micro avg       0.85      0.85      0.85       484\n",
      "   macro avg       0.85      0.85      0.85       484\n",
      "weighted avg       0.85      0.85      0.85       484\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       False       0.85      0.84      0.84       229\n",
      "        True       0.86      0.86      0.86       255\n",
      "\n",
      "   micro avg       0.85      0.85      0.85       484\n",
      "   macro avg       0.85      0.85      0.85       484\n",
      "weighted avg       0.85      0.85      0.85       484\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       False       0.85      0.84      0.85       229\n",
      "        True       0.86      0.87      0.86       255\n",
      "\n",
      "   micro avg       0.86      0.86      0.86       484\n",
      "   macro avg       0.86      0.85      0.85       484\n",
      "weighted avg       0.86      0.86      0.86       484\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       False       0.85      0.84      0.84       229\n",
      "        True       0.86      0.86      0.86       255\n",
      "\n",
      "   micro avg       0.85      0.85      0.85       484\n",
      "   macro avg       0.85      0.85      0.85       484\n",
      "weighted avg       0.85      0.85      0.85       484\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       False       0.84      0.84      0.84       229\n",
      "        True       0.86      0.86      0.86       255\n",
      "\n",
      "   micro avg       0.85      0.85      0.85       484\n",
      "   macro avg       0.85      0.85      0.85       484\n",
      "weighted avg       0.85      0.85      0.85       484\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       False       0.84      0.85      0.84       229\n",
      "        True       0.86      0.85      0.86       255\n",
      "\n",
      "   micro avg       0.85      0.85      0.85       484\n",
      "   macro avg       0.85      0.85      0.85       484\n",
      "weighted avg       0.85      0.85      0.85       484\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       False       0.84      0.84      0.84       229\n",
      "        True       0.86      0.86      0.86       255\n",
      "\n",
      "   micro avg       0.85      0.85      0.85       484\n",
      "   macro avg       0.85      0.85      0.85       484\n",
      "weighted avg       0.85      0.85      0.85       484\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       False       0.85      0.83      0.84       229\n",
      "        True       0.85      0.86      0.86       255\n",
      "\n",
      "   micro avg       0.85      0.85      0.85       484\n",
      "   macro avg       0.85      0.85      0.85       484\n",
      "weighted avg       0.85      0.85      0.85       484\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       False       0.85      0.82      0.83       229\n",
      "        True       0.84      0.87      0.85       255\n",
      "\n",
      "   micro avg       0.85      0.85      0.85       484\n",
      "   macro avg       0.85      0.84      0.84       484\n",
      "weighted avg       0.85      0.85      0.84       484\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       False       0.85      0.84      0.84       229\n",
      "        True       0.86      0.86      0.86       255\n",
      "\n",
      "   micro avg       0.85      0.85      0.85       484\n",
      "   macro avg       0.85      0.85      0.85       484\n",
      "weighted avg       0.85      0.85      0.85       484\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       False       0.84      0.86      0.85       229\n",
      "        True       0.87      0.86      0.86       255\n",
      "\n",
      "   micro avg       0.86      0.86      0.86       484\n",
      "   macro avg       0.86      0.86      0.86       484\n",
      "weighted avg       0.86      0.86      0.86       484\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       False       0.84      0.86      0.85       229\n",
      "        True       0.87      0.85      0.86       255\n",
      "\n",
      "   micro avg       0.85      0.85      0.85       484\n",
      "   macro avg       0.85      0.85      0.85       484\n",
      "weighted avg       0.85      0.85      0.85       484\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       False       0.84      0.85      0.85       229\n",
      "        True       0.86      0.86      0.86       255\n",
      "\n",
      "   micro avg       0.85      0.85      0.85       484\n",
      "   macro avg       0.85      0.85      0.85       484\n",
      "weighted avg       0.85      0.85      0.85       484\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       False       0.85      0.85      0.85       229\n",
      "        True       0.86      0.86      0.86       255\n",
      "\n",
      "   micro avg       0.86      0.86      0.86       484\n",
      "   macro avg       0.85      0.85      0.85       484\n",
      "weighted avg       0.86      0.86      0.86       484\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       False       0.85      0.84      0.84       229\n",
      "        True       0.86      0.87      0.86       255\n",
      "\n",
      "   micro avg       0.85      0.85      0.85       484\n",
      "   macro avg       0.85      0.85      0.85       484\n",
      "weighted avg       0.85      0.85      0.85       484\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       False       0.85      0.85      0.85       229\n",
      "        True       0.86      0.86      0.86       255\n",
      "\n",
      "   micro avg       0.86      0.86      0.86       484\n",
      "   macro avg       0.85      0.85      0.85       484\n",
      "weighted avg       0.86      0.86      0.86       484\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       False       0.84      0.85      0.85       229\n",
      "        True       0.87      0.86      0.86       255\n",
      "\n",
      "   micro avg       0.86      0.86      0.86       484\n",
      "   macro avg       0.85      0.86      0.86       484\n",
      "weighted avg       0.86      0.86      0.86       484\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       False       0.84      0.86      0.85       229\n",
      "        True       0.87      0.85      0.86       255\n",
      "\n",
      "   micro avg       0.85      0.85      0.85       484\n",
      "   macro avg       0.85      0.85      0.85       484\n",
      "weighted avg       0.85      0.85      0.85       484\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       False       0.84      0.85      0.85       229\n",
      "        True       0.86      0.86      0.86       255\n",
      "\n",
      "   micro avg       0.85      0.85      0.85       484\n",
      "   macro avg       0.85      0.85      0.85       484\n",
      "weighted avg       0.85      0.85      0.85       484\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       False       0.85      0.84      0.84       229\n",
      "        True       0.86      0.86      0.86       255\n",
      "\n",
      "   micro avg       0.85      0.85      0.85       484\n",
      "   macro avg       0.85      0.85      0.85       484\n",
      "weighted avg       0.85      0.85      0.85       484\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       False       0.85      0.83      0.84       229\n",
      "        True       0.85      0.87      0.86       255\n",
      "\n",
      "   micro avg       0.85      0.85      0.85       484\n",
      "   macro avg       0.85      0.85      0.85       484\n",
      "weighted avg       0.85      0.85      0.85       484\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       False       0.85      0.84      0.84       229\n",
      "        True       0.86      0.86      0.86       255\n",
      "\n",
      "   micro avg       0.85      0.85      0.85       484\n",
      "   macro avg       0.85      0.85      0.85       484\n",
      "weighted avg       0.85      0.85      0.85       484\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "       False       0.84      0.84      0.84       229\n",
      "        True       0.86      0.86      0.86       255\n",
      "\n",
      "   micro avg       0.85      0.85      0.85       484\n",
      "   macro avg       0.85      0.85      0.85       484\n",
      "weighted avg       0.85      0.85      0.85       484\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       False       0.84      0.86      0.85       229\n",
      "        True       0.87      0.85      0.86       255\n",
      "\n",
      "   micro avg       0.85      0.85      0.85       484\n",
      "   macro avg       0.85      0.85      0.85       484\n",
      "weighted avg       0.85      0.85      0.85       484\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       False       0.84      0.83      0.84       229\n",
      "        True       0.85      0.86      0.85       255\n",
      "\n",
      "   micro avg       0.85      0.85      0.85       484\n",
      "   macro avg       0.84      0.84      0.84       484\n",
      "weighted avg       0.84      0.85      0.84       484\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       False       0.84      0.83      0.83       229\n",
      "        True       0.85      0.86      0.85       255\n",
      "\n",
      "   micro avg       0.85      0.85      0.85       484\n",
      "   macro avg       0.84      0.84      0.84       484\n",
      "weighted avg       0.85      0.85      0.84       484\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       False       0.85      0.82      0.83       229\n",
      "        True       0.84      0.87      0.85       255\n",
      "\n",
      "   micro avg       0.84      0.84      0.84       484\n",
      "   macro avg       0.84      0.84      0.84       484\n",
      "weighted avg       0.84      0.84      0.84       484\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       False       0.84      0.83      0.83       229\n",
      "        True       0.85      0.86      0.85       255\n",
      "\n",
      "   micro avg       0.85      0.85      0.85       484\n",
      "   macro avg       0.84      0.84      0.84       484\n",
      "weighted avg       0.85      0.85      0.84       484\n",
      "\n"
     ]
    }
   ],
   "source": [
    "a1_1 = normalize(x_test1, train_mean1, train_std1, imputer1, cols_to_normalize)\n",
    "a1_2 = normalize(x_test1, train_mean2, train_std2, imputer2, cols_to_normalize)\n",
    "a1_3 = normalize(x_test1, train_mean3, train_std3, imputer3, cols_to_normalize)\n",
    "a1_4 = normalize(x_test1, train_mean4, train_std4, imputer4, cols_to_normalize)\n",
    "a1_5 = normalize(x_test1, train_mean5, train_std5, imputer5, cols_to_normalize)\n",
    "a1_6 = normalize(x_test1, train_mean6, train_std6, imputer6, cols_to_normalize)\n",
    "\n",
    "y1_1 = score(m1, a1_1, y_test1)\n",
    "y1_2 = score(m2, a1_2, y_test1)\n",
    "y1_3 = score(m3, a1_3, y_test1)\n",
    "y1_4 = score(m4, a1_4, y_test1)\n",
    "y1_5 = score(m5, a1_5, y_test1)\n",
    "y1_6 = score(m6, a1_6, y_test1)\n",
    "\n",
    "a2_1 = normalize(x_test2, train_mean1, train_std1, imputer1, cols_to_normalize)\n",
    "a2_2 = normalize(x_test2, train_mean2, train_std2, imputer2, cols_to_normalize)\n",
    "a2_3 = normalize(x_test2, train_mean3, train_std3, imputer3, cols_to_normalize)\n",
    "a2_4 = normalize(x_test2, train_mean4, train_std4, imputer4, cols_to_normalize)\n",
    "a2_5 = normalize(x_test2, train_mean5, train_std5, imputer5, cols_to_normalize)\n",
    "a2_6 = normalize(x_test2, train_mean6, train_std6, imputer6, cols_to_normalize)\n",
    "\n",
    "y2_1 = score(m1, a2_1, y_test2)\n",
    "y2_2 = score(m2, a2_2, y_test2)\n",
    "y2_3 = score(m3, a2_3, y_test2)\n",
    "y2_4 = score(m4, a2_4, y_test2)\n",
    "y2_5 = score(m5, a2_5, y_test2)\n",
    "y2_6 = score(m6, a2_6, y_test2)\n",
    "\n",
    "\n",
    "a3_1 = normalize(x_test3, train_mean1, train_std1, imputer1, cols_to_normalize)\n",
    "a3_2 = normalize(x_test3, train_mean2, train_std2, imputer2, cols_to_normalize)\n",
    "a3_3 = normalize(x_test3, train_mean3, train_std3, imputer3, cols_to_normalize)\n",
    "a3_4 = normalize(x_test3, train_mean4, train_std4, imputer4, cols_to_normalize)\n",
    "a3_5 = normalize(x_test3, train_mean5, train_std5, imputer5, cols_to_normalize)\n",
    "a3_6 = normalize(x_test3, train_mean6, train_std6, imputer6, cols_to_normalize)\n",
    "\n",
    "y3_1 = score(m1, a3_1, y_test3)\n",
    "y3_2 = score(m2, a3_2, y_test3)\n",
    "y3_3 = score(m3, a3_3, y_test3)\n",
    "y3_4 = score(m4, a3_4, y_test3)\n",
    "y3_5 = score(m5, a3_5, y_test3)\n",
    "y3_6 = score(m6, a3_6, y_test3)\n",
    "\n",
    "\n",
    "a4_1 = normalize(x_test4, train_mean1, train_std1, imputer1, cols_to_normalize)\n",
    "a4_2 = normalize(x_test4, train_mean2, train_std2, imputer2, cols_to_normalize)\n",
    "a4_3 = normalize(x_test4, train_mean3, train_std3, imputer3, cols_to_normalize)\n",
    "a4_4 = normalize(x_test4, train_mean4, train_std4, imputer4, cols_to_normalize)\n",
    "a4_5 = normalize(x_test4, train_mean5, train_std5, imputer5, cols_to_normalize)\n",
    "a4_6 = normalize(x_test4, train_mean6, train_std6, imputer6, cols_to_normalize)\n",
    "\n",
    "y4_1 = score(m1, a4_1, y_test4)\n",
    "y4_2 = score(m2, a4_2, y_test4)\n",
    "y4_3 = score(m3, a4_3, y_test4)\n",
    "y4_4 = score(m4, a4_4, y_test4)\n",
    "y4_5 = score(m5, a4_5, y_test4)\n",
    "y4_6 = score(m6, a4_6, y_test4)\n",
    "\n",
    "\n",
    "a5_1 = normalize(x_test5, train_mean1, train_std1, imputer1, cols_to_normalize)\n",
    "a5_2 = normalize(x_test5, train_mean2, train_std2, imputer2, cols_to_normalize)\n",
    "a5_3 = normalize(x_test5, train_mean3, train_std3, imputer3, cols_to_normalize)\n",
    "a5_4 = normalize(x_test5, train_mean4, train_std4, imputer4, cols_to_normalize)\n",
    "a5_5 = normalize(x_test5, train_mean5, train_std5, imputer5, cols_to_normalize)\n",
    "a5_6 = normalize(x_test5, train_mean6, train_std6, imputer6, cols_to_normalize)\n",
    "\n",
    "y5_1 = score(m1, a5_1, y_test5)\n",
    "y5_2 = score(m2, a5_2, y_test5)\n",
    "y5_3 = score(m3, a5_3, y_test5)\n",
    "y5_4 = score(m4, a5_4, y_test5)\n",
    "y5_5 = score(m5, a5_5, y_test5)\n",
    "y5_6 = score(m6, a5_6, y_test5)\n",
    "\n",
    "\n",
    "a6_1 = normalize(x_test6, train_mean1, train_std1, imputer1, cols_to_normalize)\n",
    "a6_2 = normalize(x_test6, train_mean2, train_std2, imputer2, cols_to_normalize)\n",
    "a6_3 = normalize(x_test6, train_mean3, train_std3, imputer3, cols_to_normalize)\n",
    "a6_4 = normalize(x_test6, train_mean4, train_std4, imputer4, cols_to_normalize)\n",
    "a6_5 = normalize(x_test6, train_mean5, train_std5, imputer5, cols_to_normalize)\n",
    "a6_6 = normalize(x_test6, train_mean6, train_std6, imputer6, cols_to_normalize)\n",
    "\n",
    "y6_1 = score(m1, a6_1, y_test6)\n",
    "y6_2 = score(m2, a6_2, y_test6)\n",
    "y6_3 = score(m3, a6_3, y_test6)\n",
    "y6_4 = score(m4, a6_4, y_test6)\n",
    "y6_5 = score(m5, a6_5, y_test6)\n",
    "y6_6 = score(m6, a6_6, y_test6)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 487,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "articleLength                          3638.943152\n",
       "countOfDistinctIndustry                   5.619121\n",
       "countOfOccurence                          3.150904\n",
       "countOfOccurenceOfAliases                 0.147287\n",
       "countOfOccurenceOfNamePreserveList        0.159690\n",
       "countOfSignificantStrings                 1.041860\n",
       "countOfUrlMatch                           0.045478\n",
       "countryMatchByOverlapScore                0.282507\n",
       "directCityMatchScore                      0.055451\n",
       "directCountryMatchScore                   0.076762\n",
       "directStateMatchScore                     0.039327\n",
       "empCount                              16671.832041\n",
       "exactMatch                                0.331783\n",
       "fieldMatch                                2.332300\n",
       "isIndustry                                0.063049\n",
       "isProminentByItself                       0.373127\n",
       "isProminentByParent                       0.137984\n",
       "isPublic                                  0.193282\n",
       "isUrlMatched                              0.026873\n",
       "stateMatchByOverlapScore                  0.220135\n",
       "sumOfIndustry                            41.783979\n",
       "tickerMatch                               0.073385\n",
       "w2vScore                                  7.112842\n",
       "dtype: float64"
      ]
     },
     "execution_count": 487,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_mean1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 425,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(484,) (484, 6)\n",
      "(484,) (484, 6)\n",
      "(484,) (484, 6)\n",
      "(484,) (484, 6)\n",
      "(484,) (484, 6)\n",
      "(484,) (484, 6)\n"
     ]
    }
   ],
   "source": [
    "y1_all = np.concatenate((y1_1, y1_2, y1_3, y1_4, y1_5, y1_6), axis=1)\n",
    "print(np.sum(y1_all, axis=1).shape, y1_all.shape)\n",
    "s1 = np.sum(y1_all, axis=1)\n",
    "\n",
    "y2_all = np.concatenate((y2_1, y2_2, y2_3, y2_4, y2_5, y2_6), axis=1)\n",
    "print(np.sum(y2_all, axis=1).shape, y2_all.shape)\n",
    "s2 = np.sum(y2_all, axis=1)\n",
    "\n",
    "y3_all = np.concatenate((y3_1, y3_2, y3_3, y3_4, y3_5, y3_6), axis=1)\n",
    "print(np.sum(y3_all, axis=1).shape, y3_all.shape)\n",
    "s3 = np.sum(y3_all, axis=1)\n",
    "\n",
    "y4_all = np.concatenate((y4_1, y4_2, y4_3, y4_4, y4_5, y4_6), axis=1)\n",
    "print(np.sum(y4_all, axis=1).shape, y4_all.shape)\n",
    "s4 = np.sum(y4_all, axis=1)\n",
    "\n",
    "y5_all = np.concatenate((y5_1, y5_2, y5_3, y5_4, y5_5, y5_6), axis=1)\n",
    "print(np.sum(y5_all, axis=1).shape, y5_all.shape)\n",
    "s5 = np.sum(y5_all, axis=1)\n",
    "\n",
    "y6_all = np.concatenate((y6_1, y6_2, y6_3, y6_4, y6_5, y6_6), axis=1)\n",
    "print(np.sum(y6_all, axis=1).shape, y6_all.shape)\n",
    "s6 = np.sum(y6_all, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 440,
   "metadata": {},
   "outputs": [],
   "source": [
    "ytest_all = np.concatenate((np.asarray(y_test1['isGold']==1.0).reshape(y_test1.shape[0],1),\n",
    "                         np.asarray(y_test2['isGold']==1.0).reshape(y_test1.shape[0],1),\n",
    "                         np.asarray(y_test3['isGold']==1.0).reshape(y_test1.shape[0],1),\n",
    "                         np.asarray(y_test4['isGold']==1.0).reshape(y_test1.shape[0],1),\n",
    "                         np.asarray(y_test5['isGold']==1.0).reshape(y_test1.shape[0],1),\n",
    "                         np.asarray(y_test6['isGold']==1.0).reshape(y_test1.shape[0],1)))\n",
    "\n",
    "s_all = np.concatenate((np.asarray(s1 > 3), \n",
    "               np.asarray(s2 > 3),\n",
    "               np.asarray(s3 > 3),\n",
    "               np.asarray(s4 > 3),\n",
    "               np.asarray(s5 > 3),\n",
    "               np.asarray(s6 > 3))).reshape(-1,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 444,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "       False       0.84      0.84      0.84      1374\n",
      "        True       0.86      0.86      0.86      1530\n",
      "\n",
      "   micro avg       0.85      0.85      0.85      2904\n",
      "   macro avg       0.85      0.85      0.85      2904\n",
      "weighted avg       0.85      0.85      0.85      2904\n",
      "\n"
     ]
    }
   ],
   "source": [
    "s_all.shape\n",
    "print(classification_report(ytest_all, s_all))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 428,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "       False       0.84      0.86      0.85       229\n",
      "        True       0.87      0.86      0.86       255\n",
      "\n",
      "   micro avg       0.86      0.86      0.86       484\n",
      "   macro avg       0.86      0.86      0.86       484\n",
      "weighted avg       0.86      0.86      0.86       484\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       False       0.84      0.85      0.85       229\n",
      "        True       0.87      0.86      0.86       255\n",
      "\n",
      "   micro avg       0.86      0.86      0.86       484\n",
      "   macro avg       0.85      0.86      0.86       484\n",
      "weighted avg       0.86      0.86      0.86       484\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       False       0.84      0.85      0.85       229\n",
      "        True       0.86      0.86      0.86       255\n",
      "\n",
      "   micro avg       0.85      0.85      0.85       484\n",
      "   macro avg       0.85      0.85      0.85       484\n",
      "weighted avg       0.85      0.85      0.85       484\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       False       0.84      0.85      0.85       229\n",
      "        True       0.86      0.86      0.86       255\n",
      "\n",
      "   micro avg       0.85      0.85      0.85       484\n",
      "   macro avg       0.85      0.85      0.85       484\n",
      "weighted avg       0.85      0.85      0.85       484\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       False       0.84      0.84      0.84       229\n",
      "        True       0.86      0.86      0.86       255\n",
      "\n",
      "   micro avg       0.85      0.85      0.85       484\n",
      "   macro avg       0.85      0.85      0.85       484\n",
      "weighted avg       0.85      0.85      0.85       484\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       False       0.84      0.83      0.83       229\n",
      "        True       0.85      0.86      0.85       255\n",
      "\n",
      "   micro avg       0.84      0.84      0.84       484\n",
      "   macro avg       0.84      0.84      0.84       484\n",
      "weighted avg       0.84      0.84      0.84       484\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(np.asarray(y_test1['isGold']==1.0), np.asarray(s1 > 3)))\n",
    "print(classification_report(np.asarray(y_test2['isGold']==1.0), np.asarray(s2 > 3)))\n",
    "print(classification_report(np.asarray(y_test3['isGold']==1.0), np.asarray(s3 > 3)))\n",
    "print(classification_report(np.asarray(y_test4['isGold']==1.0), np.asarray(s4 > 3)))\n",
    "print(classification_report(np.asarray(y_test5['isGold']==1.0), np.asarray(s5 > 3)))\n",
    "print(classification_report(np.asarray(y_test6['isGold']==1.0), np.asarray(s6 > 3)))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 477,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   articleLength  countOfDistinctIndustry  countOfOccurence  \\\n",
      "0         3854.0                      7.0              12.0   \n",
      "\n",
      "   countOfOccurenceOfAliases  countOfOccurenceOfNamePreserveList  \\\n",
      "0                        0.0                                 0.0   \n",
      "\n",
      "   countOfSignificantStrings  countOfUrlMatch  countryMatchByOverlapScore  \\\n",
      "0                        0.0              0.0                         0.5   \n",
      "\n",
      "   directCityMatchScore  directCountryMatchScore  ...  fieldMatch  isIndustry  \\\n",
      "0                   0.0                      0.0  ...         2.0         0.0   \n",
      "\n",
      "   isProminentByItself  isProminentByParent  isPublic  isUrlMatched  \\\n",
      "0                  0.0                  0.0       0.0           0.0   \n",
      "\n",
      "   stateMatchByOverlapScore  sumOfIndustry  tickerMatch  w2vScore  \n",
      "0                       0.7            8.0          0.0       0.0  \n",
      "\n",
      "[1 rows x 23 columns]\n",
      "['articleLength', 'countOfDistinctIndustry', 'countOfOccurence', 'countOfOccurenceOfAliases', 'countOfOccurenceOfNamePreserveList', 'countOfSignificantStrings', 'countOfUrlMatch', 'countryMatchByOverlapScore', 'directCityMatchScore', 'directCountryMatchScore', 'directStateMatchScore', 'empCount', 'exactMatch', 'fieldMatch', 'isIndustry', 'isProminentByItself', 'isProminentByParent', 'isPublic', 'isUrlMatched', 'stateMatchByOverlapScore', 'sumOfIndustry', 'tickerMatch', 'w2vScore']\n"
     ]
    }
   ],
   "source": [
    "q0 = np.asarray(x_test1.iloc[0,:]).reshape(1, -1)\n",
    "q = pandas.DataFrame(data=q0, columns=x_test1.columns.tolist())\n",
    "print(q.head())\n",
    "print(x_test1.columns.tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 475,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For Dikshith\n",
    "# save_model(\"imputer1.p\", imputer1)\n",
    "# save_model(\"imputer2.p\", imputer2)\n",
    "# save_model(\"imputer3.p\", imputer3)\n",
    "# save_model(\"imputer4.p\", imputer4)\n",
    "# save_model(\"imputer5.p\", imputer5)\n",
    "# save_model(\"imputer6.p\", imputer6)\n",
    "# save_model(\"cols_to_normalize.p\", cols_to_normalize)\n",
    "# save_model(\"train_std1.p\", train_std1)\n",
    "# save_model(\"train_std2.p\", train_std2)\n",
    "# save_model(\"train_std3.p\", train_std3)\n",
    "# save_model(\"train_std4.p\", train_std4)\n",
    "# save_model(\"train_std5.p\", train_std5)\n",
    "# save_model(\"train_std6.p\", train_std6)\n",
    "# save_model(\"train_mean1.p\", train_mean1)\n",
    "# save_model(\"train_mean2.p\", train_mean2)\n",
    "# save_model(\"train_mean3.p\", train_mean3)\n",
    "# save_model(\"train_mean4.p\", train_mean4)\n",
    "# save_model(\"train_mean5.p\", train_mean5)\n",
    "# save_model(\"train_mean6.p\", train_mean6)\n",
    "save_model(\"input_columns_list.p\", x_test1.columns.tolist())\n",
    "\n",
    "# # Step1. Load Data\n",
    "# t_imputer1 = load_model(\"imputer1.p\")\n",
    "# t_imputer2 = load_model(\"imputer2.p\")\n",
    "# t_imputer3 = load_model(\"imputer3.p\")\n",
    "# t_imputer4 = load_model(\"imputer4.p\")\n",
    "# t_imputer5 = load_model(\"imputer5.p\")\n",
    "# t_imputer6 = load_model(\"imputer6.p\")\n",
    "# t_cols_to_normalize = load_model(\"cols_to_normalize.p\")\n",
    "# t_train_std1 = load_model(\"train_std1.p\")\n",
    "# t_train_std2 = load_model(\"train_std2.p\")\n",
    "# t_train_std3 = load_model(\"train_std3.p\")\n",
    "# t_train_std4 = load_model(\"train_std4.p\")\n",
    "# t_train_std5 = load_model(\"train_std5.p\")\n",
    "# t_train_std6 = load_model(\"train_std6.p\")\n",
    "# t_train_mean1 = load_model(\"train_mean1.p\")\n",
    "# t_train_mean2 = load_model(\"train_mean2.p\")\n",
    "# t_train_mean3 = load_model(\"train_mean3.p\")\n",
    "# t_train_mean4 = load_model(\"train_mean4.p\")\n",
    "# t_train_mean5 = load_model(\"train_mean5.p\")\n",
    "# t_train_mean6 = load_model(\"train_mean6.p\")\n",
    "\n",
    "# # Step2. Load Models\n",
    "# m1 = load_model('m1.sav')\n",
    "# m2 = load_model('m2.sav')\n",
    "# m3 = load_model('m3.sav')\n",
    "# m4 = load_model('m4.sav')\n",
    "# m5 = load_model('m5.sav')\n",
    "# m6 = load_model('m6.sav')\n",
    "\n",
    "# ## Step3. Preprocess Data (normalize x_test1 using mean, stdDev and imputers)\n",
    "# a1_1 = normalize(x_test1, train_mean1, train_std1, imputer1, cols_to_normalize)\n",
    "# a1_2 = normalize(x_test1, train_mean2, train_std2, imputer2, cols_to_normalize)\n",
    "# a1_3 = normalize(x_test1, train_mean3, train_std3, imputer3, cols_to_normalize)\n",
    "# a1_4 = normalize(x_test1, train_mean4, train_std4, imputer4, cols_to_normalize)\n",
    "# a1_5 = normalize(x_test1, train_mean5, train_std5, imputer5, cols_to_normalize)\n",
    "# a1_6 = normalize(x_test1, train_mean6, train_std6, imputer6, cols_to_normalize)\n",
    "\n",
    "# ## Step4. predict outcome using 6 models\n",
    "# y_pred1 = m1.predict(x_test1)\n",
    "# y_pred2 = m2.predict(x_test1)\n",
    "# y_pred3 = m3.predict(x_test1)\n",
    "# y_pred4 = m4.predict(x_test1)\n",
    "# y_pred5 = m5.predict(x_test1)\n",
    "# y_pred6 = m6.predict(x_test1)\n",
    "\n",
    "# ## Step5. Combine decision of all models and see if >3 models classified it gold\n",
    "# y_predall = np.concatenate((y_pred1, y_pred2, y_pred3, y_pred4, y_pred5, y_pred6), axis=1)\n",
    "# s1 = np.sum(y1_all, axis=1)\n",
    "# s1 > 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cs230-env",
   "language": "python",
   "name": "cs230-env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
