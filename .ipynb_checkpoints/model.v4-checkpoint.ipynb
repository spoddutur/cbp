{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import import_ipynb\n",
    "#from model import *\n",
    "import numpy as np\n",
    "import itertools\n",
    "import glob\n",
    "import os\n",
    "import json\n",
    "import re\n",
    "import pickle\n",
    "import math\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from keras.models import Model\n",
    "from keras.backend import mean, sum\n",
    "from keras.layers import Dense, Input, Dropout, LSTM, Activation, GRU, Concatenate, Multiply, Reshape\n",
    "from keras.layers.embeddings import Embedding\n",
    "from keras.preprocessing import sequence\n",
    "from keras.initializers import glorot_uniform\n",
    "from keras.layers import Lambda\n",
    "from keras.optimizers import Adam\n",
    "np.random.seed(1)\n",
    "from keras.models import Sequential\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# given x (?,dim) always return (max_len, dim) by padding with zeros\n",
    "def padding(max_len, x, dim ):\n",
    "    x_len = x.shape[0]\n",
    "    # truncate if more than max_len else pad with zeros\n",
    "    if(x_len >= max_len):\n",
    "        return x[0:max_len]\n",
    "    else:   \n",
    "        padding = np.zeros((max_len-x_len, dim))     \n",
    "        if(len(x.shape) > 1):\n",
    "            assert dim == x.shape[1],\"dimensions didnt match in padding\"   \n",
    "            return np.concatenate((x, padding))\n",
    "        else:\n",
    "            return padding\n",
    "        \n",
    "# given 1D array x, we return array of shape (max_len, dim) by replicating each element dim times and apdding with zeros at end\n",
    "def reshape_mask(max_len, x, dim):\n",
    "    # mask is a 1D array so padd with dim == 1\n",
    "    padded_question_mask = np.squeeze(padding(max_len, x, 1))\n",
    "    final_question_mask = []\n",
    "    for qm in padded_question_mask:\n",
    "        # make each mask index into array of dimension dim\n",
    "        final_question_mask.append(np.array([qm]*dim))\n",
    "    return np.asarray(final_question_mask)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "s_DimOfQuestionVector = 300\n",
    "s_DimOfTripletVector  = 900\n",
    "s_DimOfMask           = 50\n",
    "s_QuestionMaxWords    = 60\n",
    "s_TripletsMaxNumbers  = 500"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X:/cs230/proj0/ned-graphs/data_wiki_encoded/train/train_8.ipwk\n"
     ]
    }
   ],
   "source": [
    "def prepare_data(data, \n",
    "                 question_max_words, \n",
    "                 triplets_max_numbers, \n",
    "                 dimOfQuestionVector, \n",
    "                 dimOfTripletVector, \n",
    "                 dimOfMask):\n",
    "    question_vectors = []\n",
    "    question_masks = []\n",
    "    triplet_vectors = []\n",
    "    Y = []\n",
    "    for elem in data:\n",
    "        item_question             = elem[\"question\"]\n",
    "        padded_item_question      = padding(question_max_words, item_question, dimOfQuestionVector)\n",
    "        item_question_mask        = np.reshape(elem[\"question_mask\"], (len(elem[\"question_mask\"]), 1) )\n",
    "        padded_item_question_mask = reshape_mask(question_max_words, item_question_mask, dimOfMask)\n",
    "        item_correct_triplets     = elem[\"correct_triplets\"]\n",
    "        item_wrong_triplets       = elem[\"wrong_triplets\"]\n",
    "        \n",
    "        # for triplets take mean of each S, P  and 0 to get 3,300 vectors which are then concatenated to dimOfTripletVector vector\n",
    "        item_correct_triplets_vectors = [] \n",
    "        for tr in item_correct_triplets: # There are triplets_max_numbers triplets\n",
    "            # Each tr has s, p and o. Each of the _s, _p and _o's are (num_tokens, dimOfTripletVector) size\n",
    "            _s = np.mean(tr[0], axis=0)\n",
    "            _p = np.mean(tr[1], axis=0)\n",
    "            _o = np.mean(tr[2], axis=0)\n",
    "            item_correct_triplets_vectors.append(np.concatenate((_s, _p, _o))) # adding (900,) vector for each triplet\n",
    "        #pad triplet vectors so we have (triplets_max_numbers, dimOfTripletVector)  encoding for all triplets\n",
    "        padded_item_triplets_vectors = padding(triplets_max_numbers, np.asarray(item_correct_triplets_vectors), dimOfTripletVector)\n",
    "        \n",
    "        triplet_vectors.append(padded_item_triplets_vectors)\n",
    "        question_vectors.append(padded_item_question)\n",
    "        question_masks.append(padded_item_question_mask)\n",
    "        Y.append(1)\n",
    "\n",
    "        # for wrong triplets\n",
    "        item_wrong_triplets_vectors = []\n",
    "        for tr in item_wrong_triplets:\n",
    "            _s = np.mean(tr[0], axis=0)\n",
    "            _p = np.mean(tr[1], axis=0)\n",
    "            _o = np.mean(tr[2], axis=0)\n",
    "            item_wrong_triplets_vectors.append(np.concatenate((_s, _p, _o)))\n",
    "        padded_item_wrong_triplets_vectors = padding(triplets_max_numbers, np.asarray(item_wrong_triplets_vectors), dimOfTripletVector)\n",
    "                \n",
    "        triplet_vectors.append(padded_item_wrong_triplets_vectors)\n",
    "        question_vectors.append(padded_item_question)\n",
    "        question_masks.append(padded_item_question_mask)\n",
    "        Y.append(0)\n",
    "        \n",
    "        \n",
    "        \n",
    "    question_vectors = np.asarray(question_vectors)\n",
    "    question_masks   = np.asarray(question_masks)\n",
    "    triplet_vectors  = np.asarray(triplet_vectors)\n",
    "    Y                = np.asarray(Y)\n",
    "    return question_vectors, question_masks, triplet_vectors, Y\n",
    "\n",
    "def generate_model_inputs():\n",
    "    file_list = glob.glob('X:/cs230/proj0/ned-graphs/data_wiki_encoded/train/train_8.ipwk')\n",
    "    data = []\n",
    "    num = 0\n",
    "    for inputFile in file_list:\n",
    "        print(inputFile)\n",
    "        f = open(inputFile, 'rb')\n",
    "        test = pickle.load(f)\n",
    "        data = np.append(data, test)\n",
    "        f.close()\n",
    "        num += 1\n",
    "        if num == 1:\n",
    "            break\n",
    "    \n",
    "    return prepare_data(data, \n",
    "                        question_max_words   = s_QuestionMaxWords, \n",
    "                        triplets_max_numbers = s_TripletsMaxNumbers, \n",
    "                        dimOfQuestionVector  = s_DimOfQuestionVector, \n",
    "                        dimOfTripletVector   = s_DimOfTripletVector, \n",
    "                        dimOfMask            = s_DimOfMask )\n",
    "\n",
    "question_vectors, question_masks, triplet_vectors, Y = generate_model_inputs()#prepare_data(data, question_max_words=60, triplets_max_numbers=500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(200, 60, 300)\n",
      "(200, 60, 50)\n",
      "(200, 500, 900)\n",
      "(200,)\n"
     ]
    }
   ],
   "source": [
    "print(question_vectors.shape)\n",
    "print(question_masks.shape)\n",
    "print(triplet_vectors.shape)\n",
    "print(Y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "questions_input_shape      = (s_QuestionMaxWords,   s_DimOfQuestionVector)\n",
    "questions_mask_input_shape = (s_QuestionMaxWords,   s_DimOfMask )\n",
    "triplets_input_shape       = (s_TripletsMaxNumbers, s_DimOfTripletVector )\n",
    "# question_vectors(, 60, 300), question_masks(, 60, 300), triplet_vectors (,500,900), Y\n",
    "\n",
    "gru_dimension = s_DimOfMask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "question_vectors_input (InputLa (None, 60, 300)      0                                            \n",
      "__________________________________________________________________________________________________\n",
      "triplets_input (InputLayer)     (None, 500, 900)     0                                            \n",
      "__________________________________________________________________________________________________\n",
      "Sentence_GRU1 (GRU)             (None, 60, 50)       52650       question_vectors_input[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "Dense50T (Dense)                (None, 500, 50)      45050       triplets_input[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "question_masks_input (InputLaye (None, 60, 50)       0                                            \n",
      "__________________________________________________________________________________________________\n",
      "Sentence_GRU2 (GRU)             (None, 60, 50)       15150       Sentence_GRU1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "Triplet_GRU1 (GRU)              (None, 500, 50)      15150       Dense50T[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "multiply_2 (Multiply)           (None, 60, 50)       0           question_masks_input[0][0]       \n",
      "                                                                 Sentence_GRU2[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "Triplet_GRU2 (GRU)              (None, 500, 50)      15150       Triplet_GRU1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "AMeanLayer (Lambda)             (None, 50)           0           multiply_2[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "TAMeanLayer (Lambda)            (None, 50)           0           Triplet_GRU2[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_2 (Concatenate)     (None, 100)          0           AMeanLayer[0][0]                 \n",
      "                                                                 TAMeanLayer[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "Dense64 (Dense)                 (None, 64)           6464        concatenate_2[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "Dense1 (Dense)                  (None, 1)            65          Dense64[0][0]                    \n",
      "==================================================================================================\n",
      "Total params: 149,679\n",
      "Trainable params: 149,679\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "# question inputs\n",
    "question_vectors_input = Input(shape=questions_input_shape,      dtype='float32', name=\"question_vectors_input\")   \n",
    "question_masks_input   = Input(shape=questions_mask_input_shape, dtype='float32', name=\"question_masks_input\")\n",
    "\n",
    "# triplets input\n",
    "triplets_input = Input(shape=triplets_input_shape, dtype='float32', name=\"triplets_input\")  #(None, 500, 900)\n",
    "\n",
    "# layers\n",
    "# gru1 = Bidirectional(GRU( 50, return_sequences=True, name=\"Sentence_GRU1\"))\n",
    "# gru2 = Bidirectional(GRU( 50, return_sequences=False, name=\"Sentence_GRU2\"))\n",
    "# tgru1 = Bidirectional(GRU( 50, return_sequences=True, name=\"Triplet_GRU1\"))\n",
    "# tgru2 = Bidirectional(GRU( 50, return_sequences=False, name=\"Triplet_GRU2\"))\n",
    "\n",
    "gru1 =  (GRU( gru_dimension,  return_sequences=True,  name=\"Sentence_GRU1\"))\n",
    "gru2 =  (GRU( gru_dimension,  return_sequences=True,  name=\"Sentence_GRU2\"))\n",
    "tgru1 = (GRU( gru_dimension,  return_sequences=True,  name=\"Triplet_GRU1\"))\n",
    "tgru2 = (GRU( gru_dimension,  return_sequences=True, name=\"Triplet_GRU2\"))\n",
    "mean_layer = Lambda(lambda xin: mean(xin, axis=1), name=\"AMeanLayer\")\n",
    "tmean_layer = Lambda(lambda xin: mean(xin, axis=1), name=\"TAMeanLayer\")\n",
    "\n",
    "X_question = gru2(gru1(question_vectors_input))             # (None, 3000, 50) -> (None, 60, 50)\n",
    "X_question = Multiply()([question_masks_input, X_question]) # (None, 60, 50)\n",
    "X_question = mean_layer(X_question)                         # (None, 60, 50) -> (None, 50)\n",
    "\n",
    "X_triplets = Dense(50, activation='relu', name=\"Dense50T\")(triplets_input)    # (None,500,900) -> (None,500,50)\n",
    "X_triplets = tgru2(tgru1(X_triplets))                                         # (None,500,50)  -> (None,50)\n",
    "X_triplets = tmean_layer(X_triplets)                                          # (None, 500, 50) -> (None, 50)\n",
    "X_concatenated = Concatenate()([X_question, X_triplets])                      # (None,100)\n",
    "X_concatenated = Dense(64, activation='relu', name=\"Dense64\")(X_concatenated) # (None,100) -> (None,64)        \n",
    "Y_pred = Dense(1, activation='sigmoid', name=\"Dense1\")(X_concatenated)        # (None,64)  -> sigmoid    \n",
    "\n",
    "model = Model(inputs=[question_vectors_input, question_masks_input, triplets_input], outputs=Y_pred)\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "#model.fit([question_vectors, question_masks, triplet_vectors], Y, epochs = 30, batch_size = 20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "ename": "MemoryError",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mMemoryError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-26-8ea299fb3939>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     41\u001b[0m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mclassification_report\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mY\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mY_pred\u001b[0m\u001b[1;33m>\u001b[0m\u001b[1;36m0.5\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     42\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 43\u001b[1;33m \u001b[0mEvalModel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-26-8ea299fb3939>\u001b[0m in \u001b[0;36mEvalModel\u001b[1;34m(model)\u001b[0m\n\u001b[0;32m     30\u001b[0m                                                                                 \u001b[0mdimOfQuestionVector\u001b[0m  \u001b[1;33m=\u001b[0m \u001b[0ms_DimOfQuestionVector\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     31\u001b[0m                                                                                 \u001b[0mdimOfTripletVector\u001b[0m   \u001b[1;33m=\u001b[0m \u001b[0ms_DimOfTripletVector\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 32\u001b[1;33m                                                                                 dimOfMask            = s_DimOfMask )\n\u001b[0m\u001b[0;32m     33\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     34\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-15-5dd086365f27>\u001b[0m in \u001b[0;36mprepare_data\u001b[1;34m(data, question_max_words, triplets_max_numbers, dimOfQuestionVector, dimOfTripletVector, dimOfMask)\u001b[0m\n\u001b[0;32m     51\u001b[0m     \u001b[0mquestion_vectors\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0masarray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mquestion_vectors\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     52\u001b[0m     \u001b[0mquestion_masks\u001b[0m   \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0masarray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mquestion_masks\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 53\u001b[1;33m     \u001b[0mtriplet_vectors\u001b[0m  \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0masarray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtriplet_vectors\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     54\u001b[0m     \u001b[0mY\u001b[0m                \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0masarray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mY\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     55\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mquestion_vectors\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mquestion_masks\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtriplet_vectors\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mY\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mx:\\cs230\\alpha\\.env\\lib\\site-packages\\numpy\\core\\numeric.py\u001b[0m in \u001b[0;36masarray\u001b[1;34m(a, dtype, order)\u001b[0m\n\u001b[0;32m    536\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    537\u001b[0m     \"\"\"\n\u001b[1;32m--> 538\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0marray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ma\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0morder\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0morder\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    539\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    540\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mMemoryError\u001b[0m: "
     ]
    }
   ],
   "source": [
    "file_name = \"train_epoch_\" + str(4) + \".save\"\n",
    "model.load_weights(file_name)\n",
    "\n",
    "\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "def EvalModel( model ):\n",
    "    file_list         = ['X:/cs230/proj0/ned-graphs/data_wiki_encoded/dev/dev_10.ipwk',\n",
    "                         'X:/cs230/proj0/ned-graphs/data_wiki_encoded/dev/dev_11.ipwk',\n",
    "                         'X:/cs230/proj0/ned-graphs/data_wiki_encoded/dev/dev_12.ipwk',\n",
    "                         'X:/cs230/proj0/ned-graphs/data_wiki_encoded/dev/dev_13.ipwk'\n",
    "                        ]\n",
    "    \n",
    "    file_list_count   = len(file_list)\n",
    "    \n",
    "    data = []\n",
    "    file_index       = 0\n",
    "    # train on batches of files\n",
    "    for file_index in range(0, file_list_count) :\n",
    "        inputFile = file_list[file_index]\n",
    "        file_index       += 1\n",
    "        # print(inputFile)\n",
    "        f = open(inputFile, 'rb')\n",
    "        test = pickle.load(f)\n",
    "        data = np.append(data, test)\n",
    "        f.close()\n",
    "    \n",
    "    question_vectors, question_masks, triplet_vectors, Y = prepare_data(data, \n",
    "                                                                                question_max_words   = s_QuestionMaxWords, \n",
    "                                                                                triplets_max_numbers = s_TripletsMaxNumbers, \n",
    "                                                                                dimOfQuestionVector  = s_DimOfQuestionVector, \n",
    "                                                                                dimOfTripletVector   = s_DimOfTripletVector, \n",
    "                                                                                dimOfMask            = s_DimOfMask )\n",
    "        \n",
    "    \n",
    "    loss, acc = model.evaluate([question_vectors, question_masks, triplet_vectors], Y)\n",
    "    print( \"loss = \" + str(loss) + \" acc  \" + str(acc))\n",
    "    Y_pred = model.predict([question_vectors, question_masks, triplet_vectors])\n",
    "    Y_pred = np.squeeze(Y_pred)\n",
    "    #print(y.astype(np.float))\n",
    "    print(confusion_matrix(Y, Y_pred>0.5))\n",
    "    print(classification_report(Y, Y_pred>0.5))\n",
    "\n",
    "EvalModel(model)   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "459\n",
      "92\n"
     ]
    }
   ],
   "source": [
    "#TRAIN\n",
    "s_NumEpocs        = 5\n",
    "s_NumFilesInBatch = 5\n",
    "file_list         = glob.glob('X:/cs230/proj0/ned-graphs/data_wiki_encoded/train/train_*.ipwk')\n",
    "file_list_count   = len(file_list)\n",
    "file_batch_count  = math.ceil(( file_list_count / s_NumFilesInBatch ))\n",
    "\n",
    "print(file_list_count)\n",
    "print(file_batch_count)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training on Epoch  2 batch  5  Files [5] start  0 / 459\n",
      "Epoch 1/10\n",
      "1000/1000 [==============================] - 13s 13ms/step - loss: 0.2591 - acc: 0.9060\n",
      "Epoch 2/10\n",
      "1000/1000 [==============================] - 11s 11ms/step - loss: 0.1631 - acc: 0.9390\n",
      "Epoch 3/10\n",
      "1000/1000 [==============================] - 11s 11ms/step - loss: 0.1212 - acc: 0.9590\n",
      "Epoch 4/10\n",
      "1000/1000 [==============================] - 11s 11ms/step - loss: 0.0990 - acc: 0.9660\n",
      "Epoch 5/10\n",
      "1000/1000 [==============================] - 11s 11ms/step - loss: 0.0797 - acc: 0.9750\n",
      "Epoch 6/10\n",
      "1000/1000 [==============================] - 11s 11ms/step - loss: 0.0683 - acc: 0.9770\n",
      "Epoch 7/10\n",
      "1000/1000 [==============================] - 11s 11ms/step - loss: 0.0586 - acc: 0.9810\n",
      "Epoch 8/10\n",
      "1000/1000 [==============================] - 11s 11ms/step - loss: 0.0515 - acc: 0.9810\n",
      "Epoch 9/10\n",
      "1000/1000 [==============================] - 12s 12ms/step - loss: 0.0447 - acc: 0.9840\n",
      "Epoch 10/10\n",
      "1000/1000 [==============================] - 12s 12ms/step - loss: 0.0400 - acc: 0.9840\n",
      "Training on Epoch  2 batch  5  Files [5] start  5 / 459\n",
      "Epoch 1/10\n",
      "1000/1000 [==============================] - 15s 15ms/step - loss: 0.3353 - acc: 0.9070\n",
      "Epoch 2/10\n",
      "1000/1000 [==============================] - 15s 15ms/step - loss: 0.2171 - acc: 0.9250\n",
      "Epoch 3/10\n",
      "1000/1000 [==============================] - 16s 16ms/step - loss: 0.1526 - acc: 0.9510\n",
      "Epoch 4/10\n",
      "1000/1000 [==============================] - 16s 16ms/step - loss: 0.1275 - acc: 0.9630\n",
      "Epoch 5/10\n",
      "1000/1000 [==============================] - 16s 16ms/step - loss: 0.1017 - acc: 0.9680\n",
      "Epoch 6/10\n",
      "1000/1000 [==============================] - 16s 16ms/step - loss: 0.0858 - acc: 0.9730\n",
      "Epoch 7/10\n",
      "1000/1000 [==============================] - 16s 16ms/step - loss: 0.0712 - acc: 0.9740\n",
      "Epoch 8/10\n",
      "1000/1000 [==============================] - 16s 16ms/step - loss: 0.0548 - acc: 0.9810\n",
      "Epoch 9/10\n",
      "1000/1000 [==============================] - 16s 16ms/step - loss: 0.0445 - acc: 0.9880\n",
      "Epoch 10/10\n",
      "1000/1000 [==============================] - 17s 17ms/step - loss: 0.0379 - acc: 0.9890\n",
      "Training on Epoch  2 batch  5  Files [5] start  10 / 459\n",
      "Epoch 1/10\n",
      "1000/1000 [==============================] - 15s 15ms/step - loss: 0.3534 - acc: 0.8840\n",
      "Epoch 2/10\n",
      "1000/1000 [==============================] - 16s 16ms/step - loss: 0.2386 - acc: 0.9160\n",
      "Epoch 3/10\n",
      "1000/1000 [==============================] - 16s 16ms/step - loss: 0.1608 - acc: 0.9350\n",
      "Epoch 4/10\n",
      "1000/1000 [==============================] - 17s 17ms/step - loss: 0.1285 - acc: 0.9550\n",
      "Epoch 5/10\n",
      "1000/1000 [==============================] - 17s 17ms/step - loss: 0.1051 - acc: 0.9630\n",
      "Epoch 6/10\n",
      "1000/1000 [==============================] - 18s 18ms/step - loss: 0.0854 - acc: 0.9710\n",
      "Epoch 7/10\n",
      "1000/1000 [==============================] - 18s 18ms/step - loss: 0.0732 - acc: 0.9780\n",
      "Epoch 8/10\n",
      "1000/1000 [==============================] - 17s 17ms/step - loss: 0.0617 - acc: 0.9800\n",
      "Epoch 9/10\n",
      "1000/1000 [==============================] - 18s 18ms/step - loss: 0.0524 - acc: 0.9830\n",
      "Epoch 10/10\n",
      "1000/1000 [==============================] - 18s 18ms/step - loss: 0.0449 - acc: 0.9830\n",
      "Training on Epoch  2 batch  5  Files [5] start  15 / 459\n",
      "Epoch 1/10\n",
      "1000/1000 [==============================] - 18s 18ms/step - loss: 0.3414 - acc: 0.8950\n",
      "Epoch 2/10\n",
      "1000/1000 [==============================] - 19s 19ms/step - loss: 0.2331 - acc: 0.9190\n",
      "Epoch 3/10\n",
      "1000/1000 [==============================] - 19s 19ms/step - loss: 0.1635 - acc: 0.9370\n",
      "Epoch 4/10\n",
      "1000/1000 [==============================] - 19s 19ms/step - loss: 0.1279 - acc: 0.9540\n",
      "Epoch 5/10\n",
      "1000/1000 [==============================] - 20s 20ms/step - loss: 0.1058 - acc: 0.9690\n",
      "Epoch 6/10\n",
      "1000/1000 [==============================] - 20s 20ms/step - loss: 0.0912 - acc: 0.9720\n",
      "Epoch 7/10\n",
      "1000/1000 [==============================] - 20s 20ms/step - loss: 0.0747 - acc: 0.9750\n",
      "Epoch 8/10\n",
      "1000/1000 [==============================] - 20s 20ms/step - loss: 0.0667 - acc: 0.9840\n",
      "Epoch 9/10\n",
      "1000/1000 [==============================] - 20s 20ms/step - loss: 0.0569 - acc: 0.9830\n",
      "Epoch 10/10\n",
      "1000/1000 [==============================] - 21s 21ms/step - loss: 0.0500 - acc: 0.9840\n",
      "Training on Epoch  2 batch  5  Files [5] start  20 / 459\n",
      "Epoch 1/10\n",
      "1000/1000 [==============================] - 19s 19ms/step - loss: 0.3159 - acc: 0.9030\n",
      "Epoch 2/10\n",
      "1000/1000 [==============================] - 20s 20ms/step - loss: 0.2336 - acc: 0.9210\n",
      "Epoch 3/10\n",
      "1000/1000 [==============================] - 20s 20ms/step - loss: 0.1702 - acc: 0.9370\n",
      "Epoch 4/10\n",
      "1000/1000 [==============================] - 21s 21ms/step - loss: 0.1306 - acc: 0.9530\n",
      "Epoch 5/10\n",
      "1000/1000 [==============================] - 21s 21ms/step - loss: 0.1086 - acc: 0.9640\n",
      "Epoch 6/10\n",
      "1000/1000 [==============================] - 21s 21ms/step - loss: 0.0930 - acc: 0.9680\n",
      "Epoch 7/10\n",
      "1000/1000 [==============================] - 21s 21ms/step - loss: 0.0766 - acc: 0.9770\n",
      "Epoch 8/10\n",
      "1000/1000 [==============================] - 21s 21ms/step - loss: 0.0689 - acc: 0.9780\n",
      "Epoch 9/10\n",
      "1000/1000 [==============================] - 21s 21ms/step - loss: 0.0599 - acc: 0.9830\n",
      "Epoch 10/10\n",
      "1000/1000 [==============================] - 21s 21ms/step - loss: 0.0526 - acc: 0.9840\n",
      "Training on Epoch  2 batch  5  Files [5] start  25 / 459\n",
      "Epoch 1/10\n",
      "1000/1000 [==============================] - 21s 21ms/step - loss: 0.3420 - acc: 0.8710\n",
      "Epoch 2/10\n",
      "1000/1000 [==============================] - 21s 21ms/step - loss: 0.2489 - acc: 0.8940\n",
      "Epoch 3/10\n",
      "1000/1000 [==============================] - 23s 23ms/step - loss: 0.1916 - acc: 0.9250\n",
      "Epoch 4/10\n",
      "1000/1000 [==============================] - 21s 21ms/step - loss: 0.1638 - acc: 0.9360\n",
      "Epoch 5/10\n",
      "1000/1000 [==============================] - 21s 21ms/step - loss: 0.1408 - acc: 0.9530\n",
      "Epoch 6/10\n",
      "1000/1000 [==============================] - 20s 20ms/step - loss: 0.1220 - acc: 0.9570\n",
      "Epoch 7/10\n",
      "1000/1000 [==============================] - 21s 21ms/step - loss: 0.1064 - acc: 0.9630\n",
      "Epoch 8/10\n",
      "1000/1000 [==============================] - 22s 22ms/step - loss: 0.0896 - acc: 0.9650\n",
      "Epoch 9/10\n",
      "1000/1000 [==============================] - 21s 21ms/step - loss: 0.0811 - acc: 0.9690\n",
      "Epoch 10/10\n",
      "1000/1000 [==============================] - 21s 21ms/step - loss: 0.0748 - acc: 0.9720\n",
      "Training on Epoch  2 batch  5  Files [5] start  30 / 459\n",
      "Epoch 1/10\n",
      "1000/1000 [==============================] - 25s 25ms/step - loss: 0.2886 - acc: 0.9010\n",
      "Epoch 2/10\n",
      "1000/1000 [==============================] - 26s 26ms/step - loss: 0.2001 - acc: 0.9330\n",
      "Epoch 3/10\n",
      "1000/1000 [==============================] - 26s 26ms/step - loss: 0.1437 - acc: 0.9520\n",
      "Epoch 4/10\n",
      "1000/1000 [==============================] - 26s 26ms/step - loss: 0.1213 - acc: 0.9580\n",
      "Epoch 5/10\n",
      "1000/1000 [==============================] - 26s 26ms/step - loss: 0.1026 - acc: 0.9660\n",
      "Epoch 6/10\n",
      "1000/1000 [==============================] - 26s 26ms/step - loss: 0.0893 - acc: 0.9720\n",
      "Epoch 7/10\n",
      "1000/1000 [==============================] - 26s 26ms/step - loss: 0.0789 - acc: 0.9740\n",
      "Epoch 8/10\n",
      "1000/1000 [==============================] - 26s 26ms/step - loss: 0.0713 - acc: 0.9750\n",
      "Epoch 9/10\n",
      "1000/1000 [==============================] - 27s 27ms/step - loss: 0.0661 - acc: 0.9760\n",
      "Epoch 10/10\n",
      "1000/1000 [==============================] - 26s 26ms/step - loss: 0.0616 - acc: 0.9770\n",
      "Training on Epoch  2 batch  5  Files [5] start  35 / 459\n",
      "Epoch 1/10\n",
      "1000/1000 [==============================] - 21s 21ms/step - loss: 0.2900 - acc: 0.8970\n",
      "Epoch 2/10\n",
      "1000/1000 [==============================] - 22s 22ms/step - loss: 0.1988 - acc: 0.9260\n",
      "Epoch 3/10\n",
      "1000/1000 [==============================] - 22s 22ms/step - loss: 0.1695 - acc: 0.9300\n",
      "Epoch 4/10\n",
      "1000/1000 [==============================] - 22s 22ms/step - loss: 0.1322 - acc: 0.9450\n",
      "Epoch 5/10\n",
      "1000/1000 [==============================] - 22s 22ms/step - loss: 0.1041 - acc: 0.9560\n",
      "Epoch 6/10\n",
      "1000/1000 [==============================] - 22s 22ms/step - loss: 0.0909 - acc: 0.9660\n",
      "Epoch 7/10\n",
      "1000/1000 [==============================] - 23s 23ms/step - loss: 0.0774 - acc: 0.9680\n",
      "Epoch 8/10\n",
      "1000/1000 [==============================] - 23s 23ms/step - loss: 0.0686 - acc: 0.9690\n",
      "Epoch 9/10\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000/1000 [==============================] - 22s 22ms/step - loss: 0.0622 - acc: 0.9710\n",
      "Epoch 10/10\n",
      "1000/1000 [==============================] - 22s 22ms/step - loss: 0.0575 - acc: 0.9770\n",
      "Training on Epoch  2 batch  5  Files [5] start  40 / 459\n",
      "Epoch 1/10\n",
      "1000/1000 [==============================] - 26s 26ms/step - loss: 0.2884 - acc: 0.9090\n",
      "Epoch 2/10\n",
      "1000/1000 [==============================] - 27s 27ms/step - loss: 0.2026 - acc: 0.9260\n",
      "Epoch 3/10\n",
      "1000/1000 [==============================] - 27s 27ms/step - loss: 0.1449 - acc: 0.9490\n",
      "Epoch 4/10\n",
      "1000/1000 [==============================] - 27s 27ms/step - loss: 0.1137 - acc: 0.9620\n",
      "Epoch 5/10\n",
      "1000/1000 [==============================] - 27s 27ms/step - loss: 0.1021 - acc: 0.9700\n",
      "Epoch 6/10\n",
      "1000/1000 [==============================] - 28s 28ms/step - loss: 0.0875 - acc: 0.9750\n",
      "Epoch 7/10\n",
      "1000/1000 [==============================] - 27s 27ms/step - loss: 0.0777 - acc: 0.9780\n",
      "Epoch 8/10\n",
      "1000/1000 [==============================] - 27s 27ms/step - loss: 0.0678 - acc: 0.9770\n",
      "Epoch 9/10\n",
      "1000/1000 [==============================] - 28s 28ms/step - loss: 0.0592 - acc: 0.9770\n",
      "Epoch 10/10\n",
      "1000/1000 [==============================] - 28s 28ms/step - loss: 0.0516 - acc: 0.9780\n",
      "Training on Epoch  2 batch  5  Files [5] start  45 / 459\n",
      "Epoch 1/10\n",
      "1000/1000 [==============================] - 23s 23ms/step - loss: 0.2639 - acc: 0.9100\n",
      "Epoch 2/10\n",
      "1000/1000 [==============================] - 23s 23ms/step - loss: 0.2122 - acc: 0.9270\n",
      "Epoch 3/10\n",
      "1000/1000 [==============================] - 23s 23ms/step - loss: 0.1684 - acc: 0.9310\n",
      "Epoch 4/10\n",
      "1000/1000 [==============================] - 23s 23ms/step - loss: 0.1332 - acc: 0.9500\n",
      "Epoch 5/10\n",
      "1000/1000 [==============================] - 23s 23ms/step - loss: 0.1168 - acc: 0.9570\n",
      "Epoch 6/10\n",
      "1000/1000 [==============================] - 23s 23ms/step - loss: 0.1006 - acc: 0.9650\n",
      "Epoch 7/10\n",
      "1000/1000 [==============================] - 23s 23ms/step - loss: 0.0902 - acc: 0.9680\n",
      "Epoch 8/10\n",
      "1000/1000 [==============================] - 23s 23ms/step - loss: 0.0775 - acc: 0.9740\n",
      "Epoch 9/10\n",
      "1000/1000 [==============================] - 23s 23ms/step - loss: 0.0722 - acc: 0.9730\n",
      "Epoch 10/10\n",
      "1000/1000 [==============================] - 24s 24ms/step - loss: 0.0646 - acc: 0.9790\n",
      "Training on Epoch  2 batch  5  Files [5] start  50 / 459\n",
      "Epoch 1/10\n",
      "1000/1000 [==============================] - 25s 25ms/step - loss: 0.3136 - acc: 0.8840\n",
      "Epoch 2/10\n",
      "1000/1000 [==============================] - 26s 26ms/step - loss: 0.2312 - acc: 0.9070\n",
      "Epoch 3/10\n",
      "1000/1000 [==============================] - 27s 27ms/step - loss: 0.1783 - acc: 0.9370\n",
      "Epoch 4/10\n",
      "1000/1000 [==============================] - 27s 27ms/step - loss: 0.1513 - acc: 0.9410\n",
      "Epoch 5/10\n",
      "1000/1000 [==============================] - 27s 27ms/step - loss: 0.1368 - acc: 0.9490\n",
      "Epoch 6/10\n",
      "1000/1000 [==============================] - 27s 27ms/step - loss: 0.1177 - acc: 0.9600\n",
      "Epoch 7/10\n",
      "1000/1000 [==============================] - 27s 27ms/step - loss: 0.1075 - acc: 0.9610\n",
      "Epoch 8/10\n",
      "1000/1000 [==============================] - 27s 27ms/step - loss: 0.1002 - acc: 0.9630\n",
      "Epoch 9/10\n",
      "1000/1000 [==============================] - 27s 27ms/step - loss: 0.0901 - acc: 0.9670\n",
      "Epoch 10/10\n",
      "1000/1000 [==============================] - 28s 28ms/step - loss: 0.0830 - acc: 0.9680\n",
      "Training on Epoch  2 batch  5  Files [5] start  55 / 459\n",
      "Epoch 1/10\n",
      "1000/1000 [==============================] - 22s 22ms/step - loss: 0.3344 - acc: 0.8820\n",
      "Epoch 2/10\n",
      "1000/1000 [==============================] - 22s 22ms/step - loss: 0.2416 - acc: 0.9010\n",
      "Epoch 3/10\n",
      "1000/1000 [==============================] - 22s 22ms/step - loss: 0.1857 - acc: 0.9320\n",
      "Epoch 4/10\n",
      "1000/1000 [==============================] - 23s 23ms/step - loss: 0.1545 - acc: 0.9490\n",
      "Epoch 5/10\n",
      "1000/1000 [==============================] - 22s 22ms/step - loss: 0.1313 - acc: 0.9570\n",
      "Epoch 6/10\n",
      "1000/1000 [==============================] - 22s 22ms/step - loss: 0.1105 - acc: 0.9650\n",
      "Epoch 7/10\n",
      "1000/1000 [==============================] - 23s 23ms/step - loss: 0.0968 - acc: 0.9690\n",
      "Epoch 8/10\n",
      "1000/1000 [==============================] - 23s 23ms/step - loss: 0.0857 - acc: 0.9750\n",
      "Epoch 9/10\n",
      "1000/1000 [==============================] - 23s 23ms/step - loss: 0.0776 - acc: 0.9770\n",
      "Epoch 10/10\n",
      "1000/1000 [==============================] - 22s 22ms/step - loss: 0.0702 - acc: 0.9790\n",
      "Training on Epoch  2 batch  5  Files [5] start  60 / 459\n",
      "Epoch 1/10\n",
      "1000/1000 [==============================] - 24s 24ms/step - loss: 0.3282 - acc: 0.8770\n",
      "Epoch 2/10\n",
      "1000/1000 [==============================] - 25s 25ms/step - loss: 0.2286 - acc: 0.9150\n",
      "Epoch 3/10\n",
      "1000/1000 [==============================] - 25s 25ms/step - loss: 0.1655 - acc: 0.9420\n",
      "Epoch 4/10\n",
      "1000/1000 [==============================] - 25s 25ms/step - loss: 0.1398 - acc: 0.9480\n",
      "Epoch 5/10\n",
      "1000/1000 [==============================] - 25s 25ms/step - loss: 0.1219 - acc: 0.9500\n",
      "Epoch 6/10\n",
      "1000/1000 [==============================] - 25s 25ms/step - loss: 0.1096 - acc: 0.9580\n",
      "Epoch 7/10\n",
      "1000/1000 [==============================] - 25s 25ms/step - loss: 0.0973 - acc: 0.9640\n",
      "Epoch 8/10\n",
      "1000/1000 [==============================] - 25s 25ms/step - loss: 0.0880 - acc: 0.9680\n",
      "Epoch 9/10\n",
      "1000/1000 [==============================] - 25s 25ms/step - loss: 0.0827 - acc: 0.9720\n",
      "Epoch 10/10\n",
      "1000/1000 [==============================] - 25s 25ms/step - loss: 0.0763 - acc: 0.9720\n",
      "Training on Epoch  2 batch  5  Files [5] start  65 / 459\n",
      "Epoch 1/10\n",
      "1000/1000 [==============================] - 26s 26ms/step - loss: 0.2661 - acc: 0.9040\n",
      "Epoch 2/10\n",
      "1000/1000 [==============================] - 27s 27ms/step - loss: 0.1935 - acc: 0.9240\n",
      "Epoch 3/10\n",
      "1000/1000 [==============================] - 27s 27ms/step - loss: 0.1485 - acc: 0.9450\n",
      "Epoch 4/10\n",
      "1000/1000 [==============================] - 27s 27ms/step - loss: 0.1194 - acc: 0.9530\n",
      "Epoch 5/10\n",
      "1000/1000 [==============================] - 27s 27ms/step - loss: 0.0997 - acc: 0.9600\n",
      "Epoch 6/10\n",
      "1000/1000 [==============================] - 27s 27ms/step - loss: 0.0900 - acc: 0.9670\n",
      "Epoch 7/10\n",
      "1000/1000 [==============================] - 26s 26ms/step - loss: 0.0803 - acc: 0.9710\n",
      "Epoch 8/10\n",
      "1000/1000 [==============================] - 27s 27ms/step - loss: 0.0721 - acc: 0.9740\n",
      "Epoch 9/10\n",
      "1000/1000 [==============================] - 27s 27ms/step - loss: 0.0670 - acc: 0.9750\n",
      "Epoch 10/10\n",
      "1000/1000 [==============================] - 27s 27ms/step - loss: 0.0611 - acc: 0.9760\n",
      "Training on Epoch  2 batch  5  Files [5] start  70 / 459\n",
      "Epoch 1/10\n",
      "1000/1000 [==============================] - 26s 26ms/step - loss: 0.3537 - acc: 0.8820\n",
      "Epoch 2/10\n",
      "1000/1000 [==============================] - 26s 26ms/step - loss: 0.2249 - acc: 0.9080\n",
      "Epoch 3/10\n",
      "1000/1000 [==============================] - 27s 27ms/step - loss: 0.1666 - acc: 0.9460\n",
      "Epoch 4/10\n",
      "1000/1000 [==============================] - 26s 26ms/step - loss: 0.1413 - acc: 0.9550\n",
      "Epoch 5/10\n",
      "1000/1000 [==============================] - 26s 26ms/step - loss: 0.1307 - acc: 0.9590\n",
      "Epoch 6/10\n",
      "1000/1000 [==============================] - 27s 27ms/step - loss: 0.1178 - acc: 0.9660\n",
      "Epoch 7/10\n",
      "1000/1000 [==============================] - 27s 27ms/step - loss: 0.1160 - acc: 0.9670\n",
      "Epoch 8/10\n",
      "1000/1000 [==============================] - 27s 27ms/step - loss: 0.0975 - acc: 0.9720\n",
      "Epoch 9/10\n",
      "1000/1000 [==============================] - 27s 27ms/step - loss: 0.0871 - acc: 0.9760\n",
      "Epoch 10/10\n",
      "1000/1000 [==============================] - 27s 27ms/step - loss: 0.0777 - acc: 0.9760\n",
      "Training on Epoch  2 batch  5  Files [5] start  75 / 459\n",
      "Epoch 1/10\n",
      "1000/1000 [==============================] - 29s 29ms/step - loss: 0.3239 - acc: 0.8740\n",
      "Epoch 2/10\n",
      "1000/1000 [==============================] - 29s 29ms/step - loss: 0.2405 - acc: 0.8950\n",
      "Epoch 3/10\n",
      "1000/1000 [==============================] - 30s 30ms/step - loss: 0.1909 - acc: 0.9320\n",
      "Epoch 4/10\n",
      "1000/1000 [==============================] - 30s 30ms/step - loss: 0.1570 - acc: 0.9380\n",
      "Epoch 5/10\n",
      "1000/1000 [==============================] - 30s 30ms/step - loss: 0.1350 - acc: 0.9510\n",
      "Epoch 6/10\n",
      "1000/1000 [==============================] - 30s 30ms/step - loss: 0.1217 - acc: 0.9550\n",
      "Epoch 7/10\n",
      "1000/1000 [==============================] - 29s 29ms/step - loss: 0.1100 - acc: 0.9610\n",
      "Epoch 8/10\n",
      "1000/1000 [==============================] - 30s 30ms/step - loss: 0.1006 - acc: 0.9630\n",
      "Epoch 9/10\n",
      "1000/1000 [==============================] - 30s 30ms/step - loss: 0.0909 - acc: 0.9700\n",
      "Epoch 10/10\n",
      "1000/1000 [==============================] - 31s 31ms/step - loss: 0.0838 - acc: 0.9640\n",
      "Training on Epoch  2 batch  5  Files [5] start  80 / 459\n",
      "Epoch 1/10\n",
      "1000/1000 [==============================] - 26s 26ms/step - loss: 0.3513 - acc: 0.8690\n",
      "Epoch 2/10\n",
      "1000/1000 [==============================] - 26s 26ms/step - loss: 0.2506 - acc: 0.9020\n",
      "Epoch 3/10\n",
      "1000/1000 [==============================] - 27s 27ms/step - loss: 0.1834 - acc: 0.9320\n",
      "Epoch 4/10\n",
      "1000/1000 [==============================] - 26s 26ms/step - loss: 0.1552 - acc: 0.9470\n",
      "Epoch 5/10\n",
      "1000/1000 [==============================] - 26s 26ms/step - loss: 0.1366 - acc: 0.9540\n",
      "Epoch 6/10\n",
      "1000/1000 [==============================] - 26s 26ms/step - loss: 0.1145 - acc: 0.9590\n",
      "Epoch 7/10\n",
      "1000/1000 [==============================] - 27s 27ms/step - loss: 0.1005 - acc: 0.9650\n",
      "Epoch 8/10\n",
      "1000/1000 [==============================] - 26s 26ms/step - loss: 0.0885 - acc: 0.9730\n",
      "Epoch 9/10\n",
      "1000/1000 [==============================] - 27s 27ms/step - loss: 0.0831 - acc: 0.9710\n",
      "Epoch 10/10\n",
      "1000/1000 [==============================] - 26s 26ms/step - loss: 0.0763 - acc: 0.9740\n",
      "Training on Epoch  2 batch  5  Files [5] start  85 / 459\n",
      "Epoch 1/10\n",
      "1000/1000 [==============================] - 31s 31ms/step - loss: 0.3758 - acc: 0.8690\n",
      "Epoch 2/10\n",
      "1000/1000 [==============================] - 31s 31ms/step - loss: 0.2510 - acc: 0.9030\n",
      "Epoch 3/10\n",
      "1000/1000 [==============================] - 31s 31ms/step - loss: 0.2052 - acc: 0.9220\n",
      "Epoch 4/10\n",
      "1000/1000 [==============================] - 31s 31ms/step - loss: 0.1707 - acc: 0.9380\n",
      "Epoch 5/10\n",
      "1000/1000 [==============================] - 37s 37ms/step - loss: 0.1425 - acc: 0.9480\n",
      "Epoch 6/10\n",
      "1000/1000 [==============================] - 41s 41ms/step - loss: 0.1223 - acc: 0.9550\n",
      "Epoch 7/10\n",
      "1000/1000 [==============================] - 41s 41ms/step - loss: 0.1088 - acc: 0.9550\n",
      "Epoch 8/10\n",
      "1000/1000 [==============================] - 41s 41ms/step - loss: 0.0925 - acc: 0.9620\n",
      "Epoch 9/10\n",
      "1000/1000 [==============================] - 41s 41ms/step - loss: 0.0824 - acc: 0.9740\n",
      "Epoch 10/10\n",
      "1000/1000 [==============================] - 40s 40ms/step - loss: 0.0758 - acc: 0.9780\n",
      "Training on Epoch  2 batch  5  Files [5] start  90 / 459\n",
      "Epoch 1/10\n",
      "1000/1000 [==============================] - 32s 32ms/step - loss: 0.3224 - acc: 0.8810\n",
      "Epoch 2/10\n",
      "1000/1000 [==============================] - 33s 33ms/step - loss: 0.2288 - acc: 0.9140\n",
      "Epoch 3/10\n",
      "1000/1000 [==============================] - 33s 33ms/step - loss: 0.1750 - acc: 0.9370\n",
      "Epoch 4/10\n",
      "1000/1000 [==============================] - 34s 34ms/step - loss: 0.1369 - acc: 0.9570\n",
      "Epoch 5/10\n",
      "1000/1000 [==============================] - 33s 33ms/step - loss: 0.1157 - acc: 0.9660\n",
      "Epoch 6/10\n",
      "1000/1000 [==============================] - 33s 33ms/step - loss: 0.1015 - acc: 0.9670\n",
      "Epoch 7/10\n",
      "1000/1000 [==============================] - 33s 33ms/step - loss: 0.0928 - acc: 0.9730\n",
      "Epoch 8/10\n",
      "1000/1000 [==============================] - 33s 33ms/step - loss: 0.0805 - acc: 0.9770\n",
      "Epoch 9/10\n",
      "1000/1000 [==============================] - 34s 34ms/step - loss: 0.0732 - acc: 0.9780\n",
      "Epoch 10/10\n",
      "1000/1000 [==============================] - 34s 34ms/step - loss: 0.0672 - acc: 0.9820\n",
      "Training on Epoch  2 batch  5  Files [5] start  95 / 459\n",
      "Epoch 1/10\n",
      "1000/1000 [==============================] - 34s 34ms/step - loss: 0.3364 - acc: 0.8800\n",
      "Epoch 2/10\n",
      "1000/1000 [==============================] - 36s 36ms/step - loss: 0.2498 - acc: 0.9020\n",
      "Epoch 3/10\n",
      "1000/1000 [==============================] - 37s 37ms/step - loss: 0.2210 - acc: 0.9060\n",
      "Epoch 4/10\n",
      "1000/1000 [==============================] - 37s 37ms/step - loss: 0.1805 - acc: 0.9240\n",
      "Epoch 5/10\n",
      "1000/1000 [==============================] - 37s 37ms/step - loss: 0.1497 - acc: 0.9360\n",
      "Epoch 6/10\n",
      "1000/1000 [==============================] - 36s 36ms/step - loss: 0.1304 - acc: 0.9490\n",
      "Epoch 7/10\n",
      "1000/1000 [==============================] - 37s 37ms/step - loss: 0.1081 - acc: 0.9600\n",
      "Epoch 8/10\n",
      "1000/1000 [==============================] - 37s 37ms/step - loss: 0.0947 - acc: 0.9660\n",
      "Epoch 9/10\n",
      "1000/1000 [==============================] - 37s 37ms/step - loss: 0.0852 - acc: 0.9720\n",
      "Epoch 10/10\n",
      "1000/1000 [==============================] - 38s 38ms/step - loss: 0.0782 - acc: 0.9700\n",
      "Training on Epoch  2 batch  5  Files [5] start  100 / 459\n",
      "Epoch 1/10\n",
      "1000/1000 [==============================] - 37s 37ms/step - loss: 0.2770 - acc: 0.9090\n",
      "Epoch 2/10\n",
      "1000/1000 [==============================] - 37s 37ms/step - loss: 0.2042 - acc: 0.9300\n",
      "Epoch 3/10\n",
      "1000/1000 [==============================] - 37s 37ms/step - loss: 0.1621 - acc: 0.9470\n",
      "Epoch 4/10\n",
      "1000/1000 [==============================] - 38s 38ms/step - loss: 0.1296 - acc: 0.9630\n",
      "Epoch 5/10\n",
      "1000/1000 [==============================] - 37s 37ms/step - loss: 0.1048 - acc: 0.9700\n",
      "Epoch 6/10\n",
      "1000/1000 [==============================] - 37s 37ms/step - loss: 0.0878 - acc: 0.9750\n",
      "Epoch 7/10\n",
      "1000/1000 [==============================] - 37s 37ms/step - loss: 0.0730 - acc: 0.9780\n",
      "Epoch 8/10\n",
      "1000/1000 [==============================] - 37s 37ms/step - loss: 0.0634 - acc: 0.9790\n",
      "Epoch 9/10\n",
      "1000/1000 [==============================] - 38s 38ms/step - loss: 0.0550 - acc: 0.9850\n",
      "Epoch 10/10\n",
      "1000/1000 [==============================] - 37s 37ms/step - loss: 0.0470 - acc: 0.9870\n",
      "Training on Epoch  2 batch  5  Files [5] start  105 / 459\n",
      "Epoch 1/10\n",
      "1000/1000 [==============================] - 38s 38ms/step - loss: 0.2944 - acc: 0.9040\n",
      "Epoch 2/10\n",
      "1000/1000 [==============================] - 37s 37ms/step - loss: 0.2123 - acc: 0.9160\n",
      "Epoch 3/10\n",
      "1000/1000 [==============================] - 37s 37ms/step - loss: 0.1571 - acc: 0.9440\n",
      "Epoch 4/10\n",
      "1000/1000 [==============================] - 37s 37ms/step - loss: 0.1186 - acc: 0.9600\n",
      "Epoch 5/10\n",
      "1000/1000 [==============================] - 37s 37ms/step - loss: 0.0962 - acc: 0.9630\n",
      "Epoch 6/10\n",
      "1000/1000 [==============================] - 37s 37ms/step - loss: 0.0792 - acc: 0.9710\n",
      "Epoch 7/10\n",
      "1000/1000 [==============================] - 37s 37ms/step - loss: 0.0692 - acc: 0.9760\n",
      "Epoch 8/10\n",
      "1000/1000 [==============================] - 37s 37ms/step - loss: 0.0590 - acc: 0.9820\n",
      "Epoch 9/10\n",
      "1000/1000 [==============================] - 38s 38ms/step - loss: 0.0540 - acc: 0.9830\n",
      "Epoch 10/10\n",
      "1000/1000 [==============================] - 38s 38ms/step - loss: 0.0471 - acc: 0.9840\n",
      "Training on Epoch  2 batch  5  Files [5] start  110 / 459\n",
      "Epoch 1/10\n",
      "1000/1000 [==============================] - 39s 39ms/step - loss: 0.3160 - acc: 0.8850\n",
      "Epoch 2/10\n",
      "1000/1000 [==============================] - 40s 40ms/step - loss: 0.2234 - acc: 0.9130\n",
      "Epoch 3/10\n",
      "1000/1000 [==============================] - 40s 40ms/step - loss: 0.1742 - acc: 0.9330\n",
      "Epoch 4/10\n",
      "1000/1000 [==============================] - 40s 40ms/step - loss: 0.1452 - acc: 0.9430\n",
      "Epoch 5/10\n",
      "1000/1000 [==============================] - 40s 40ms/step - loss: 0.1184 - acc: 0.9570\n",
      "Epoch 6/10\n",
      "1000/1000 [==============================] - 39s 39ms/step - loss: 0.1036 - acc: 0.9640\n",
      "Epoch 7/10\n",
      "1000/1000 [==============================] - 40s 40ms/step - loss: 0.0898 - acc: 0.9710\n",
      "Epoch 8/10\n",
      "1000/1000 [==============================] - 40s 40ms/step - loss: 0.0804 - acc: 0.9750\n",
      "Epoch 9/10\n",
      "1000/1000 [==============================] - 40s 40ms/step - loss: 0.0721 - acc: 0.9800\n",
      "Epoch 10/10\n",
      "1000/1000 [==============================] - 40s 40ms/step - loss: 0.0659 - acc: 0.9800\n",
      "Training on Epoch  2 batch  5  Files [5] start  115 / 459\n",
      "Epoch 1/10\n",
      "1000/1000 [==============================] - 46s 46ms/step - loss: 0.3640 - acc: 0.8560\n",
      "Epoch 2/10\n",
      "1000/1000 [==============================] - 47s 47ms/step - loss: 0.3020 - acc: 0.8750\n",
      "Epoch 3/10\n",
      "1000/1000 [==============================] - 47s 47ms/step - loss: 0.2380 - acc: 0.9020\n",
      "Epoch 4/10\n",
      "1000/1000 [==============================] - 47s 47ms/step - loss: 0.1997 - acc: 0.9210\n",
      "Epoch 5/10\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000/1000 [==============================] - 48s 48ms/step - loss: 0.1800 - acc: 0.9250\n",
      "Epoch 6/10\n",
      "1000/1000 [==============================] - 48s 48ms/step - loss: 0.1572 - acc: 0.9420\n",
      "Epoch 7/10\n",
      "1000/1000 [==============================] - 48s 48ms/step - loss: 0.1440 - acc: 0.9450\n",
      "Epoch 8/10\n",
      "1000/1000 [==============================] - 47s 47ms/step - loss: 0.1328 - acc: 0.9470\n",
      "Epoch 9/10\n",
      "1000/1000 [==============================] - 48s 48ms/step - loss: 0.1250 - acc: 0.9500\n",
      "Epoch 10/10\n",
      "1000/1000 [==============================] - 47s 47ms/step - loss: 0.1187 - acc: 0.9520\n",
      "Training on Epoch  2 batch  5  Files [5] start  120 / 459\n",
      "Epoch 1/10\n",
      "1000/1000 [==============================] - 38s 38ms/step - loss: 0.2589 - acc: 0.8770\n",
      "Epoch 2/10\n",
      "1000/1000 [==============================] - 39s 39ms/step - loss: 0.2247 - acc: 0.8920\n",
      "Epoch 3/10\n",
      "1000/1000 [==============================] - 40s 40ms/step - loss: 0.2062 - acc: 0.9060\n",
      "Epoch 4/10\n",
      "1000/1000 [==============================] - 41s 41ms/step - loss: 0.1926 - acc: 0.9110\n",
      "Epoch 5/10\n",
      "1000/1000 [==============================] - 41s 41ms/step - loss: 0.1832 - acc: 0.9160\n",
      "Epoch 6/10\n",
      "1000/1000 [==============================] - 41s 41ms/step - loss: 0.1770 - acc: 0.9190\n",
      "Epoch 7/10\n",
      "1000/1000 [==============================] - 41s 41ms/step - loss: 0.1690 - acc: 0.9210\n",
      "Epoch 8/10\n",
      "1000/1000 [==============================] - 41s 41ms/step - loss: 0.1636 - acc: 0.9280\n",
      "Epoch 9/10\n",
      "1000/1000 [==============================] - 42s 42ms/step - loss: 0.1599 - acc: 0.9280\n",
      "Epoch 10/10\n",
      "1000/1000 [==============================] - 41s 41ms/step - loss: 0.1563 - acc: 0.9280\n",
      "Training on Epoch  2 batch  5  Files [5] start  125 / 459\n",
      "Epoch 1/10\n",
      "1000/1000 [==============================] - 56s 56ms/step - loss: 0.3477 - acc: 0.8710\n",
      "Epoch 2/10\n",
      "1000/1000 [==============================] - 55s 55ms/step - loss: 0.2806 - acc: 0.8890\n",
      "Epoch 3/10\n",
      "1000/1000 [==============================] - 56s 56ms/step - loss: 0.2315 - acc: 0.8960\n",
      "Epoch 4/10\n",
      "1000/1000 [==============================] - 55s 55ms/step - loss: 0.2113 - acc: 0.9070\n",
      "Epoch 5/10\n",
      "1000/1000 [==============================] - 56s 56ms/step - loss: 0.1943 - acc: 0.9200\n",
      "Epoch 6/10\n",
      "1000/1000 [==============================] - 55s 55ms/step - loss: 0.1801 - acc: 0.9220\n",
      "Epoch 7/10\n",
      "1000/1000 [==============================] - 57s 57ms/step - loss: 0.1700 - acc: 0.9250\n",
      "Epoch 8/10\n",
      "1000/1000 [==============================] - 56s 56ms/step - loss: 0.1628 - acc: 0.9270\n",
      "Epoch 9/10\n",
      "1000/1000 [==============================] - 56s 56ms/step - loss: 0.1570 - acc: 0.9310\n",
      "Epoch 10/10\n",
      "1000/1000 [==============================] - 56s 56ms/step - loss: 0.1513 - acc: 0.9330\n",
      "Training on Epoch  2 batch  5  Files [5] start  130 / 459\n",
      "Epoch 1/10\n",
      "1000/1000 [==============================] - 41s 41ms/step - loss: 0.3389 - acc: 0.8550\n",
      "Epoch 2/10\n",
      "1000/1000 [==============================] - 42s 42ms/step - loss: 0.2941 - acc: 0.8750\n",
      "Epoch 3/10\n",
      "1000/1000 [==============================] - 43s 43ms/step - loss: 0.2660 - acc: 0.8860\n",
      "Epoch 4/10\n",
      "1000/1000 [==============================] - 43s 43ms/step - loss: 0.2448 - acc: 0.8960\n",
      "Epoch 5/10\n",
      "1000/1000 [==============================] - 43s 43ms/step - loss: 0.2288 - acc: 0.9000\n",
      "Epoch 6/10\n",
      "1000/1000 [==============================] - 44s 44ms/step - loss: 0.2127 - acc: 0.9090\n",
      "Epoch 7/10\n",
      "1000/1000 [==============================] - 44s 44ms/step - loss: 0.2025 - acc: 0.9160\n",
      "Epoch 8/10\n",
      "1000/1000 [==============================] - 44s 44ms/step - loss: 0.1946 - acc: 0.9170\n",
      "Epoch 9/10\n",
      "1000/1000 [==============================] - 44s 44ms/step - loss: 0.1939 - acc: 0.9190\n",
      "Epoch 10/10\n",
      "1000/1000 [==============================] - 44s 44ms/step - loss: 0.1882 - acc: 0.9240\n",
      "Training on Epoch  2 batch  5  Files [5] start  135 / 459\n",
      "Epoch 1/10\n",
      "1000/1000 [==============================] - 48s 48ms/step - loss: 0.3518 - acc: 0.8420\n",
      "Epoch 2/10\n",
      "1000/1000 [==============================] - 48s 48ms/step - loss: 0.2957 - acc: 0.8640\n",
      "Epoch 3/10\n",
      "1000/1000 [==============================] - 50s 50ms/step - loss: 0.2562 - acc: 0.8730\n",
      "Epoch 4/10\n",
      "1000/1000 [==============================] - 49s 49ms/step - loss: 0.2383 - acc: 0.8860\n",
      "Epoch 5/10\n",
      "1000/1000 [==============================] - 48s 48ms/step - loss: 0.2225 - acc: 0.8940\n",
      "Epoch 6/10\n",
      "1000/1000 [==============================] - 50s 50ms/step - loss: 0.2097 - acc: 0.8970\n",
      "Epoch 7/10\n",
      "1000/1000 [==============================] - 49s 49ms/step - loss: 0.2041 - acc: 0.9010\n",
      "Epoch 8/10\n",
      "1000/1000 [==============================] - 49s 49ms/step - loss: 0.1963 - acc: 0.9070\n",
      "Epoch 9/10\n",
      "1000/1000 [==============================] - 50s 50ms/step - loss: 0.1916 - acc: 0.9050\n",
      "Epoch 10/10\n",
      "1000/1000 [==============================] - 49s 49ms/step - loss: 0.1909 - acc: 0.9070\n",
      "Training on Epoch  2 batch  5  Files [5] start  140 / 459\n",
      "Epoch 1/10\n",
      "1000/1000 [==============================] - 40s 40ms/step - loss: 0.3200 - acc: 0.8660\n",
      "Epoch 2/10\n",
      "1000/1000 [==============================] - 41s 41ms/step - loss: 0.2665 - acc: 0.8840\n",
      "Epoch 3/10\n",
      "1000/1000 [==============================] - 41s 41ms/step - loss: 0.2131 - acc: 0.8960\n",
      "Epoch 4/10\n",
      "1000/1000 [==============================] - 40s 40ms/step - loss: 0.1826 - acc: 0.9110\n",
      "Epoch 5/10\n",
      "1000/1000 [==============================] - 40s 40ms/step - loss: 0.1606 - acc: 0.9180\n",
      "Epoch 6/10\n",
      "1000/1000 [==============================] - 40s 40ms/step - loss: 0.1463 - acc: 0.9280\n",
      "Epoch 7/10\n",
      "1000/1000 [==============================] - 41s 41ms/step - loss: 0.1319 - acc: 0.9340\n",
      "Epoch 8/10\n",
      "1000/1000 [==============================] - 41s 41ms/step - loss: 0.1249 - acc: 0.9370\n",
      "Epoch 9/10\n",
      "1000/1000 [==============================] - 42s 42ms/step - loss: 0.1215 - acc: 0.9350\n",
      "Epoch 10/10\n",
      "1000/1000 [==============================] - 41s 41ms/step - loss: 0.1155 - acc: 0.9430\n",
      "Training on Epoch  2 batch  5  Files [5] start  145 / 459\n",
      "Epoch 1/10\n",
      "1000/1000 [==============================] - 45s 45ms/step - loss: 0.2681 - acc: 0.9010\n",
      "Epoch 2/10\n",
      "1000/1000 [==============================] - 45s 45ms/step - loss: 0.2053 - acc: 0.9270\n",
      "Epoch 3/10\n",
      "1000/1000 [==============================] - 45s 45ms/step - loss: 0.1570 - acc: 0.9420\n",
      "Epoch 4/10\n",
      "1000/1000 [==============================] - 45s 45ms/step - loss: 0.1265 - acc: 0.9540\n",
      "Epoch 5/10\n",
      "1000/1000 [==============================] - 45s 45ms/step - loss: 0.1114 - acc: 0.9600\n",
      "Epoch 6/10\n",
      "1000/1000 [==============================] - 45s 45ms/step - loss: 0.0946 - acc: 0.9660\n",
      "Epoch 7/10\n",
      "1000/1000 [==============================] - 45s 45ms/step - loss: 0.0808 - acc: 0.9700\n",
      "Epoch 8/10\n",
      "1000/1000 [==============================] - 45s 45ms/step - loss: 0.0697 - acc: 0.9730\n",
      "Epoch 9/10\n",
      "1000/1000 [==============================] - 45s 45ms/step - loss: 0.0617 - acc: 0.9760\n",
      "Epoch 10/10\n",
      "1000/1000 [==============================] - 45s 45ms/step - loss: 0.0558 - acc: 0.9790\n",
      "Training on Epoch  2 batch  5  Files [5] start  150 / 459\n",
      "Epoch 1/10\n",
      "1000/1000 [==============================] - 51s 51ms/step - loss: 0.3235 - acc: 0.8860\n",
      "Epoch 2/10\n",
      "1000/1000 [==============================] - 52s 52ms/step - loss: 0.2228 - acc: 0.9160\n",
      "Epoch 3/10\n",
      "1000/1000 [==============================] - 52s 52ms/step - loss: 0.1790 - acc: 0.9340\n",
      "Epoch 4/10\n",
      "1000/1000 [==============================] - 53s 53ms/step - loss: 0.1487 - acc: 0.9480\n",
      "Epoch 5/10\n",
      "1000/1000 [==============================] - 53s 53ms/step - loss: 0.1340 - acc: 0.9510\n",
      "Epoch 6/10\n",
      "1000/1000 [==============================] - 54s 54ms/step - loss: 0.1229 - acc: 0.9550\n",
      "Epoch 7/10\n",
      "1000/1000 [==============================] - 53s 53ms/step - loss: 0.1146 - acc: 0.9580\n",
      "Epoch 8/10\n",
      "1000/1000 [==============================] - 53s 53ms/step - loss: 0.1086 - acc: 0.9620\n",
      "Epoch 9/10\n",
      "1000/1000 [==============================] - 53s 53ms/step - loss: 0.1002 - acc: 0.9630\n",
      "Epoch 10/10\n",
      "1000/1000 [==============================] - 53s 53ms/step - loss: 0.0946 - acc: 0.9670\n",
      "Training on Epoch  2 batch  5  Files [5] start  155 / 459\n",
      "Epoch 1/10\n",
      "1000/1000 [==============================] - 37s 37ms/step - loss: 0.2039 - acc: 0.9130\n",
      "Epoch 2/10\n",
      "1000/1000 [==============================] - 37s 37ms/step - loss: 0.1514 - acc: 0.9320\n",
      "Epoch 3/10\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000/1000 [==============================] - 37s 37ms/step - loss: 0.1212 - acc: 0.9450\n",
      "Epoch 4/10\n",
      "1000/1000 [==============================] - 37s 37ms/step - loss: 0.1011 - acc: 0.9520\n",
      "Epoch 5/10\n",
      "1000/1000 [==============================] - 37s 37ms/step - loss: 0.0908 - acc: 0.9540\n",
      "Epoch 6/10\n",
      "1000/1000 [==============================] - 37s 37ms/step - loss: 0.0845 - acc: 0.9590\n",
      "Epoch 7/10\n",
      "1000/1000 [==============================] - 37s 37ms/step - loss: 0.0765 - acc: 0.9640\n",
      "Epoch 8/10\n",
      "1000/1000 [==============================] - 37s 37ms/step - loss: 0.0718 - acc: 0.9680\n",
      "Epoch 9/10\n",
      "1000/1000 [==============================] - 37s 37ms/step - loss: 0.0679 - acc: 0.9700\n",
      "Epoch 10/10\n",
      "1000/1000 [==============================] - 37s 37ms/step - loss: 0.0649 - acc: 0.9700\n",
      "Training on Epoch  2 batch  5  Files [5] start  160 / 459\n",
      "Epoch 1/10\n",
      "1000/1000 [==============================] - 38s 38ms/step - loss: 0.2360 - acc: 0.9040\n",
      "Epoch 2/10\n",
      "1000/1000 [==============================] - 38s 38ms/step - loss: 0.1720 - acc: 0.9250\n",
      "Epoch 3/10\n",
      "1000/1000 [==============================] - 38s 38ms/step - loss: 0.1309 - acc: 0.9370\n",
      "Epoch 4/10\n",
      "1000/1000 [==============================] - 39s 39ms/step - loss: 0.1050 - acc: 0.9510\n",
      "Epoch 5/10\n",
      "1000/1000 [==============================] - 39s 39ms/step - loss: 0.0894 - acc: 0.9620\n",
      "Epoch 6/10\n",
      "1000/1000 [==============================] - 40s 40ms/step - loss: 0.0817 - acc: 0.9660\n",
      "Epoch 7/10\n",
      "1000/1000 [==============================] - 39s 39ms/step - loss: 0.0740 - acc: 0.9710\n",
      "Epoch 8/10\n",
      "1000/1000 [==============================] - 39s 39ms/step - loss: 0.0674 - acc: 0.9750\n",
      "Epoch 9/10\n",
      "1000/1000 [==============================] - 39s 39ms/step - loss: 0.0636 - acc: 0.9730\n",
      "Epoch 10/10\n",
      "1000/1000 [==============================] - 39s 39ms/step - loss: 0.0597 - acc: 0.9740\n",
      "Training on Epoch  2 batch  5  Files [5] start  165 / 459\n",
      "Epoch 1/10\n",
      "1000/1000 [==============================] - 42s 42ms/step - loss: 0.2181 - acc: 0.8990\n",
      "Epoch 2/10\n",
      "1000/1000 [==============================] - 42s 42ms/step - loss: 0.1678 - acc: 0.9240\n",
      "Epoch 3/10\n",
      "1000/1000 [==============================] - 43s 43ms/step - loss: 0.1373 - acc: 0.9380\n",
      "Epoch 4/10\n",
      "1000/1000 [==============================] - 42s 42ms/step - loss: 0.1170 - acc: 0.9470\n",
      "Epoch 5/10\n",
      "1000/1000 [==============================] - 42s 42ms/step - loss: 0.1022 - acc: 0.9500\n",
      "Epoch 6/10\n",
      "1000/1000 [==============================] - 42s 42ms/step - loss: 0.0945 - acc: 0.9550\n",
      "Epoch 7/10\n",
      "1000/1000 [==============================] - 42s 42ms/step - loss: 0.0876 - acc: 0.9600\n",
      "Epoch 8/10\n",
      "1000/1000 [==============================] - 42s 42ms/step - loss: 0.0831 - acc: 0.9610\n",
      "Epoch 9/10\n",
      "1000/1000 [==============================] - 42s 42ms/step - loss: 0.0794 - acc: 0.9630\n",
      "Epoch 10/10\n",
      "1000/1000 [==============================] - 42s 42ms/step - loss: 0.0765 - acc: 0.9660\n",
      "Training on Epoch  2 batch  5  Files [5] start  170 / 459\n",
      "Epoch 1/10\n",
      "1000/1000 [==============================] - 48s 48ms/step - loss: 0.2128 - acc: 0.9320\n",
      "Epoch 2/10\n",
      "1000/1000 [==============================] - 48s 48ms/step - loss: 0.1525 - acc: 0.9440\n",
      "Epoch 3/10\n",
      "1000/1000 [==============================] - 49s 49ms/step - loss: 0.1155 - acc: 0.9560\n",
      "Epoch 4/10\n",
      "1000/1000 [==============================] - 50s 50ms/step - loss: 0.0997 - acc: 0.9620\n",
      "Epoch 5/10\n",
      "1000/1000 [==============================] - 49s 49ms/step - loss: 0.0911 - acc: 0.9660\n",
      "Epoch 6/10\n",
      "1000/1000 [==============================] - 49s 49ms/step - loss: 0.0807 - acc: 0.9680\n",
      "Epoch 7/10\n",
      "1000/1000 [==============================] - 49s 49ms/step - loss: 0.0779 - acc: 0.9690\n",
      "Epoch 8/10\n",
      "1000/1000 [==============================] - 48s 48ms/step - loss: 0.0683 - acc: 0.9710\n",
      "Epoch 9/10\n",
      "1000/1000 [==============================] - 49s 49ms/step - loss: 0.0646 - acc: 0.9720\n",
      "Epoch 10/10\n",
      "1000/1000 [==============================] - 49s 49ms/step - loss: 0.0619 - acc: 0.9770\n",
      "Training on Epoch  2 batch  5  Files [5] start  175 / 459\n",
      "Epoch 1/10\n",
      "1000/1000 [==============================] - 49s 49ms/step - loss: 0.2109 - acc: 0.9140\n",
      "Epoch 2/10\n",
      "1000/1000 [==============================] - 51s 51ms/step - loss: 0.1579 - acc: 0.9360\n",
      "Epoch 3/10\n",
      "1000/1000 [==============================] - 50s 50ms/step - loss: 0.1287 - acc: 0.9500\n",
      "Epoch 4/10\n",
      "1000/1000 [==============================] - 51s 51ms/step - loss: 0.1076 - acc: 0.9520\n",
      "Epoch 5/10\n",
      "1000/1000 [==============================] - 50s 50ms/step - loss: 0.0932 - acc: 0.9610\n",
      "Epoch 6/10\n",
      "1000/1000 [==============================] - 54s 54ms/step - loss: 0.0850 - acc: 0.9670\n",
      "Epoch 7/10\n",
      "1000/1000 [==============================] - 52s 52ms/step - loss: 0.0802 - acc: 0.9670\n",
      "Epoch 8/10\n",
      "1000/1000 [==============================] - 51s 51ms/step - loss: 0.0746 - acc: 0.9670\n",
      "Epoch 9/10\n",
      "1000/1000 [==============================] - 50s 50ms/step - loss: 0.0723 - acc: 0.9650\n",
      "Epoch 10/10\n",
      "1000/1000 [==============================] - 50s 50ms/step - loss: 0.0688 - acc: 0.9710\n",
      "Training on Epoch  2 batch  5  Files [5] start  180 / 459\n",
      "Epoch 1/10\n",
      "1000/1000 [==============================] - 40s 40ms/step - loss: 0.1366 - acc: 0.9400\n",
      "Epoch 2/10\n",
      "1000/1000 [==============================] - 39s 39ms/step - loss: 0.1103 - acc: 0.9560\n",
      "Epoch 3/10\n",
      "1000/1000 [==============================] - 39s 39ms/step - loss: 0.0945 - acc: 0.9590\n",
      "Epoch 4/10\n",
      "1000/1000 [==============================] - 39s 39ms/step - loss: 0.0875 - acc: 0.9620\n",
      "Epoch 5/10\n",
      "1000/1000 [==============================] - 39s 39ms/step - loss: 0.0772 - acc: 0.9710\n",
      "Epoch 6/10\n",
      "1000/1000 [==============================] - 39s 39ms/step - loss: 0.0747 - acc: 0.9650\n",
      "Epoch 7/10\n",
      "1000/1000 [==============================] - 43s 43ms/step - loss: 0.0682 - acc: 0.9710\n",
      "Epoch 8/10\n",
      "1000/1000 [==============================] - 42s 42ms/step - loss: 0.0659 - acc: 0.9700\n",
      "Epoch 9/10\n",
      "1000/1000 [==============================] - 41s 41ms/step - loss: 0.0634 - acc: 0.9710\n",
      "Epoch 10/10\n",
      "1000/1000 [==============================] - 42s 42ms/step - loss: 0.0615 - acc: 0.9720\n",
      "Training on Epoch  2 batch  5  Files [5] start  185 / 459\n",
      "Epoch 1/10\n",
      "1000/1000 [==============================] - 55s 55ms/step - loss: 0.1698 - acc: 0.9280\n",
      "Epoch 2/10\n",
      "1000/1000 [==============================] - 55s 55ms/step - loss: 0.1478 - acc: 0.9250\n",
      "Epoch 3/10\n",
      "1000/1000 [==============================] - 56s 56ms/step - loss: 0.1283 - acc: 0.9300\n",
      "Epoch 4/10\n",
      "1000/1000 [==============================] - 56s 56ms/step - loss: 0.1179 - acc: 0.9340\n",
      "Epoch 5/10\n",
      "1000/1000 [==============================] - 55s 55ms/step - loss: 0.1136 - acc: 0.9400\n",
      "Epoch 6/10\n",
      "1000/1000 [==============================] - 55s 55ms/step - loss: 0.1031 - acc: 0.9440\n",
      "Epoch 7/10\n",
      "1000/1000 [==============================] - 55s 55ms/step - loss: 0.1040 - acc: 0.9470\n",
      "Epoch 8/10\n",
      "1000/1000 [==============================] - 55s 55ms/step - loss: 0.0987 - acc: 0.9470\n",
      "Epoch 9/10\n",
      "1000/1000 [==============================] - 54s 54ms/step - loss: 0.0948 - acc: 0.9520\n",
      "Epoch 10/10\n",
      "1000/1000 [==============================] - 54s 54ms/step - loss: 0.0957 - acc: 0.9520\n",
      "Training on Epoch  2 batch  5  Files [5] start  190 / 459\n",
      "Epoch 1/10\n",
      "1000/1000 [==============================] - 50s 50ms/step - loss: 0.2149 - acc: 0.9150\n",
      "Epoch 2/10\n",
      "1000/1000 [==============================] - 50s 50ms/step - loss: 0.1734 - acc: 0.9280\n",
      "Epoch 3/10\n",
      "1000/1000 [==============================] - 51s 51ms/step - loss: 0.1486 - acc: 0.9250\n",
      "Epoch 4/10\n",
      "1000/1000 [==============================] - 50s 50ms/step - loss: 0.1293 - acc: 0.9360\n",
      "Epoch 5/10\n",
      "1000/1000 [==============================] - 50s 50ms/step - loss: 0.1144 - acc: 0.9430\n",
      "Epoch 6/10\n",
      "1000/1000 [==============================] - 49s 49ms/step - loss: 0.1078 - acc: 0.9450\n",
      "Epoch 7/10\n",
      "1000/1000 [==============================] - 50s 50ms/step - loss: 0.1005 - acc: 0.9490\n",
      "Epoch 8/10\n",
      "1000/1000 [==============================] - 51s 51ms/step - loss: 0.0965 - acc: 0.9530\n",
      "Epoch 9/10\n",
      "1000/1000 [==============================] - 51s 51ms/step - loss: 0.0918 - acc: 0.9530\n",
      "Epoch 10/10\n",
      "1000/1000 [==============================] - 53s 53ms/step - loss: 0.0911 - acc: 0.9550\n",
      "Training on Epoch  2 batch  5  Files [5] start  195 / 459\n",
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000/1000 [==============================] - 54s 54ms/step - loss: 0.2337 - acc: 0.8920\n",
      "Epoch 2/10\n",
      "1000/1000 [==============================] - 52s 52ms/step - loss: 0.1918 - acc: 0.9030\n",
      "Epoch 3/10\n",
      "1000/1000 [==============================] - 56s 56ms/step - loss: 0.1714 - acc: 0.9060\n",
      "Epoch 4/10\n",
      "1000/1000 [==============================] - 58s 58ms/step - loss: 0.1559 - acc: 0.9060\n",
      "Epoch 5/10\n",
      "1000/1000 [==============================] - 58s 58ms/step - loss: 0.1473 - acc: 0.9120\n",
      "Epoch 6/10\n",
      "1000/1000 [==============================] - 56s 56ms/step - loss: 0.1396 - acc: 0.9210\n",
      "Epoch 7/10\n",
      "1000/1000 [==============================] - 57s 57ms/step - loss: 0.1340 - acc: 0.9250\n",
      "Epoch 8/10\n",
      "1000/1000 [==============================] - 57s 57ms/step - loss: 0.1283 - acc: 0.9220\n",
      "Epoch 9/10\n",
      "1000/1000 [==============================] - 57s 57ms/step - loss: 0.1250 - acc: 0.9310\n",
      "Epoch 10/10\n",
      "1000/1000 [==============================] - 60s 60ms/step - loss: 0.1224 - acc: 0.9320\n",
      "Training on Epoch  2 batch  5  Files [5] start  200 / 459\n",
      "Epoch 1/10\n",
      "1000/1000 [==============================] - 50s 50ms/step - loss: 0.2147 - acc: 0.9100\n",
      "Epoch 2/10\n",
      "1000/1000 [==============================] - 51s 51ms/step - loss: 0.1768 - acc: 0.9130\n",
      "Epoch 3/10\n",
      "1000/1000 [==============================] - 51s 51ms/step - loss: 0.1495 - acc: 0.9250\n",
      "Epoch 4/10\n",
      "1000/1000 [==============================] - 51s 51ms/step - loss: 0.1319 - acc: 0.9340\n",
      "Epoch 5/10\n",
      "1000/1000 [==============================] - 51s 51ms/step - loss: 0.1204 - acc: 0.9390\n",
      "Epoch 6/10\n",
      "1000/1000 [==============================] - 50s 50ms/step - loss: 0.1120 - acc: 0.9430\n",
      "Epoch 7/10\n",
      "1000/1000 [==============================] - 50s 50ms/step - loss: 0.1067 - acc: 0.9460\n",
      "Epoch 8/10\n",
      "1000/1000 [==============================] - 51s 51ms/step - loss: 0.1025 - acc: 0.9510\n",
      "Epoch 9/10\n",
      "1000/1000 [==============================] - 50s 50ms/step - loss: 0.0985 - acc: 0.9520\n",
      "Epoch 10/10\n",
      "1000/1000 [==============================] - 51s 51ms/step - loss: 0.0962 - acc: 0.9510\n",
      "Training on Epoch  2 batch  5  Files [5] start  205 / 459\n",
      "Epoch 1/10\n",
      "1000/1000 [==============================] - 52s 52ms/step - loss: 0.1715 - acc: 0.9020\n",
      "Epoch 2/10\n",
      "1000/1000 [==============================] - 52s 52ms/step - loss: 0.1412 - acc: 0.9170\n",
      "Epoch 3/10\n",
      "1000/1000 [==============================] - 52s 52ms/step - loss: 0.1295 - acc: 0.9220\n",
      "Epoch 4/10\n",
      "1000/1000 [==============================] - 52s 52ms/step - loss: 0.1192 - acc: 0.9320\n",
      "Epoch 5/10\n",
      "1000/1000 [==============================] - 52s 52ms/step - loss: 0.1149 - acc: 0.9370\n",
      "Epoch 6/10\n",
      "1000/1000 [==============================] - 51s 51ms/step - loss: 0.1096 - acc: 0.9410\n",
      "Epoch 7/10\n",
      "1000/1000 [==============================] - 53s 53ms/step - loss: 0.1061 - acc: 0.9450\n",
      "Epoch 8/10\n",
      "1000/1000 [==============================] - 52s 52ms/step - loss: 0.1030 - acc: 0.9380\n",
      "Epoch 9/10\n",
      "1000/1000 [==============================] - 53s 53ms/step - loss: 0.1005 - acc: 0.9460\n",
      "Epoch 10/10\n",
      "1000/1000 [==============================] - 52s 52ms/step - loss: 0.0958 - acc: 0.9490\n",
      "Training on Epoch  2 batch  5  Files [5] start  210 / 459\n",
      "Epoch 1/10\n",
      "1000/1000 [==============================] - 46s 46ms/step - loss: 0.1953 - acc: 0.9260\n",
      "Epoch 2/10\n",
      "1000/1000 [==============================] - 46s 46ms/step - loss: 0.1398 - acc: 0.9390\n",
      "Epoch 3/10\n",
      "1000/1000 [==============================] - 45s 45ms/step - loss: 0.1148 - acc: 0.9510\n",
      "Epoch 4/10\n",
      "1000/1000 [==============================] - 45s 45ms/step - loss: 0.0941 - acc: 0.9640\n",
      "Epoch 5/10\n",
      "1000/1000 [==============================] - 44s 44ms/step - loss: 0.0820 - acc: 0.9650\n",
      "Epoch 6/10\n",
      "1000/1000 [==============================] - 45s 45ms/step - loss: 0.0735 - acc: 0.9700\n",
      "Epoch 7/10\n",
      "1000/1000 [==============================] - 44s 44ms/step - loss: 0.0703 - acc: 0.9690\n",
      "Epoch 8/10\n",
      "1000/1000 [==============================] - 43s 43ms/step - loss: 0.0631 - acc: 0.9770\n",
      "Epoch 9/10\n",
      "1000/1000 [==============================] - 43s 43ms/step - loss: 0.0580 - acc: 0.9810\n",
      "Epoch 10/10\n",
      "1000/1000 [==============================] - 43s 43ms/step - loss: 0.0557 - acc: 0.9800\n",
      "Training on Epoch  2 batch  5  Files [5] start  215 / 459\n",
      "Epoch 1/10\n",
      "1000/1000 [==============================] - 56s 56ms/step - loss: 0.2255 - acc: 0.9010\n",
      "Epoch 2/10\n",
      "1000/1000 [==============================] - 55s 55ms/step - loss: 0.1991 - acc: 0.9100\n",
      "Epoch 3/10\n",
      "1000/1000 [==============================] - 57s 57ms/step - loss: 0.1591 - acc: 0.9330\n",
      "Epoch 4/10\n",
      "1000/1000 [==============================] - 56s 56ms/step - loss: 0.1478 - acc: 0.9290\n",
      "Epoch 5/10\n",
      "1000/1000 [==============================] - 55s 55ms/step - loss: 0.1462 - acc: 0.9280\n",
      "Epoch 6/10\n",
      "1000/1000 [==============================] - 56s 56ms/step - loss: 0.1376 - acc: 0.9350\n",
      "Epoch 7/10\n",
      "1000/1000 [==============================] - 58s 58ms/step - loss: 0.1362 - acc: 0.9320\n",
      "Epoch 8/10\n",
      "1000/1000 [==============================] - 57s 57ms/step - loss: 0.1304 - acc: 0.9370\n",
      "Epoch 9/10\n",
      "1000/1000 [==============================] - 57s 57ms/step - loss: 0.1280 - acc: 0.9430\n",
      "Epoch 10/10\n",
      "1000/1000 [==============================] - 55s 55ms/step - loss: 0.1257 - acc: 0.9400\n",
      "Training on Epoch  2 batch  5  Files [5] start  220 / 459\n",
      "Epoch 1/10\n",
      "1000/1000 [==============================] - 48s 48ms/step - loss: 0.2519 - acc: 0.9080\n",
      "Epoch 2/10\n",
      "1000/1000 [==============================] - 51s 51ms/step - loss: 0.1871 - acc: 0.9200\n",
      "Epoch 3/10\n",
      "1000/1000 [==============================] - 48s 48ms/step - loss: 0.1518 - acc: 0.9370\n",
      "Epoch 4/10\n",
      "1000/1000 [==============================] - 48s 48ms/step - loss: 0.1327 - acc: 0.9440\n",
      "Epoch 5/10\n",
      "1000/1000 [==============================] - 49s 49ms/step - loss: 0.1195 - acc: 0.9440\n",
      "Epoch 6/10\n",
      "1000/1000 [==============================] - 57s 57ms/step - loss: 0.1078 - acc: 0.9490\n",
      "Epoch 7/10\n",
      "1000/1000 [==============================] - 55s 55ms/step - loss: 0.0997 - acc: 0.9570\n",
      "Epoch 8/10\n",
      "1000/1000 [==============================] - 53s 53ms/step - loss: 0.0931 - acc: 0.9570\n",
      "Epoch 9/10\n",
      "1000/1000 [==============================] - 54s 54ms/step - loss: 0.0877 - acc: 0.9570\n",
      "Epoch 10/10\n",
      "1000/1000 [==============================] - 53s 53ms/step - loss: 0.0829 - acc: 0.9590\n",
      "Training on Epoch  2 batch  5  Files [5] start  225 / 459\n",
      "Epoch 1/10\n",
      "1000/1000 [==============================] - 44s 44ms/step - loss: 0.1552 - acc: 0.9420\n",
      "Epoch 2/10\n",
      "1000/1000 [==============================] - 44s 44ms/step - loss: 0.1349 - acc: 0.9490\n",
      "Epoch 3/10\n",
      "1000/1000 [==============================] - 44s 44ms/step - loss: 0.1132 - acc: 0.9540\n",
      "Epoch 4/10\n",
      "1000/1000 [==============================] - 46s 46ms/step - loss: 0.0950 - acc: 0.9590\n",
      "Epoch 5/10\n",
      "1000/1000 [==============================] - 44s 44ms/step - loss: 0.0839 - acc: 0.9630\n",
      "Epoch 6/10\n",
      "1000/1000 [==============================] - 45s 45ms/step - loss: 0.0752 - acc: 0.9690\n",
      "Epoch 7/10\n",
      "1000/1000 [==============================] - 43s 43ms/step - loss: 0.0691 - acc: 0.9720\n",
      "Epoch 8/10\n",
      "1000/1000 [==============================] - 43s 43ms/step - loss: 0.0619 - acc: 0.9770\n",
      "Epoch 9/10\n",
      "1000/1000 [==============================] - 43s 43ms/step - loss: 0.0580 - acc: 0.9800\n",
      "Epoch 10/10\n",
      "1000/1000 [==============================] - 44s 44ms/step - loss: 0.0544 - acc: 0.9800\n",
      "Training on Epoch  2 batch  5  Files [5] start  230 / 459\n",
      "Epoch 1/10\n",
      "1000/1000 [==============================] - 47s 47ms/step - loss: 0.1758 - acc: 0.9250\n",
      "Epoch 2/10\n",
      "1000/1000 [==============================] - 46s 46ms/step - loss: 0.1343 - acc: 0.9290\n",
      "Epoch 3/10\n",
      "1000/1000 [==============================] - 47s 47ms/step - loss: 0.1113 - acc: 0.9340\n",
      "Epoch 4/10\n",
      "1000/1000 [==============================] - 46s 46ms/step - loss: 0.1000 - acc: 0.9490\n",
      "Epoch 5/10\n",
      "1000/1000 [==============================] - 47s 47ms/step - loss: 0.0938 - acc: 0.9570\n",
      "Epoch 6/10\n",
      "1000/1000 [==============================] - 47s 47ms/step - loss: 0.0894 - acc: 0.9590\n",
      "Epoch 7/10\n",
      "1000/1000 [==============================] - 46s 46ms/step - loss: 0.0890 - acc: 0.9600\n",
      "Epoch 8/10\n",
      "1000/1000 [==============================] - 47s 47ms/step - loss: 0.0848 - acc: 0.9640\n",
      "Epoch 9/10\n",
      "1000/1000 [==============================] - 47s 47ms/step - loss: 0.0824 - acc: 0.9600\n",
      "Epoch 10/10\n",
      "1000/1000 [==============================] - 46s 46ms/step - loss: 0.0797 - acc: 0.9610\n",
      "Training on Epoch  2 batch  5  Files [5] start  235 / 459\n",
      "Epoch 1/10\n",
      "1000/1000 [==============================] - 46s 46ms/step - loss: 0.1652 - acc: 0.9280\n",
      "Epoch 2/10\n",
      "1000/1000 [==============================] - 45s 45ms/step - loss: 0.1216 - acc: 0.9400\n",
      "Epoch 3/10\n",
      "1000/1000 [==============================] - 45s 45ms/step - loss: 0.0965 - acc: 0.9500\n",
      "Epoch 4/10\n",
      "1000/1000 [==============================] - 45s 45ms/step - loss: 0.0857 - acc: 0.9580\n",
      "Epoch 5/10\n",
      "1000/1000 [==============================] - 45s 45ms/step - loss: 0.0777 - acc: 0.9600\n",
      "Epoch 6/10\n",
      "1000/1000 [==============================] - 45s 45ms/step - loss: 0.0717 - acc: 0.9630\n",
      "Epoch 7/10\n",
      "1000/1000 [==============================] - 46s 46ms/step - loss: 0.0680 - acc: 0.9630\n",
      "Epoch 8/10\n",
      "1000/1000 [==============================] - 46s 46ms/step - loss: 0.0653 - acc: 0.9690\n",
      "Epoch 9/10\n",
      "1000/1000 [==============================] - 46s 46ms/step - loss: 0.0628 - acc: 0.9700\n",
      "Epoch 10/10\n",
      "1000/1000 [==============================] - 47s 47ms/step - loss: 0.0608 - acc: 0.9740\n",
      "Training on Epoch  2 batch  5  Files [5] start  240 / 459\n",
      "Epoch 1/10\n",
      "1000/1000 [==============================] - 48s 48ms/step - loss: 0.1249 - acc: 0.9500\n",
      "Epoch 2/10\n",
      "1000/1000 [==============================] - 49s 49ms/step - loss: 0.0850 - acc: 0.9610\n",
      "Epoch 3/10\n",
      "1000/1000 [==============================] - 49s 49ms/step - loss: 0.0685 - acc: 0.9670\n",
      "Epoch 4/10\n",
      "1000/1000 [==============================] - 49s 49ms/step - loss: 0.0597 - acc: 0.9720\n",
      "Epoch 5/10\n",
      "1000/1000 [==============================] - 49s 49ms/step - loss: 0.0543 - acc: 0.9750\n",
      "Epoch 6/10\n",
      "1000/1000 [==============================] - 49s 49ms/step - loss: 0.0490 - acc: 0.9780\n",
      "Epoch 7/10\n",
      "1000/1000 [==============================] - 49s 49ms/step - loss: 0.0458 - acc: 0.9790\n",
      "Epoch 8/10\n",
      "1000/1000 [==============================] - 48s 48ms/step - loss: 0.0437 - acc: 0.9800\n",
      "Epoch 9/10\n",
      "1000/1000 [==============================] - 45s 45ms/step - loss: 0.0427 - acc: 0.9800\n",
      "Epoch 10/10\n",
      "1000/1000 [==============================] - 45s 45ms/step - loss: 0.0409 - acc: 0.9820\n",
      "Training on Epoch  2 batch  5  Files [5] start  245 / 459\n",
      "Epoch 1/10\n",
      "1000/1000 [==============================] - 49s 49ms/step - loss: 0.1601 - acc: 0.9300\n",
      "Epoch 2/10\n",
      "1000/1000 [==============================] - 49s 49ms/step - loss: 0.1252 - acc: 0.9420\n",
      "Epoch 3/10\n",
      "1000/1000 [==============================] - 49s 49ms/step - loss: 0.1008 - acc: 0.9410\n",
      "Epoch 4/10\n",
      "1000/1000 [==============================] - 49s 49ms/step - loss: 0.0922 - acc: 0.9430\n",
      "Epoch 5/10\n",
      "1000/1000 [==============================] - 49s 49ms/step - loss: 0.0809 - acc: 0.9650\n",
      "Epoch 6/10\n",
      "1000/1000 [==============================] - 49s 49ms/step - loss: 0.0784 - acc: 0.9650\n",
      "Epoch 7/10\n",
      "1000/1000 [==============================] - 50s 50ms/step - loss: 0.0746 - acc: 0.9630\n",
      "Epoch 8/10\n",
      "1000/1000 [==============================] - 49s 49ms/step - loss: 0.0703 - acc: 0.9650\n",
      "Epoch 9/10\n",
      "1000/1000 [==============================] - 49s 49ms/step - loss: 0.0690 - acc: 0.9650\n",
      "Epoch 10/10\n",
      "1000/1000 [==============================] - 49s 49ms/step - loss: 0.0668 - acc: 0.9650\n",
      "Training on Epoch  2 batch  5  Files [5] start  250 / 459\n",
      "Epoch 1/10\n",
      "1000/1000 [==============================] - 57s 57ms/step - loss: 0.2811 - acc: 0.8990\n",
      "Epoch 2/10\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 0.1568 - acc: 0.9220\n",
      "Epoch 3/10\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 0.1324 - acc: 0.9330\n",
      "Epoch 4/10\n",
      "1000/1000 [==============================] - 58s 58ms/step - loss: 0.1224 - acc: 0.9370\n",
      "Epoch 5/10\n",
      "1000/1000 [==============================] - 58s 58ms/step - loss: 0.1153 - acc: 0.9460\n",
      "Epoch 6/10\n",
      "1000/1000 [==============================] - 63s 63ms/step - loss: 0.1086 - acc: 0.9460\n",
      "Epoch 7/10\n",
      "1000/1000 [==============================] - 67s 67ms/step - loss: 0.1035 - acc: 0.9470\n",
      "Epoch 8/10\n",
      "1000/1000 [==============================] - 68s 68ms/step - loss: 0.1001 - acc: 0.9510\n",
      "Epoch 9/10\n",
      "1000/1000 [==============================] - 67s 67ms/step - loss: 0.0980 - acc: 0.9520\n",
      "Epoch 10/10\n",
      "1000/1000 [==============================] - 67s 67ms/step - loss: 0.0958 - acc: 0.9520\n",
      "Training on Epoch  2 batch  5  Files [5] start  255 / 459\n",
      "Epoch 1/10\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 0.1283 - acc: 0.9380\n",
      "Epoch 2/10\n",
      "1000/1000 [==============================] - 57s 57ms/step - loss: 0.1099 - acc: 0.9470\n",
      "Epoch 3/10\n",
      "1000/1000 [==============================] - 58s 58ms/step - loss: 0.0967 - acc: 0.9500\n",
      "Epoch 4/10\n",
      "1000/1000 [==============================] - 57s 57ms/step - loss: 0.0886 - acc: 0.9560\n",
      "Epoch 5/10\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 0.0839 - acc: 0.9600\n",
      "Epoch 6/10\n",
      "1000/1000 [==============================] - 58s 58ms/step - loss: 0.0807 - acc: 0.9600\n",
      "Epoch 7/10\n",
      "1000/1000 [==============================] - 58s 58ms/step - loss: 0.0780 - acc: 0.9640\n",
      "Epoch 8/10\n",
      "1000/1000 [==============================] - 58s 58ms/step - loss: 0.0765 - acc: 0.9640\n",
      "Epoch 9/10\n",
      "1000/1000 [==============================] - 58s 58ms/step - loss: 0.0752 - acc: 0.9640\n",
      "Epoch 10/10\n",
      "1000/1000 [==============================] - 57s 57ms/step - loss: 0.0735 - acc: 0.9650\n",
      "Training on Epoch  2 batch  5  Files [5] start  260 / 459\n",
      "Epoch 1/10\n",
      "1000/1000 [==============================] - 44s 44ms/step - loss: 0.2086 - acc: 0.9120\n",
      "Epoch 2/10\n",
      "1000/1000 [==============================] - 45s 45ms/step - loss: 0.1507 - acc: 0.9300\n",
      "Epoch 3/10\n",
      "1000/1000 [==============================] - 44s 44ms/step - loss: 0.1247 - acc: 0.9510\n",
      "Epoch 4/10\n",
      "1000/1000 [==============================] - 44s 44ms/step - loss: 0.1121 - acc: 0.9620\n",
      "Epoch 5/10\n",
      "1000/1000 [==============================] - 45s 45ms/step - loss: 0.1062 - acc: 0.9600\n",
      "Epoch 6/10\n",
      "1000/1000 [==============================] - 45s 45ms/step - loss: 0.0990 - acc: 0.9590\n",
      "Epoch 7/10\n",
      "1000/1000 [==============================] - 45s 45ms/step - loss: 0.0938 - acc: 0.9600\n",
      "Epoch 8/10\n",
      "1000/1000 [==============================] - 44s 44ms/step - loss: 0.0916 - acc: 0.9610\n",
      "Epoch 9/10\n",
      "1000/1000 [==============================] - 45s 45ms/step - loss: 0.0900 - acc: 0.9660\n",
      "Epoch 10/10\n",
      "1000/1000 [==============================] - 44s 44ms/step - loss: 0.0840 - acc: 0.9670\n",
      "Training on Epoch  2 batch  5  Files [5] start  265 / 459\n",
      "Epoch 1/10\n",
      "1000/1000 [==============================] - 58s 58ms/step - loss: 0.1830 - acc: 0.9090\n",
      "Epoch 2/10\n",
      "1000/1000 [==============================] - 58s 58ms/step - loss: 0.1417 - acc: 0.9250\n",
      "Epoch 3/10\n",
      "1000/1000 [==============================] - 57s 57ms/step - loss: 0.1119 - acc: 0.9480\n",
      "Epoch 4/10\n",
      "1000/1000 [==============================] - 57s 57ms/step - loss: 0.0969 - acc: 0.9530\n",
      "Epoch 5/10\n",
      "1000/1000 [==============================] - 57s 57ms/step - loss: 0.0853 - acc: 0.9580\n",
      "Epoch 6/10\n",
      "1000/1000 [==============================] - 57s 57ms/step - loss: 0.0784 - acc: 0.9630\n",
      "Epoch 7/10\n",
      "1000/1000 [==============================] - 58s 58ms/step - loss: 0.0730 - acc: 0.9650\n",
      "Epoch 8/10\n",
      "1000/1000 [==============================] - 57s 57ms/step - loss: 0.0692 - acc: 0.9680\n",
      "Epoch 9/10\n",
      "1000/1000 [==============================] - 57s 57ms/step - loss: 0.0661 - acc: 0.9690\n",
      "Epoch 10/10\n",
      "1000/1000 [==============================] - 56s 56ms/step - loss: 0.0637 - acc: 0.9700\n",
      "Training on Epoch  2 batch  5  Files [5] start  270 / 459\n",
      "Epoch 1/10\n",
      "1000/1000 [==============================] - 67s 67ms/step - loss: 0.1910 - acc: 0.9120\n",
      "Epoch 2/10\n",
      "1000/1000 [==============================] - 66s 66ms/step - loss: 0.1502 - acc: 0.9280\n",
      "Epoch 3/10\n",
      "1000/1000 [==============================] - 67s 67ms/step - loss: 0.1251 - acc: 0.9360\n",
      "Epoch 4/10\n",
      "1000/1000 [==============================] - 66s 66ms/step - loss: 0.1142 - acc: 0.9450\n",
      "Epoch 5/10\n",
      "1000/1000 [==============================] - 66s 66ms/step - loss: 0.1060 - acc: 0.9510\n",
      "Epoch 6/10\n",
      "1000/1000 [==============================] - 68s 68ms/step - loss: 0.1007 - acc: 0.9590\n",
      "Epoch 7/10\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000/1000 [==============================] - 67s 67ms/step - loss: 0.0969 - acc: 0.9610\n",
      "Epoch 8/10\n",
      "1000/1000 [==============================] - 69s 69ms/step - loss: 0.0925 - acc: 0.9600\n",
      "Epoch 9/10\n",
      "1000/1000 [==============================] - 65s 65ms/step - loss: 0.0890 - acc: 0.9620\n",
      "Epoch 10/10\n",
      "1000/1000 [==============================] - 68s 68ms/step - loss: 0.0843 - acc: 0.9650\n",
      "Training on Epoch  2 batch  5  Files [5] start  275 / 459\n",
      "Epoch 1/10\n",
      "1000/1000 [==============================] - 58s 58ms/step - loss: 0.1858 - acc: 0.9400\n",
      "Epoch 2/10\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 0.1283 - acc: 0.9480\n",
      "Epoch 3/10\n",
      "1000/1000 [==============================] - 58s 58ms/step - loss: 0.1056 - acc: 0.9510\n",
      "Epoch 4/10\n",
      "1000/1000 [==============================] - 58s 58ms/step - loss: 0.0867 - acc: 0.9580\n",
      "Epoch 5/10\n",
      "1000/1000 [==============================] - 57s 57ms/step - loss: 0.0778 - acc: 0.9660\n",
      "Epoch 6/10\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 0.0683 - acc: 0.9740\n",
      "Epoch 7/10\n",
      "1000/1000 [==============================] - 57s 57ms/step - loss: 0.0641 - acc: 0.9740\n",
      "Epoch 8/10\n",
      "1000/1000 [==============================] - 57s 57ms/step - loss: 0.0603 - acc: 0.9770\n",
      "Epoch 9/10\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 0.0575 - acc: 0.9780\n",
      "Epoch 10/10\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 0.0550 - acc: 0.9770\n",
      "Training on Epoch  2 batch  5  Files [5] start  280 / 459\n",
      "Epoch 1/10\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 0.1572 - acc: 0.9240\n",
      "Epoch 2/10\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 0.1233 - acc: 0.9360\n",
      "Epoch 3/10\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 0.0988 - acc: 0.9530\n",
      "Epoch 4/10\n",
      "1000/1000 [==============================] - 58s 58ms/step - loss: 0.0882 - acc: 0.9610\n",
      "Epoch 5/10\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 0.0821 - acc: 0.9590\n",
      "Epoch 6/10\n",
      "1000/1000 [==============================] - 58s 58ms/step - loss: 0.0770 - acc: 0.9640\n",
      "Epoch 7/10\n",
      "1000/1000 [==============================] - 58s 58ms/step - loss: 0.0751 - acc: 0.9630\n",
      "Epoch 8/10\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 0.0706 - acc: 0.9620\n",
      "Epoch 9/10\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 0.0686 - acc: 0.9640\n",
      "Epoch 10/10\n",
      "1000/1000 [==============================] - 58s 58ms/step - loss: 0.0675 - acc: 0.9640\n",
      "Training on Epoch  2 batch  5  Files [5] start  285 / 459\n",
      "Epoch 1/10\n",
      "1000/1000 [==============================] - 62s 62ms/step - loss: 0.2021 - acc: 0.9010\n",
      "Epoch 2/10\n",
      "1000/1000 [==============================] - 64s 64ms/step - loss: 0.1685 - acc: 0.9010\n",
      "Epoch 3/10\n",
      "1000/1000 [==============================] - 64s 64ms/step - loss: 0.1475 - acc: 0.9210\n",
      "Epoch 4/10\n",
      "1000/1000 [==============================] - 63s 63ms/step - loss: 0.1381 - acc: 0.9290\n",
      "Epoch 5/10\n",
      "1000/1000 [==============================] - 61s 61ms/step - loss: 0.1323 - acc: 0.9320\n",
      "Epoch 6/10\n",
      "1000/1000 [==============================] - 63s 63ms/step - loss: 0.1277 - acc: 0.9360\n",
      "Epoch 7/10\n",
      "1000/1000 [==============================] - 61s 61ms/step - loss: 0.1252 - acc: 0.9350\n",
      "Epoch 8/10\n",
      "1000/1000 [==============================] - 63s 63ms/step - loss: 0.1215 - acc: 0.9410\n",
      "Epoch 9/10\n",
      "1000/1000 [==============================] - 62s 62ms/step - loss: 0.1173 - acc: 0.9420\n",
      "Epoch 10/10\n",
      "1000/1000 [==============================] - 62s 62ms/step - loss: 0.1147 - acc: 0.9430\n",
      "Training on Epoch  2 batch  5  Files [5] start  290 / 459\n",
      "Epoch 1/10\n",
      "1000/1000 [==============================] - 64s 64ms/step - loss: 0.2154 - acc: 0.9090\n",
      "Epoch 2/10\n",
      "1000/1000 [==============================] - 66s 66ms/step - loss: 0.1710 - acc: 0.9270\n",
      "Epoch 3/10\n",
      "1000/1000 [==============================] - 65s 65ms/step - loss: 0.1411 - acc: 0.9350\n",
      "Epoch 4/10\n",
      "1000/1000 [==============================] - 66s 66ms/step - loss: 0.1293 - acc: 0.9390\n",
      "Epoch 5/10\n",
      "1000/1000 [==============================] - 65s 65ms/step - loss: 0.1206 - acc: 0.9430\n",
      "Epoch 6/10\n",
      "1000/1000 [==============================] - 66s 66ms/step - loss: 0.1085 - acc: 0.9470\n",
      "Epoch 7/10\n",
      "1000/1000 [==============================] - 65s 65ms/step - loss: 0.1035 - acc: 0.9480\n",
      "Epoch 8/10\n",
      "1000/1000 [==============================] - 67s 67ms/step - loss: 0.0970 - acc: 0.9520\n",
      "Epoch 9/10\n",
      "1000/1000 [==============================] - 66s 66ms/step - loss: 0.0932 - acc: 0.9590\n",
      "Epoch 10/10\n",
      "1000/1000 [==============================] - 68s 68ms/step - loss: 0.0897 - acc: 0.9590\n",
      "Training on Epoch  2 batch  5  Files [5] start  295 / 459\n",
      "Epoch 1/10\n",
      "1000/1000 [==============================] - 62s 62ms/step - loss: 0.1142 - acc: 0.9380\n",
      "Epoch 2/10\n",
      "1000/1000 [==============================] - 61s 61ms/step - loss: 0.0859 - acc: 0.9610\n",
      "Epoch 3/10\n",
      "1000/1000 [==============================] - 61s 61ms/step - loss: 0.0772 - acc: 0.9700\n",
      "Epoch 4/10\n",
      "1000/1000 [==============================] - 61s 61ms/step - loss: 0.0713 - acc: 0.9700\n",
      "Epoch 5/10\n",
      "1000/1000 [==============================] - 61s 61ms/step - loss: 0.0677 - acc: 0.9710\n",
      "Epoch 6/10\n",
      "1000/1000 [==============================] - 61s 61ms/step - loss: 0.0650 - acc: 0.9710\n",
      "Epoch 7/10\n",
      "1000/1000 [==============================] - 62s 62ms/step - loss: 0.0624 - acc: 0.9740\n",
      "Epoch 8/10\n",
      "1000/1000 [==============================] - 62s 62ms/step - loss: 0.0606 - acc: 0.9770\n",
      "Epoch 9/10\n",
      "1000/1000 [==============================] - 62s 62ms/step - loss: 0.0586 - acc: 0.9770\n",
      "Epoch 10/10\n",
      "1000/1000 [==============================] - 60s 60ms/step - loss: 0.0572 - acc: 0.9770\n",
      "Training on Epoch  2 batch  5  Files [5] start  300 / 459\n",
      "Epoch 1/10\n",
      "1000/1000 [==============================] - 43s 43ms/step - loss: 0.1976 - acc: 0.9160\n",
      "Epoch 2/10\n",
      "1000/1000 [==============================] - 44s 44ms/step - loss: 0.1460 - acc: 0.9350\n",
      "Epoch 3/10\n",
      "1000/1000 [==============================] - 44s 44ms/step - loss: 0.1198 - acc: 0.9510\n",
      "Epoch 4/10\n",
      "1000/1000 [==============================] - 45s 45ms/step - loss: 0.1049 - acc: 0.9580\n",
      "Epoch 5/10\n",
      "1000/1000 [==============================] - 44s 44ms/step - loss: 0.0971 - acc: 0.9620\n",
      "Epoch 6/10\n",
      "1000/1000 [==============================] - 42s 42ms/step - loss: 0.0921 - acc: 0.9620\n",
      "Epoch 7/10\n",
      "1000/1000 [==============================] - 44s 44ms/step - loss: 0.0845 - acc: 0.9640\n",
      "Epoch 8/10\n",
      "1000/1000 [==============================] - 43s 43ms/step - loss: 0.0803 - acc: 0.9670\n",
      "Epoch 9/10\n",
      "1000/1000 [==============================] - 43s 43ms/step - loss: 0.0751 - acc: 0.9720\n",
      "Epoch 10/10\n",
      "1000/1000 [==============================] - 43s 43ms/step - loss: 0.0717 - acc: 0.9730\n",
      "Training on Epoch  2 batch  5  Files [5] start  305 / 459\n",
      "Epoch 1/10\n",
      "1000/1000 [==============================] - 55s 55ms/step - loss: 0.1423 - acc: 0.9400\n",
      "Epoch 2/10\n",
      "1000/1000 [==============================] - 55s 55ms/step - loss: 0.1026 - acc: 0.9540\n",
      "Epoch 3/10\n",
      "1000/1000 [==============================] - 54s 54ms/step - loss: 0.0877 - acc: 0.9660\n",
      "Epoch 4/10\n",
      "1000/1000 [==============================] - 54s 54ms/step - loss: 0.0758 - acc: 0.9710\n",
      "Epoch 5/10\n",
      "1000/1000 [==============================] - 55s 55ms/step - loss: 0.0714 - acc: 0.9710\n",
      "Epoch 6/10\n",
      "1000/1000 [==============================] - 53s 53ms/step - loss: 0.0685 - acc: 0.9670\n",
      "Epoch 7/10\n",
      "1000/1000 [==============================] - 53s 53ms/step - loss: 0.0652 - acc: 0.9690\n",
      "Epoch 8/10\n",
      "1000/1000 [==============================] - 53s 53ms/step - loss: 0.0594 - acc: 0.9710\n",
      "Epoch 9/10\n",
      "1000/1000 [==============================] - 54s 54ms/step - loss: 0.0575 - acc: 0.9780\n",
      "Epoch 10/10\n",
      "1000/1000 [==============================] - 54s 54ms/step - loss: 0.0551 - acc: 0.9740\n",
      "Training on Epoch  2 batch  5  Files [5] start  310 / 459\n",
      "Epoch 1/10\n",
      "1000/1000 [==============================] - 54s 54ms/step - loss: 0.2617 - acc: 0.9060\n",
      "Epoch 2/10\n",
      "1000/1000 [==============================] - 52s 52ms/step - loss: 0.2045 - acc: 0.9170\n",
      "Epoch 3/10\n",
      "1000/1000 [==============================] - 53s 53ms/step - loss: 0.1529 - acc: 0.9290\n",
      "Epoch 4/10\n",
      "1000/1000 [==============================] - 52s 52ms/step - loss: 0.1281 - acc: 0.9400\n",
      "Epoch 5/10\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000/1000 [==============================] - 52s 52ms/step - loss: 0.1184 - acc: 0.9460\n",
      "Epoch 6/10\n",
      "1000/1000 [==============================] - 52s 52ms/step - loss: 0.1068 - acc: 0.9450\n",
      "Epoch 7/10\n",
      "1000/1000 [==============================] - 52s 52ms/step - loss: 0.0991 - acc: 0.9510\n",
      "Epoch 8/10\n",
      "1000/1000 [==============================] - 52s 52ms/step - loss: 0.0929 - acc: 0.9560\n",
      "Epoch 9/10\n",
      "1000/1000 [==============================] - 52s 52ms/step - loss: 0.0846 - acc: 0.9610\n",
      "Epoch 10/10\n",
      "1000/1000 [==============================] - 52s 52ms/step - loss: 0.0812 - acc: 0.9670\n",
      "Training on Epoch  2 batch  5  Files [5] start  315 / 459\n",
      "Epoch 1/10\n",
      "1000/1000 [==============================] - 54s 54ms/step - loss: 0.1525 - acc: 0.9300\n",
      "Epoch 2/10\n",
      "1000/1000 [==============================] - 53s 53ms/step - loss: 0.1277 - acc: 0.9360\n",
      "Epoch 3/10\n",
      "1000/1000 [==============================] - 54s 54ms/step - loss: 0.1124 - acc: 0.9370\n",
      "Epoch 4/10\n",
      "1000/1000 [==============================] - 53s 53ms/step - loss: 0.1098 - acc: 0.9410\n",
      "Epoch 5/10\n",
      "1000/1000 [==============================] - 54s 54ms/step - loss: 0.1026 - acc: 0.9440\n",
      "Epoch 6/10\n",
      "1000/1000 [==============================] - 53s 53ms/step - loss: 0.0995 - acc: 0.9450\n",
      "Epoch 7/10\n",
      "1000/1000 [==============================] - 54s 54ms/step - loss: 0.0954 - acc: 0.9500\n",
      "Epoch 8/10\n",
      "1000/1000 [==============================] - 53s 53ms/step - loss: 0.0933 - acc: 0.9470\n",
      "Epoch 9/10\n",
      "1000/1000 [==============================] - 53s 53ms/step - loss: 0.0903 - acc: 0.9510\n",
      "Epoch 10/10\n",
      "1000/1000 [==============================] - 54s 54ms/step - loss: 0.0884 - acc: 0.9510\n",
      "Training on Epoch  2 batch  5  Files [5] start  320 / 459\n",
      "Epoch 1/10\n",
      "1000/1000 [==============================] - 45s 45ms/step - loss: 0.1512 - acc: 0.9320\n",
      "Epoch 2/10\n",
      "1000/1000 [==============================] - 45s 45ms/step - loss: 0.1197 - acc: 0.9440\n",
      "Epoch 3/10\n",
      "1000/1000 [==============================] - 46s 46ms/step - loss: 0.1020 - acc: 0.9550\n",
      "Epoch 4/10\n",
      "1000/1000 [==============================] - 46s 46ms/step - loss: 0.0858 - acc: 0.9610\n",
      "Epoch 5/10\n",
      "1000/1000 [==============================] - 45s 45ms/step - loss: 0.0786 - acc: 0.9610\n",
      "Epoch 6/10\n",
      "1000/1000 [==============================] - 45s 45ms/step - loss: 0.0718 - acc: 0.9670\n",
      "Epoch 7/10\n",
      "1000/1000 [==============================] - 45s 45ms/step - loss: 0.0658 - acc: 0.9730\n",
      "Epoch 8/10\n",
      "1000/1000 [==============================] - 46s 46ms/step - loss: 0.0612 - acc: 0.9720\n",
      "Epoch 9/10\n",
      "1000/1000 [==============================] - 46s 46ms/step - loss: 0.0581 - acc: 0.9740\n",
      "Epoch 10/10\n",
      "1000/1000 [==============================] - 45s 45ms/step - loss: 0.0561 - acc: 0.9740\n",
      "Training on Epoch  2 batch  5  Files [5] start  325 / 459\n",
      "Epoch 1/10\n",
      "1000/1000 [==============================] - 53s 53ms/step - loss: 0.1293 - acc: 0.9420\n",
      "Epoch 2/10\n",
      "1000/1000 [==============================] - 53s 53ms/step - loss: 0.1043 - acc: 0.9500\n",
      "Epoch 3/10\n",
      "1000/1000 [==============================] - 53s 53ms/step - loss: 0.0909 - acc: 0.9570\n",
      "Epoch 4/10\n",
      "1000/1000 [==============================] - 53s 53ms/step - loss: 0.0812 - acc: 0.9600\n",
      "Epoch 5/10\n",
      "1000/1000 [==============================] - 53s 53ms/step - loss: 0.0737 - acc: 0.9650\n",
      "Epoch 6/10\n",
      "1000/1000 [==============================] - 53s 53ms/step - loss: 0.0696 - acc: 0.9640\n",
      "Epoch 7/10\n",
      "1000/1000 [==============================] - 52s 52ms/step - loss: 0.0665 - acc: 0.9660\n",
      "Epoch 8/10\n",
      "1000/1000 [==============================] - 53s 53ms/step - loss: 0.0631 - acc: 0.9700\n",
      "Epoch 9/10\n",
      "1000/1000 [==============================] - 53s 53ms/step - loss: 0.0606 - acc: 0.9690\n",
      "Epoch 10/10\n",
      "1000/1000 [==============================] - 53s 53ms/step - loss: 0.0584 - acc: 0.9700\n",
      "Training on Epoch  2 batch  5  Files [5] start  330 / 459\n",
      "Epoch 1/10\n",
      "1000/1000 [==============================] - 52s 52ms/step - loss: 0.2485 - acc: 0.9050\n",
      "Epoch 2/10\n",
      "1000/1000 [==============================] - 53s 53ms/step - loss: 0.1744 - acc: 0.9210\n",
      "Epoch 3/10\n",
      "1000/1000 [==============================] - 52s 52ms/step - loss: 0.1349 - acc: 0.9380\n",
      "Epoch 4/10\n",
      "1000/1000 [==============================] - 52s 52ms/step - loss: 0.1181 - acc: 0.9450\n",
      "Epoch 5/10\n",
      "1000/1000 [==============================] - 51s 51ms/step - loss: 0.1030 - acc: 0.9560\n",
      "Epoch 6/10\n",
      "1000/1000 [==============================] - 51s 51ms/step - loss: 0.0954 - acc: 0.9630\n",
      "Epoch 7/10\n",
      "1000/1000 [==============================] - 51s 51ms/step - loss: 0.0902 - acc: 0.9630\n",
      "Epoch 8/10\n",
      "1000/1000 [==============================] - 52s 52ms/step - loss: 0.0829 - acc: 0.9670\n",
      "Epoch 9/10\n",
      "1000/1000 [==============================] - 51s 51ms/step - loss: 0.0802 - acc: 0.9630\n",
      "Epoch 10/10\n",
      "1000/1000 [==============================] - 51s 51ms/step - loss: 0.0765 - acc: 0.9640\n",
      "Training on Epoch  2 batch  5  Files [5] start  335 / 459\n",
      "Epoch 1/10\n",
      "1000/1000 [==============================] - 54s 54ms/step - loss: 0.2048 - acc: 0.9110\n",
      "Epoch 2/10\n",
      "1000/1000 [==============================] - 53s 53ms/step - loss: 0.1671 - acc: 0.9190\n",
      "Epoch 3/10\n",
      "1000/1000 [==============================] - 53s 53ms/step - loss: 0.1423 - acc: 0.9300\n",
      "Epoch 4/10\n",
      "1000/1000 [==============================] - 54s 54ms/step - loss: 0.1261 - acc: 0.9320\n",
      "Epoch 5/10\n",
      "1000/1000 [==============================] - 55s 55ms/step - loss: 0.1102 - acc: 0.9370\n",
      "Epoch 6/10\n",
      "1000/1000 [==============================] - 54s 54ms/step - loss: 0.1047 - acc: 0.9450\n",
      "Epoch 7/10\n",
      "1000/1000 [==============================] - 55s 55ms/step - loss: 0.0982 - acc: 0.9450\n",
      "Epoch 8/10\n",
      "1000/1000 [==============================] - 53s 53ms/step - loss: 0.0938 - acc: 0.9450\n",
      "Epoch 9/10\n",
      "1000/1000 [==============================] - 54s 54ms/step - loss: 0.0908 - acc: 0.9480\n",
      "Epoch 10/10\n",
      "1000/1000 [==============================] - 54s 54ms/step - loss: 0.0901 - acc: 0.9530\n",
      "Training on Epoch  2 batch  5  Files [5] start  340 / 459\n",
      "Epoch 1/10\n",
      "1000/1000 [==============================] - 62s 62ms/step - loss: 0.1161 - acc: 0.9430\n",
      "Epoch 2/10\n",
      "1000/1000 [==============================] - 61s 61ms/step - loss: 0.0982 - acc: 0.9520\n",
      "Epoch 3/10\n",
      "1000/1000 [==============================] - 61s 61ms/step - loss: 0.0891 - acc: 0.9620\n",
      "Epoch 4/10\n",
      "1000/1000 [==============================] - 61s 61ms/step - loss: 0.1240 - acc: 0.9420\n",
      "Epoch 5/10\n",
      "1000/1000 [==============================] - 62s 62ms/step - loss: 0.0940 - acc: 0.9480\n",
      "Epoch 6/10\n",
      "1000/1000 [==============================] - 62s 62ms/step - loss: 0.0836 - acc: 0.9520\n",
      "Epoch 7/10\n",
      "1000/1000 [==============================] - 62s 62ms/step - loss: 0.0809 - acc: 0.9590\n",
      "Epoch 8/10\n",
      "1000/1000 [==============================] - 61s 61ms/step - loss: 0.0718 - acc: 0.9550\n",
      "Epoch 9/10\n",
      "1000/1000 [==============================] - 61s 61ms/step - loss: 0.0713 - acc: 0.9570\n",
      "Epoch 10/10\n",
      "1000/1000 [==============================] - 61s 61ms/step - loss: 0.0695 - acc: 0.9600\n",
      "Training on Epoch  2 batch  5  Files [5] start  345 / 459\n",
      "Epoch 1/10\n",
      "1000/1000 [==============================] - 55s 55ms/step - loss: 0.2584 - acc: 0.8920\n",
      "Epoch 2/10\n",
      "1000/1000 [==============================] - 55s 55ms/step - loss: 0.1722 - acc: 0.9280\n",
      "Epoch 3/10\n",
      "1000/1000 [==============================] - 55s 55ms/step - loss: 0.1300 - acc: 0.9410\n",
      "Epoch 4/10\n",
      "1000/1000 [==============================] - 55s 55ms/step - loss: 0.0981 - acc: 0.9530\n",
      "Epoch 5/10\n",
      "1000/1000 [==============================] - 56s 56ms/step - loss: 0.0867 - acc: 0.9600\n",
      "Epoch 6/10\n",
      "1000/1000 [==============================] - 55s 55ms/step - loss: 0.0781 - acc: 0.9600\n",
      "Epoch 7/10\n",
      "1000/1000 [==============================] - 55s 55ms/step - loss: 0.0662 - acc: 0.9730\n",
      "Epoch 8/10\n",
      "1000/1000 [==============================] - 55s 55ms/step - loss: 0.0611 - acc: 0.9730\n",
      "Epoch 9/10\n",
      "1000/1000 [==============================] - 55s 55ms/step - loss: 0.0542 - acc: 0.9740\n",
      "Epoch 10/10\n",
      "1000/1000 [==============================] - 55s 55ms/step - loss: 0.0502 - acc: 0.9770\n",
      "Training on Epoch  2 batch  5  Files [5] start  350 / 459\n",
      "Epoch 1/10\n",
      "1000/1000 [==============================] - 52s 52ms/step - loss: 0.4183 - acc: 0.8670\n",
      "Epoch 2/10\n",
      "1000/1000 [==============================] - 52s 52ms/step - loss: 0.2688 - acc: 0.8940\n",
      "Epoch 3/10\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000/1000 [==============================] - 52s 52ms/step - loss: 0.2174 - acc: 0.9140\n",
      "Epoch 4/10\n",
      "1000/1000 [==============================] - 52s 52ms/step - loss: 0.1724 - acc: 0.9370\n",
      "Epoch 5/10\n",
      "1000/1000 [==============================] - 53s 53ms/step - loss: 0.1511 - acc: 0.9400\n",
      "Epoch 6/10\n",
      "1000/1000 [==============================] - 52s 52ms/step - loss: 0.1295 - acc: 0.9530\n",
      "Epoch 7/10\n",
      "1000/1000 [==============================] - 52s 52ms/step - loss: 0.1089 - acc: 0.9620\n",
      "Epoch 8/10\n",
      "1000/1000 [==============================] - 52s 52ms/step - loss: 0.0964 - acc: 0.9660\n",
      "Epoch 9/10\n",
      "1000/1000 [==============================] - 53s 53ms/step - loss: 0.0874 - acc: 0.9680\n",
      "Epoch 10/10\n",
      "1000/1000 [==============================] - 53s 53ms/step - loss: 0.0784 - acc: 0.9720\n",
      "Training on Epoch  2 batch  5  Files [5] start  355 / 459\n",
      "Epoch 1/10\n",
      "1000/1000 [==============================] - 47s 47ms/step - loss: 0.2823 - acc: 0.9010\n",
      "Epoch 2/10\n",
      "1000/1000 [==============================] - 48s 48ms/step - loss: 0.2054 - acc: 0.9210\n",
      "Epoch 3/10\n",
      "1000/1000 [==============================] - 47s 47ms/step - loss: 0.1513 - acc: 0.9410\n",
      "Epoch 4/10\n",
      "1000/1000 [==============================] - 48s 48ms/step - loss: 0.1181 - acc: 0.9530\n",
      "Epoch 5/10\n",
      "1000/1000 [==============================] - 48s 48ms/step - loss: 0.0984 - acc: 0.9600\n",
      "Epoch 6/10\n",
      "1000/1000 [==============================] - 48s 48ms/step - loss: 0.0842 - acc: 0.9730\n",
      "Epoch 7/10\n",
      "1000/1000 [==============================] - 48s 48ms/step - loss: 0.0750 - acc: 0.9770\n",
      "Epoch 8/10\n",
      "1000/1000 [==============================] - 47s 47ms/step - loss: 0.0642 - acc: 0.9800\n",
      "Epoch 9/10\n",
      "1000/1000 [==============================] - 48s 48ms/step - loss: 0.0561 - acc: 0.9820\n",
      "Epoch 10/10\n",
      "1000/1000 [==============================] - 48s 48ms/step - loss: 0.0501 - acc: 0.9820\n",
      "Training on Epoch  2 batch  5  Files [5] start  360 / 459\n",
      "Epoch 1/10\n",
      "1000/1000 [==============================] - 61s 61ms/step - loss: 0.2747 - acc: 0.9010\n",
      "Epoch 2/10\n",
      "1000/1000 [==============================] - 67s 67ms/step - loss: 0.1585 - acc: 0.9380\n",
      "Epoch 3/10\n",
      "1000/1000 [==============================] - 67s 67ms/step - loss: 0.0986 - acc: 0.9720\n",
      "Epoch 4/10\n",
      "1000/1000 [==============================] - 65s 65ms/step - loss: 0.0708 - acc: 0.9750\n",
      "Epoch 5/10\n",
      "1000/1000 [==============================] - 66s 66ms/step - loss: 0.0551 - acc: 0.9810\n",
      "Epoch 6/10\n",
      "1000/1000 [==============================] - 63s 63ms/step - loss: 0.0438 - acc: 0.9870\n",
      "Epoch 7/10\n",
      "1000/1000 [==============================] - 62s 62ms/step - loss: 0.0455 - acc: 0.9880\n",
      "Epoch 8/10\n",
      "1000/1000 [==============================] - 62s 62ms/step - loss: 0.0376 - acc: 0.9900\n",
      "Epoch 9/10\n",
      "1000/1000 [==============================] - 62s 62ms/step - loss: 0.0294 - acc: 0.9920\n",
      "Epoch 10/10\n",
      "1000/1000 [==============================] - 62s 62ms/step - loss: 0.0242 - acc: 0.9940\n",
      "Training on Epoch  2 batch  5  Files [5] start  365 / 459\n",
      "Epoch 1/10\n",
      "1000/1000 [==============================] - 56s 56ms/step - loss: 0.3739 - acc: 0.8850\n",
      "Epoch 2/10\n",
      "1000/1000 [==============================] - 58s 58ms/step - loss: 0.2153 - acc: 0.9090\n",
      "Epoch 3/10\n",
      "1000/1000 [==============================] - 55s 55ms/step - loss: 0.1548 - acc: 0.9390\n",
      "Epoch 4/10\n",
      "1000/1000 [==============================] - 56s 56ms/step - loss: 0.1272 - acc: 0.9560\n",
      "Epoch 5/10\n",
      "1000/1000 [==============================] - 57s 57ms/step - loss: 0.1035 - acc: 0.9650\n",
      "Epoch 6/10\n",
      "1000/1000 [==============================] - 56s 56ms/step - loss: 0.0885 - acc: 0.9730\n",
      "Epoch 7/10\n",
      "1000/1000 [==============================] - 56s 56ms/step - loss: 0.0773 - acc: 0.9760\n",
      "Epoch 8/10\n",
      "1000/1000 [==============================] - 56s 56ms/step - loss: 0.0653 - acc: 0.9780\n",
      "Epoch 9/10\n",
      "1000/1000 [==============================] - 57s 57ms/step - loss: 0.0610 - acc: 0.9820\n",
      "Epoch 10/10\n",
      "1000/1000 [==============================] - 56s 56ms/step - loss: 0.0567 - acc: 0.9830\n",
      "Training on Epoch  2 batch  5  Files [5] start  370 / 459\n",
      "Epoch 1/10\n",
      "1000/1000 [==============================] - 49s 49ms/step - loss: 0.2711 - acc: 0.9210\n",
      "Epoch 2/10\n",
      "1000/1000 [==============================] - 49s 49ms/step - loss: 0.1746 - acc: 0.9260\n",
      "Epoch 3/10\n",
      "1000/1000 [==============================] - 49s 49ms/step - loss: 0.1335 - acc: 0.9460\n",
      "Epoch 4/10\n",
      "1000/1000 [==============================] - 49s 49ms/step - loss: 0.1087 - acc: 0.9580\n",
      "Epoch 5/10\n",
      "1000/1000 [==============================] - 49s 49ms/step - loss: 0.0937 - acc: 0.9590\n",
      "Epoch 6/10\n",
      "1000/1000 [==============================] - 49s 49ms/step - loss: 0.0825 - acc: 0.9700\n",
      "Epoch 7/10\n",
      "1000/1000 [==============================] - 49s 49ms/step - loss: 0.0774 - acc: 0.9710\n",
      "Epoch 8/10\n",
      "1000/1000 [==============================] - 49s 49ms/step - loss: 0.0726 - acc: 0.9670\n",
      "Epoch 9/10\n",
      "1000/1000 [==============================] - 49s 49ms/step - loss: 0.0666 - acc: 0.9700\n",
      "Epoch 10/10\n",
      "1000/1000 [==============================] - 49s 49ms/step - loss: 0.0633 - acc: 0.9720\n",
      "Training on Epoch  2 batch  5  Files [5] start  375 / 459\n",
      "Epoch 1/10\n",
      "1000/1000 [==============================] - 48s 48ms/step - loss: 0.2980 - acc: 0.8980\n",
      "Epoch 2/10\n",
      "1000/1000 [==============================] - 50s 50ms/step - loss: 0.1865 - acc: 0.9280\n",
      "Epoch 3/10\n",
      "1000/1000 [==============================] - 49s 49ms/step - loss: 0.1469 - acc: 0.9420\n",
      "Epoch 4/10\n",
      "1000/1000 [==============================] - 49s 49ms/step - loss: 0.1193 - acc: 0.9520\n",
      "Epoch 5/10\n",
      "1000/1000 [==============================] - 49s 49ms/step - loss: 0.0991 - acc: 0.9660\n",
      "Epoch 6/10\n",
      "1000/1000 [==============================] - 49s 49ms/step - loss: 0.0828 - acc: 0.9740\n",
      "Epoch 7/10\n",
      "1000/1000 [==============================] - 50s 50ms/step - loss: 0.0727 - acc: 0.9740\n",
      "Epoch 8/10\n",
      "1000/1000 [==============================] - 49s 49ms/step - loss: 0.0633 - acc: 0.9760\n",
      "Epoch 9/10\n",
      "1000/1000 [==============================] - 49s 49ms/step - loss: 0.0565 - acc: 0.9800\n",
      "Epoch 10/10\n",
      "1000/1000 [==============================] - 49s 49ms/step - loss: 0.0500 - acc: 0.9810\n",
      "Training on Epoch  2 batch  5  Files [5] start  380 / 459\n",
      "Epoch 1/10\n",
      "1000/1000 [==============================] - 47s 47ms/step - loss: 0.2929 - acc: 0.9020\n",
      "Epoch 2/10\n",
      "1000/1000 [==============================] - 48s 48ms/step - loss: 0.1847 - acc: 0.9250\n",
      "Epoch 3/10\n",
      "1000/1000 [==============================] - 48s 48ms/step - loss: 0.1233 - acc: 0.9490\n",
      "Epoch 4/10\n",
      "1000/1000 [==============================] - 48s 48ms/step - loss: 0.0972 - acc: 0.9650\n",
      "Epoch 5/10\n",
      "1000/1000 [==============================] - 48s 48ms/step - loss: 0.0811 - acc: 0.9690\n",
      "Epoch 6/10\n",
      "1000/1000 [==============================] - 48s 48ms/step - loss: 0.0683 - acc: 0.9730\n",
      "Epoch 7/10\n",
      "1000/1000 [==============================] - 49s 49ms/step - loss: 0.0608 - acc: 0.9760\n",
      "Epoch 8/10\n",
      "1000/1000 [==============================] - 48s 48ms/step - loss: 0.0547 - acc: 0.9780\n",
      "Epoch 9/10\n",
      "1000/1000 [==============================] - 48s 48ms/step - loss: 0.0514 - acc: 0.9810\n",
      "Epoch 10/10\n",
      "1000/1000 [==============================] - 48s 48ms/step - loss: 0.0480 - acc: 0.9850\n",
      "Training on Epoch  2 batch  5  Files [5] start  385 / 459\n",
      "Epoch 1/10\n",
      "1000/1000 [==============================] - 56s 56ms/step - loss: 0.3092 - acc: 0.8950\n",
      "Epoch 2/10\n",
      "1000/1000 [==============================] - 58s 58ms/step - loss: 0.2010 - acc: 0.9170\n",
      "Epoch 3/10\n",
      "1000/1000 [==============================] - 57s 57ms/step - loss: 0.1374 - acc: 0.9420\n",
      "Epoch 4/10\n",
      "1000/1000 [==============================] - 58s 58ms/step - loss: 0.1062 - acc: 0.9660\n",
      "Epoch 5/10\n",
      "1000/1000 [==============================] - 56s 56ms/step - loss: 0.0834 - acc: 0.9690\n",
      "Epoch 6/10\n",
      "1000/1000 [==============================] - 58s 58ms/step - loss: 0.0696 - acc: 0.9740\n",
      "Epoch 7/10\n",
      "1000/1000 [==============================] - 57s 57ms/step - loss: 0.0608 - acc: 0.9780\n",
      "Epoch 8/10\n",
      "1000/1000 [==============================] - 57s 57ms/step - loss: 0.0543 - acc: 0.9800\n",
      "Epoch 9/10\n",
      "1000/1000 [==============================] - 57s 57ms/step - loss: 0.0496 - acc: 0.9810\n",
      "Epoch 10/10\n",
      "1000/1000 [==============================] - 57s 57ms/step - loss: 0.0455 - acc: 0.9830\n",
      "Training on Epoch  2 batch  5  Files [5] start  390 / 459\n",
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000/1000 [==============================] - 54s 54ms/step - loss: 0.3747 - acc: 0.8770\n",
      "Epoch 2/10\n",
      "1000/1000 [==============================] - 55s 55ms/step - loss: 0.2169 - acc: 0.9220\n",
      "Epoch 3/10\n",
      "1000/1000 [==============================] - 55s 55ms/step - loss: 0.1427 - acc: 0.9510\n",
      "Epoch 4/10\n",
      "1000/1000 [==============================] - 54s 54ms/step - loss: 0.1058 - acc: 0.9660\n",
      "Epoch 5/10\n",
      "1000/1000 [==============================] - 54s 54ms/step - loss: 0.0831 - acc: 0.9780\n",
      "Epoch 6/10\n",
      "1000/1000 [==============================] - 54s 54ms/step - loss: 0.0659 - acc: 0.9820\n",
      "Epoch 7/10\n",
      "1000/1000 [==============================] - 55s 55ms/step - loss: 0.0553 - acc: 0.9820\n",
      "Epoch 8/10\n",
      "1000/1000 [==============================] - 56s 56ms/step - loss: 0.0465 - acc: 0.9860\n",
      "Epoch 9/10\n",
      "1000/1000 [==============================] - 54s 54ms/step - loss: 0.0390 - acc: 0.9870\n",
      "Epoch 10/10\n",
      "1000/1000 [==============================] - 58s 58ms/step - loss: 0.0346 - acc: 0.9890\n",
      "Training on Epoch  2 batch  5  Files [5] start  395 / 459\n",
      "Epoch 1/10\n",
      "1000/1000 [==============================] - 54s 54ms/step - loss: 0.3348 - acc: 0.8850\n",
      "Epoch 2/10\n",
      "1000/1000 [==============================] - 57s 57ms/step - loss: 0.2038 - acc: 0.9210\n",
      "Epoch 3/10\n",
      "1000/1000 [==============================] - 57s 57ms/step - loss: 0.1545 - acc: 0.9380\n",
      "Epoch 4/10\n",
      "1000/1000 [==============================] - 63s 63ms/step - loss: 0.1168 - acc: 0.9500\n",
      "Epoch 5/10\n",
      "1000/1000 [==============================] - 72s 72ms/step - loss: 0.0915 - acc: 0.9620\n",
      "Epoch 6/10\n",
      "1000/1000 [==============================] - 55s 55ms/step - loss: 0.0760 - acc: 0.9670\n",
      "Epoch 7/10\n",
      "1000/1000 [==============================] - 58s 58ms/step - loss: 0.0675 - acc: 0.9770\n",
      "Epoch 8/10\n",
      "1000/1000 [==============================] - 55s 55ms/step - loss: 0.0565 - acc: 0.9780\n",
      "Epoch 9/10\n",
      "1000/1000 [==============================] - 55s 55ms/step - loss: 0.0510 - acc: 0.9820\n",
      "Epoch 10/10\n",
      "1000/1000 [==============================] - 56s 56ms/step - loss: 0.0462 - acc: 0.9850\n",
      "Training on Epoch  2 batch  5  Files [5] start  400 / 459\n",
      "Epoch 1/10\n",
      "1000/1000 [==============================] - 78s 78ms/step - loss: 0.3781 - acc: 0.8900\n",
      "Epoch 2/10\n",
      "1000/1000 [==============================] - 56s 56ms/step - loss: 0.2359 - acc: 0.9150\n",
      "Epoch 3/10\n",
      "1000/1000 [==============================] - 51s 51ms/step - loss: 0.1723 - acc: 0.9410\n",
      "Epoch 4/10\n",
      "1000/1000 [==============================] - 52s 52ms/step - loss: 0.1368 - acc: 0.9470\n",
      "Epoch 5/10\n",
      "1000/1000 [==============================] - 52s 52ms/step - loss: 0.1181 - acc: 0.9570\n",
      "Epoch 6/10\n",
      "1000/1000 [==============================] - 53s 53ms/step - loss: 0.0934 - acc: 0.9700\n",
      "Epoch 7/10\n",
      "1000/1000 [==============================] - 54s 54ms/step - loss: 0.0836 - acc: 0.9680\n",
      "Epoch 8/10\n",
      "1000/1000 [==============================] - 56s 56ms/step - loss: 0.0675 - acc: 0.9780\n",
      "Epoch 9/10\n",
      "1000/1000 [==============================] - 57s 57ms/step - loss: 0.0572 - acc: 0.9820\n",
      "Epoch 10/10\n",
      "1000/1000 [==============================] - 92s 92ms/step - loss: 0.0514 - acc: 0.9840\n",
      "Training on Epoch  2 batch  5  Files [5] start  405 / 459\n",
      "Epoch 1/10\n",
      "1000/1000 [==============================] - 83s 83ms/step - loss: 0.3014 - acc: 0.9030\n",
      "Epoch 2/10\n",
      "1000/1000 [==============================] - 100s 100ms/step - loss: 0.1893 - acc: 0.9250\n",
      "Epoch 3/10\n",
      "1000/1000 [==============================] - 78s 78ms/step - loss: 0.1349 - acc: 0.9510\n",
      "Epoch 4/10\n",
      "1000/1000 [==============================] - 126s 126ms/step - loss: 0.0983 - acc: 0.9680\n",
      "Epoch 5/10\n",
      "1000/1000 [==============================] - 108s 108ms/step - loss: 0.0711 - acc: 0.9780\n",
      "Epoch 6/10\n",
      "1000/1000 [==============================] - 99s 99ms/step - loss: 0.0550 - acc: 0.9860\n",
      "Epoch 7/10\n",
      "1000/1000 [==============================] - 97s 97ms/step - loss: 0.0446 - acc: 0.9870\n",
      "Epoch 8/10\n",
      "1000/1000 [==============================] - 91s 91ms/step - loss: 0.0374 - acc: 0.9880\n",
      "Epoch 9/10\n",
      "1000/1000 [==============================] - 91s 91ms/step - loss: 0.0320 - acc: 0.9910\n",
      "Epoch 10/10\n",
      "1000/1000 [==============================] - 94s 94ms/step - loss: 0.0272 - acc: 0.9950\n",
      "Training on Epoch  2 batch  5  Files [5] start  410 / 459\n",
      "Epoch 1/10\n",
      "1000/1000 [==============================] - 75s 75ms/step - loss: 0.3325 - acc: 0.8870\n",
      "Epoch 2/10\n",
      "1000/1000 [==============================] - 76s 76ms/step - loss: 0.1829 - acc: 0.9380\n",
      "Epoch 3/10\n",
      "1000/1000 [==============================] - 75s 75ms/step - loss: 0.1157 - acc: 0.9590\n",
      "Epoch 4/10\n",
      "1000/1000 [==============================] - 58s 58ms/step - loss: 0.0845 - acc: 0.9680\n",
      "Epoch 5/10\n",
      "1000/1000 [==============================] - 47s 47ms/step - loss: 0.0654 - acc: 0.9730\n",
      "Epoch 6/10\n",
      "1000/1000 [==============================] - 45s 45ms/step - loss: 0.0549 - acc: 0.9810\n",
      "Epoch 7/10\n",
      "1000/1000 [==============================] - 46s 46ms/step - loss: 0.0463 - acc: 0.9830\n",
      "Epoch 8/10\n",
      "1000/1000 [==============================] - 47s 47ms/step - loss: 0.0402 - acc: 0.9830\n",
      "Epoch 9/10\n",
      "1000/1000 [==============================] - 46s 46ms/step - loss: 0.0349 - acc: 0.9900\n",
      "Epoch 10/10\n",
      "1000/1000 [==============================] - 45s 45ms/step - loss: 0.0315 - acc: 0.9890\n",
      "Training on Epoch  2 batch  5  Files [5] start  415 / 459\n",
      "Epoch 1/10\n",
      "1000/1000 [==============================] - 51s 51ms/step - loss: 0.3554 - acc: 0.8870\n",
      "Epoch 2/10\n",
      "1000/1000 [==============================] - 91s 91ms/step - loss: 0.2146 - acc: 0.9220\n",
      "Epoch 3/10\n",
      "1000/1000 [==============================] - 75s 75ms/step - loss: 0.1526 - acc: 0.9450\n",
      "Epoch 4/10\n",
      "1000/1000 [==============================] - 88s 88ms/step - loss: 0.1126 - acc: 0.9620\n",
      "Epoch 5/10\n",
      "1000/1000 [==============================] - 56s 56ms/step - loss: 0.0874 - acc: 0.9670\n",
      "Epoch 6/10\n",
      "1000/1000 [==============================] - 54s 54ms/step - loss: 0.0701 - acc: 0.9740\n",
      "Epoch 7/10\n",
      "1000/1000 [==============================] - 58s 58ms/step - loss: 0.0563 - acc: 0.9830\n",
      "Epoch 8/10\n",
      "1000/1000 [==============================] - 67s 67ms/step - loss: 0.0472 - acc: 0.9880\n",
      "Epoch 9/10\n",
      "1000/1000 [==============================] - 50s 50ms/step - loss: 0.0387 - acc: 0.9910\n",
      "Epoch 10/10\n",
      "1000/1000 [==============================] - 50s 50ms/step - loss: 0.0325 - acc: 0.9920\n",
      "Training on Epoch  2 batch  5  Files [5] start  420 / 459\n",
      "Epoch 1/10\n",
      "1000/1000 [==============================] - 63s 63ms/step - loss: 0.3035 - acc: 0.8920\n",
      "Epoch 2/10\n",
      "1000/1000 [==============================] - 64s 64ms/step - loss: 0.1873 - acc: 0.9290\n",
      "Epoch 3/10\n",
      "1000/1000 [==============================] - 65s 65ms/step - loss: 0.1421 - acc: 0.9550\n",
      "Epoch 4/10\n",
      "1000/1000 [==============================] - 65s 65ms/step - loss: 0.1095 - acc: 0.9620\n",
      "Epoch 5/10\n",
      "1000/1000 [==============================] - 67s 67ms/step - loss: 0.0894 - acc: 0.9670\n",
      "Epoch 6/10\n",
      "1000/1000 [==============================] - 64s 64ms/step - loss: 0.0694 - acc: 0.9790\n",
      "Epoch 7/10\n",
      "1000/1000 [==============================] - 64s 64ms/step - loss: 0.0605 - acc: 0.9790\n",
      "Epoch 8/10\n",
      "1000/1000 [==============================] - 65s 65ms/step - loss: 0.0513 - acc: 0.9810\n",
      "Epoch 9/10\n",
      "1000/1000 [==============================] - 65s 65ms/step - loss: 0.0440 - acc: 0.9840\n",
      "Epoch 10/10\n",
      "1000/1000 [==============================] - 65s 65ms/step - loss: 0.0394 - acc: 0.9850\n",
      "Training on Epoch  2 batch  5  Files [5] start  425 / 459\n",
      "Epoch 1/10\n",
      "1000/1000 [==============================] - 50s 50ms/step - loss: 0.3376 - acc: 0.8950\n",
      "Epoch 2/10\n",
      "1000/1000 [==============================] - 50s 50ms/step - loss: 0.2271 - acc: 0.9150\n",
      "Epoch 3/10\n",
      "1000/1000 [==============================] - 50s 50ms/step - loss: 0.1534 - acc: 0.9450\n",
      "Epoch 4/10\n",
      "1000/1000 [==============================] - 49s 49ms/step - loss: 0.1186 - acc: 0.9590\n",
      "Epoch 5/10\n",
      "1000/1000 [==============================] - 50s 50ms/step - loss: 0.0956 - acc: 0.9670\n",
      "Epoch 6/10\n",
      "1000/1000 [==============================] - 49s 49ms/step - loss: 0.0746 - acc: 0.9740\n",
      "Epoch 7/10\n",
      "1000/1000 [==============================] - 48s 48ms/step - loss: 0.0596 - acc: 0.9770\n",
      "Epoch 8/10\n",
      "1000/1000 [==============================] - 49s 49ms/step - loss: 0.0498 - acc: 0.9890\n",
      "Epoch 9/10\n",
      "1000/1000 [==============================] - 62s 62ms/step - loss: 0.0415 - acc: 0.9870\n",
      "Epoch 10/10\n",
      "1000/1000 [==============================] - 96s 96ms/step - loss: 0.0355 - acc: 0.9890\n",
      "Training on Epoch  2 batch  5  Files [5] start  430 / 459\n",
      "Epoch 1/10\n",
      "1000/1000 [==============================] - 92s 92ms/step - loss: 0.3501 - acc: 0.8890\n",
      "Epoch 2/10\n",
      "1000/1000 [==============================] - 92s 92ms/step - loss: 0.2214 - acc: 0.9050\n",
      "Epoch 3/10\n",
      "1000/1000 [==============================] - 92s 92ms/step - loss: 0.1541 - acc: 0.9370\n",
      "Epoch 4/10\n",
      "1000/1000 [==============================] - 94s 94ms/step - loss: 0.1142 - acc: 0.9570\n",
      "Epoch 5/10\n",
      "1000/1000 [==============================] - 91s 91ms/step - loss: 0.0972 - acc: 0.9630\n",
      "Epoch 6/10\n",
      "1000/1000 [==============================] - 94s 94ms/step - loss: 0.0805 - acc: 0.9710\n",
      "Epoch 7/10\n",
      "1000/1000 [==============================] - 96s 96ms/step - loss: 0.0662 - acc: 0.9790\n",
      "Epoch 8/10\n",
      "1000/1000 [==============================] - 93s 93ms/step - loss: 0.0572 - acc: 0.9800\n",
      "Epoch 9/10\n",
      "1000/1000 [==============================] - 94s 94ms/step - loss: 0.0497 - acc: 0.9830\n",
      "Epoch 10/10\n",
      "1000/1000 [==============================] - 111s 111ms/step - loss: 0.0443 - acc: 0.9860\n",
      "Training on Epoch  2 batch  5  Files [5] start  435 / 459\n",
      "Epoch 1/10\n",
      "1000/1000 [==============================] - 51s 51ms/step - loss: 0.2994 - acc: 0.9120\n",
      "Epoch 2/10\n",
      "1000/1000 [==============================] - 50s 50ms/step - loss: 0.1963 - acc: 0.9360\n",
      "Epoch 3/10\n",
      "1000/1000 [==============================] - 51s 51ms/step - loss: 0.1372 - acc: 0.9510\n",
      "Epoch 4/10\n",
      "1000/1000 [==============================] - 50s 50ms/step - loss: 0.1037 - acc: 0.9650\n",
      "Epoch 5/10\n",
      "1000/1000 [==============================] - 49s 49ms/step - loss: 0.0808 - acc: 0.9750\n",
      "Epoch 6/10\n",
      "1000/1000 [==============================] - 50s 50ms/step - loss: 0.0684 - acc: 0.9780\n",
      "Epoch 7/10\n",
      "1000/1000 [==============================] - 49s 49ms/step - loss: 0.0608 - acc: 0.9830\n",
      "Epoch 8/10\n",
      "1000/1000 [==============================] - 50s 50ms/step - loss: 0.0544 - acc: 0.9820\n",
      "Epoch 9/10\n",
      "1000/1000 [==============================] - 49s 49ms/step - loss: 0.0496 - acc: 0.9840\n",
      "Epoch 10/10\n",
      "1000/1000 [==============================] - 50s 50ms/step - loss: 0.0451 - acc: 0.9850\n",
      "Training on Epoch  2 batch  5  Files [5] start  440 / 459\n",
      "Epoch 1/10\n",
      "1000/1000 [==============================] - 58s 58ms/step - loss: 0.2081 - acc: 0.9440\n",
      "Epoch 2/10\n",
      "1000/1000 [==============================] - 53s 53ms/step - loss: 0.1260 - acc: 0.9650\n",
      "Epoch 3/10\n",
      "1000/1000 [==============================] - 54s 54ms/step - loss: 0.0837 - acc: 0.9730\n",
      "Epoch 4/10\n",
      "1000/1000 [==============================] - 56s 56ms/step - loss: 0.0525 - acc: 0.9860\n",
      "Epoch 5/10\n",
      "1000/1000 [==============================] - 53s 53ms/step - loss: 0.0381 - acc: 0.9930\n",
      "Epoch 6/10\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 0.0326 - acc: 0.9940\n",
      "Epoch 7/10\n",
      "1000/1000 [==============================] - 56s 56ms/step - loss: 0.0263 - acc: 0.9960\n",
      "Epoch 8/10\n",
      "1000/1000 [==============================] - 56s 56ms/step - loss: 0.0220 - acc: 0.9970\n",
      "Epoch 9/10\n",
      "1000/1000 [==============================] - 54s 54ms/step - loss: 0.0181 - acc: 0.9970\n",
      "Epoch 10/10\n",
      "1000/1000 [==============================] - 54s 54ms/step - loss: 0.0163 - acc: 0.9970\n",
      "Training on Epoch  2 batch  5  Files [5] start  445 / 459\n",
      "Epoch 1/10\n",
      "1000/1000 [==============================] - 50s 50ms/step - loss: 0.2188 - acc: 0.9290\n",
      "Epoch 2/10\n",
      "1000/1000 [==============================] - 51s 51ms/step - loss: 0.1267 - acc: 0.9660\n",
      "Epoch 3/10\n",
      "1000/1000 [==============================] - 51s 51ms/step - loss: 0.0760 - acc: 0.9730\n",
      "Epoch 4/10\n",
      "1000/1000 [==============================] - 51s 51ms/step - loss: 0.0504 - acc: 0.9820\n",
      "Epoch 5/10\n",
      "1000/1000 [==============================] - 51s 51ms/step - loss: 0.0385 - acc: 0.9890\n",
      "Epoch 6/10\n",
      "1000/1000 [==============================] - 50s 50ms/step - loss: 0.0319 - acc: 0.9900\n",
      "Epoch 7/10\n",
      "1000/1000 [==============================] - 54s 54ms/step - loss: 0.0280 - acc: 0.9870\n",
      "Epoch 8/10\n",
      "1000/1000 [==============================] - 53s 53ms/step - loss: 0.0236 - acc: 0.9890\n",
      "Epoch 9/10\n",
      "1000/1000 [==============================] - 52s 52ms/step - loss: 0.0209 - acc: 0.9920\n",
      "Epoch 10/10\n",
      "1000/1000 [==============================] - 51s 51ms/step - loss: 0.0188 - acc: 0.9930\n",
      "Training on Epoch  2 batch  5  Files [5] start  450 / 459\n",
      "Epoch 1/10\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 0.2235 - acc: 0.9270\n",
      "Epoch 2/10\n",
      "1000/1000 [==============================] - 60s 60ms/step - loss: 0.1332 - acc: 0.9540\n",
      "Epoch 3/10\n",
      "1000/1000 [==============================] - 58s 58ms/step - loss: 0.0954 - acc: 0.9700\n",
      "Epoch 4/10\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 0.0751 - acc: 0.9710\n",
      "Epoch 5/10\n",
      "1000/1000 [==============================] - 58s 58ms/step - loss: 0.0562 - acc: 0.9810\n",
      "Epoch 6/10\n",
      "1000/1000 [==============================] - 58s 58ms/step - loss: 0.0474 - acc: 0.9820\n",
      "Epoch 7/10\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 0.0391 - acc: 0.9840\n",
      "Epoch 8/10\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 0.0344 - acc: 0.9880\n",
      "Epoch 9/10\n",
      "1000/1000 [==============================] - 58s 58ms/step - loss: 0.0307 - acc: 0.9860\n",
      "Epoch 10/10\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 0.0268 - acc: 0.9890\n",
      "Training on Epoch  2 batch  4  Files [5] start  455 / 459\n",
      "Epoch 1/10\n",
      "800/800 [==============================] - 41s 51ms/step - loss: 0.3118 - acc: 0.9250\n",
      "Epoch 2/10\n",
      "800/800 [==============================] - 40s 50ms/step - loss: 0.2152 - acc: 0.9400\n",
      "Epoch 3/10\n",
      "800/800 [==============================] - 43s 54ms/step - loss: 0.1385 - acc: 0.9625\n",
      "Epoch 4/10\n",
      "800/800 [==============================] - 43s 53ms/step - loss: 0.1087 - acc: 0.9700\n",
      "Epoch 5/10\n",
      "800/800 [==============================] - 39s 49ms/step - loss: 0.0920 - acc: 0.9738\n",
      "Epoch 6/10\n",
      "800/800 [==============================] - 39s 49ms/step - loss: 0.0793 - acc: 0.9738\n",
      "Epoch 7/10\n",
      "800/800 [==============================] - 39s 49ms/step - loss: 0.0690 - acc: 0.9800\n",
      "Epoch 8/10\n",
      "800/800 [==============================] - 40s 50ms/step - loss: 0.0621 - acc: 0.9838\n",
      "Epoch 9/10\n",
      "800/800 [==============================] - 39s 49ms/step - loss: 0.0568 - acc: 0.9838\n",
      "Epoch 10/10\n",
      "800/800 [==============================] - 40s 49ms/step - loss: 0.0534 - acc: 0.9863\n",
      "Training on Epoch  3 batch  5  Files [5] start  0 / 459\n",
      "Epoch 1/10\n",
      "1000/1000 [==============================] - 53s 53ms/step - loss: 0.2721 - acc: 0.9020\n",
      "Epoch 2/10\n",
      "1000/1000 [==============================] - 51s 51ms/step - loss: 0.1895 - acc: 0.9330\n",
      "Epoch 3/10\n",
      "1000/1000 [==============================] - 52s 52ms/step - loss: 0.1318 - acc: 0.9510\n",
      "Epoch 4/10\n",
      "1000/1000 [==============================] - 52s 52ms/step - loss: 0.0986 - acc: 0.9660\n",
      "Epoch 5/10\n",
      "1000/1000 [==============================] - 51s 51ms/step - loss: 0.0809 - acc: 0.9690\n",
      "Epoch 6/10\n",
      "1000/1000 [==============================] - 51s 51ms/step - loss: 0.0649 - acc: 0.9760\n",
      "Epoch 7/10\n",
      "1000/1000 [==============================] - 51s 51ms/step - loss: 0.0545 - acc: 0.9840\n",
      "Epoch 8/10\n",
      "1000/1000 [==============================] - 52s 52ms/step - loss: 0.0464 - acc: 0.9870\n",
      "Epoch 9/10\n",
      "1000/1000 [==============================] - 55s 55ms/step - loss: 0.0407 - acc: 0.9900\n",
      "Epoch 10/10\n",
      "1000/1000 [==============================] - 52s 52ms/step - loss: 0.0367 - acc: 0.9900\n",
      "Training on Epoch  3 batch  5  Files [5] start  5 / 459\n",
      "Epoch 1/10\n",
      "1000/1000 [==============================] - 52s 52ms/step - loss: 0.2323 - acc: 0.9170\n",
      "Epoch 2/10\n",
      "1000/1000 [==============================] - 51s 51ms/step - loss: 0.1506 - acc: 0.9490\n",
      "Epoch 3/10\n",
      "1000/1000 [==============================] - 53s 53ms/step - loss: 0.1082 - acc: 0.9690\n",
      "Epoch 4/10\n",
      "1000/1000 [==============================] - 52s 52ms/step - loss: 0.0779 - acc: 0.9800\n",
      "Epoch 5/10\n",
      "1000/1000 [==============================] - 51s 51ms/step - loss: 0.0637 - acc: 0.9810\n",
      "Epoch 6/10\n",
      "1000/1000 [==============================] - 50s 50ms/step - loss: 0.0529 - acc: 0.9890\n",
      "Epoch 7/10\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000/1000 [==============================] - 51s 51ms/step - loss: 0.0482 - acc: 0.9900\n",
      "Epoch 8/10\n",
      "1000/1000 [==============================] - 51s 51ms/step - loss: 0.0391 - acc: 0.9900\n",
      "Epoch 9/10\n",
      "1000/1000 [==============================] - 51s 51ms/step - loss: 0.0338 - acc: 0.9920\n",
      "Epoch 10/10\n",
      "1000/1000 [==============================] - 52s 52ms/step - loss: 0.0287 - acc: 0.9940\n",
      "Training on Epoch  3 batch  5  Files [5] start  10 / 459\n",
      "Epoch 1/10\n",
      "1000/1000 [==============================] - 64s 64ms/step - loss: 0.2870 - acc: 0.9020\n",
      "Epoch 2/10\n",
      "1000/1000 [==============================] - 63s 63ms/step - loss: 0.1877 - acc: 0.9370\n",
      "Epoch 3/10\n",
      "1000/1000 [==============================] - 63s 63ms/step - loss: 0.1241 - acc: 0.9530\n",
      "Epoch 4/10\n",
      "1000/1000 [==============================] - 70s 70ms/step - loss: 0.0934 - acc: 0.9730\n",
      "Epoch 5/10\n",
      "1000/1000 [==============================] - 65s 65ms/step - loss: 0.0768 - acc: 0.9790\n",
      "Epoch 6/10\n",
      "1000/1000 [==============================] - 64s 64ms/step - loss: 0.0617 - acc: 0.9830\n",
      "Epoch 7/10\n",
      "1000/1000 [==============================] - 66s 66ms/step - loss: 0.0490 - acc: 0.9870\n",
      "Epoch 8/10\n",
      "1000/1000 [==============================] - 64s 64ms/step - loss: 0.0411 - acc: 0.9900\n",
      "Epoch 9/10\n",
      "1000/1000 [==============================] - 65s 65ms/step - loss: 0.0346 - acc: 0.9930\n",
      "Epoch 10/10\n",
      "1000/1000 [==============================] - 64s 64ms/step - loss: 0.0295 - acc: 0.9920\n",
      "Training on Epoch  3 batch  5  Files [5] start  15 / 459\n",
      "Epoch 1/10\n",
      "1000/1000 [==============================] - 70s 70ms/step - loss: 0.2834 - acc: 0.9140\n",
      "Epoch 2/10\n",
      "1000/1000 [==============================] - 66s 66ms/step - loss: 0.1860 - acc: 0.9400\n",
      "Epoch 3/10\n",
      "1000/1000 [==============================] - 62s 62ms/step - loss: 0.1205 - acc: 0.9570\n",
      "Epoch 4/10\n",
      "1000/1000 [==============================] - 60s 60ms/step - loss: 0.0880 - acc: 0.9740\n",
      "Epoch 5/10\n",
      "1000/1000 [==============================] - 64s 64ms/step - loss: 0.0769 - acc: 0.9790\n",
      "Epoch 6/10\n",
      "1000/1000 [==============================] - 66s 66ms/step - loss: 0.0622 - acc: 0.9850\n",
      "Epoch 7/10\n",
      "1000/1000 [==============================] - 61s 61ms/step - loss: 0.0525 - acc: 0.9830\n",
      "Epoch 8/10\n",
      "1000/1000 [==============================] - 58s 58ms/step - loss: 0.0441 - acc: 0.9850\n",
      "Epoch 9/10\n",
      "1000/1000 [==============================] - 62s 62ms/step - loss: 0.0391 - acc: 0.9880\n",
      "Epoch 10/10\n",
      "1000/1000 [==============================] - 67s 67ms/step - loss: 0.0344 - acc: 0.9890\n",
      "Training on Epoch  3 batch  5  Files [5] start  20 / 459\n",
      "Epoch 1/10\n",
      "1000/1000 [==============================] - 49s 49ms/step - loss: 0.3182 - acc: 0.9060\n",
      "Epoch 2/10\n",
      "1000/1000 [==============================] - 48s 48ms/step - loss: 0.2071 - acc: 0.9280\n",
      "Epoch 3/10\n",
      "1000/1000 [==============================] - 47s 47ms/step - loss: 0.1411 - acc: 0.9390\n",
      "Epoch 4/10\n",
      "1000/1000 [==============================] - 47s 47ms/step - loss: 0.1069 - acc: 0.9560\n",
      "Epoch 5/10\n",
      "1000/1000 [==============================] - 47s 47ms/step - loss: 0.0825 - acc: 0.9710\n",
      "Epoch 6/10\n",
      "1000/1000 [==============================] - 47s 47ms/step - loss: 0.0645 - acc: 0.9770\n",
      "Epoch 7/10\n",
      "1000/1000 [==============================] - 47s 47ms/step - loss: 0.0526 - acc: 0.9820\n",
      "Epoch 8/10\n",
      "1000/1000 [==============================] - 48s 48ms/step - loss: 0.0452 - acc: 0.9850\n",
      "Epoch 9/10\n",
      "1000/1000 [==============================] - 46s 46ms/step - loss: 0.0387 - acc: 0.9870\n",
      "Epoch 10/10\n",
      "1000/1000 [==============================] - 47s 47ms/step - loss: 0.0351 - acc: 0.9870\n",
      "Training on Epoch  3 batch  5  Files [5] start  25 / 459\n",
      "Epoch 1/10\n",
      "1000/1000 [==============================] - 50s 50ms/step - loss: 0.3384 - acc: 0.8800\n",
      "Epoch 2/10\n",
      "1000/1000 [==============================] - 53s 53ms/step - loss: 0.2181 - acc: 0.9230\n",
      "Epoch 3/10\n",
      "1000/1000 [==============================] - 53s 53ms/step - loss: 0.1557 - acc: 0.9390\n",
      "Epoch 4/10\n",
      "1000/1000 [==============================] - 53s 53ms/step - loss: 0.1207 - acc: 0.9480\n",
      "Epoch 5/10\n",
      "1000/1000 [==============================] - 52s 52ms/step - loss: 0.1012 - acc: 0.9550\n",
      "Epoch 6/10\n",
      "1000/1000 [==============================] - 52s 52ms/step - loss: 0.0873 - acc: 0.9640\n",
      "Epoch 7/10\n",
      "1000/1000 [==============================] - 52s 52ms/step - loss: 0.0755 - acc: 0.9710\n",
      "Epoch 8/10\n",
      "1000/1000 [==============================] - 53s 53ms/step - loss: 0.0671 - acc: 0.9730\n",
      "Epoch 9/10\n",
      "1000/1000 [==============================] - 52s 52ms/step - loss: 0.0624 - acc: 0.9740\n",
      "Epoch 10/10\n",
      "1000/1000 [==============================] - 53s 53ms/step - loss: 0.0574 - acc: 0.9760\n",
      "Training on Epoch  3 batch  5  Files [5] start  30 / 459\n",
      "Epoch 1/10\n",
      "1000/1000 [==============================] - 56s 56ms/step - loss: 0.2911 - acc: 0.8960\n",
      "Epoch 2/10\n",
      "1000/1000 [==============================] - 56s 56ms/step - loss: 0.1789 - acc: 0.9370\n",
      "Epoch 3/10\n",
      "1000/1000 [==============================] - 56s 56ms/step - loss: 0.1292 - acc: 0.9560\n",
      "Epoch 4/10\n",
      "1000/1000 [==============================] - 54s 54ms/step - loss: 0.1017 - acc: 0.9620\n",
      "Epoch 5/10\n",
      "1000/1000 [==============================] - 55s 55ms/step - loss: 0.0824 - acc: 0.9730\n",
      "Epoch 6/10\n",
      "1000/1000 [==============================] - 56s 56ms/step - loss: 0.0718 - acc: 0.9730\n",
      "Epoch 7/10\n",
      "1000/1000 [==============================] - 56s 56ms/step - loss: 0.0610 - acc: 0.9750\n",
      "Epoch 8/10\n",
      "1000/1000 [==============================] - 56s 56ms/step - loss: 0.0533 - acc: 0.9800\n",
      "Epoch 9/10\n",
      "1000/1000 [==============================] - 56s 56ms/step - loss: 0.0444 - acc: 0.9870\n",
      "Epoch 10/10\n",
      "1000/1000 [==============================] - 55s 55ms/step - loss: 0.0389 - acc: 0.9890\n",
      "Training on Epoch  3 batch  5  Files [5] start  35 / 459\n",
      "Epoch 1/10\n",
      "1000/1000 [==============================] - 57s 57ms/step - loss: 0.2622 - acc: 0.9110\n",
      "Epoch 2/10\n",
      "1000/1000 [==============================] - 58s 58ms/step - loss: 0.1694 - acc: 0.9400\n",
      "Epoch 3/10\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 0.1117 - acc: 0.9540\n",
      "Epoch 4/10\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 0.0905 - acc: 0.9640\n",
      "Epoch 5/10\n",
      "1000/1000 [==============================] - 58s 58ms/step - loss: 0.0827 - acc: 0.9650\n",
      "Epoch 6/10\n",
      "1000/1000 [==============================] - 58s 58ms/step - loss: 0.0707 - acc: 0.9680\n",
      "Epoch 7/10\n",
      "1000/1000 [==============================] - 57s 57ms/step - loss: 0.0631 - acc: 0.9740\n",
      "Epoch 8/10\n",
      "1000/1000 [==============================] - 56s 56ms/step - loss: 0.0567 - acc: 0.9770\n",
      "Epoch 9/10\n",
      "1000/1000 [==============================] - 57s 57ms/step - loss: 0.0540 - acc: 0.9770\n",
      "Epoch 10/10\n",
      "1000/1000 [==============================] - 57s 57ms/step - loss: 0.0502 - acc: 0.9760\n",
      "Training on Epoch  3 batch  5  Files [5] start  40 / 459\n",
      "Epoch 1/10\n",
      "1000/1000 [==============================] - 48s 48ms/step - loss: 0.2400 - acc: 0.9210\n",
      "Epoch 2/10\n",
      "1000/1000 [==============================] - 46s 46ms/step - loss: 0.1685 - acc: 0.9370\n",
      "Epoch 3/10\n",
      "1000/1000 [==============================] - 46s 46ms/step - loss: 0.1155 - acc: 0.9590\n",
      "Epoch 4/10\n",
      "1000/1000 [==============================] - 47s 47ms/step - loss: 0.0898 - acc: 0.9690\n",
      "Epoch 5/10\n",
      "1000/1000 [==============================] - 46s 46ms/step - loss: 0.0742 - acc: 0.9710\n",
      "Epoch 6/10\n",
      "1000/1000 [==============================] - 46s 46ms/step - loss: 0.0626 - acc: 0.9770\n",
      "Epoch 7/10\n",
      "1000/1000 [==============================] - 46s 46ms/step - loss: 0.0537 - acc: 0.9820\n",
      "Epoch 8/10\n",
      "1000/1000 [==============================] - 47s 47ms/step - loss: 0.0474 - acc: 0.9800\n",
      "Epoch 9/10\n",
      "1000/1000 [==============================] - 46s 46ms/step - loss: 0.0417 - acc: 0.9870\n",
      "Epoch 10/10\n",
      "1000/1000 [==============================] - 47s 47ms/step - loss: 0.0373 - acc: 0.9910\n",
      "Training on Epoch  3 batch  5  Files [5] start  45 / 459\n",
      "Epoch 1/10\n",
      "1000/1000 [==============================] - 53s 53ms/step - loss: 0.2823 - acc: 0.9090\n",
      "Epoch 2/10\n",
      "1000/1000 [==============================] - 50s 50ms/step - loss: 0.1840 - acc: 0.9370\n",
      "Epoch 3/10\n",
      "1000/1000 [==============================] - 51s 51ms/step - loss: 0.1378 - acc: 0.9540\n",
      "Epoch 4/10\n",
      "1000/1000 [==============================] - 52s 52ms/step - loss: 0.1127 - acc: 0.9590\n",
      "Epoch 5/10\n",
      "1000/1000 [==============================] - 51s 51ms/step - loss: 0.1025 - acc: 0.9640\n",
      "Epoch 6/10\n",
      "1000/1000 [==============================] - 50s 50ms/step - loss: 0.0936 - acc: 0.9650\n",
      "Epoch 7/10\n",
      "1000/1000 [==============================] - 51s 51ms/step - loss: 0.0853 - acc: 0.9700\n",
      "Epoch 8/10\n",
      "1000/1000 [==============================] - 51s 51ms/step - loss: 0.0773 - acc: 0.9710\n",
      "Epoch 9/10\n",
      "1000/1000 [==============================] - 51s 51ms/step - loss: 0.0719 - acc: 0.9770\n",
      "Epoch 10/10\n",
      "1000/1000 [==============================] - 52s 52ms/step - loss: 0.0681 - acc: 0.9750\n",
      "Training on Epoch  3 batch  5  Files [5] start  50 / 459\n",
      "Epoch 1/10\n",
      "1000/1000 [==============================] - 57s 57ms/step - loss: 0.3131 - acc: 0.8950\n",
      "Epoch 2/10\n",
      "1000/1000 [==============================] - 58s 58ms/step - loss: 0.2135 - acc: 0.9180\n",
      "Epoch 3/10\n",
      "1000/1000 [==============================] - 57s 57ms/step - loss: 0.1574 - acc: 0.9360\n",
      "Epoch 4/10\n",
      "1000/1000 [==============================] - 56s 56ms/step - loss: 0.1213 - acc: 0.9540\n",
      "Epoch 5/10\n",
      "1000/1000 [==============================] - 57s 57ms/step - loss: 0.1007 - acc: 0.9600\n",
      "Epoch 6/10\n",
      "1000/1000 [==============================] - 58s 58ms/step - loss: 0.0819 - acc: 0.9680\n",
      "Epoch 7/10\n",
      "1000/1000 [==============================] - 57s 57ms/step - loss: 0.0715 - acc: 0.9700\n",
      "Epoch 8/10\n",
      "1000/1000 [==============================] - 57s 57ms/step - loss: 0.0644 - acc: 0.9760\n",
      "Epoch 9/10\n",
      "1000/1000 [==============================] - 57s 57ms/step - loss: 0.0578 - acc: 0.9790\n",
      "Epoch 10/10\n",
      "1000/1000 [==============================] - 58s 58ms/step - loss: 0.0506 - acc: 0.9810\n",
      "Training on Epoch  3 batch  5  Files [5] start  55 / 459\n",
      "Epoch 1/10\n",
      "1000/1000 [==============================] - 53s 53ms/step - loss: 0.3290 - acc: 0.8890\n",
      "Epoch 2/10\n",
      "1000/1000 [==============================] - 53s 53ms/step - loss: 0.2131 - acc: 0.9260\n",
      "Epoch 3/10\n",
      "1000/1000 [==============================] - 53s 53ms/step - loss: 0.1555 - acc: 0.9420\n",
      "Epoch 4/10\n",
      "1000/1000 [==============================] - 53s 53ms/step - loss: 0.1192 - acc: 0.9560\n",
      "Epoch 5/10\n",
      "1000/1000 [==============================] - 53s 53ms/step - loss: 0.0952 - acc: 0.9640\n",
      "Epoch 6/10\n",
      "1000/1000 [==============================] - 55s 55ms/step - loss: 0.0781 - acc: 0.9720\n",
      "Epoch 7/10\n",
      "1000/1000 [==============================] - 53s 53ms/step - loss: 0.0669 - acc: 0.9750\n",
      "Epoch 8/10\n",
      "1000/1000 [==============================] - 54s 54ms/step - loss: 0.0589 - acc: 0.9800\n",
      "Epoch 9/10\n",
      "1000/1000 [==============================] - 54s 54ms/step - loss: 0.0516 - acc: 0.9810\n",
      "Epoch 10/10\n",
      "1000/1000 [==============================] - 55s 55ms/step - loss: 0.0460 - acc: 0.9830\n",
      "Training on Epoch  3 batch  5  Files [5] start  60 / 459\n",
      "Epoch 1/10\n",
      "1000/1000 [==============================] - 45s 45ms/step - loss: 0.3267 - acc: 0.8880\n",
      "Epoch 2/10\n",
      "1000/1000 [==============================] - 45s 45ms/step - loss: 0.2052 - acc: 0.9200\n",
      "Epoch 3/10\n",
      "1000/1000 [==============================] - 45s 45ms/step - loss: 0.1365 - acc: 0.9440\n",
      "Epoch 4/10\n",
      "1000/1000 [==============================] - 46s 46ms/step - loss: 0.1067 - acc: 0.9600\n",
      "Epoch 5/10\n",
      "1000/1000 [==============================] - 45s 45ms/step - loss: 0.0911 - acc: 0.9690\n",
      "Epoch 6/10\n",
      "1000/1000 [==============================] - 48s 48ms/step - loss: 0.0824 - acc: 0.9750\n",
      "Epoch 7/10\n",
      "1000/1000 [==============================] - 47s 47ms/step - loss: 0.0712 - acc: 0.9760\n",
      "Epoch 8/10\n",
      "1000/1000 [==============================] - 46s 46ms/step - loss: 0.0646 - acc: 0.9800\n",
      "Epoch 9/10\n",
      "1000/1000 [==============================] - 46s 46ms/step - loss: 0.0583 - acc: 0.9810\n",
      "Epoch 10/10\n",
      "1000/1000 [==============================] - 47s 47ms/step - loss: 0.0552 - acc: 0.9820\n",
      "Training on Epoch  3 batch  5  Files [5] start  65 / 459\n",
      "Epoch 1/10\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 0.3493 - acc: 0.8940\n",
      "Epoch 2/10\n",
      "1000/1000 [==============================] - 65s 65ms/step - loss: 0.2299 - acc: 0.9220\n",
      "Epoch 3/10\n",
      "1000/1000 [==============================] - 64s 64ms/step - loss: 0.1610 - acc: 0.9420\n",
      "Epoch 4/10\n",
      "1000/1000 [==============================] - 65s 65ms/step - loss: 0.1273 - acc: 0.9530\n",
      "Epoch 5/10\n",
      "1000/1000 [==============================] - 62s 62ms/step - loss: 0.1105 - acc: 0.9590\n",
      "Epoch 6/10\n",
      "1000/1000 [==============================] - 62s 62ms/step - loss: 0.0967 - acc: 0.9610\n",
      "Epoch 7/10\n",
      "1000/1000 [==============================] - 60s 60ms/step - loss: 0.0867 - acc: 0.9680\n",
      "Epoch 8/10\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 0.0781 - acc: 0.9720\n",
      "Epoch 9/10\n",
      "1000/1000 [==============================] - 60s 60ms/step - loss: 0.0725 - acc: 0.9730\n",
      "Epoch 10/10\n",
      "1000/1000 [==============================] - 58s 58ms/step - loss: 0.0675 - acc: 0.9750\n",
      "Training on Epoch  3 batch  5  Files [5] start  70 / 459\n",
      "Epoch 1/10\n",
      "1000/1000 [==============================] - 60s 60ms/step - loss: 0.2897 - acc: 0.8880\n",
      "Epoch 2/10\n",
      "1000/1000 [==============================] - 56s 56ms/step - loss: 0.1988 - acc: 0.9230\n",
      "Epoch 3/10\n",
      "1000/1000 [==============================] - 57s 57ms/step - loss: 0.1573 - acc: 0.9500\n",
      "Epoch 4/10\n",
      "1000/1000 [==============================] - 57s 57ms/step - loss: 0.1286 - acc: 0.9560\n",
      "Epoch 5/10\n",
      "1000/1000 [==============================] - 58s 58ms/step - loss: 0.1046 - acc: 0.9650\n",
      "Epoch 6/10\n",
      "1000/1000 [==============================] - 55s 55ms/step - loss: 0.0930 - acc: 0.9700\n",
      "Epoch 7/10\n",
      "1000/1000 [==============================] - 80s 80ms/step - loss: 0.0861 - acc: 0.9720\n",
      "Epoch 8/10\n",
      "1000/1000 [==============================] - 55s 55ms/step - loss: 0.0784 - acc: 0.9730\n",
      "Epoch 9/10\n",
      "1000/1000 [==============================] - 55s 55ms/step - loss: 0.0720 - acc: 0.9740\n",
      "Epoch 10/10\n",
      "1000/1000 [==============================] - 58s 58ms/step - loss: 0.0648 - acc: 0.9760\n",
      "Training on Epoch  3 batch  5  Files [5] start  75 / 459\n",
      "Epoch 1/10\n",
      "1000/1000 [==============================] - 63s 63ms/step - loss: 0.3111 - acc: 0.8870\n",
      "Epoch 2/10\n",
      "1000/1000 [==============================] - 68s 68ms/step - loss: 0.2196 - acc: 0.9070\n",
      "Epoch 3/10\n",
      "1000/1000 [==============================] - 66s 66ms/step - loss: 0.1725 - acc: 0.9260\n",
      "Epoch 4/10\n",
      "1000/1000 [==============================] - 65s 65ms/step - loss: 0.1393 - acc: 0.9470\n",
      "Epoch 5/10\n",
      "1000/1000 [==============================] - 67s 67ms/step - loss: 0.1191 - acc: 0.9420\n",
      "Epoch 6/10\n",
      "1000/1000 [==============================] - 68s 68ms/step - loss: 0.1014 - acc: 0.9510\n",
      "Epoch 7/10\n",
      "1000/1000 [==============================] - 68s 68ms/step - loss: 0.0896 - acc: 0.9600\n",
      "Epoch 8/10\n",
      "1000/1000 [==============================] - 69s 69ms/step - loss: 0.0807 - acc: 0.9630\n",
      "Epoch 9/10\n",
      "1000/1000 [==============================] - 67s 67ms/step - loss: 0.0741 - acc: 0.9700\n",
      "Epoch 10/10\n",
      "1000/1000 [==============================] - 66s 66ms/step - loss: 0.0678 - acc: 0.9720\n",
      "Training on Epoch  3 batch  5  Files [5] start  80 / 459\n",
      "Epoch 1/10\n",
      "1000/1000 [==============================] - 58s 58ms/step - loss: 0.3513 - acc: 0.8910\n",
      "Epoch 2/10\n",
      "1000/1000 [==============================] - 58s 58ms/step - loss: 0.2443 - acc: 0.9160\n",
      "Epoch 3/10\n",
      "1000/1000 [==============================] - 60s 60ms/step - loss: 0.1635 - acc: 0.9390\n",
      "Epoch 4/10\n",
      "1000/1000 [==============================] - 60s 60ms/step - loss: 0.1328 - acc: 0.9510\n",
      "Epoch 5/10\n",
      "1000/1000 [==============================] - 65s 65ms/step - loss: 0.1018 - acc: 0.9640\n",
      "Epoch 6/10\n",
      "1000/1000 [==============================] - 70s 70ms/step - loss: 0.0884 - acc: 0.9700\n",
      "Epoch 7/10\n",
      "1000/1000 [==============================] - 65s 65ms/step - loss: 0.0806 - acc: 0.9720\n",
      "Epoch 8/10\n",
      "1000/1000 [==============================] - 64s 64ms/step - loss: 0.0732 - acc: 0.9720\n",
      "Epoch 9/10\n",
      "1000/1000 [==============================] - 64s 64ms/step - loss: 0.0659 - acc: 0.9740\n",
      "Epoch 10/10\n",
      "1000/1000 [==============================] - 64s 64ms/step - loss: 0.0576 - acc: 0.9780\n",
      "Training on Epoch  3 batch  5  Files [5] start  85 / 459\n",
      "Epoch 1/10\n",
      "1000/1000 [==============================] - 52s 52ms/step - loss: 0.3415 - acc: 0.8870\n",
      "Epoch 2/10\n",
      "1000/1000 [==============================] - 55s 55ms/step - loss: 0.2282 - acc: 0.9120\n",
      "Epoch 3/10\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000/1000 [==============================] - 56s 56ms/step - loss: 0.1656 - acc: 0.9330\n",
      "Epoch 4/10\n",
      "1000/1000 [==============================] - 52s 52ms/step - loss: 0.1279 - acc: 0.9510\n",
      "Epoch 5/10\n",
      "1000/1000 [==============================] - 69s 69ms/step - loss: 0.1047 - acc: 0.9610\n",
      "Epoch 6/10\n",
      "1000/1000 [==============================] - 67s 67ms/step - loss: 0.0899 - acc: 0.9650\n",
      "Epoch 7/10\n",
      "1000/1000 [==============================] - 70s 70ms/step - loss: 0.0783 - acc: 0.9720\n",
      "Epoch 8/10\n",
      "1000/1000 [==============================] - 70s 70ms/step - loss: 0.0713 - acc: 0.9730\n",
      "Epoch 9/10\n",
      "1000/1000 [==============================] - 70s 70ms/step - loss: 0.0653 - acc: 0.9740\n",
      "Epoch 10/10\n",
      "1000/1000 [==============================] - 69s 69ms/step - loss: 0.0603 - acc: 0.9800\n",
      "Training on Epoch  3 batch  5  Files [5] start  90 / 459\n",
      "Epoch 1/10\n",
      "1000/1000 [==============================] - 68s 68ms/step - loss: 0.3607 - acc: 0.8850\n",
      "Epoch 2/10\n",
      "1000/1000 [==============================] - 67s 67ms/step - loss: 0.2377 - acc: 0.9160\n",
      "Epoch 3/10\n",
      "1000/1000 [==============================] - 64s 64ms/step - loss: 0.1754 - acc: 0.9330\n",
      "Epoch 4/10\n",
      "1000/1000 [==============================] - 62s 62ms/step - loss: 0.1330 - acc: 0.9550\n",
      "Epoch 5/10\n",
      "1000/1000 [==============================] - 66s 66ms/step - loss: 0.1083 - acc: 0.9660\n",
      "Epoch 6/10\n",
      "1000/1000 [==============================] - 65s 65ms/step - loss: 0.0909 - acc: 0.9740\n",
      "Epoch 7/10\n",
      "1000/1000 [==============================] - 66s 66ms/step - loss: 0.0783 - acc: 0.9750\n",
      "Epoch 8/10\n",
      "1000/1000 [==============================] - 66s 66ms/step - loss: 0.0713 - acc: 0.9750\n",
      "Epoch 9/10\n",
      "1000/1000 [==============================] - 64s 64ms/step - loss: 0.0655 - acc: 0.9750\n",
      "Epoch 10/10\n",
      "1000/1000 [==============================] - 67s 67ms/step - loss: 0.0605 - acc: 0.9790\n",
      "Training on Epoch  3 batch  5  Files [5] start  95 / 459\n",
      "Epoch 1/10\n",
      "1000/1000 [==============================] - 81s 81ms/step - loss: 0.3032 - acc: 0.8790\n",
      "Epoch 2/10\n",
      "1000/1000 [==============================] - 83s 83ms/step - loss: 0.1957 - acc: 0.9190\n",
      "Epoch 3/10\n",
      "1000/1000 [==============================] - 70s 70ms/step - loss: 0.1424 - acc: 0.9430\n",
      "Epoch 4/10\n",
      "1000/1000 [==============================] - 63s 63ms/step - loss: 0.1165 - acc: 0.9550\n",
      "Epoch 5/10\n",
      "1000/1000 [==============================] - 62s 62ms/step - loss: 0.0988 - acc: 0.9640\n",
      "Epoch 6/10\n",
      "1000/1000 [==============================] - 69s 69ms/step - loss: 0.0888 - acc: 0.9650\n",
      "Epoch 7/10\n",
      "1000/1000 [==============================] - 69s 69ms/step - loss: 0.0812 - acc: 0.9660\n",
      "Epoch 8/10\n",
      "1000/1000 [==============================] - 81s 81ms/step - loss: 0.0743 - acc: 0.9710\n",
      "Epoch 9/10\n",
      "1000/1000 [==============================] - 75s 75ms/step - loss: 0.0680 - acc: 0.9750\n",
      "Epoch 10/10\n",
      "1000/1000 [==============================] - 71s 71ms/step - loss: 0.0643 - acc: 0.9740\n",
      "Training on Epoch  3 batch  5  Files [5] start  100 / 459\n",
      "Epoch 1/10\n",
      "1000/1000 [==============================] - 63s 63ms/step - loss: 0.2821 - acc: 0.9060\n",
      "Epoch 2/10\n",
      "1000/1000 [==============================] - 64s 64ms/step - loss: 0.1732 - acc: 0.9400\n",
      "Epoch 3/10\n",
      "1000/1000 [==============================] - 61s 61ms/step - loss: 0.1202 - acc: 0.9620\n",
      "Epoch 4/10\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 0.0918 - acc: 0.9690\n",
      "Epoch 5/10\n",
      "1000/1000 [==============================] - 61s 61ms/step - loss: 0.0742 - acc: 0.9760\n",
      "Epoch 6/10\n",
      "1000/1000 [==============================] - 69s 69ms/step - loss: 0.0585 - acc: 0.9820\n",
      "Epoch 7/10\n",
      "1000/1000 [==============================] - 72s 72ms/step - loss: 0.0456 - acc: 0.9860\n",
      "Epoch 8/10\n",
      "1000/1000 [==============================] - 69s 69ms/step - loss: 0.0370 - acc: 0.9880\n",
      "Epoch 9/10\n",
      "1000/1000 [==============================] - 64s 64ms/step - loss: 0.0308 - acc: 0.9940\n",
      "Epoch 10/10\n",
      "1000/1000 [==============================] - 66s 66ms/step - loss: 0.0266 - acc: 0.9920\n",
      "Training on Epoch  3 batch  5  Files [5] start  105 / 459\n",
      "Epoch 1/10\n",
      "1000/1000 [==============================] - 68s 68ms/step - loss: 0.2812 - acc: 0.9080\n",
      "Epoch 2/10\n",
      "1000/1000 [==============================] - 68s 68ms/step - loss: 0.1728 - acc: 0.9340\n",
      "Epoch 3/10\n",
      "1000/1000 [==============================] - 68s 68ms/step - loss: 0.1225 - acc: 0.9590\n",
      "Epoch 4/10\n",
      "1000/1000 [==============================] - 69s 69ms/step - loss: 0.0904 - acc: 0.9690\n",
      "Epoch 5/10\n",
      "1000/1000 [==============================] - 69s 69ms/step - loss: 0.0740 - acc: 0.9760\n",
      "Epoch 6/10\n",
      "1000/1000 [==============================] - 67s 67ms/step - loss: 0.0612 - acc: 0.9800\n",
      "Epoch 7/10\n",
      "1000/1000 [==============================] - 70s 70ms/step - loss: 0.0519 - acc: 0.9810\n",
      "Epoch 8/10\n",
      "1000/1000 [==============================] - 67s 67ms/step - loss: 0.0461 - acc: 0.9830\n",
      "Epoch 9/10\n",
      "1000/1000 [==============================] - 66s 66ms/step - loss: 0.0407 - acc: 0.9870\n",
      "Epoch 10/10\n",
      "1000/1000 [==============================] - 68s 68ms/step - loss: 0.0365 - acc: 0.9890\n",
      "Training on Epoch  3 batch  5  Files [5] start  110 / 459\n",
      "Epoch 1/10\n",
      "1000/1000 [==============================] - 68s 68ms/step - loss: 0.3747 - acc: 0.8810\n",
      "Epoch 2/10\n",
      "1000/1000 [==============================] - 71s 71ms/step - loss: 0.2356 - acc: 0.9130\n",
      "Epoch 3/10\n",
      "1000/1000 [==============================] - 72s 72ms/step - loss: 0.1693 - acc: 0.9300\n",
      "Epoch 4/10\n",
      "1000/1000 [==============================] - 75s 75ms/step - loss: 0.1292 - acc: 0.9510\n",
      "Epoch 5/10\n",
      "1000/1000 [==============================] - 74s 74ms/step - loss: 0.1040 - acc: 0.9610\n",
      "Epoch 6/10\n",
      "1000/1000 [==============================] - 70s 70ms/step - loss: 0.0904 - acc: 0.9660\n",
      "Epoch 7/10\n",
      "1000/1000 [==============================] - 72s 72ms/step - loss: 0.0803 - acc: 0.9680\n",
      "Epoch 8/10\n",
      "1000/1000 [==============================] - 72s 72ms/step - loss: 0.0713 - acc: 0.9730\n",
      "Epoch 9/10\n",
      "1000/1000 [==============================] - 71s 71ms/step - loss: 0.0648 - acc: 0.9760\n",
      "Epoch 10/10\n",
      "1000/1000 [==============================] - 76s 76ms/step - loss: 0.0593 - acc: 0.9780\n",
      "Training on Epoch  3 batch  5  Files [5] start  115 / 459\n",
      "Epoch 1/10\n",
      "1000/1000 [==============================] - 63s 63ms/step - loss: 0.3727 - acc: 0.8650\n",
      "Epoch 2/10\n",
      "1000/1000 [==============================] - 62s 62ms/step - loss: 0.2559 - acc: 0.8910\n",
      "Epoch 3/10\n",
      "1000/1000 [==============================] - 63s 63ms/step - loss: 0.2023 - acc: 0.9060\n",
      "Epoch 4/10\n",
      "1000/1000 [==============================] - 62s 62ms/step - loss: 0.1699 - acc: 0.9260\n",
      "Epoch 5/10\n",
      "1000/1000 [==============================] - 64s 64ms/step - loss: 0.1570 - acc: 0.9320\n",
      "Epoch 6/10\n",
      "1000/1000 [==============================] - 63s 63ms/step - loss: 0.1455 - acc: 0.9330\n",
      "Epoch 7/10\n",
      "1000/1000 [==============================] - 64s 64ms/step - loss: 0.1333 - acc: 0.9430\n",
      "Epoch 8/10\n",
      "1000/1000 [==============================] - 67s 67ms/step - loss: 0.1250 - acc: 0.9470\n",
      "Epoch 9/10\n",
      "1000/1000 [==============================] - 62s 62ms/step - loss: 0.1169 - acc: 0.9520\n",
      "Epoch 10/10\n",
      "1000/1000 [==============================] - 63s 63ms/step - loss: 0.1107 - acc: 0.9530\n",
      "Training on Epoch  3 batch  5  Files [5] start  120 / 459\n",
      "Epoch 1/10\n",
      "1000/1000 [==============================] - 53s 53ms/step - loss: 0.2490 - acc: 0.8720\n",
      "Epoch 2/10\n",
      "1000/1000 [==============================] - 54s 54ms/step - loss: 0.2116 - acc: 0.9000\n",
      "Epoch 3/10\n",
      "1000/1000 [==============================] - 56s 56ms/step - loss: 0.1940 - acc: 0.9120\n",
      "Epoch 4/10\n",
      "1000/1000 [==============================] - 55s 55ms/step - loss: 0.1802 - acc: 0.9160\n",
      "Epoch 5/10\n",
      "1000/1000 [==============================] - 55s 55ms/step - loss: 0.1719 - acc: 0.9200\n",
      "Epoch 6/10\n",
      "1000/1000 [==============================] - 55s 55ms/step - loss: 0.1666 - acc: 0.9220\n",
      "Epoch 7/10\n",
      "1000/1000 [==============================] - 56s 56ms/step - loss: 0.1604 - acc: 0.9230\n",
      "Epoch 8/10\n",
      "1000/1000 [==============================] - 56s 56ms/step - loss: 0.1576 - acc: 0.9280\n",
      "Epoch 9/10\n",
      "1000/1000 [==============================] - 56s 56ms/step - loss: 0.1541 - acc: 0.9260\n",
      "Epoch 10/10\n",
      "1000/1000 [==============================] - 57s 57ms/step - loss: 0.1507 - acc: 0.9250\n",
      "Training on Epoch  3 batch  5  Files [5] start  125 / 459\n",
      "Epoch 1/10\n",
      "1000/1000 [==============================] - 69s 69ms/step - loss: 0.3541 - acc: 0.8700\n",
      "Epoch 2/10\n",
      "1000/1000 [==============================] - 69s 69ms/step - loss: 0.2759 - acc: 0.8870\n",
      "Epoch 3/10\n",
      "1000/1000 [==============================] - 70s 70ms/step - loss: 0.2244 - acc: 0.9000\n",
      "Epoch 4/10\n",
      "1000/1000 [==============================] - 70s 70ms/step - loss: 0.2013 - acc: 0.9120\n",
      "Epoch 5/10\n",
      "1000/1000 [==============================] - 69s 69ms/step - loss: 0.1902 - acc: 0.9180\n",
      "Epoch 6/10\n",
      "1000/1000 [==============================] - 69s 69ms/step - loss: 0.1803 - acc: 0.9210\n",
      "Epoch 7/10\n",
      "1000/1000 [==============================] - 69s 69ms/step - loss: 0.1722 - acc: 0.9210\n",
      "Epoch 8/10\n",
      "1000/1000 [==============================] - 70s 70ms/step - loss: 0.1638 - acc: 0.9240\n",
      "Epoch 9/10\n",
      "1000/1000 [==============================] - 70s 70ms/step - loss: 0.1581 - acc: 0.9290\n",
      "Epoch 10/10\n",
      "1000/1000 [==============================] - 70s 70ms/step - loss: 0.1535 - acc: 0.9310\n",
      "Training on Epoch  3 batch  5  Files [5] start  130 / 459\n",
      "Epoch 1/10\n",
      "1000/1000 [==============================] - 72s 72ms/step - loss: 0.3656 - acc: 0.8490\n",
      "Epoch 2/10\n",
      "1000/1000 [==============================] - 72s 72ms/step - loss: 0.2932 - acc: 0.8740\n",
      "Epoch 3/10\n",
      "1000/1000 [==============================] - 72s 72ms/step - loss: 0.2458 - acc: 0.8880\n",
      "Epoch 4/10\n",
      "1000/1000 [==============================] - 72s 72ms/step - loss: 0.2252 - acc: 0.9030\n",
      "Epoch 5/10\n",
      "1000/1000 [==============================] - 72s 72ms/step - loss: 0.2148 - acc: 0.9060\n",
      "Epoch 6/10\n",
      "1000/1000 [==============================] - 73s 73ms/step - loss: 0.2016 - acc: 0.9100\n",
      "Epoch 7/10\n",
      "1000/1000 [==============================] - 72s 72ms/step - loss: 0.1931 - acc: 0.9120\n",
      "Epoch 8/10\n",
      "1000/1000 [==============================] - 73s 73ms/step - loss: 0.1856 - acc: 0.9180\n",
      "Epoch 9/10\n",
      "1000/1000 [==============================] - 74s 74ms/step - loss: 0.1778 - acc: 0.9220\n",
      "Epoch 10/10\n",
      "1000/1000 [==============================] - 74s 74ms/step - loss: 0.1732 - acc: 0.9220\n",
      "Training on Epoch  3 batch  5  Files [5] start  135 / 459\n",
      "Epoch 1/10\n",
      "1000/1000 [==============================] - 72s 72ms/step - loss: 0.3231 - acc: 0.8590\n",
      "Epoch 2/10\n",
      "1000/1000 [==============================] - 73s 73ms/step - loss: 0.2709 - acc: 0.8800\n",
      "Epoch 3/10\n",
      "1000/1000 [==============================] - 69s 69ms/step - loss: 0.2390 - acc: 0.8900\n",
      "Epoch 4/10\n",
      "1000/1000 [==============================] - 68s 68ms/step - loss: 0.2262 - acc: 0.9000\n",
      "Epoch 5/10\n",
      "1000/1000 [==============================] - 67s 67ms/step - loss: 0.2210 - acc: 0.9100\n",
      "Epoch 6/10\n",
      "1000/1000 [==============================] - 67s 67ms/step - loss: 0.2128 - acc: 0.9010\n",
      "Epoch 7/10\n",
      "1000/1000 [==============================] - 68s 68ms/step - loss: 0.2010 - acc: 0.9040\n",
      "Epoch 8/10\n",
      "1000/1000 [==============================] - 66s 66ms/step - loss: 0.1875 - acc: 0.9140\n",
      "Epoch 9/10\n",
      "1000/1000 [==============================] - 67s 67ms/step - loss: 0.1840 - acc: 0.9130\n",
      "Epoch 10/10\n",
      "1000/1000 [==============================] - 67s 67ms/step - loss: 0.1774 - acc: 0.9170\n",
      "Training on Epoch  3 batch  5  Files [5] start  140 / 459\n",
      "Epoch 1/10\n",
      "1000/1000 [==============================] - 72s 72ms/step - loss: 0.3342 - acc: 0.8770\n",
      "Epoch 2/10\n",
      "1000/1000 [==============================] - 70s 70ms/step - loss: 0.2374 - acc: 0.8970\n",
      "Epoch 3/10\n",
      "1000/1000 [==============================] - 68s 68ms/step - loss: 0.1958 - acc: 0.9110\n",
      "Epoch 4/10\n",
      "1000/1000 [==============================] - 67s 67ms/step - loss: 0.1715 - acc: 0.9210\n",
      "Epoch 5/10\n",
      "1000/1000 [==============================] - 68s 68ms/step - loss: 0.1533 - acc: 0.9240\n",
      "Epoch 6/10\n",
      "1000/1000 [==============================] - 67s 67ms/step - loss: 0.1416 - acc: 0.9260\n",
      "Epoch 7/10\n",
      "1000/1000 [==============================] - 65s 65ms/step - loss: 0.1337 - acc: 0.9290\n",
      "Epoch 8/10\n",
      "1000/1000 [==============================] - 66s 66ms/step - loss: 0.1260 - acc: 0.9340\n",
      "Epoch 9/10\n",
      "1000/1000 [==============================] - 65s 65ms/step - loss: 0.1205 - acc: 0.9360\n",
      "Epoch 10/10\n",
      "1000/1000 [==============================] - 65s 65ms/step - loss: 0.1171 - acc: 0.9380\n",
      "Training on Epoch  3 batch  5  Files [5] start  145 / 459\n",
      "Epoch 1/10\n",
      "1000/1000 [==============================] - 55s 55ms/step - loss: 0.3022 - acc: 0.8870\n",
      "Epoch 2/10\n",
      "1000/1000 [==============================] - 54s 54ms/step - loss: 0.1891 - acc: 0.9270\n",
      "Epoch 3/10\n",
      "1000/1000 [==============================] - 54s 54ms/step - loss: 0.1335 - acc: 0.9460\n",
      "Epoch 4/10\n",
      "1000/1000 [==============================] - 54s 54ms/step - loss: 0.0994 - acc: 0.9650\n",
      "Epoch 5/10\n",
      "1000/1000 [==============================] - 54s 54ms/step - loss: 0.0852 - acc: 0.9720\n",
      "Epoch 6/10\n",
      "1000/1000 [==============================] - 54s 54ms/step - loss: 0.0689 - acc: 0.9760\n",
      "Epoch 7/10\n",
      "1000/1000 [==============================] - 53s 53ms/step - loss: 0.0590 - acc: 0.9830\n",
      "Epoch 8/10\n",
      "1000/1000 [==============================] - 54s 54ms/step - loss: 0.0534 - acc: 0.9800\n",
      "Epoch 9/10\n",
      "1000/1000 [==============================] - 53s 53ms/step - loss: 0.0445 - acc: 0.9870\n",
      "Epoch 10/10\n",
      "1000/1000 [==============================] - 53s 53ms/step - loss: 0.0371 - acc: 0.9900\n",
      "Training on Epoch  3 batch  5  Files [5] start  150 / 459\n",
      "Epoch 1/10\n",
      "1000/1000 [==============================] - 63s 63ms/step - loss: 0.3124 - acc: 0.8900\n",
      "Epoch 2/10\n",
      "1000/1000 [==============================] - 62s 62ms/step - loss: 0.2319 - acc: 0.9050\n",
      "Epoch 3/10\n",
      "1000/1000 [==============================] - 63s 63ms/step - loss: 0.1617 - acc: 0.9350\n",
      "Epoch 4/10\n",
      "1000/1000 [==============================] - 63s 63ms/step - loss: 0.1366 - acc: 0.9410\n",
      "Epoch 5/10\n",
      "1000/1000 [==============================] - 63s 63ms/step - loss: 0.1134 - acc: 0.9610\n",
      "Epoch 6/10\n",
      "1000/1000 [==============================] - 63s 63ms/step - loss: 0.0979 - acc: 0.9640\n",
      "Epoch 7/10\n",
      "1000/1000 [==============================] - 62s 62ms/step - loss: 0.0893 - acc: 0.9690\n",
      "Epoch 8/10\n",
      "1000/1000 [==============================] - 62s 62ms/step - loss: 0.0875 - acc: 0.9730\n",
      "Epoch 9/10\n",
      "1000/1000 [==============================] - 63s 63ms/step - loss: 0.0791 - acc: 0.9690\n",
      "Epoch 10/10\n",
      "1000/1000 [==============================] - 62s 62ms/step - loss: 0.0720 - acc: 0.9720\n",
      "Training on Epoch  3 batch  5  Files [5] start  155 / 459\n",
      "Epoch 1/10\n",
      "1000/1000 [==============================] - 58s 58ms/step - loss: 0.1961 - acc: 0.9160\n",
      "Epoch 2/10\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 0.1449 - acc: 0.9360\n",
      "Epoch 3/10\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 0.1083 - acc: 0.9480\n",
      "Epoch 4/10\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 0.0882 - acc: 0.9700\n",
      "Epoch 5/10\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 0.0822 - acc: 0.9630\n",
      "Epoch 6/10\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 0.0743 - acc: 0.9690\n",
      "Epoch 7/10\n",
      "1000/1000 [==============================] - 58s 58ms/step - loss: 0.0688 - acc: 0.9700\n",
      "Epoch 8/10\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 0.0657 - acc: 0.9730\n",
      "Epoch 9/10\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 0.0614 - acc: 0.9750\n",
      "Epoch 10/10\n",
      "1000/1000 [==============================] - 58s 58ms/step - loss: 0.0594 - acc: 0.9750\n",
      "Training on Epoch  3 batch  5  Files [5] start  160 / 459\n",
      "Epoch 1/10\n",
      "1000/1000 [==============================] - 56s 56ms/step - loss: 0.2057 - acc: 0.9230\n",
      "Epoch 2/10\n",
      "1000/1000 [==============================] - 56s 56ms/step - loss: 0.1456 - acc: 0.9390\n",
      "Epoch 3/10\n",
      "1000/1000 [==============================] - 56s 56ms/step - loss: 0.1110 - acc: 0.9520\n",
      "Epoch 4/10\n",
      "1000/1000 [==============================] - 57s 57ms/step - loss: 0.0933 - acc: 0.9600\n",
      "Epoch 5/10\n",
      "1000/1000 [==============================] - 56s 56ms/step - loss: 0.0847 - acc: 0.9660\n",
      "Epoch 6/10\n",
      "1000/1000 [==============================] - 56s 56ms/step - loss: 0.0777 - acc: 0.9730\n",
      "Epoch 7/10\n",
      "1000/1000 [==============================] - 56s 56ms/step - loss: 0.0694 - acc: 0.9710\n",
      "Epoch 8/10\n",
      "1000/1000 [==============================] - 57s 57ms/step - loss: 0.0637 - acc: 0.9720\n",
      "Epoch 9/10\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000/1000 [==============================] - 57s 57ms/step - loss: 0.0587 - acc: 0.9760\n",
      "Epoch 10/10\n",
      "1000/1000 [==============================] - 56s 56ms/step - loss: 0.0534 - acc: 0.9780\n",
      "Training on Epoch  3 batch  5  Files [5] start  165 / 459\n",
      "Epoch 1/10\n",
      "1000/1000 [==============================] - 60s 60ms/step - loss: 0.1908 - acc: 0.9190\n",
      "Epoch 2/10\n",
      "1000/1000 [==============================] - 60s 60ms/step - loss: 0.1721 - acc: 0.9190\n",
      "Epoch 3/10\n",
      "1000/1000 [==============================] - 60s 60ms/step - loss: 0.1350 - acc: 0.9320\n",
      "Epoch 4/10\n",
      "1000/1000 [==============================] - 60s 60ms/step - loss: 0.1118 - acc: 0.9500\n",
      "Epoch 5/10\n",
      "1000/1000 [==============================] - 60s 60ms/step - loss: 0.1049 - acc: 0.9450\n",
      "Epoch 6/10\n",
      "1000/1000 [==============================] - 61s 61ms/step - loss: 0.0927 - acc: 0.9540\n",
      "Epoch 7/10\n",
      "1000/1000 [==============================] - 60s 60ms/step - loss: 0.0877 - acc: 0.9550\n",
      "Epoch 8/10\n",
      "1000/1000 [==============================] - 60s 60ms/step - loss: 0.0818 - acc: 0.9620\n",
      "Epoch 9/10\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 0.0806 - acc: 0.9540\n",
      "Epoch 10/10\n",
      "1000/1000 [==============================] - 60s 60ms/step - loss: 0.0751 - acc: 0.9650\n",
      "Training on Epoch  3 batch  5  Files [5] start  170 / 459\n",
      "Epoch 1/10\n",
      "1000/1000 [==============================] - 73s 73ms/step - loss: 0.1626 - acc: 0.9280\n",
      "Epoch 2/10\n",
      "1000/1000 [==============================] - 73s 73ms/step - loss: 0.1297 - acc: 0.9350\n",
      "Epoch 3/10\n",
      "1000/1000 [==============================] - 73s 73ms/step - loss: 0.1060 - acc: 0.9540\n",
      "Epoch 4/10\n",
      "1000/1000 [==============================] - 74s 74ms/step - loss: 0.0857 - acc: 0.9600\n",
      "Epoch 5/10\n",
      "1000/1000 [==============================] - 74s 74ms/step - loss: 0.0790 - acc: 0.9580\n",
      "Epoch 6/10\n",
      "1000/1000 [==============================] - 73s 73ms/step - loss: 0.0717 - acc: 0.9630\n",
      "Epoch 7/10\n",
      "1000/1000 [==============================] - 73s 73ms/step - loss: 0.0668 - acc: 0.9670\n",
      "Epoch 8/10\n",
      "1000/1000 [==============================] - 73s 73ms/step - loss: 0.0636 - acc: 0.9650\n",
      "Epoch 9/10\n",
      "1000/1000 [==============================] - 74s 74ms/step - loss: 0.0602 - acc: 0.9640\n",
      "Epoch 10/10\n",
      "1000/1000 [==============================] - 72s 72ms/step - loss: 0.0557 - acc: 0.9700\n",
      "Training on Epoch  3 batch  5  Files [5] start  175 / 459\n",
      "Epoch 1/10\n",
      "1000/1000 [==============================] - 62s 62ms/step - loss: 0.2065 - acc: 0.9130\n",
      "Epoch 2/10\n",
      "1000/1000 [==============================] - 62s 62ms/step - loss: 0.1394 - acc: 0.9400\n",
      "Epoch 3/10\n",
      "1000/1000 [==============================] - 61s 61ms/step - loss: 0.1168 - acc: 0.9470\n",
      "Epoch 4/10\n",
      "1000/1000 [==============================] - 61s 61ms/step - loss: 0.0997 - acc: 0.9640\n",
      "Epoch 5/10\n",
      "1000/1000 [==============================] - 61s 61ms/step - loss: 0.0869 - acc: 0.9670\n",
      "Epoch 6/10\n",
      "1000/1000 [==============================] - 61s 61ms/step - loss: 0.0736 - acc: 0.9680\n",
      "Epoch 7/10\n",
      "1000/1000 [==============================] - 61s 61ms/step - loss: 0.0693 - acc: 0.9730\n",
      "Epoch 8/10\n",
      "1000/1000 [==============================] - 61s 61ms/step - loss: 0.0666 - acc: 0.9750\n",
      "Epoch 9/10\n",
      "1000/1000 [==============================] - 62s 62ms/step - loss: 0.0630 - acc: 0.9770\n",
      "Epoch 10/10\n",
      "1000/1000 [==============================] - 61s 61ms/step - loss: 0.0603 - acc: 0.9770\n",
      "Training on Epoch  3 batch  5  Files [5] start  180 / 459\n",
      "Epoch 1/10\n",
      "1000/1000 [==============================] - 65s 65ms/step - loss: 0.1478 - acc: 0.9310\n",
      "Epoch 2/10\n",
      "1000/1000 [==============================] - 65s 65ms/step - loss: 0.1154 - acc: 0.9530\n",
      "Epoch 3/10\n",
      "1000/1000 [==============================] - 65s 65ms/step - loss: 0.1069 - acc: 0.9530\n",
      "Epoch 4/10\n",
      "1000/1000 [==============================] - 65s 65ms/step - loss: 0.0899 - acc: 0.9590\n",
      "Epoch 5/10\n",
      "1000/1000 [==============================] - 64s 64ms/step - loss: 0.0796 - acc: 0.9590\n",
      "Epoch 6/10\n",
      "1000/1000 [==============================] - 65s 65ms/step - loss: 0.0739 - acc: 0.9630\n",
      "Epoch 7/10\n",
      "1000/1000 [==============================] - 65s 65ms/step - loss: 0.0714 - acc: 0.9640\n",
      "Epoch 8/10\n",
      "1000/1000 [==============================] - 65s 65ms/step - loss: 0.0657 - acc: 0.9660\n",
      "Epoch 9/10\n",
      "1000/1000 [==============================] - 65s 65ms/step - loss: 0.0619 - acc: 0.9700\n",
      "Epoch 10/10\n",
      "1000/1000 [==============================] - 65s 65ms/step - loss: 0.0603 - acc: 0.9690\n",
      "Training on Epoch  3 batch  5  Files [5] start  185 / 459\n",
      "Epoch 1/10\n",
      "1000/1000 [==============================] - 57s 57ms/step - loss: 0.1499 - acc: 0.9300\n",
      "Epoch 2/10\n",
      "1000/1000 [==============================] - 57s 57ms/step - loss: 0.1268 - acc: 0.9300\n",
      "Epoch 3/10\n",
      "1000/1000 [==============================] - 57s 57ms/step - loss: 0.1141 - acc: 0.9320\n",
      "Epoch 4/10\n",
      "1000/1000 [==============================] - 58s 58ms/step - loss: 0.1072 - acc: 0.9470\n",
      "Epoch 5/10\n",
      "1000/1000 [==============================] - 57s 57ms/step - loss: 0.0995 - acc: 0.9480\n",
      "Epoch 6/10\n",
      "1000/1000 [==============================] - 58s 58ms/step - loss: 0.0999 - acc: 0.9440\n",
      "Epoch 7/10\n",
      "1000/1000 [==============================] - 57s 57ms/step - loss: 0.0942 - acc: 0.9490\n",
      "Epoch 8/10\n",
      "1000/1000 [==============================] - 57s 57ms/step - loss: 0.0920 - acc: 0.9550\n",
      "Epoch 9/10\n",
      "1000/1000 [==============================] - 57s 57ms/step - loss: 0.0891 - acc: 0.9550\n",
      "Epoch 10/10\n",
      "1000/1000 [==============================] - 58s 58ms/step - loss: 0.0876 - acc: 0.9550\n",
      "Training on Epoch  3 batch  5  Files [5] start  190 / 459\n",
      "Epoch 1/10\n",
      "1000/1000 [==============================] - 55s 55ms/step - loss: 0.2041 - acc: 0.9140\n",
      "Epoch 2/10\n",
      "1000/1000 [==============================] - 55s 55ms/step - loss: 0.1477 - acc: 0.9290\n",
      "Epoch 3/10\n",
      "1000/1000 [==============================] - 55s 55ms/step - loss: 0.1140 - acc: 0.9470\n",
      "Epoch 4/10\n",
      "1000/1000 [==============================] - 55s 55ms/step - loss: 0.1367 - acc: 0.9250\n",
      "Epoch 5/10\n",
      "1000/1000 [==============================] - 55s 55ms/step - loss: 0.1159 - acc: 0.9320\n",
      "Epoch 6/10\n",
      "1000/1000 [==============================] - 55s 55ms/step - loss: 0.1128 - acc: 0.9450\n",
      "Epoch 7/10\n",
      "1000/1000 [==============================] - 55s 55ms/step - loss: 0.1064 - acc: 0.9450\n",
      "Epoch 8/10\n",
      "1000/1000 [==============================] - 55s 55ms/step - loss: 0.1012 - acc: 0.9490\n",
      "Epoch 9/10\n",
      "1000/1000 [==============================] - 56s 56ms/step - loss: 0.0991 - acc: 0.9550\n",
      "Epoch 10/10\n",
      "1000/1000 [==============================] - 55s 55ms/step - loss: 0.0949 - acc: 0.9500\n",
      "Training on Epoch  3 batch  5  Files [5] start  195 / 459\n",
      "Epoch 1/10\n",
      "1000/1000 [==============================] - 67s 67ms/step - loss: 0.2052 - acc: 0.8980\n",
      "Epoch 2/10\n",
      "1000/1000 [==============================] - 67s 67ms/step - loss: 0.1787 - acc: 0.9070\n",
      "Epoch 3/10\n",
      "1000/1000 [==============================] - 68s 68ms/step - loss: 0.1575 - acc: 0.9160\n",
      "Epoch 4/10\n",
      "1000/1000 [==============================] - 67s 67ms/step - loss: 0.1453 - acc: 0.9230\n",
      "Epoch 5/10\n",
      "1000/1000 [==============================] - 67s 67ms/step - loss: 0.1363 - acc: 0.9310\n",
      "Epoch 6/10\n",
      "1000/1000 [==============================] - 66s 66ms/step - loss: 0.1335 - acc: 0.9280\n",
      "Epoch 7/10\n",
      "1000/1000 [==============================] - 67s 67ms/step - loss: 0.1282 - acc: 0.9290\n",
      "Epoch 8/10\n",
      "1000/1000 [==============================] - 72s 72ms/step - loss: 0.1255 - acc: 0.9330\n",
      "Epoch 9/10\n",
      "1000/1000 [==============================] - 72s 72ms/step - loss: 0.1214 - acc: 0.9320\n",
      "Epoch 10/10\n",
      "1000/1000 [==============================] - 71s 71ms/step - loss: 0.1209 - acc: 0.9320\n",
      "Training on Epoch  3 batch  5  Files [5] start  200 / 459\n",
      "Epoch 1/10\n",
      "1000/1000 [==============================] - 66s 66ms/step - loss: 0.2616 - acc: 0.8920\n",
      "Epoch 2/10\n",
      "1000/1000 [==============================] - 67s 67ms/step - loss: 0.1844 - acc: 0.9080\n",
      "Epoch 3/10\n",
      "1000/1000 [==============================] - 67s 67ms/step - loss: 0.1490 - acc: 0.9280\n",
      "Epoch 4/10\n",
      "1000/1000 [==============================] - 66s 66ms/step - loss: 0.1310 - acc: 0.9340\n",
      "Epoch 5/10\n",
      "1000/1000 [==============================] - 66s 66ms/step - loss: 0.1219 - acc: 0.9430\n",
      "Epoch 6/10\n",
      "1000/1000 [==============================] - 65s 65ms/step - loss: 0.1140 - acc: 0.9470\n",
      "Epoch 7/10\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000/1000 [==============================] - 65s 65ms/step - loss: 0.1094 - acc: 0.9480\n",
      "Epoch 8/10\n",
      "1000/1000 [==============================] - 64s 64ms/step - loss: 0.1036 - acc: 0.9510\n",
      "Epoch 9/10\n",
      "1000/1000 [==============================] - 65s 65ms/step - loss: 0.1005 - acc: 0.9530\n",
      "Epoch 10/10\n",
      "1000/1000 [==============================] - 62s 62ms/step - loss: 0.0966 - acc: 0.9560\n",
      "Training on Epoch  3 batch  5  Files [5] start  205 / 459\n",
      "Epoch 1/10\n",
      "1000/1000 [==============================] - 64s 64ms/step - loss: 0.1665 - acc: 0.9120\n",
      "Epoch 2/10\n",
      "1000/1000 [==============================] - 65s 65ms/step - loss: 0.1418 - acc: 0.9140\n",
      "Epoch 3/10\n",
      "1000/1000 [==============================] - 65s 65ms/step - loss: 0.1263 - acc: 0.9240\n",
      "Epoch 4/10\n",
      "1000/1000 [==============================] - 65s 65ms/step - loss: 0.1238 - acc: 0.9250\n",
      "Epoch 5/10\n",
      "1000/1000 [==============================] - 65s 65ms/step - loss: 0.1151 - acc: 0.9380\n",
      "Epoch 6/10\n",
      "1000/1000 [==============================] - 64s 64ms/step - loss: 0.1108 - acc: 0.9360\n",
      "Epoch 7/10\n",
      "1000/1000 [==============================] - 65s 65ms/step - loss: 0.1074 - acc: 0.9470\n",
      "Epoch 8/10\n",
      "1000/1000 [==============================] - 65s 65ms/step - loss: 0.1044 - acc: 0.9440\n",
      "Epoch 9/10\n",
      "1000/1000 [==============================] - 64s 64ms/step - loss: 0.1004 - acc: 0.9520\n",
      "Epoch 10/10\n",
      "1000/1000 [==============================] - 65s 65ms/step - loss: 0.0980 - acc: 0.9520\n",
      "Training on Epoch  3 batch  5  Files [5] start  210 / 459\n",
      "Epoch 1/10\n",
      "1000/1000 [==============================] - 54s 54ms/step - loss: 0.1742 - acc: 0.9200\n",
      "Epoch 2/10\n",
      "1000/1000 [==============================] - 54s 54ms/step - loss: 0.1334 - acc: 0.9330\n",
      "Epoch 3/10\n",
      "1000/1000 [==============================] - 53s 53ms/step - loss: 0.1028 - acc: 0.9540\n",
      "Epoch 4/10\n",
      "1000/1000 [==============================] - 53s 53ms/step - loss: 0.0843 - acc: 0.9650\n",
      "Epoch 5/10\n",
      "1000/1000 [==============================] - 53s 53ms/step - loss: 0.0756 - acc: 0.9730\n",
      "Epoch 6/10\n",
      "1000/1000 [==============================] - 53s 53ms/step - loss: 0.0675 - acc: 0.9730\n",
      "Epoch 7/10\n",
      "1000/1000 [==============================] - 53s 53ms/step - loss: 0.0583 - acc: 0.9770\n",
      "Epoch 8/10\n",
      "1000/1000 [==============================] - 53s 53ms/step - loss: 0.0540 - acc: 0.9780\n",
      "Epoch 9/10\n",
      "1000/1000 [==============================] - 53s 53ms/step - loss: 0.0481 - acc: 0.9820\n",
      "Epoch 10/10\n",
      "1000/1000 [==============================] - 53s 53ms/step - loss: 0.0447 - acc: 0.9830\n",
      "Training on Epoch  3 batch  5  Files [5] start  215 / 459\n",
      "Epoch 1/10\n",
      "1000/1000 [==============================] - 70s 70ms/step - loss: 0.2337 - acc: 0.8980\n",
      "Epoch 2/10\n",
      "1000/1000 [==============================] - 71s 71ms/step - loss: 0.1874 - acc: 0.9120\n",
      "Epoch 3/10\n",
      "1000/1000 [==============================] - 71s 71ms/step - loss: 0.1585 - acc: 0.9240\n",
      "Epoch 4/10\n",
      "1000/1000 [==============================] - 70s 70ms/step - loss: 0.1451 - acc: 0.9340\n",
      "Epoch 5/10\n",
      "1000/1000 [==============================] - 70s 70ms/step - loss: 0.1379 - acc: 0.9340\n",
      "Epoch 6/10\n",
      "1000/1000 [==============================] - 70s 70ms/step - loss: 0.1301 - acc: 0.9380\n",
      "Epoch 7/10\n",
      "1000/1000 [==============================] - 70s 70ms/step - loss: 0.1270 - acc: 0.9390\n",
      "Epoch 8/10\n",
      "1000/1000 [==============================] - 70s 70ms/step - loss: 0.1219 - acc: 0.9380\n",
      "Epoch 9/10\n",
      "1000/1000 [==============================] - 70s 70ms/step - loss: 0.1188 - acc: 0.9430\n",
      "Epoch 10/10\n",
      "1000/1000 [==============================] - 70s 70ms/step - loss: 0.1173 - acc: 0.9440\n",
      "Training on Epoch  3 batch  5  Files [5] start  220 / 459\n",
      "Epoch 1/10\n",
      "1000/1000 [==============================] - 56s 56ms/step - loss: 0.2753 - acc: 0.8980\n",
      "Epoch 2/10\n",
      "1000/1000 [==============================] - 56s 56ms/step - loss: 0.1791 - acc: 0.9140\n",
      "Epoch 3/10\n",
      "1000/1000 [==============================] - 55s 55ms/step - loss: 0.1327 - acc: 0.9380\n",
      "Epoch 4/10\n",
      "1000/1000 [==============================] - 56s 56ms/step - loss: 0.1230 - acc: 0.9360\n",
      "Epoch 5/10\n",
      "1000/1000 [==============================] - 56s 56ms/step - loss: 0.1037 - acc: 0.9560\n",
      "Epoch 6/10\n",
      "1000/1000 [==============================] - 56s 56ms/step - loss: 0.0944 - acc: 0.9630\n",
      "Epoch 7/10\n",
      "1000/1000 [==============================] - 55s 55ms/step - loss: 0.0849 - acc: 0.9630\n",
      "Epoch 8/10\n",
      "1000/1000 [==============================] - 56s 56ms/step - loss: 0.0806 - acc: 0.9640\n",
      "Epoch 9/10\n",
      "1000/1000 [==============================] - 56s 56ms/step - loss: 0.0752 - acc: 0.9680\n",
      "Epoch 10/10\n",
      "1000/1000 [==============================] - 56s 56ms/step - loss: 0.0718 - acc: 0.9700\n",
      "Training on Epoch  3 batch  5  Files [5] start  225 / 459\n",
      "Epoch 1/10\n",
      "1000/1000 [==============================] - 71s 71ms/step - loss: 0.1481 - acc: 0.9310\n",
      "Epoch 2/10\n",
      "1000/1000 [==============================] - 67s 67ms/step - loss: 0.1048 - acc: 0.9510\n",
      "Epoch 3/10\n",
      "1000/1000 [==============================] - 68s 68ms/step - loss: 0.0843 - acc: 0.9600\n",
      "Epoch 4/10\n",
      "1000/1000 [==============================] - 67s 67ms/step - loss: 0.0723 - acc: 0.9700\n",
      "Epoch 5/10\n",
      "1000/1000 [==============================] - 66s 66ms/step - loss: 0.0641 - acc: 0.9730\n",
      "Epoch 6/10\n",
      "1000/1000 [==============================] - 66s 66ms/step - loss: 0.0601 - acc: 0.9720\n",
      "Epoch 7/10\n",
      "1000/1000 [==============================] - 66s 66ms/step - loss: 0.0566 - acc: 0.9760\n",
      "Epoch 8/10\n",
      "1000/1000 [==============================] - 66s 66ms/step - loss: 0.0528 - acc: 0.9770\n",
      "Epoch 9/10\n",
      "1000/1000 [==============================] - 66s 66ms/step - loss: 0.0508 - acc: 0.9770\n",
      "Epoch 10/10\n",
      "1000/1000 [==============================] - 66s 66ms/step - loss: 0.0480 - acc: 0.9790\n",
      "Training on Epoch  3 batch  5  Files [5] start  230 / 459\n",
      "Epoch 1/10\n",
      "1000/1000 [==============================] - 58s 58ms/step - loss: 0.1371 - acc: 0.9300\n",
      "Epoch 2/10\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 0.1207 - acc: 0.9420\n",
      "Epoch 3/10\n",
      "1000/1000 [==============================] - 58s 58ms/step - loss: 0.1050 - acc: 0.9440\n",
      "Epoch 4/10\n",
      "1000/1000 [==============================] - 58s 58ms/step - loss: 0.0981 - acc: 0.9470\n",
      "Epoch 5/10\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 0.0947 - acc: 0.9520\n",
      "Epoch 6/10\n",
      "1000/1000 [==============================] - 58s 58ms/step - loss: 0.0884 - acc: 0.9550\n",
      "Epoch 7/10\n",
      "1000/1000 [==============================] - 58s 58ms/step - loss: 0.0881 - acc: 0.9520\n",
      "Epoch 8/10\n",
      "1000/1000 [==============================] - 58s 58ms/step - loss: 0.0852 - acc: 0.9570\n",
      "Epoch 9/10\n",
      "1000/1000 [==============================] - 58s 58ms/step - loss: 0.0846 - acc: 0.9560\n",
      "Epoch 10/10\n",
      "1000/1000 [==============================] - 58s 58ms/step - loss: 0.0815 - acc: 0.9550\n",
      "Training on Epoch  3 batch  5  Files [5] start  235 / 459\n",
      "Epoch 1/10\n",
      "1000/1000 [==============================] - 58s 58ms/step - loss: 0.1595 - acc: 0.9320\n",
      "Epoch 2/10\n",
      "1000/1000 [==============================] - 58s 58ms/step - loss: 0.1093 - acc: 0.9480\n",
      "Epoch 3/10\n",
      "1000/1000 [==============================] - 66s 66ms/step - loss: 0.0954 - acc: 0.9460\n",
      "Epoch 4/10\n",
      "1000/1000 [==============================] - 62s 62ms/step - loss: 0.0846 - acc: 0.9510\n",
      "Epoch 5/10\n",
      "1000/1000 [==============================] - 60s 60ms/step - loss: 0.0771 - acc: 0.9640\n",
      "Epoch 6/10\n",
      "1000/1000 [==============================] - 60s 60ms/step - loss: 0.0715 - acc: 0.9650\n",
      "Epoch 7/10\n",
      "1000/1000 [==============================] - 61s 61ms/step - loss: 0.0682 - acc: 0.9640\n",
      "Epoch 8/10\n",
      "1000/1000 [==============================] - 61s 61ms/step - loss: 0.0648 - acc: 0.9650\n",
      "Epoch 9/10\n",
      "1000/1000 [==============================] - 61s 61ms/step - loss: 0.0635 - acc: 0.9660\n",
      "Epoch 10/10\n",
      "1000/1000 [==============================] - 61s 61ms/step - loss: 0.0603 - acc: 0.9680\n",
      "Training on Epoch  3 batch  5  Files [5] start  240 / 459\n",
      "Epoch 1/10\n",
      "1000/1000 [==============================] - 57s 57ms/step - loss: 0.1194 - acc: 0.9430\n",
      "Epoch 2/10\n",
      "1000/1000 [==============================] - 58s 58ms/step - loss: 0.0873 - acc: 0.9590\n",
      "Epoch 3/10\n",
      "1000/1000 [==============================] - 57s 57ms/step - loss: 0.0718 - acc: 0.9670\n",
      "Epoch 4/10\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 0.0604 - acc: 0.9730\n",
      "Epoch 5/10\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000/1000 [==============================] - 58s 58ms/step - loss: 0.0575 - acc: 0.9740\n",
      "Epoch 6/10\n",
      "1000/1000 [==============================] - 63s 63ms/step - loss: 0.0518 - acc: 0.9750\n",
      "Epoch 7/10\n",
      "1000/1000 [==============================] - 63s 63ms/step - loss: 0.0480 - acc: 0.9760\n",
      "Epoch 8/10\n",
      "1000/1000 [==============================] - 58s 58ms/step - loss: 0.0465 - acc: 0.9780\n",
      "Epoch 9/10\n",
      "1000/1000 [==============================] - 57s 57ms/step - loss: 0.0450 - acc: 0.9790\n",
      "Epoch 10/10\n",
      "1000/1000 [==============================] - 62s 62ms/step - loss: 0.0429 - acc: 0.9790\n",
      "Training on Epoch  3 batch  5  Files [5] start  245 / 459\n",
      "Epoch 1/10\n",
      "1000/1000 [==============================] - 69s 69ms/step - loss: 0.1507 - acc: 0.9310\n",
      "Epoch 2/10\n",
      "1000/1000 [==============================] - 71s 71ms/step - loss: 0.1172 - acc: 0.9420\n",
      "Epoch 3/10\n",
      "1000/1000 [==============================] - 70s 70ms/step - loss: 0.0879 - acc: 0.9450\n",
      "Epoch 4/10\n",
      "1000/1000 [==============================] - 62s 62ms/step - loss: 0.0849 - acc: 0.9490\n",
      "Epoch 5/10\n",
      "1000/1000 [==============================] - 61s 61ms/step - loss: 0.0778 - acc: 0.9580\n",
      "Epoch 6/10\n",
      "1000/1000 [==============================] - 61s 61ms/step - loss: 0.0740 - acc: 0.9630\n",
      "Epoch 7/10\n",
      "1000/1000 [==============================] - 62s 62ms/step - loss: 0.0726 - acc: 0.9600\n",
      "Epoch 8/10\n",
      "1000/1000 [==============================] - 63s 63ms/step - loss: 0.0691 - acc: 0.9630\n",
      "Epoch 9/10\n",
      "1000/1000 [==============================] - 62s 62ms/step - loss: 0.0677 - acc: 0.9650\n",
      "Epoch 10/10\n",
      "1000/1000 [==============================] - 61s 61ms/step - loss: 0.0659 - acc: 0.9670\n",
      "Training on Epoch  3 batch  5  Files [5] start  250 / 459\n",
      "Epoch 1/10\n",
      "1000/1000 [==============================] - 66s 66ms/step - loss: 0.1899 - acc: 0.9070\n",
      "Epoch 2/10\n",
      "1000/1000 [==============================] - 66s 66ms/step - loss: 0.1372 - acc: 0.9300\n",
      "Epoch 3/10\n",
      "1000/1000 [==============================] - 66s 66ms/step - loss: 0.1202 - acc: 0.9350\n",
      "Epoch 4/10\n",
      "1000/1000 [==============================] - 66s 66ms/step - loss: 0.1115 - acc: 0.9440\n",
      "Epoch 5/10\n",
      "1000/1000 [==============================] - 66s 66ms/step - loss: 0.1032 - acc: 0.9450\n",
      "Epoch 6/10\n",
      "1000/1000 [==============================] - 66s 66ms/step - loss: 0.0987 - acc: 0.9480\n",
      "Epoch 7/10\n",
      "1000/1000 [==============================] - 66s 66ms/step - loss: 0.0967 - acc: 0.9470\n",
      "Epoch 8/10\n",
      "1000/1000 [==============================] - 65s 65ms/step - loss: 0.0936 - acc: 0.9530\n",
      "Epoch 9/10\n",
      "1000/1000 [==============================] - 65s 65ms/step - loss: 0.0916 - acc: 0.9580\n",
      "Epoch 10/10\n",
      "1000/1000 [==============================] - 64s 64ms/step - loss: 0.0907 - acc: 0.9550\n",
      "Training on Epoch  3 batch  5  Files [5] start  255 / 459\n",
      "Epoch 1/10\n",
      "1000/1000 [==============================] - 62s 62ms/step - loss: 0.1295 - acc: 0.9450\n",
      "Epoch 2/10\n",
      "1000/1000 [==============================] - 66s 66ms/step - loss: 0.1080 - acc: 0.9480\n",
      "Epoch 3/10\n",
      "1000/1000 [==============================] - 65s 65ms/step - loss: 0.0884 - acc: 0.9560\n",
      "Epoch 4/10\n",
      "1000/1000 [==============================] - 66s 66ms/step - loss: 0.0830 - acc: 0.9590\n",
      "Epoch 5/10\n",
      "1000/1000 [==============================] - 63s 63ms/step - loss: 0.0787 - acc: 0.9590\n",
      "Epoch 6/10\n",
      "1000/1000 [==============================] - 64s 64ms/step - loss: 0.0765 - acc: 0.9580\n",
      "Epoch 7/10\n",
      "1000/1000 [==============================] - 63s 63ms/step - loss: 0.0733 - acc: 0.9620\n",
      "Epoch 8/10\n",
      "1000/1000 [==============================] - 63s 63ms/step - loss: 0.0724 - acc: 0.9600\n",
      "Epoch 9/10\n",
      "1000/1000 [==============================] - 63s 63ms/step - loss: 0.0712 - acc: 0.9610\n",
      "Epoch 10/10\n",
      "1000/1000 [==============================] - 64s 64ms/step - loss: 0.0698 - acc: 0.9650\n",
      "Training on Epoch  3 batch  5  Files [5] start  260 / 459\n",
      "Epoch 1/10\n",
      "1000/1000 [==============================] - 68s 68ms/step - loss: 0.2180 - acc: 0.9160\n",
      "Epoch 2/10\n",
      "1000/1000 [==============================] - 67s 67ms/step - loss: 0.1580 - acc: 0.9320\n",
      "Epoch 3/10\n",
      "1000/1000 [==============================] - 67s 67ms/step - loss: 0.1245 - acc: 0.9440\n",
      "Epoch 4/10\n",
      "1000/1000 [==============================] - 67s 67ms/step - loss: 0.1028 - acc: 0.9530\n",
      "Epoch 5/10\n",
      "1000/1000 [==============================] - 67s 67ms/step - loss: 0.0943 - acc: 0.9590\n",
      "Epoch 6/10\n",
      "1000/1000 [==============================] - 67s 67ms/step - loss: 0.0890 - acc: 0.9590\n",
      "Epoch 7/10\n",
      "1000/1000 [==============================] - 67s 67ms/step - loss: 0.0844 - acc: 0.9620\n",
      "Epoch 8/10\n",
      "1000/1000 [==============================] - 67s 67ms/step - loss: 0.0814 - acc: 0.9670\n",
      "Epoch 9/10\n",
      "1000/1000 [==============================] - 67s 67ms/step - loss: 0.0782 - acc: 0.9620\n",
      "Epoch 10/10\n",
      "1000/1000 [==============================] - 68s 68ms/step - loss: 0.0757 - acc: 0.9650\n",
      "Training on Epoch  3 batch  5  Files [5] start  265 / 459\n",
      "Epoch 1/10\n",
      "1000/1000 [==============================] - 64s 64ms/step - loss: 0.1831 - acc: 0.9220\n",
      "Epoch 2/10\n",
      "1000/1000 [==============================] - 64s 64ms/step - loss: 0.1324 - acc: 0.9340\n",
      "Epoch 3/10\n",
      "1000/1000 [==============================] - 63s 63ms/step - loss: 0.1058 - acc: 0.9490\n",
      "Epoch 4/10\n",
      "1000/1000 [==============================] - 63s 63ms/step - loss: 0.0931 - acc: 0.9520\n",
      "Epoch 5/10\n",
      "1000/1000 [==============================] - 63s 63ms/step - loss: 0.0839 - acc: 0.9620\n",
      "Epoch 6/10\n",
      "1000/1000 [==============================] - 63s 63ms/step - loss: 0.0762 - acc: 0.9690\n",
      "Epoch 7/10\n",
      "1000/1000 [==============================] - 63s 63ms/step - loss: 0.0722 - acc: 0.9660\n",
      "Epoch 8/10\n",
      "1000/1000 [==============================] - 63s 63ms/step - loss: 0.0682 - acc: 0.9680\n",
      "Epoch 9/10\n",
      "1000/1000 [==============================] - 64s 64ms/step - loss: 0.0653 - acc: 0.9710\n",
      "Epoch 10/10\n",
      "1000/1000 [==============================] - 63s 63ms/step - loss: 0.0629 - acc: 0.9720\n",
      "Training on Epoch  3 batch  5  Files [5] start  270 / 459\n",
      "Epoch 1/10\n",
      "1000/1000 [==============================] - 68s 68ms/step - loss: 0.1672 - acc: 0.9270\n",
      "Epoch 2/10\n",
      "1000/1000 [==============================] - 68s 68ms/step - loss: 0.1386 - acc: 0.9380\n",
      "Epoch 3/10\n",
      "1000/1000 [==============================] - 68s 68ms/step - loss: 0.1126 - acc: 0.9420\n",
      "Epoch 4/10\n",
      "1000/1000 [==============================] - 68s 68ms/step - loss: 0.1032 - acc: 0.9520\n",
      "Epoch 5/10\n",
      "1000/1000 [==============================] - 68s 68ms/step - loss: 0.0947 - acc: 0.9520\n",
      "Epoch 6/10\n",
      "1000/1000 [==============================] - 69s 69ms/step - loss: 0.0901 - acc: 0.9580\n",
      "Epoch 7/10\n",
      "1000/1000 [==============================] - 69s 69ms/step - loss: 0.0873 - acc: 0.9580\n",
      "Epoch 8/10\n",
      "1000/1000 [==============================] - 68s 68ms/step - loss: 0.0824 - acc: 0.9610\n",
      "Epoch 9/10\n",
      "1000/1000 [==============================] - 69s 69ms/step - loss: 0.0799 - acc: 0.9570\n",
      "Epoch 10/10\n",
      "1000/1000 [==============================] - 69s 69ms/step - loss: 0.0772 - acc: 0.9650\n",
      "Training on Epoch  3 batch  5  Files [5] start  275 / 459\n",
      "Epoch 1/10\n",
      "1000/1000 [==============================] - 56s 56ms/step - loss: 0.1581 - acc: 0.9430\n",
      "Epoch 2/10\n",
      "1000/1000 [==============================] - 57s 57ms/step - loss: 0.1153 - acc: 0.9560\n",
      "Epoch 3/10\n",
      "1000/1000 [==============================] - 56s 56ms/step - loss: 0.0854 - acc: 0.9590\n",
      "Epoch 4/10\n",
      "1000/1000 [==============================] - 57s 57ms/step - loss: 0.0756 - acc: 0.9670\n",
      "Epoch 5/10\n",
      "1000/1000 [==============================] - 57s 57ms/step - loss: 0.0684 - acc: 0.9690\n",
      "Epoch 6/10\n",
      "1000/1000 [==============================] - 57s 57ms/step - loss: 0.0627 - acc: 0.9700\n",
      "Epoch 7/10\n",
      "1000/1000 [==============================] - 56s 56ms/step - loss: 0.0596 - acc: 0.9700\n",
      "Epoch 8/10\n",
      "1000/1000 [==============================] - 57s 57ms/step - loss: 0.0575 - acc: 0.9750\n",
      "Epoch 9/10\n",
      "1000/1000 [==============================] - 56s 56ms/step - loss: 0.0546 - acc: 0.9750\n",
      "Epoch 10/10\n",
      "1000/1000 [==============================] - 58s 58ms/step - loss: 0.0533 - acc: 0.9750\n",
      "Training on Epoch  3 batch  5  Files [5] start  280 / 459\n",
      "Epoch 1/10\n",
      "1000/1000 [==============================] - 57s 57ms/step - loss: 0.1547 - acc: 0.9330\n",
      "Epoch 2/10\n",
      "1000/1000 [==============================] - 57s 57ms/step - loss: 0.1140 - acc: 0.9430\n",
      "Epoch 3/10\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000/1000 [==============================] - 57s 57ms/step - loss: 0.0908 - acc: 0.9510\n",
      "Epoch 4/10\n",
      "1000/1000 [==============================] - 58s 58ms/step - loss: 0.0852 - acc: 0.9580\n",
      "Epoch 5/10\n",
      "1000/1000 [==============================] - 57s 57ms/step - loss: 0.0786 - acc: 0.9590\n",
      "Epoch 6/10\n",
      "1000/1000 [==============================] - 56s 56ms/step - loss: 0.0736 - acc: 0.9670\n",
      "Epoch 7/10\n",
      "1000/1000 [==============================] - 57s 57ms/step - loss: 0.0721 - acc: 0.9670\n",
      "Epoch 8/10\n",
      "1000/1000 [==============================] - 57s 57ms/step - loss: 0.0707 - acc: 0.9680\n",
      "Epoch 9/10\n",
      "1000/1000 [==============================] - 57s 57ms/step - loss: 0.0698 - acc: 0.9630\n",
      "Epoch 10/10\n",
      "1000/1000 [==============================] - 56s 56ms/step - loss: 0.0674 - acc: 0.9660\n",
      "Training on Epoch  3 batch  5  Files [5] start  285 / 459\n",
      "Epoch 1/10\n",
      "1000/1000 [==============================] - 70s 70ms/step - loss: 0.1805 - acc: 0.9090\n",
      "Epoch 2/10\n",
      "1000/1000 [==============================] - 70s 70ms/step - loss: 0.1656 - acc: 0.9020\n",
      "Epoch 3/10\n",
      "1000/1000 [==============================] - 69s 69ms/step - loss: 0.1474 - acc: 0.9120\n",
      "Epoch 4/10\n",
      "1000/1000 [==============================] - 70s 70ms/step - loss: 0.1367 - acc: 0.9290\n",
      "Epoch 5/10\n",
      "1000/1000 [==============================] - 70s 70ms/step - loss: 0.1302 - acc: 0.9330\n",
      "Epoch 6/10\n",
      "1000/1000 [==============================] - 69s 69ms/step - loss: 0.1251 - acc: 0.9410\n",
      "Epoch 7/10\n",
      "1000/1000 [==============================] - 69s 69ms/step - loss: 0.1195 - acc: 0.9430\n",
      "Epoch 8/10\n",
      "1000/1000 [==============================] - 70s 70ms/step - loss: 0.1161 - acc: 0.9420\n",
      "Epoch 9/10\n",
      "1000/1000 [==============================] - 69s 69ms/step - loss: 0.1128 - acc: 0.9430\n",
      "Epoch 10/10\n",
      "1000/1000 [==============================] - 70s 70ms/step - loss: 0.1121 - acc: 0.9430\n",
      "Training on Epoch  3 batch  5  Files [5] start  290 / 459\n",
      "Epoch 1/10\n",
      "1000/1000 [==============================] - 75s 75ms/step - loss: 0.1932 - acc: 0.9170\n",
      "Epoch 2/10\n",
      "1000/1000 [==============================] - 74s 74ms/step - loss: 0.1482 - acc: 0.9320\n",
      "Epoch 3/10\n",
      "1000/1000 [==============================] - 75s 75ms/step - loss: 0.1315 - acc: 0.9420\n",
      "Epoch 4/10\n",
      "1000/1000 [==============================] - 75s 75ms/step - loss: 0.1202 - acc: 0.9470\n",
      "Epoch 5/10\n",
      "1000/1000 [==============================] - 74s 74ms/step - loss: 0.1121 - acc: 0.9530\n",
      "Epoch 6/10\n",
      "1000/1000 [==============================] - 75s 75ms/step - loss: 0.1042 - acc: 0.9550\n",
      "Epoch 7/10\n",
      "1000/1000 [==============================] - 75s 75ms/step - loss: 0.0991 - acc: 0.9550\n",
      "Epoch 8/10\n",
      "1000/1000 [==============================] - 74s 74ms/step - loss: 0.0987 - acc: 0.9490\n",
      "Epoch 9/10\n",
      "1000/1000 [==============================] - 75s 75ms/step - loss: 0.0943 - acc: 0.9570\n",
      "Epoch 10/10\n",
      "1000/1000 [==============================] - 75s 75ms/step - loss: 0.0900 - acc: 0.9580\n",
      "Training on Epoch  3 batch  5  Files [5] start  295 / 459\n",
      "Epoch 1/10\n",
      "1000/1000 [==============================] - 60s 60ms/step - loss: 0.0990 - acc: 0.9540\n",
      "Epoch 2/10\n",
      "1000/1000 [==============================] - 61s 61ms/step - loss: 0.0850 - acc: 0.9630\n",
      "Epoch 3/10\n",
      "1000/1000 [==============================] - 61s 61ms/step - loss: 0.0746 - acc: 0.9700\n",
      "Epoch 4/10\n",
      "1000/1000 [==============================] - 61s 61ms/step - loss: 0.0680 - acc: 0.9740\n",
      "Epoch 5/10\n",
      "1000/1000 [==============================] - 61s 61ms/step - loss: 0.0643 - acc: 0.9740\n",
      "Epoch 6/10\n",
      "1000/1000 [==============================] - 61s 61ms/step - loss: 0.0608 - acc: 0.9750\n",
      "Epoch 7/10\n",
      "1000/1000 [==============================] - 61s 61ms/step - loss: 0.0587 - acc: 0.9730\n",
      "Epoch 8/10\n",
      "1000/1000 [==============================] - 60s 60ms/step - loss: 0.0561 - acc: 0.9720\n",
      "Epoch 9/10\n",
      "1000/1000 [==============================] - 60s 60ms/step - loss: 0.0546 - acc: 0.9760\n",
      "Epoch 10/10\n",
      "1000/1000 [==============================] - 60s 60ms/step - loss: 0.0529 - acc: 0.9760\n",
      "Training on Epoch  3 batch  5  Files [5] start  300 / 459\n",
      "Epoch 1/10\n",
      "1000/1000 [==============================] - 54s 54ms/step - loss: 0.2174 - acc: 0.9140\n",
      "Epoch 2/10\n",
      "1000/1000 [==============================] - 54s 54ms/step - loss: 0.1525 - acc: 0.9390\n",
      "Epoch 3/10\n",
      "1000/1000 [==============================] - 54s 54ms/step - loss: 0.1244 - acc: 0.9510\n",
      "Epoch 4/10\n",
      "1000/1000 [==============================] - 54s 54ms/step - loss: 0.1087 - acc: 0.9550\n",
      "Epoch 5/10\n",
      "1000/1000 [==============================] - 54s 54ms/step - loss: 0.0989 - acc: 0.9590\n",
      "Epoch 6/10\n",
      "1000/1000 [==============================] - 54s 54ms/step - loss: 0.0921 - acc: 0.9670\n",
      "Epoch 7/10\n",
      "1000/1000 [==============================] - 54s 54ms/step - loss: 0.0829 - acc: 0.9700\n",
      "Epoch 8/10\n",
      "1000/1000 [==============================] - 54s 54ms/step - loss: 0.0779 - acc: 0.9710\n",
      "Epoch 9/10\n",
      "1000/1000 [==============================] - 53s 53ms/step - loss: 0.0732 - acc: 0.9740\n",
      "Epoch 10/10\n",
      "1000/1000 [==============================] - 54s 54ms/step - loss: 0.0688 - acc: 0.9690\n",
      "Training on Epoch  3 batch  5  Files [5] start  305 / 459\n",
      "Epoch 1/10\n",
      "1000/1000 [==============================] - 66s 66ms/step - loss: 0.1578 - acc: 0.9320\n",
      "Epoch 2/10\n",
      "1000/1000 [==============================] - 66s 66ms/step - loss: 0.1186 - acc: 0.9460\n",
      "Epoch 3/10\n",
      "1000/1000 [==============================] - 66s 66ms/step - loss: 0.0900 - acc: 0.9620\n",
      "Epoch 4/10\n",
      "1000/1000 [==============================] - 66s 66ms/step - loss: 0.0781 - acc: 0.9670\n",
      "Epoch 5/10\n",
      "1000/1000 [==============================] - 66s 66ms/step - loss: 0.0735 - acc: 0.9690\n",
      "Epoch 6/10\n",
      "1000/1000 [==============================] - 66s 66ms/step - loss: 0.0662 - acc: 0.9740\n",
      "Epoch 7/10\n",
      "1000/1000 [==============================] - 66s 66ms/step - loss: 0.0681 - acc: 0.9740\n",
      "Epoch 8/10\n",
      "1000/1000 [==============================] - 67s 67ms/step - loss: 0.0578 - acc: 0.9780\n",
      "Epoch 9/10\n",
      "1000/1000 [==============================] - 66s 66ms/step - loss: 0.0587 - acc: 0.9760\n",
      "Epoch 10/10\n",
      "1000/1000 [==============================] - 66s 66ms/step - loss: 0.0521 - acc: 0.9780\n",
      "Training on Epoch  3 batch  5  Files [5] start  310 / 459\n",
      "Epoch 1/10\n",
      "1000/1000 [==============================] - 66s 66ms/step - loss: 0.2735 - acc: 0.9080\n",
      "Epoch 2/10\n",
      "1000/1000 [==============================] - 66s 66ms/step - loss: 0.1886 - acc: 0.9320\n",
      "Epoch 3/10\n",
      "1000/1000 [==============================] - 66s 66ms/step - loss: 0.1335 - acc: 0.9410\n",
      "Epoch 4/10\n",
      "1000/1000 [==============================] - 66s 66ms/step - loss: 0.1132 - acc: 0.9450\n",
      "Epoch 5/10\n",
      "1000/1000 [==============================] - 66s 66ms/step - loss: 0.0938 - acc: 0.9640\n",
      "Epoch 6/10\n",
      "1000/1000 [==============================] - 66s 66ms/step - loss: 0.0875 - acc: 0.9670\n",
      "Epoch 7/10\n",
      "1000/1000 [==============================] - 66s 66ms/step - loss: 0.0819 - acc: 0.9670\n",
      "Epoch 8/10\n",
      "1000/1000 [==============================] - 66s 66ms/step - loss: 0.0761 - acc: 0.9650\n",
      "Epoch 9/10\n",
      "1000/1000 [==============================] - 66s 66ms/step - loss: 0.0702 - acc: 0.9660\n",
      "Epoch 10/10\n",
      "1000/1000 [==============================] - 66s 66ms/step - loss: 0.0645 - acc: 0.9730\n",
      "Training on Epoch  3 batch  5  Files [5] start  315 / 459\n",
      "Epoch 1/10\n",
      "1000/1000 [==============================] - 67s 67ms/step - loss: 0.1806 - acc: 0.9160\n",
      "Epoch 2/10\n",
      "1000/1000 [==============================] - 66s 66ms/step - loss: 0.1332 - acc: 0.9360\n",
      "Epoch 3/10\n",
      "1000/1000 [==============================] - 67s 67ms/step - loss: 0.1111 - acc: 0.9380\n",
      "Epoch 4/10\n",
      "1000/1000 [==============================] - 68s 68ms/step - loss: 0.0983 - acc: 0.9470\n",
      "Epoch 5/10\n",
      "1000/1000 [==============================] - 65s 65ms/step - loss: 0.0936 - acc: 0.9450\n",
      "Epoch 6/10\n",
      "1000/1000 [==============================] - 68s 68ms/step - loss: 0.0884 - acc: 0.9490\n",
      "Epoch 7/10\n",
      "1000/1000 [==============================] - 73s 73ms/step - loss: 0.0862 - acc: 0.9560\n",
      "Epoch 8/10\n",
      "1000/1000 [==============================] - 69s 69ms/step - loss: 0.0821 - acc: 0.9600\n",
      "Epoch 9/10\n",
      "1000/1000 [==============================] - 71s 71ms/step - loss: 0.0810 - acc: 0.9620\n",
      "Epoch 10/10\n",
      "1000/1000 [==============================] - 71s 71ms/step - loss: 0.0788 - acc: 0.9590\n",
      "Training on Epoch  3 batch  5  Files [5] start  320 / 459\n",
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000/1000 [==============================] - 84s 84ms/step - loss: 0.1912 - acc: 0.9320\n",
      "Epoch 2/10\n",
      "1000/1000 [==============================] - 74s 74ms/step - loss: 0.1308 - acc: 0.9450\n",
      "Epoch 3/10\n",
      "1000/1000 [==============================] - 75s 75ms/step - loss: 0.1067 - acc: 0.9480\n",
      "Epoch 4/10\n",
      "1000/1000 [==============================] - 69s 69ms/step - loss: 0.0943 - acc: 0.9580\n",
      "Epoch 5/10\n",
      "1000/1000 [==============================] - 69s 69ms/step - loss: 0.0797 - acc: 0.9660\n",
      "Epoch 6/10\n",
      "1000/1000 [==============================] - 70s 70ms/step - loss: 0.0689 - acc: 0.9710\n",
      "Epoch 7/10\n",
      "1000/1000 [==============================] - 76s 76ms/step - loss: 0.0633 - acc: 0.9680\n",
      "Epoch 8/10\n",
      "1000/1000 [==============================] - 70s 70ms/step - loss: 0.0580 - acc: 0.9710\n",
      "Epoch 9/10\n",
      "1000/1000 [==============================] - 72s 72ms/step - loss: 0.0553 - acc: 0.9730\n",
      "Epoch 10/10\n",
      "1000/1000 [==============================] - 70s 70ms/step - loss: 0.0514 - acc: 0.9730\n",
      "Training on Epoch  3 batch  5  Files [5] start  325 / 459\n",
      "Epoch 1/10\n",
      "1000/1000 [==============================] - 67s 67ms/step - loss: 0.1365 - acc: 0.9420\n",
      "Epoch 2/10\n",
      "1000/1000 [==============================] - 69s 69ms/step - loss: 0.1079 - acc: 0.9530\n",
      "Epoch 3/10\n",
      "1000/1000 [==============================] - 66s 66ms/step - loss: 0.1007 - acc: 0.9550\n",
      "Epoch 4/10\n",
      "1000/1000 [==============================] - 62s 62ms/step - loss: 0.0905 - acc: 0.9560\n",
      "Epoch 5/10\n",
      "1000/1000 [==============================] - 67s 67ms/step - loss: 0.0894 - acc: 0.9580\n",
      "Epoch 6/10\n",
      "1000/1000 [==============================] - 65s 65ms/step - loss: 0.0838 - acc: 0.9620\n",
      "Epoch 7/10\n",
      "1000/1000 [==============================] - 63s 63ms/step - loss: 0.0857 - acc: 0.9580\n",
      "Epoch 8/10\n",
      "1000/1000 [==============================] - 63s 63ms/step - loss: 0.1055 - acc: 0.9550\n",
      "Epoch 9/10\n",
      "1000/1000 [==============================] - 69s 69ms/step - loss: 0.0828 - acc: 0.9590\n",
      "Epoch 10/10\n",
      "1000/1000 [==============================] - 64s 64ms/step - loss: 0.0842 - acc: 0.9580\n",
      "Training on Epoch  3 batch  5  Files [5] start  330 / 459\n",
      "Epoch 1/10\n",
      "1000/1000 [==============================] - 71s 71ms/step - loss: 0.2877 - acc: 0.8810\n",
      "Epoch 2/10\n",
      "1000/1000 [==============================] - 66s 66ms/step - loss: 0.1978 - acc: 0.9080\n",
      "Epoch 3/10\n",
      "1000/1000 [==============================] - 65s 65ms/step - loss: 0.1598 - acc: 0.9350\n",
      "Epoch 4/10\n",
      "1000/1000 [==============================] - 65s 65ms/step - loss: 0.1361 - acc: 0.9390\n",
      "Epoch 5/10\n",
      "1000/1000 [==============================] - 66s 66ms/step - loss: 0.1222 - acc: 0.9450\n",
      "Epoch 6/10\n",
      "1000/1000 [==============================] - 68s 68ms/step - loss: 0.1068 - acc: 0.9530\n",
      "Epoch 7/10\n",
      "1000/1000 [==============================] - 65s 65ms/step - loss: 0.0971 - acc: 0.9550\n",
      "Epoch 8/10\n",
      "1000/1000 [==============================] - 66s 66ms/step - loss: 0.0929 - acc: 0.9570\n",
      "Epoch 9/10\n",
      "1000/1000 [==============================] - 71s 71ms/step - loss: 0.0860 - acc: 0.9680\n",
      "Epoch 10/10\n",
      "1000/1000 [==============================] - 73s 73ms/step - loss: 0.0808 - acc: 0.9670\n",
      "Training on Epoch  3 batch  5  Files [5] start  335 / 459\n",
      "Epoch 1/10\n",
      "1000/1000 [==============================] - 60s 60ms/step - loss: 0.2030 - acc: 0.9090\n",
      "Epoch 2/10\n",
      "1000/1000 [==============================] - 64s 64ms/step - loss: 0.1665 - acc: 0.9140\n",
      "Epoch 3/10\n",
      "1000/1000 [==============================] - 62s 62ms/step - loss: 0.1417 - acc: 0.9280\n",
      "Epoch 4/10\n",
      "1000/1000 [==============================] - 66s 66ms/step - loss: 0.1235 - acc: 0.9340\n",
      "Epoch 5/10\n",
      "1000/1000 [==============================] - 63s 63ms/step - loss: 0.1200 - acc: 0.9410\n",
      "Epoch 6/10\n",
      "1000/1000 [==============================] - 68s 68ms/step - loss: 0.1145 - acc: 0.9360\n",
      "Epoch 7/10\n",
      "1000/1000 [==============================] - 64s 64ms/step - loss: 0.1133 - acc: 0.9370\n",
      "Epoch 8/10\n",
      "1000/1000 [==============================] - 64s 64ms/step - loss: 0.1057 - acc: 0.9450\n",
      "Epoch 9/10\n",
      "1000/1000 [==============================] - 62s 62ms/step - loss: 0.1030 - acc: 0.9480\n",
      "Epoch 10/10\n",
      "1000/1000 [==============================] - 62s 62ms/step - loss: 0.0999 - acc: 0.9440\n",
      "Training on Epoch  3 batch  5  Files [5] start  340 / 459\n",
      "Epoch 1/10\n",
      "1000/1000 [==============================] - 80s 80ms/step - loss: 0.1109 - acc: 0.9510\n",
      "Epoch 2/10\n",
      "1000/1000 [==============================] - 77s 77ms/step - loss: 0.1012 - acc: 0.9490\n",
      "Epoch 3/10\n",
      "1000/1000 [==============================] - 74s 74ms/step - loss: 0.0862 - acc: 0.9580\n",
      "Epoch 4/10\n",
      "1000/1000 [==============================] - 75s 75ms/step - loss: 0.0782 - acc: 0.9600\n",
      "Epoch 5/10\n",
      "1000/1000 [==============================] - 77s 77ms/step - loss: 0.0727 - acc: 0.9590\n",
      "Epoch 6/10\n",
      "1000/1000 [==============================] - 86s 86ms/step - loss: 0.0705 - acc: 0.9620\n",
      "Epoch 7/10\n",
      "1000/1000 [==============================] - 78s 78ms/step - loss: 0.0687 - acc: 0.9610\n",
      "Epoch 8/10\n",
      "1000/1000 [==============================] - 83s 83ms/step - loss: 0.0668 - acc: 0.9640\n",
      "Epoch 9/10\n",
      "1000/1000 [==============================] - 74s 74ms/step - loss: 0.0650 - acc: 0.9700\n",
      "Epoch 10/10\n",
      "1000/1000 [==============================] - 74s 74ms/step - loss: 0.0638 - acc: 0.9700\n",
      "Training on Epoch  3 batch  5  Files [5] start  345 / 459\n",
      "Epoch 1/10\n",
      "1000/1000 [==============================] - 53s 53ms/step - loss: 0.2554 - acc: 0.9020\n",
      "Epoch 2/10\n",
      "1000/1000 [==============================] - 53s 53ms/step - loss: 0.1604 - acc: 0.9310\n",
      "Epoch 3/10\n",
      "1000/1000 [==============================] - 53s 53ms/step - loss: 0.1252 - acc: 0.9340\n",
      "Epoch 4/10\n",
      "1000/1000 [==============================] - 53s 53ms/step - loss: 0.0967 - acc: 0.9600\n",
      "Epoch 5/10\n",
      "1000/1000 [==============================] - 53s 53ms/step - loss: 0.0858 - acc: 0.9660\n",
      "Epoch 6/10\n",
      "1000/1000 [==============================] - 53s 53ms/step - loss: 0.0813 - acc: 0.9650\n",
      "Epoch 7/10\n",
      "1000/1000 [==============================] - 53s 53ms/step - loss: 0.0708 - acc: 0.9700\n",
      "Epoch 8/10\n",
      "1000/1000 [==============================] - 53s 53ms/step - loss: 0.0620 - acc: 0.9750\n",
      "Epoch 9/10\n",
      "1000/1000 [==============================] - 53s 53ms/step - loss: 0.0573 - acc: 0.9770\n",
      "Epoch 10/10\n",
      "1000/1000 [==============================] - 53s 53ms/step - loss: 0.0518 - acc: 0.9780\n",
      "Training on Epoch  3 batch  5  Files [5] start  350 / 459\n",
      "Epoch 1/10\n",
      "1000/1000 [==============================] - 60s 60ms/step - loss: 0.3822 - acc: 0.8690\n",
      "Epoch 2/10\n",
      "1000/1000 [==============================] - 61s 61ms/step - loss: 0.2846 - acc: 0.9020\n",
      "Epoch 3/10\n",
      "1000/1000 [==============================] - 61s 61ms/step - loss: 0.2259 - acc: 0.9150\n",
      "Epoch 4/10\n",
      "1000/1000 [==============================] - 62s 62ms/step - loss: 0.1788 - acc: 0.9340\n",
      "Epoch 5/10\n",
      "1000/1000 [==============================] - 60s 60ms/step - loss: 0.1417 - acc: 0.9520\n",
      "Epoch 6/10\n",
      "1000/1000 [==============================] - 60s 60ms/step - loss: 0.1261 - acc: 0.9530\n",
      "Epoch 7/10\n",
      "1000/1000 [==============================] - 61s 61ms/step - loss: 0.1098 - acc: 0.9630\n",
      "Epoch 8/10\n",
      "1000/1000 [==============================] - 61s 61ms/step - loss: 0.0954 - acc: 0.9740\n",
      "Epoch 9/10\n",
      "1000/1000 [==============================] - 60s 60ms/step - loss: 0.0856 - acc: 0.9710\n",
      "Epoch 10/10\n",
      "1000/1000 [==============================] - 61s 61ms/step - loss: 0.0774 - acc: 0.9720\n",
      "Training on Epoch  3 batch  5  Files [5] start  355 / 459\n",
      "Epoch 1/10\n",
      "1000/1000 [==============================] - 60s 60ms/step - loss: 0.3013 - acc: 0.8840\n",
      "Epoch 2/10\n",
      "1000/1000 [==============================] - 60s 60ms/step - loss: 0.2075 - acc: 0.9190\n",
      "Epoch 3/10\n",
      "1000/1000 [==============================] - 60s 60ms/step - loss: 0.1662 - acc: 0.9310\n",
      "Epoch 4/10\n",
      "1000/1000 [==============================] - 60s 60ms/step - loss: 0.1408 - acc: 0.9460\n",
      "Epoch 5/10\n",
      "1000/1000 [==============================] - 61s 61ms/step - loss: 0.1186 - acc: 0.9530\n",
      "Epoch 6/10\n",
      "1000/1000 [==============================] - 60s 60ms/step - loss: 0.1059 - acc: 0.9580\n",
      "Epoch 7/10\n",
      "1000/1000 [==============================] - 61s 61ms/step - loss: 0.0925 - acc: 0.9630\n",
      "Epoch 8/10\n",
      "1000/1000 [==============================] - 61s 61ms/step - loss: 0.0816 - acc: 0.9680\n",
      "Epoch 9/10\n",
      "1000/1000 [==============================] - 61s 61ms/step - loss: 0.0743 - acc: 0.9710\n",
      "Epoch 10/10\n",
      "1000/1000 [==============================] - 61s 61ms/step - loss: 0.0662 - acc: 0.9750\n",
      "Training on Epoch  3 batch  5  Files [5] start  360 / 459\n",
      "Epoch 1/10\n",
      "1000/1000 [==============================] - 61s 61ms/step - loss: 0.2671 - acc: 0.9100\n",
      "Epoch 2/10\n",
      "1000/1000 [==============================] - 61s 61ms/step - loss: 0.2041 - acc: 0.9340\n",
      "Epoch 3/10\n",
      "1000/1000 [==============================] - 61s 61ms/step - loss: 0.1516 - acc: 0.9520\n",
      "Epoch 4/10\n",
      "1000/1000 [==============================] - 66s 66ms/step - loss: 0.1424 - acc: 0.9490\n",
      "Epoch 5/10\n",
      "1000/1000 [==============================] - 67s 67ms/step - loss: 0.1115 - acc: 0.9580\n",
      "Epoch 6/10\n",
      "1000/1000 [==============================] - 67s 67ms/step - loss: 0.0956 - acc: 0.9680\n",
      "Epoch 7/10\n",
      "1000/1000 [==============================] - 65s 65ms/step - loss: 0.0752 - acc: 0.9760\n",
      "Epoch 8/10\n",
      "1000/1000 [==============================] - 62s 62ms/step - loss: 0.0627 - acc: 0.9820\n",
      "Epoch 9/10\n",
      "1000/1000 [==============================] - 62s 62ms/step - loss: 0.0533 - acc: 0.9840\n",
      "Epoch 10/10\n",
      "1000/1000 [==============================] - 62s 62ms/step - loss: 0.0481 - acc: 0.9860\n",
      "Training on Epoch  3 batch  5  Files [5] start  365 / 459\n",
      "Epoch 1/10\n",
      "1000/1000 [==============================] - 64s 64ms/step - loss: 0.3692 - acc: 0.8720\n",
      "Epoch 2/10\n",
      "1000/1000 [==============================] - 66s 66ms/step - loss: 0.2624 - acc: 0.8970\n",
      "Epoch 3/10\n",
      "1000/1000 [==============================] - 64s 64ms/step - loss: 0.1874 - acc: 0.9310\n",
      "Epoch 4/10\n",
      "1000/1000 [==============================] - 66s 66ms/step - loss: 0.1550 - acc: 0.9420\n",
      "Epoch 5/10\n",
      "1000/1000 [==============================] - 64s 64ms/step - loss: 0.1367 - acc: 0.9520\n",
      "Epoch 6/10\n",
      "1000/1000 [==============================] - 65s 65ms/step - loss: 0.1213 - acc: 0.9590\n",
      "Epoch 7/10\n",
      "1000/1000 [==============================] - 66s 66ms/step - loss: 0.1060 - acc: 0.9640\n",
      "Epoch 8/10\n",
      "1000/1000 [==============================] - 64s 64ms/step - loss: 0.0959 - acc: 0.9690\n",
      "Epoch 9/10\n",
      "1000/1000 [==============================] - 64s 64ms/step - loss: 0.0883 - acc: 0.9720\n",
      "Epoch 10/10\n",
      "1000/1000 [==============================] - 65s 65ms/step - loss: 0.0793 - acc: 0.9730\n",
      "Training on Epoch  3 batch  5  Files [5] start  370 / 459\n",
      "Epoch 1/10\n",
      "1000/1000 [==============================] - 64s 64ms/step - loss: 0.2587 - acc: 0.9100\n",
      "Epoch 2/10\n",
      "1000/1000 [==============================] - 65s 65ms/step - loss: 0.1832 - acc: 0.9280\n",
      "Epoch 3/10\n",
      "1000/1000 [==============================] - 64s 64ms/step - loss: 0.1558 - acc: 0.9320\n",
      "Epoch 4/10\n",
      "1000/1000 [==============================] - 65s 65ms/step - loss: 0.1334 - acc: 0.9340\n",
      "Epoch 5/10\n",
      "1000/1000 [==============================] - 65s 65ms/step - loss: 0.1212 - acc: 0.9380\n",
      "Epoch 6/10\n",
      "1000/1000 [==============================] - 65s 65ms/step - loss: 0.1070 - acc: 0.9450\n",
      "Epoch 7/10\n",
      "1000/1000 [==============================] - 66s 66ms/step - loss: 0.0979 - acc: 0.9500\n",
      "Epoch 8/10\n",
      "1000/1000 [==============================] - 68s 68ms/step - loss: 0.0839 - acc: 0.9600\n",
      "Epoch 9/10\n",
      "1000/1000 [==============================] - 67s 67ms/step - loss: 0.0764 - acc: 0.9660\n",
      "Epoch 10/10\n",
      "1000/1000 [==============================] - 64s 64ms/step - loss: 0.0712 - acc: 0.9650\n",
      "Training on Epoch  3 batch  5  Files [5] start  375 / 459\n",
      "Epoch 1/10\n",
      "1000/1000 [==============================] - 57s 57ms/step - loss: 0.3287 - acc: 0.8860\n",
      "Epoch 2/10\n",
      "1000/1000 [==============================] - 57s 57ms/step - loss: 0.2285 - acc: 0.9130\n",
      "Epoch 3/10\n",
      "1000/1000 [==============================] - 57s 57ms/step - loss: 0.1676 - acc: 0.9360\n",
      "Epoch 4/10\n",
      "1000/1000 [==============================] - 57s 57ms/step - loss: 0.1353 - acc: 0.9410\n",
      "Epoch 5/10\n",
      "1000/1000 [==============================] - 57s 57ms/step - loss: 0.1112 - acc: 0.9550\n",
      "Epoch 6/10\n",
      "1000/1000 [==============================] - 56s 56ms/step - loss: 0.1003 - acc: 0.9620\n",
      "Epoch 7/10\n",
      "1000/1000 [==============================] - 57s 57ms/step - loss: 0.0880 - acc: 0.9750\n",
      "Epoch 8/10\n",
      "1000/1000 [==============================] - 56s 56ms/step - loss: 0.0772 - acc: 0.9790\n",
      "Epoch 9/10\n",
      "1000/1000 [==============================] - 56s 56ms/step - loss: 0.0705 - acc: 0.9780\n",
      "Epoch 10/10\n",
      "1000/1000 [==============================] - 57s 57ms/step - loss: 0.0630 - acc: 0.9800\n",
      "Training on Epoch  3 batch  5  Files [5] start  380 / 459\n",
      "Epoch 1/10\n",
      "1000/1000 [==============================] - 51s 51ms/step - loss: 0.2367 - acc: 0.9030\n",
      "Epoch 2/10\n",
      "1000/1000 [==============================] - 52s 52ms/step - loss: 0.1587 - acc: 0.9260\n",
      "Epoch 3/10\n",
      "1000/1000 [==============================] - 51s 51ms/step - loss: 0.1136 - acc: 0.9560\n",
      "Epoch 4/10\n",
      "1000/1000 [==============================] - 53s 53ms/step - loss: 0.0914 - acc: 0.9630\n",
      "Epoch 5/10\n",
      "1000/1000 [==============================] - 54s 54ms/step - loss: 0.0768 - acc: 0.9710\n",
      "Epoch 6/10\n",
      "1000/1000 [==============================] - 53s 53ms/step - loss: 0.0693 - acc: 0.9760\n",
      "Epoch 7/10\n",
      "1000/1000 [==============================] - 53s 53ms/step - loss: 0.0593 - acc: 0.9820\n",
      "Epoch 8/10\n",
      "1000/1000 [==============================] - 53s 53ms/step - loss: 0.0583 - acc: 0.9820\n",
      "Epoch 9/10\n",
      "1000/1000 [==============================] - 53s 53ms/step - loss: 0.0530 - acc: 0.9840\n",
      "Epoch 10/10\n",
      "1000/1000 [==============================] - 51s 51ms/step - loss: 0.0483 - acc: 0.9860\n",
      "Training on Epoch  3 batch  5  Files [5] start  385 / 459\n",
      "Epoch 1/10\n",
      "1000/1000 [==============================] - 48s 48ms/step - loss: 0.3357 - acc: 0.8880\n",
      "Epoch 2/10\n",
      "1000/1000 [==============================] - 48s 48ms/step - loss: 0.2418 - acc: 0.9050\n",
      "Epoch 3/10\n",
      "1000/1000 [==============================] - 47s 47ms/step - loss: 0.1888 - acc: 0.9210\n",
      "Epoch 4/10\n",
      "1000/1000 [==============================] - 48s 48ms/step - loss: 0.1572 - acc: 0.9370\n",
      "Epoch 5/10\n",
      "1000/1000 [==============================] - 48s 48ms/step - loss: 0.1231 - acc: 0.9520\n",
      "Epoch 6/10\n",
      "1000/1000 [==============================] - 48s 48ms/step - loss: 0.1029 - acc: 0.9630\n",
      "Epoch 7/10\n",
      "1000/1000 [==============================] - 53s 53ms/step - loss: 0.0903 - acc: 0.9660\n",
      "Epoch 8/10\n",
      "1000/1000 [==============================] - 53s 53ms/step - loss: 0.0815 - acc: 0.9700\n",
      "Epoch 9/10\n",
      "1000/1000 [==============================] - 50s 50ms/step - loss: 0.0741 - acc: 0.9740\n",
      "Epoch 10/10\n",
      "1000/1000 [==============================] - 48s 48ms/step - loss: 0.0689 - acc: 0.9780\n",
      "Training on Epoch  3 batch  5  Files [5] start  390 / 459\n",
      "Epoch 1/10\n",
      "1000/1000 [==============================] - 56s 56ms/step - loss: 0.3197 - acc: 0.8790\n",
      "Epoch 2/10\n",
      "1000/1000 [==============================] - 52s 52ms/step - loss: 0.2269 - acc: 0.9130\n",
      "Epoch 3/10\n",
      "1000/1000 [==============================] - 57s 57ms/step - loss: 0.1749 - acc: 0.9300\n",
      "Epoch 4/10\n",
      "1000/1000 [==============================] - 54s 54ms/step - loss: 0.1425 - acc: 0.9420\n",
      "Epoch 5/10\n",
      "1000/1000 [==============================] - 55s 55ms/step - loss: 0.1252 - acc: 0.9570\n",
      "Epoch 6/10\n",
      "1000/1000 [==============================] - 56s 56ms/step - loss: 0.1106 - acc: 0.9590\n",
      "Epoch 7/10\n",
      "1000/1000 [==============================] - 54s 54ms/step - loss: 0.0908 - acc: 0.9690\n",
      "Epoch 8/10\n",
      "1000/1000 [==============================] - 55s 55ms/step - loss: 0.0735 - acc: 0.9700\n",
      "Epoch 9/10\n",
      "1000/1000 [==============================] - 54s 54ms/step - loss: 0.0599 - acc: 0.9790\n",
      "Epoch 10/10\n",
      "1000/1000 [==============================] - 52s 52ms/step - loss: 0.0549 - acc: 0.9830\n",
      "Training on Epoch  3 batch  5  Files [5] start  395 / 459\n",
      "Epoch 1/10\n",
      "1000/1000 [==============================] - 57s 57ms/step - loss: 0.2994 - acc: 0.8860\n",
      "Epoch 2/10\n",
      "1000/1000 [==============================] - 57s 57ms/step - loss: 0.2222 - acc: 0.9070\n",
      "Epoch 3/10\n",
      "1000/1000 [==============================] - 57s 57ms/step - loss: 0.1642 - acc: 0.9260\n",
      "Epoch 4/10\n",
      "1000/1000 [==============================] - 57s 57ms/step - loss: 0.1322 - acc: 0.9430\n",
      "Epoch 5/10\n",
      "1000/1000 [==============================] - 55s 55ms/step - loss: 0.1345 - acc: 0.9480\n",
      "Epoch 6/10\n",
      "1000/1000 [==============================] - 56s 56ms/step - loss: 0.1162 - acc: 0.9530\n",
      "Epoch 7/10\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000/1000 [==============================] - 55s 55ms/step - loss: 0.0950 - acc: 0.9600\n",
      "Epoch 8/10\n",
      "1000/1000 [==============================] - 55s 55ms/step - loss: 0.0821 - acc: 0.9670\n",
      "Epoch 9/10\n",
      "1000/1000 [==============================] - 63s 63ms/step - loss: 0.0791 - acc: 0.9700\n",
      "Epoch 10/10\n",
      "1000/1000 [==============================] - 65s 65ms/step - loss: 0.0703 - acc: 0.9720\n",
      "Training on Epoch  3 batch  5  Files [5] start  400 / 459\n",
      "Epoch 1/10\n",
      "1000/1000 [==============================] - 56s 56ms/step - loss: 0.3067 - acc: 0.8940\n",
      "Epoch 2/10\n",
      "1000/1000 [==============================] - 56s 56ms/step - loss: 0.2372 - acc: 0.9070\n",
      "Epoch 3/10\n",
      "1000/1000 [==============================] - 56s 56ms/step - loss: 0.1923 - acc: 0.9280\n",
      "Epoch 4/10\n",
      "1000/1000 [==============================] - 57s 57ms/step - loss: 0.1489 - acc: 0.9430\n",
      "Epoch 5/10\n",
      "1000/1000 [==============================] - 64s 64ms/step - loss: 0.1281 - acc: 0.9470\n",
      "Epoch 6/10\n",
      "1000/1000 [==============================] - 75s 75ms/step - loss: 0.1065 - acc: 0.9600\n",
      "Epoch 7/10\n",
      "1000/1000 [==============================] - 70s 70ms/step - loss: 0.0892 - acc: 0.9670\n",
      "Epoch 8/10\n",
      "1000/1000 [==============================] - 70s 70ms/step - loss: 0.0765 - acc: 0.9740\n",
      "Epoch 9/10\n",
      "1000/1000 [==============================] - 70s 70ms/step - loss: 0.0659 - acc: 0.9760\n",
      "Epoch 10/10\n",
      "1000/1000 [==============================] - 69s 69ms/step - loss: 0.0578 - acc: 0.9800\n",
      "Training on Epoch  3 batch  5  Files [5] start  405 / 459\n",
      "Epoch 1/10\n",
      "1000/1000 [==============================] - 83s 83ms/step - loss: 0.2759 - acc: 0.9060\n",
      "Epoch 2/10\n",
      "1000/1000 [==============================] - 84s 84ms/step - loss: 0.2001 - acc: 0.9180\n",
      "Epoch 3/10\n",
      "1000/1000 [==============================] - 83s 83ms/step - loss: 0.1654 - acc: 0.9360\n",
      "Epoch 4/10\n",
      "1000/1000 [==============================] - 84s 84ms/step - loss: 0.1374 - acc: 0.9440\n",
      "Epoch 5/10\n",
      "1000/1000 [==============================] - 83s 83ms/step - loss: 0.1197 - acc: 0.9550\n",
      "Epoch 6/10\n",
      "1000/1000 [==============================] - 83s 83ms/step - loss: 0.0967 - acc: 0.9710\n",
      "Epoch 7/10\n",
      "1000/1000 [==============================] - 84s 84ms/step - loss: 0.0801 - acc: 0.9760\n",
      "Epoch 8/10\n",
      "1000/1000 [==============================] - 80s 80ms/step - loss: 0.0648 - acc: 0.9820\n",
      "Epoch 9/10\n",
      "1000/1000 [==============================] - 75s 75ms/step - loss: 0.0560 - acc: 0.9820\n",
      "Epoch 10/10\n",
      "1000/1000 [==============================] - 68s 68ms/step - loss: 0.0652 - acc: 0.9790\n",
      "Training on Epoch  3 batch  5  Files [5] start  410 / 459\n",
      "Epoch 1/10\n",
      "1000/1000 [==============================] - 56s 56ms/step - loss: 0.3071 - acc: 0.8880\n",
      "Epoch 2/10\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 0.2227 - acc: 0.9090\n",
      "Epoch 3/10\n",
      "1000/1000 [==============================] - 58s 58ms/step - loss: 0.1757 - acc: 0.9350\n",
      "Epoch 4/10\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 0.1469 - acc: 0.9450\n",
      "Epoch 5/10\n",
      "1000/1000 [==============================] - 58s 58ms/step - loss: 0.1381 - acc: 0.9510\n",
      "Epoch 6/10\n",
      "1000/1000 [==============================] - 56s 56ms/step - loss: 0.1264 - acc: 0.9540\n",
      "Epoch 7/10\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 0.1074 - acc: 0.9590\n",
      "Epoch 8/10\n",
      "1000/1000 [==============================] - 58s 58ms/step - loss: 0.0834 - acc: 0.9690\n",
      "Epoch 9/10\n",
      "1000/1000 [==============================] - 56s 56ms/step - loss: 0.0666 - acc: 0.9760\n",
      "Epoch 10/10\n",
      "1000/1000 [==============================] - 57s 57ms/step - loss: 0.0572 - acc: 0.9810\n",
      "Training on Epoch  3 batch  5  Files [5] start  415 / 459\n",
      "Epoch 1/10\n",
      "1000/1000 [==============================] - 53s 53ms/step - loss: 0.3682 - acc: 0.8670\n",
      "Epoch 2/10\n",
      "1000/1000 [==============================] - 53s 53ms/step - loss: 0.2750 - acc: 0.9040\n",
      "Epoch 3/10\n",
      "1000/1000 [==============================] - 53s 53ms/step - loss: 0.2001 - acc: 0.9320\n",
      "Epoch 4/10\n",
      "1000/1000 [==============================] - 53s 53ms/step - loss: 0.1607 - acc: 0.9500\n",
      "Epoch 5/10\n",
      "1000/1000 [==============================] - 53s 53ms/step - loss: 0.1386 - acc: 0.9560\n",
      "Epoch 6/10\n",
      "1000/1000 [==============================] - 58s 58ms/step - loss: 0.1127 - acc: 0.9660\n",
      "Epoch 7/10\n",
      "1000/1000 [==============================] - 63s 63ms/step - loss: 0.0940 - acc: 0.9740\n",
      "Epoch 8/10\n",
      "1000/1000 [==============================] - 60s 60ms/step - loss: 0.0848 - acc: 0.9760\n",
      "Epoch 9/10\n",
      "1000/1000 [==============================] - 58s 58ms/step - loss: 0.0776 - acc: 0.9770\n",
      "Epoch 10/10\n",
      "1000/1000 [==============================] - 58s 58ms/step - loss: 0.0686 - acc: 0.9800\n",
      "Training on Epoch  3 batch  5  Files [5] start  420 / 459\n",
      "Epoch 1/10\n",
      "1000/1000 [==============================] - 67s 67ms/step - loss: 0.3083 - acc: 0.8930\n",
      "Epoch 2/10\n",
      "1000/1000 [==============================] - 66s 66ms/step - loss: 0.2227 - acc: 0.9120\n",
      "Epoch 3/10\n",
      "1000/1000 [==============================] - 64s 64ms/step - loss: 0.1709 - acc: 0.9290\n",
      "Epoch 4/10\n",
      "1000/1000 [==============================] - 65s 65ms/step - loss: 0.1415 - acc: 0.9400\n",
      "Epoch 5/10\n",
      "1000/1000 [==============================] - 65s 65ms/step - loss: 0.1184 - acc: 0.9500\n",
      "Epoch 6/10\n",
      "1000/1000 [==============================] - 65s 65ms/step - loss: 0.0979 - acc: 0.9670\n",
      "Epoch 7/10\n",
      "1000/1000 [==============================] - 67s 67ms/step - loss: 0.0832 - acc: 0.9720\n",
      "Epoch 8/10\n",
      "1000/1000 [==============================] - 67s 67ms/step - loss: 0.0707 - acc: 0.9740\n",
      "Epoch 9/10\n",
      "1000/1000 [==============================] - 68s 68ms/step - loss: 0.0607 - acc: 0.9780\n",
      "Epoch 10/10\n",
      "1000/1000 [==============================] - 66s 66ms/step - loss: 0.0552 - acc: 0.9790\n",
      "Training on Epoch  3 batch  5  Files [5] start  425 / 459\n",
      "Epoch 1/10\n",
      "1000/1000 [==============================] - 64s 64ms/step - loss: 0.3380 - acc: 0.8750\n",
      "Epoch 2/10\n",
      "1000/1000 [==============================] - 61s 61ms/step - loss: 0.2313 - acc: 0.9050\n",
      "Epoch 3/10\n",
      "1000/1000 [==============================] - 61s 61ms/step - loss: 0.1762 - acc: 0.9300\n",
      "Epoch 4/10\n",
      "1000/1000 [==============================] - 65s 65ms/step - loss: 0.1435 - acc: 0.9500\n",
      "Epoch 5/10\n",
      "1000/1000 [==============================] - 66s 66ms/step - loss: 0.1190 - acc: 0.9560\n",
      "Epoch 6/10\n",
      "1000/1000 [==============================] - 65s 65ms/step - loss: 0.1011 - acc: 0.9650\n",
      "Epoch 7/10\n",
      "1000/1000 [==============================] - 67s 67ms/step - loss: 0.0898 - acc: 0.9710\n",
      "Epoch 8/10\n",
      "1000/1000 [==============================] - 65s 65ms/step - loss: 0.0782 - acc: 0.9750\n",
      "Epoch 9/10\n",
      "1000/1000 [==============================] - 64s 64ms/step - loss: 0.0698 - acc: 0.9790\n",
      "Epoch 10/10\n",
      "1000/1000 [==============================] - 64s 64ms/step - loss: 0.0629 - acc: 0.9830\n",
      "Training on Epoch  3 batch  5  Files [5] start  430 / 459\n",
      "Epoch 1/10\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 0.3288 - acc: 0.8930\n",
      "Epoch 2/10\n",
      "1000/1000 [==============================] - 57s 57ms/step - loss: 0.2505 - acc: 0.9040\n",
      "Epoch 3/10\n",
      "1000/1000 [==============================] - 61s 61ms/step - loss: 0.1837 - acc: 0.9250\n",
      "Epoch 4/10\n",
      "1000/1000 [==============================] - 56s 56ms/step - loss: 0.1448 - acc: 0.9420\n",
      "Epoch 5/10\n",
      "1000/1000 [==============================] - 56s 56ms/step - loss: 0.1278 - acc: 0.9470\n",
      "Epoch 6/10\n",
      "1000/1000 [==============================] - 57s 57ms/step - loss: 0.1046 - acc: 0.9610\n",
      "Epoch 7/10\n",
      "1000/1000 [==============================] - 57s 57ms/step - loss: 0.0915 - acc: 0.9680\n",
      "Epoch 8/10\n",
      "1000/1000 [==============================] - 56s 56ms/step - loss: 0.0819 - acc: 0.9730\n",
      "Epoch 9/10\n",
      "1000/1000 [==============================] - 58s 58ms/step - loss: 0.0725 - acc: 0.9740\n",
      "Epoch 10/10\n",
      "1000/1000 [==============================] - 58s 58ms/step - loss: 0.0664 - acc: 0.9790\n",
      "Training on Epoch  3 batch  5  Files [5] start  435 / 459\n",
      "Epoch 1/10\n",
      "1000/1000 [==============================] - 55s 55ms/step - loss: 0.2918 - acc: 0.9010\n",
      "Epoch 2/10\n",
      "1000/1000 [==============================] - 52s 52ms/step - loss: 0.2265 - acc: 0.9140\n",
      "Epoch 3/10\n",
      "1000/1000 [==============================] - 53s 53ms/step - loss: 0.1932 - acc: 0.9240\n",
      "Epoch 4/10\n",
      "1000/1000 [==============================] - 55s 55ms/step - loss: 0.1579 - acc: 0.9380\n",
      "Epoch 5/10\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000/1000 [==============================] - 52s 52ms/step - loss: 0.1321 - acc: 0.9510\n",
      "Epoch 6/10\n",
      "1000/1000 [==============================] - 52s 52ms/step - loss: 0.1146 - acc: 0.9620\n",
      "Epoch 7/10\n",
      "1000/1000 [==============================] - 54s 54ms/step - loss: 0.1047 - acc: 0.9700\n",
      "Epoch 8/10\n",
      "1000/1000 [==============================] - 53s 53ms/step - loss: 0.0966 - acc: 0.9680\n",
      "Epoch 9/10\n",
      "1000/1000 [==============================] - 54s 54ms/step - loss: 0.0869 - acc: 0.9700\n",
      "Epoch 10/10\n",
      "1000/1000 [==============================] - 54s 54ms/step - loss: 0.0804 - acc: 0.9750\n",
      "Training on Epoch  3 batch  5  Files [5] start  440 / 459\n",
      "Epoch 1/10\n",
      "1000/1000 [==============================] - 57s 57ms/step - loss: 0.1966 - acc: 0.9350\n",
      "Epoch 2/10\n",
      "1000/1000 [==============================] - 55s 55ms/step - loss: 0.1434 - acc: 0.9510\n",
      "Epoch 3/10\n",
      "1000/1000 [==============================] - 54s 54ms/step - loss: 0.1084 - acc: 0.9710\n",
      "Epoch 4/10\n",
      "1000/1000 [==============================] - 55s 55ms/step - loss: 0.0862 - acc: 0.9780\n",
      "Epoch 5/10\n",
      "1000/1000 [==============================] - 62s 62ms/step - loss: 0.0712 - acc: 0.9810\n",
      "Epoch 6/10\n",
      "1000/1000 [==============================] - 57s 57ms/step - loss: 0.0579 - acc: 0.9840\n",
      "Epoch 7/10\n",
      "1000/1000 [==============================] - 55s 55ms/step - loss: 0.0468 - acc: 0.9880\n",
      "Epoch 8/10\n",
      "1000/1000 [==============================] - 55s 55ms/step - loss: 0.0387 - acc: 0.9910\n",
      "Epoch 9/10\n",
      "1000/1000 [==============================] - 55s 55ms/step - loss: 0.0334 - acc: 0.9930\n",
      "Epoch 10/10\n",
      "1000/1000 [==============================] - 56s 56ms/step - loss: 0.0292 - acc: 0.9950\n",
      "Training on Epoch  3 batch  5  Files [5] start  445 / 459\n",
      "Epoch 1/10\n",
      "1000/1000 [==============================] - 50s 50ms/step - loss: 0.1818 - acc: 0.9430\n",
      "Epoch 2/10\n",
      "1000/1000 [==============================] - 50s 50ms/step - loss: 0.1339 - acc: 0.9510\n",
      "Epoch 3/10\n",
      "1000/1000 [==============================] - 50s 50ms/step - loss: 0.1039 - acc: 0.9600\n",
      "Epoch 4/10\n",
      "1000/1000 [==============================] - 50s 50ms/step - loss: 0.0842 - acc: 0.9670\n",
      "Epoch 5/10\n",
      "1000/1000 [==============================] - 54s 54ms/step - loss: 0.0699 - acc: 0.9720\n",
      "Epoch 6/10\n",
      "1000/1000 [==============================] - 62s 62ms/step - loss: 0.0605 - acc: 0.9740\n",
      "Epoch 7/10\n",
      "1000/1000 [==============================] - 60s 60ms/step - loss: 0.0539 - acc: 0.9780\n",
      "Epoch 8/10\n",
      "1000/1000 [==============================] - 50s 50ms/step - loss: 0.0479 - acc: 0.9830\n",
      "Epoch 9/10\n",
      "1000/1000 [==============================] - 53s 53ms/step - loss: 0.0431 - acc: 0.9870\n",
      "Epoch 10/10\n",
      "1000/1000 [==============================] - 62s 62ms/step - loss: 0.0395 - acc: 0.9880\n",
      "Training on Epoch  3 batch  5  Files [5] start  450 / 459\n",
      "Epoch 1/10\n",
      "1000/1000 [==============================] - 63s 63ms/step - loss: 0.2453 - acc: 0.9200\n",
      "Epoch 2/10\n",
      "1000/1000 [==============================] - 74s 74ms/step - loss: 0.1940 - acc: 0.9340\n",
      "Epoch 3/10\n",
      "1000/1000 [==============================] - 74s 74ms/step - loss: 0.1383 - acc: 0.9490\n",
      "Epoch 4/10\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 0.1081 - acc: 0.9650\n",
      "Epoch 5/10\n",
      "1000/1000 [==============================] - 63s 63ms/step - loss: 0.0890 - acc: 0.9700\n",
      "Epoch 6/10\n",
      "1000/1000 [==============================] - 64s 64ms/step - loss: 0.0771 - acc: 0.9740\n",
      "Epoch 7/10\n",
      "1000/1000 [==============================] - 62s 62ms/step - loss: 0.0669 - acc: 0.9770\n",
      "Epoch 8/10\n",
      "1000/1000 [==============================] - 60s 60ms/step - loss: 0.0548 - acc: 0.9810\n",
      "Epoch 9/10\n",
      "1000/1000 [==============================] - 72s 72ms/step - loss: 0.0473 - acc: 0.9860\n",
      "Epoch 10/10\n",
      "1000/1000 [==============================] - 73s 73ms/step - loss: 0.0403 - acc: 0.9870\n",
      "Training on Epoch  3 batch  4  Files [5] start  455 / 459\n",
      "Epoch 1/10\n",
      "800/800 [==============================] - 51s 63ms/step - loss: 0.2711 - acc: 0.9125\n",
      "Epoch 2/10\n",
      "800/800 [==============================] - 51s 64ms/step - loss: 0.2044 - acc: 0.9325\n",
      "Epoch 3/10\n",
      "800/800 [==============================] - 52s 65ms/step - loss: 0.1538 - acc: 0.9488\n",
      "Epoch 4/10\n",
      "800/800 [==============================] - 50s 62ms/step - loss: 0.1335 - acc: 0.9587\n",
      "Epoch 5/10\n",
      "800/800 [==============================] - 54s 67ms/step - loss: 0.1108 - acc: 0.9650\n",
      "Epoch 6/10\n",
      "800/800 [==============================] - 53s 66ms/step - loss: 0.0996 - acc: 0.9713\n",
      "Epoch 7/10\n",
      "800/800 [==============================] - 50s 63ms/step - loss: 0.0899 - acc: 0.9738\n",
      "Epoch 8/10\n",
      "800/800 [==============================] - 50s 63ms/step - loss: 0.0820 - acc: 0.9750\n",
      "Epoch 9/10\n",
      "800/800 [==============================] - 53s 66ms/step - loss: 0.0741 - acc: 0.9775\n",
      "Epoch 10/10\n",
      "800/800 [==============================] - 51s 64ms/step - loss: 0.0685 - acc: 0.9788\n",
      "Training on Epoch  4 batch  5  Files [5] start  0 / 459\n",
      "Epoch 1/10\n",
      "1000/1000 [==============================] - 55s 55ms/step - loss: 0.2639 - acc: 0.9000\n",
      "Epoch 2/10\n",
      "1000/1000 [==============================] - 56s 56ms/step - loss: 0.1937 - acc: 0.9270\n",
      "Epoch 3/10\n",
      "1000/1000 [==============================] - 63s 63ms/step - loss: 0.1514 - acc: 0.9500\n",
      "Epoch 4/10\n",
      "1000/1000 [==============================] - 73s 73ms/step - loss: 0.1288 - acc: 0.9570\n",
      "Epoch 5/10\n",
      "1000/1000 [==============================] - 62s 62ms/step - loss: 0.1155 - acc: 0.9590\n",
      "Epoch 6/10\n",
      "1000/1000 [==============================] - 55s 55ms/step - loss: 0.1020 - acc: 0.9640\n",
      "Epoch 7/10\n",
      "1000/1000 [==============================] - 55s 55ms/step - loss: 0.0920 - acc: 0.9670\n",
      "Epoch 8/10\n",
      "1000/1000 [==============================] - 55s 55ms/step - loss: 0.0809 - acc: 0.9720\n",
      "Epoch 9/10\n",
      "1000/1000 [==============================] - 54s 54ms/step - loss: 0.0733 - acc: 0.9760\n",
      "Epoch 10/10\n",
      "1000/1000 [==============================] - 54s 54ms/step - loss: 0.0665 - acc: 0.9780\n",
      "Training on Epoch  4 batch  5  Files [5] start  5 / 459\n",
      "Epoch 1/10\n",
      "1000/1000 [==============================] - 53s 53ms/step - loss: 0.2500 - acc: 0.9140\n",
      "Epoch 2/10\n",
      "1000/1000 [==============================] - 53s 53ms/step - loss: 0.1839 - acc: 0.9400\n",
      "Epoch 3/10\n",
      "1000/1000 [==============================] - 53s 53ms/step - loss: 0.1426 - acc: 0.9590\n",
      "Epoch 4/10\n",
      "1000/1000 [==============================] - 53s 53ms/step - loss: 0.1155 - acc: 0.9680\n",
      "Epoch 5/10\n",
      "1000/1000 [==============================] - 53s 53ms/step - loss: 0.0940 - acc: 0.9710\n",
      "Epoch 6/10\n",
      "1000/1000 [==============================] - 53s 53ms/step - loss: 0.0793 - acc: 0.9750\n",
      "Epoch 7/10\n",
      "1000/1000 [==============================] - 53s 53ms/step - loss: 0.0665 - acc: 0.9810\n",
      "Epoch 8/10\n",
      "1000/1000 [==============================] - 53s 53ms/step - loss: 0.0548 - acc: 0.9830\n",
      "Epoch 9/10\n",
      "1000/1000 [==============================] - 54s 54ms/step - loss: 0.0497 - acc: 0.9860\n",
      "Epoch 10/10\n",
      "1000/1000 [==============================] - 53s 53ms/step - loss: 0.0447 - acc: 0.9880\n",
      "Training on Epoch  4 batch  5  Files [5] start  10 / 459\n",
      "Epoch 1/10\n",
      "1000/1000 [==============================] - 61s 61ms/step - loss: 0.3024 - acc: 0.8980\n",
      "Epoch 2/10\n",
      "1000/1000 [==============================] - 62s 62ms/step - loss: 0.2077 - acc: 0.9220\n",
      "Epoch 3/10\n",
      "1000/1000 [==============================] - 62s 62ms/step - loss: 0.1527 - acc: 0.9450\n",
      "Epoch 4/10\n",
      "1000/1000 [==============================] - 60s 60ms/step - loss: 0.1181 - acc: 0.9540\n",
      "Epoch 5/10\n",
      "1000/1000 [==============================] - 61s 61ms/step - loss: 0.0937 - acc: 0.9640\n",
      "Epoch 6/10\n",
      "1000/1000 [==============================] - 61s 61ms/step - loss: 0.0774 - acc: 0.9740\n",
      "Epoch 7/10\n",
      "1000/1000 [==============================] - 61s 61ms/step - loss: 0.0661 - acc: 0.9800\n",
      "Epoch 8/10\n",
      "1000/1000 [==============================] - 61s 61ms/step - loss: 0.0557 - acc: 0.9820\n",
      "Epoch 9/10\n",
      "1000/1000 [==============================] - 61s 61ms/step - loss: 0.0495 - acc: 0.9850\n",
      "Epoch 10/10\n",
      "1000/1000 [==============================] - 61s 61ms/step - loss: 0.0432 - acc: 0.9850\n",
      "Training on Epoch  4 batch  5  Files [5] start  15 / 459\n",
      "Epoch 1/10\n",
      "1000/1000 [==============================] - 60s 60ms/step - loss: 0.2932 - acc: 0.9010\n",
      "Epoch 2/10\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 0.2010 - acc: 0.9320\n",
      "Epoch 3/10\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 0.1482 - acc: 0.9490\n",
      "Epoch 4/10\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 0.1184 - acc: 0.9660\n",
      "Epoch 5/10\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 0.1009 - acc: 0.9720\n",
      "Epoch 6/10\n",
      "1000/1000 [==============================] - 58s 58ms/step - loss: 0.0830 - acc: 0.9750\n",
      "Epoch 7/10\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 0.0714 - acc: 0.9770\n",
      "Epoch 8/10\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 0.0637 - acc: 0.9790\n",
      "Epoch 9/10\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 0.0577 - acc: 0.9810\n",
      "Epoch 10/10\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 0.0526 - acc: 0.9830\n",
      "Training on Epoch  4 batch  5  Files [5] start  20 / 459\n",
      "Epoch 1/10\n",
      "1000/1000 [==============================] - 49s 49ms/step - loss: 0.3288 - acc: 0.8940\n",
      "Epoch 2/10\n",
      "1000/1000 [==============================] - 49s 49ms/step - loss: 0.2232 - acc: 0.9230\n",
      "Epoch 3/10\n",
      "1000/1000 [==============================] - 49s 49ms/step - loss: 0.1591 - acc: 0.9340\n",
      "Epoch 4/10\n",
      "1000/1000 [==============================] - 49s 49ms/step - loss: 0.1350 - acc: 0.9510\n",
      "Epoch 5/10\n",
      "1000/1000 [==============================] - 49s 49ms/step - loss: 0.1110 - acc: 0.9630\n",
      "Epoch 6/10\n",
      "1000/1000 [==============================] - 49s 49ms/step - loss: 0.0954 - acc: 0.9680\n",
      "Epoch 7/10\n",
      "1000/1000 [==============================] - 49s 49ms/step - loss: 0.0811 - acc: 0.9720\n",
      "Epoch 8/10\n",
      "1000/1000 [==============================] - 49s 49ms/step - loss: 0.0734 - acc: 0.9730\n",
      "Epoch 9/10\n",
      "1000/1000 [==============================] - 49s 49ms/step - loss: 0.0660 - acc: 0.9750\n",
      "Epoch 10/10\n",
      "1000/1000 [==============================] - 49s 49ms/step - loss: 0.0608 - acc: 0.9760\n",
      "Training on Epoch  4 batch  5  Files [5] start  25 / 459\n",
      "Epoch 1/10\n",
      "1000/1000 [==============================] - 65s 65ms/step - loss: 0.3399 - acc: 0.8810\n",
      "Epoch 2/10\n",
      "1000/1000 [==============================] - 65s 65ms/step - loss: 0.2389 - acc: 0.9110\n",
      "Epoch 3/10\n",
      "1000/1000 [==============================] - 65s 65ms/step - loss: 0.1792 - acc: 0.9290\n",
      "Epoch 4/10\n",
      "1000/1000 [==============================] - 66s 66ms/step - loss: 0.1466 - acc: 0.9400\n",
      "Epoch 5/10\n",
      "1000/1000 [==============================] - 65s 65ms/step - loss: 0.1228 - acc: 0.9580\n",
      "Epoch 6/10\n",
      "1000/1000 [==============================] - 66s 66ms/step - loss: 0.1076 - acc: 0.9580\n",
      "Epoch 7/10\n",
      "1000/1000 [==============================] - 66s 66ms/step - loss: 0.0938 - acc: 0.9660\n",
      "Epoch 8/10\n",
      "1000/1000 [==============================] - 65s 65ms/step - loss: 0.0796 - acc: 0.9710\n",
      "Epoch 9/10\n",
      "1000/1000 [==============================] - 66s 66ms/step - loss: 0.0683 - acc: 0.9770\n",
      "Epoch 10/10\n",
      "1000/1000 [==============================] - 65s 65ms/step - loss: 0.0613 - acc: 0.9800\n",
      "Training on Epoch  4 batch  5  Files [5] start  30 / 459\n",
      "Epoch 1/10\n",
      "1000/1000 [==============================] - 60s 60ms/step - loss: 0.3003 - acc: 0.8960\n",
      "Epoch 2/10\n",
      "1000/1000 [==============================] - 60s 60ms/step - loss: 0.2201 - acc: 0.9150\n",
      "Epoch 3/10\n",
      "1000/1000 [==============================] - 60s 60ms/step - loss: 0.1743 - acc: 0.9360\n",
      "Epoch 4/10\n",
      "1000/1000 [==============================] - 60s 60ms/step - loss: 0.1430 - acc: 0.9500\n",
      "Epoch 5/10\n",
      "1000/1000 [==============================] - 61s 61ms/step - loss: 0.1155 - acc: 0.9600\n",
      "Epoch 6/10\n",
      "1000/1000 [==============================] - 60s 60ms/step - loss: 0.0971 - acc: 0.9670\n",
      "Epoch 7/10\n",
      "1000/1000 [==============================] - 60s 60ms/step - loss: 0.0826 - acc: 0.9720\n",
      "Epoch 8/10\n",
      "1000/1000 [==============================] - 60s 60ms/step - loss: 0.0705 - acc: 0.9760\n",
      "Epoch 9/10\n",
      "1000/1000 [==============================] - 60s 60ms/step - loss: 0.0606 - acc: 0.9810\n",
      "Epoch 10/10\n",
      "1000/1000 [==============================] - 61s 61ms/step - loss: 0.0553 - acc: 0.9810\n",
      "Training on Epoch  4 batch  5  Files [5] start  35 / 459\n",
      "Epoch 1/10\n",
      "1000/1000 [==============================] - 66s 66ms/step - loss: 0.3108 - acc: 0.8930\n",
      "Epoch 2/10\n",
      "1000/1000 [==============================] - 63s 63ms/step - loss: 0.2103 - acc: 0.9280\n",
      "Epoch 3/10\n",
      "1000/1000 [==============================] - 64s 64ms/step - loss: 0.1572 - acc: 0.9410\n",
      "Epoch 4/10\n",
      "1000/1000 [==============================] - 64s 64ms/step - loss: 0.1274 - acc: 0.9500\n",
      "Epoch 5/10\n",
      "1000/1000 [==============================] - 64s 64ms/step - loss: 0.1140 - acc: 0.9530\n",
      "Epoch 6/10\n",
      "1000/1000 [==============================] - 65s 65ms/step - loss: 0.0998 - acc: 0.9650\n",
      "Epoch 7/10\n",
      "1000/1000 [==============================] - 74s 74ms/step - loss: 0.0883 - acc: 0.9690\n",
      "Epoch 8/10\n",
      "1000/1000 [==============================] - 84s 84ms/step - loss: 0.0791 - acc: 0.9710\n",
      "Epoch 9/10\n",
      "1000/1000 [==============================] - 68s 68ms/step - loss: 0.0692 - acc: 0.9730\n",
      "Epoch 10/10\n",
      "1000/1000 [==============================] - 65s 65ms/step - loss: 0.0662 - acc: 0.9740\n",
      "Training on Epoch  4 batch  5  Files [5] start  40 / 459\n",
      "Epoch 1/10\n",
      "1000/1000 [==============================] - 58s 58ms/step - loss: 0.2467 - acc: 0.9170\n",
      "Epoch 2/10\n",
      "1000/1000 [==============================] - 61s 61ms/step - loss: 0.1840 - acc: 0.9320\n",
      "Epoch 3/10\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 0.1360 - acc: 0.9500\n",
      "Epoch 4/10\n",
      "1000/1000 [==============================] - 61s 61ms/step - loss: 0.1179 - acc: 0.9460\n",
      "Epoch 5/10\n",
      "1000/1000 [==============================] - 60s 60ms/step - loss: 0.0934 - acc: 0.9650\n",
      "Epoch 6/10\n",
      "1000/1000 [==============================] - 60s 60ms/step - loss: 0.0853 - acc: 0.9700\n",
      "Epoch 7/10\n",
      "1000/1000 [==============================] - 60s 60ms/step - loss: 0.0786 - acc: 0.9740\n",
      "Epoch 8/10\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 0.0764 - acc: 0.9740\n",
      "Epoch 9/10\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 0.0646 - acc: 0.9780\n",
      "Epoch 10/10\n",
      "1000/1000 [==============================] - 60s 60ms/step - loss: 0.0581 - acc: 0.9800\n",
      "Training on Epoch  4 batch  5  Files [5] start  45 / 459\n",
      "Epoch 1/10\n",
      "1000/1000 [==============================] - 50s 50ms/step - loss: 0.3220 - acc: 0.8860\n",
      "Epoch 2/10\n",
      "1000/1000 [==============================] - 60s 60ms/step - loss: 0.2298 - acc: 0.9010\n",
      "Epoch 3/10\n",
      "1000/1000 [==============================] - 64s 64ms/step - loss: 0.1698 - acc: 0.9290\n",
      "Epoch 4/10\n",
      "1000/1000 [==============================] - 56s 56ms/step - loss: 0.1386 - acc: 0.9430\n",
      "Epoch 5/10\n",
      "1000/1000 [==============================] - 50s 50ms/step - loss: 0.1208 - acc: 0.9550\n",
      "Epoch 6/10\n",
      "1000/1000 [==============================] - 50s 50ms/step - loss: 0.1045 - acc: 0.9590\n",
      "Epoch 7/10\n",
      "1000/1000 [==============================] - 50s 50ms/step - loss: 0.0912 - acc: 0.9630\n",
      "Epoch 8/10\n",
      "1000/1000 [==============================] - 57s 57ms/step - loss: 0.0793 - acc: 0.9660\n",
      "Epoch 9/10\n",
      "1000/1000 [==============================] - 64s 64ms/step - loss: 0.0709 - acc: 0.9750\n",
      "Epoch 10/10\n",
      "1000/1000 [==============================] - 58s 58ms/step - loss: 0.0653 - acc: 0.9770\n",
      "Training on Epoch  4 batch  5  Files [5] start  50 / 459\n",
      "Epoch 1/10\n",
      "1000/1000 [==============================] - 57s 57ms/step - loss: 0.3212 - acc: 0.8880\n",
      "Epoch 2/10\n",
      "1000/1000 [==============================] - 56s 56ms/step - loss: 0.2334 - acc: 0.9070\n",
      "Epoch 3/10\n",
      "1000/1000 [==============================] - 57s 57ms/step - loss: 0.1708 - acc: 0.9310\n",
      "Epoch 4/10\n",
      "1000/1000 [==============================] - 57s 57ms/step - loss: 0.1332 - acc: 0.9480\n",
      "Epoch 5/10\n",
      "1000/1000 [==============================] - 56s 56ms/step - loss: 0.1052 - acc: 0.9620\n",
      "Epoch 6/10\n",
      "1000/1000 [==============================] - 57s 57ms/step - loss: 0.0879 - acc: 0.9700\n",
      "Epoch 7/10\n",
      "1000/1000 [==============================] - 62s 62ms/step - loss: 0.0784 - acc: 0.9730\n",
      "Epoch 8/10\n",
      "1000/1000 [==============================] - 70s 70ms/step - loss: 0.0684 - acc: 0.9730\n",
      "Epoch 9/10\n",
      "1000/1000 [==============================] - 65s 65ms/step - loss: 0.0618 - acc: 0.9770\n",
      "Epoch 10/10\n",
      "1000/1000 [==============================] - 57s 57ms/step - loss: 0.0563 - acc: 0.9800\n",
      "Training on Epoch  4 batch  5  Files [5] start  55 / 459\n",
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000/1000 [==============================] - 60s 60ms/step - loss: 0.2928 - acc: 0.8970\n",
      "Epoch 2/10\n",
      "1000/1000 [==============================] - 60s 60ms/step - loss: 0.2229 - acc: 0.9080\n",
      "Epoch 3/10\n",
      "1000/1000 [==============================] - 66s 66ms/step - loss: 0.1757 - acc: 0.9320\n",
      "Epoch 4/10\n",
      "1000/1000 [==============================] - 77s 77ms/step - loss: 0.1403 - acc: 0.9510\n",
      "Epoch 5/10\n",
      "1000/1000 [==============================] - 67s 67ms/step - loss: 0.1232 - acc: 0.9550\n",
      "Epoch 6/10\n",
      "1000/1000 [==============================] - 61s 61ms/step - loss: 0.1090 - acc: 0.9610\n",
      "Epoch 7/10\n",
      "1000/1000 [==============================] - 61s 61ms/step - loss: 0.0959 - acc: 0.9660\n",
      "Epoch 8/10\n",
      "1000/1000 [==============================] - 60s 60ms/step - loss: 0.0863 - acc: 0.9730\n",
      "Epoch 9/10\n",
      "1000/1000 [==============================] - 68s 68ms/step - loss: 0.0766 - acc: 0.9760\n",
      "Epoch 10/10\n",
      "1000/1000 [==============================] - 87s 87ms/step - loss: 0.0689 - acc: 0.9770\n",
      "Training on Epoch  4 batch  5  Files [5] start  60 / 459\n",
      "Epoch 1/10\n",
      "1000/1000 [==============================] - 83s 83ms/step - loss: 0.2891 - acc: 0.8940\n",
      "Epoch 2/10\n",
      "1000/1000 [==============================] - 87s 87ms/step - loss: 0.2138 - acc: 0.9140\n",
      "Epoch 3/10\n",
      "1000/1000 [==============================] - 83s 83ms/step - loss: 0.1682 - acc: 0.9310\n",
      "Epoch 4/10\n",
      "1000/1000 [==============================] - 63s 63ms/step - loss: 0.1278 - acc: 0.9510\n",
      "Epoch 5/10\n",
      "1000/1000 [==============================] - 51s 51ms/step - loss: 0.1136 - acc: 0.9570\n",
      "Epoch 6/10\n",
      "1000/1000 [==============================] - 51s 51ms/step - loss: 0.1012 - acc: 0.9650\n",
      "Epoch 7/10\n",
      "1000/1000 [==============================] - 50s 50ms/step - loss: 0.0907 - acc: 0.9660\n",
      "Epoch 8/10\n",
      "1000/1000 [==============================] - 51s 51ms/step - loss: 0.0821 - acc: 0.9720\n",
      "Epoch 9/10\n",
      "1000/1000 [==============================] - 51s 51ms/step - loss: 0.0717 - acc: 0.9730\n",
      "Epoch 10/10\n",
      "1000/1000 [==============================] - 52s 52ms/step - loss: 0.0683 - acc: 0.9730\n",
      "Training on Epoch  4 batch  5  Files [5] start  65 / 459\n",
      "Epoch 1/10\n",
      "1000/1000 [==============================] - 70s 70ms/step - loss: 0.2929 - acc: 0.9050\n",
      "Epoch 2/10\n",
      "1000/1000 [==============================] - 61s 61ms/step - loss: 0.2085 - acc: 0.9310\n",
      "Epoch 3/10\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 0.1693 - acc: 0.9330\n",
      "Epoch 4/10\n",
      "1000/1000 [==============================] - 70s 70ms/step - loss: 0.1403 - acc: 0.9480\n",
      "Epoch 5/10\n",
      "1000/1000 [==============================] - 66s 66ms/step - loss: 0.1213 - acc: 0.9570\n",
      "Epoch 6/10\n",
      "1000/1000 [==============================] - 61s 61ms/step - loss: 0.1073 - acc: 0.9610\n",
      "Epoch 7/10\n",
      "1000/1000 [==============================] - 68s 68ms/step - loss: 0.0960 - acc: 0.9640\n",
      "Epoch 8/10\n",
      "1000/1000 [==============================] - 64s 64ms/step - loss: 0.0864 - acc: 0.9670\n",
      "Epoch 9/10\n",
      "1000/1000 [==============================] - 61s 61ms/step - loss: 0.0789 - acc: 0.9710\n",
      "Epoch 10/10\n",
      "1000/1000 [==============================] - 71s 71ms/step - loss: 0.0722 - acc: 0.9720\n",
      "Training on Epoch  4 batch  5  Files [5] start  70 / 459\n",
      "Epoch 1/10\n",
      "1000/1000 [==============================] - 51s 51ms/step - loss: 0.2678 - acc: 0.9000\n",
      "Epoch 2/10\n",
      "1000/1000 [==============================] - 51s 51ms/step - loss: 0.2049 - acc: 0.9150\n",
      "Epoch 3/10\n",
      "1000/1000 [==============================] - 50s 50ms/step - loss: 0.1548 - acc: 0.9420\n",
      "Epoch 4/10\n",
      "1000/1000 [==============================] - 50s 50ms/step - loss: 0.1322 - acc: 0.9500\n",
      "Epoch 5/10\n",
      "1000/1000 [==============================] - 51s 51ms/step - loss: 0.1148 - acc: 0.9570\n",
      "Epoch 6/10\n",
      "1000/1000 [==============================] - 51s 51ms/step - loss: 0.1001 - acc: 0.9700\n",
      "Epoch 7/10\n",
      "1000/1000 [==============================] - 51s 51ms/step - loss: 0.0853 - acc: 0.9720\n",
      "Epoch 8/10\n",
      "1000/1000 [==============================] - 51s 51ms/step - loss: 0.0766 - acc: 0.9740\n",
      "Epoch 9/10\n",
      "1000/1000 [==============================] - 51s 51ms/step - loss: 0.0696 - acc: 0.9750\n",
      "Epoch 10/10\n",
      "1000/1000 [==============================] - 50s 50ms/step - loss: 0.0647 - acc: 0.9760\n",
      "Training on Epoch  4 batch  5  Files [5] start  75 / 459\n",
      "Epoch 1/10\n",
      "1000/1000 [==============================] - 58s 58ms/step - loss: 0.3616 - acc: 0.8740\n",
      "Epoch 2/10\n",
      "1000/1000 [==============================] - 58s 58ms/step - loss: 0.2694 - acc: 0.8870\n",
      "Epoch 3/10\n",
      "1000/1000 [==============================] - 57s 57ms/step - loss: 0.2119 - acc: 0.9080\n",
      "Epoch 4/10\n",
      "1000/1000 [==============================] - 57s 57ms/step - loss: 0.1732 - acc: 0.9190\n",
      "Epoch 5/10\n",
      "1000/1000 [==============================] - 58s 58ms/step - loss: 0.1543 - acc: 0.9320\n",
      "Epoch 6/10\n",
      "1000/1000 [==============================] - 58s 58ms/step - loss: 0.1359 - acc: 0.9440\n",
      "Epoch 7/10\n",
      "1000/1000 [==============================] - 57s 57ms/step - loss: 0.1224 - acc: 0.9460\n",
      "Epoch 8/10\n",
      "1000/1000 [==============================] - 57s 57ms/step - loss: 0.1107 - acc: 0.9580\n",
      "Epoch 9/10\n",
      "1000/1000 [==============================] - 57s 57ms/step - loss: 0.1024 - acc: 0.9570\n",
      "Epoch 10/10\n",
      "1000/1000 [==============================] - 57s 57ms/step - loss: 0.0941 - acc: 0.9600\n",
      "Training on Epoch  4 batch  5  Files [5] start  80 / 459\n",
      "Epoch 1/10\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 0.3373 - acc: 0.8880\n",
      "Epoch 2/10\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 0.2603 - acc: 0.9160\n",
      "Epoch 3/10\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 0.1994 - acc: 0.9240\n",
      "Epoch 4/10\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 0.1615 - acc: 0.9380\n",
      "Epoch 5/10\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 0.1377 - acc: 0.9470\n",
      "Epoch 6/10\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 0.1224 - acc: 0.9530\n",
      "Epoch 7/10\n",
      "1000/1000 [==============================] - 60s 60ms/step - loss: 0.1052 - acc: 0.9600\n",
      "Epoch 8/10\n",
      "1000/1000 [==============================] - 60s 60ms/step - loss: 0.0953 - acc: 0.9660\n",
      "Epoch 9/10\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 0.0859 - acc: 0.9670\n",
      "Epoch 10/10\n",
      "1000/1000 [==============================] - 60s 60ms/step - loss: 0.0787 - acc: 0.9700\n",
      "Training on Epoch  4 batch  5  Files [5] start  85 / 459\n",
      "Epoch 1/10\n",
      "1000/1000 [==============================] - 58s 58ms/step - loss: 0.3009 - acc: 0.8890\n",
      "Epoch 2/10\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 0.2263 - acc: 0.9160\n",
      "Epoch 3/10\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 0.1749 - acc: 0.9300\n",
      "Epoch 4/10\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 0.1395 - acc: 0.9460\n",
      "Epoch 5/10\n",
      "1000/1000 [==============================] - 58s 58ms/step - loss: 0.1163 - acc: 0.9550\n",
      "Epoch 6/10\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 0.1048 - acc: 0.9600\n",
      "Epoch 7/10\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 0.0926 - acc: 0.9650\n",
      "Epoch 8/10\n",
      "1000/1000 [==============================] - 58s 58ms/step - loss: 0.0823 - acc: 0.9690\n",
      "Epoch 9/10\n",
      "1000/1000 [==============================] - 58s 58ms/step - loss: 0.0745 - acc: 0.9750\n",
      "Epoch 10/10\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 0.0685 - acc: 0.9750\n",
      "Training on Epoch  4 batch  5  Files [5] start  90 / 459\n",
      "Epoch 1/10\n",
      "1000/1000 [==============================] - 51s 51ms/step - loss: 0.3226 - acc: 0.8940\n",
      "Epoch 2/10\n",
      "1000/1000 [==============================] - 50s 50ms/step - loss: 0.2207 - acc: 0.9240\n",
      "Epoch 3/10\n",
      "1000/1000 [==============================] - 51s 51ms/step - loss: 0.1699 - acc: 0.9390\n",
      "Epoch 4/10\n",
      "1000/1000 [==============================] - 50s 50ms/step - loss: 0.1445 - acc: 0.9450\n",
      "Epoch 5/10\n",
      "1000/1000 [==============================] - 50s 50ms/step - loss: 0.1199 - acc: 0.9610\n",
      "Epoch 6/10\n",
      "1000/1000 [==============================] - 50s 50ms/step - loss: 0.1023 - acc: 0.9690\n",
      "Epoch 7/10\n",
      "1000/1000 [==============================] - 51s 51ms/step - loss: 0.0913 - acc: 0.9730\n",
      "Epoch 8/10\n",
      "1000/1000 [==============================] - 51s 51ms/step - loss: 0.0808 - acc: 0.9750\n",
      "Epoch 9/10\n",
      "1000/1000 [==============================] - 51s 51ms/step - loss: 0.0721 - acc: 0.9770\n",
      "Epoch 10/10\n",
      "1000/1000 [==============================] - 50s 50ms/step - loss: 0.0644 - acc: 0.9810\n",
      "Training on Epoch  4 batch  5  Files [5] start  95 / 459\n",
      "Epoch 1/10\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 0.2984 - acc: 0.8910\n",
      "Epoch 2/10\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 0.2089 - acc: 0.9190\n",
      "Epoch 3/10\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 0.1601 - acc: 0.9410\n",
      "Epoch 4/10\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 0.1286 - acc: 0.9570\n",
      "Epoch 5/10\n",
      "1000/1000 [==============================] - 58s 58ms/step - loss: 0.1103 - acc: 0.9630\n",
      "Epoch 6/10\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 0.0950 - acc: 0.9680\n",
      "Epoch 7/10\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 0.0845 - acc: 0.9710\n",
      "Epoch 8/10\n",
      "1000/1000 [==============================] - 61s 61ms/step - loss: 0.0753 - acc: 0.9730\n",
      "Epoch 9/10\n",
      "1000/1000 [==============================] - 60s 60ms/step - loss: 0.0689 - acc: 0.9750\n",
      "Epoch 10/10\n",
      "1000/1000 [==============================] - 62s 62ms/step - loss: 0.0614 - acc: 0.9770\n",
      "Training on Epoch  4 batch  5  Files [5] start  100 / 459\n",
      "Epoch 1/10\n",
      "1000/1000 [==============================] - 68s 68ms/step - loss: 0.3370 - acc: 0.9000\n",
      "Epoch 2/10\n",
      "1000/1000 [==============================] - 67s 67ms/step - loss: 0.2015 - acc: 0.9200\n",
      "Epoch 3/10\n",
      "1000/1000 [==============================] - 68s 68ms/step - loss: 0.1368 - acc: 0.9420\n",
      "Epoch 4/10\n",
      "1000/1000 [==============================] - 70s 70ms/step - loss: 0.1052 - acc: 0.9590\n",
      "Epoch 5/10\n",
      "1000/1000 [==============================] - 63s 63ms/step - loss: 0.0855 - acc: 0.9760\n",
      "Epoch 6/10\n",
      "1000/1000 [==============================] - 65s 65ms/step - loss: 0.0702 - acc: 0.9800\n",
      "Epoch 7/10\n",
      "1000/1000 [==============================] - 64s 64ms/step - loss: 0.0522 - acc: 0.9850\n",
      "Epoch 8/10\n",
      "1000/1000 [==============================] - 67s 67ms/step - loss: 0.0483 - acc: 0.9880\n",
      "Epoch 9/10\n",
      "1000/1000 [==============================] - 65s 65ms/step - loss: 0.0402 - acc: 0.9910\n",
      "Epoch 10/10\n",
      "1000/1000 [==============================] - 63s 63ms/step - loss: 0.0339 - acc: 0.9920\n",
      "Training on Epoch  4 batch  5  Files [5] start  105 / 459\n",
      "Epoch 1/10\n",
      "1000/1000 [==============================] - 63s 63ms/step - loss: 0.3328 - acc: 0.8940\n",
      "Epoch 2/10\n",
      "1000/1000 [==============================] - 62s 62ms/step - loss: 0.2334 - acc: 0.9230\n",
      "Epoch 3/10\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 0.1686 - acc: 0.9460\n",
      "Epoch 4/10\n",
      "1000/1000 [==============================] - 60s 60ms/step - loss: 0.1355 - acc: 0.9620\n",
      "Epoch 5/10\n",
      "1000/1000 [==============================] - 61s 61ms/step - loss: 0.1165 - acc: 0.9620\n",
      "Epoch 6/10\n",
      "1000/1000 [==============================] - 60s 60ms/step - loss: 0.0980 - acc: 0.9750\n",
      "Epoch 7/10\n",
      "1000/1000 [==============================] - 66s 66ms/step - loss: 0.0833 - acc: 0.9810\n",
      "Epoch 8/10\n",
      "1000/1000 [==============================] - 63s 63ms/step - loss: 0.0679 - acc: 0.9850\n",
      "Epoch 9/10\n",
      "1000/1000 [==============================] - 61s 61ms/step - loss: 0.0592 - acc: 0.9910\n",
      "Epoch 10/10\n",
      "1000/1000 [==============================] - 60s 60ms/step - loss: 0.0541 - acc: 0.9930\n",
      "Training on Epoch  4 batch  5  Files [5] start  110 / 459\n",
      "Epoch 1/10\n",
      "1000/1000 [==============================] - 73s 73ms/step - loss: 0.2810 - acc: 0.8860\n",
      "Epoch 2/10\n",
      "1000/1000 [==============================] - 72s 72ms/step - loss: 0.1908 - acc: 0.9190\n",
      "Epoch 3/10\n",
      "1000/1000 [==============================] - 71s 71ms/step - loss: 0.1417 - acc: 0.9490\n",
      "Epoch 4/10\n",
      "1000/1000 [==============================] - 71s 71ms/step - loss: 0.1163 - acc: 0.9570\n",
      "Epoch 5/10\n",
      "1000/1000 [==============================] - 69s 69ms/step - loss: 0.0941 - acc: 0.9690\n",
      "Epoch 6/10\n",
      "1000/1000 [==============================] - 71s 71ms/step - loss: 0.0796 - acc: 0.9770\n",
      "Epoch 7/10\n",
      "1000/1000 [==============================] - 73s 73ms/step - loss: 0.0678 - acc: 0.9780\n",
      "Epoch 8/10\n",
      "1000/1000 [==============================] - 71s 71ms/step - loss: 0.0590 - acc: 0.9840\n",
      "Epoch 9/10\n",
      "1000/1000 [==============================] - 75s 75ms/step - loss: 0.0528 - acc: 0.9840\n",
      "Epoch 10/10\n",
      "1000/1000 [==============================] - 75s 75ms/step - loss: 0.0494 - acc: 0.9840\n",
      "Training on Epoch  4 batch  5  Files [5] start  115 / 459\n",
      "Epoch 1/10\n",
      "1000/1000 [==============================] - 72s 72ms/step - loss: 0.3641 - acc: 0.8660\n",
      "Epoch 2/10\n",
      "1000/1000 [==============================] - 71s 71ms/step - loss: 0.2710 - acc: 0.8870\n",
      "Epoch 3/10\n",
      "1000/1000 [==============================] - 71s 71ms/step - loss: 0.2161 - acc: 0.9080\n",
      "Epoch 4/10\n",
      "1000/1000 [==============================] - 73s 73ms/step - loss: 0.1760 - acc: 0.9230\n",
      "Epoch 5/10\n",
      "1000/1000 [==============================] - 60s 60ms/step - loss: 0.1534 - acc: 0.9330\n",
      "Epoch 6/10\n",
      "1000/1000 [==============================] - 60s 60ms/step - loss: 0.1349 - acc: 0.9410\n",
      "Epoch 7/10\n",
      "1000/1000 [==============================] - 63s 63ms/step - loss: 0.1261 - acc: 0.9470\n",
      "Epoch 8/10\n",
      "1000/1000 [==============================] - 60s 60ms/step - loss: 0.1183 - acc: 0.9500\n",
      "Epoch 9/10\n",
      "1000/1000 [==============================] - 61s 61ms/step - loss: 0.1116 - acc: 0.9500\n",
      "Epoch 10/10\n",
      "1000/1000 [==============================] - 61s 61ms/step - loss: 0.1072 - acc: 0.9520\n",
      "Training on Epoch  4 batch  5  Files [5] start  120 / 459\n",
      "Epoch 1/10\n",
      "1000/1000 [==============================] - 61s 61ms/step - loss: 0.2360 - acc: 0.8810\n",
      "Epoch 2/10\n",
      "1000/1000 [==============================] - 62s 62ms/step - loss: 0.2058 - acc: 0.8930\n",
      "Epoch 3/10\n",
      "1000/1000 [==============================] - 62s 62ms/step - loss: 0.1885 - acc: 0.9080\n",
      "Epoch 4/10\n",
      "1000/1000 [==============================] - 63s 63ms/step - loss: 0.1785 - acc: 0.9160\n",
      "Epoch 5/10\n",
      "1000/1000 [==============================] - 63s 63ms/step - loss: 0.1717 - acc: 0.9210\n",
      "Epoch 6/10\n",
      "1000/1000 [==============================] - 64s 64ms/step - loss: 0.1662 - acc: 0.9290\n",
      "Epoch 7/10\n",
      "1000/1000 [==============================] - 63s 63ms/step - loss: 0.1603 - acc: 0.9310\n",
      "Epoch 8/10\n",
      "1000/1000 [==============================] - 63s 63ms/step - loss: 0.1555 - acc: 0.9300\n",
      "Epoch 9/10\n",
      "1000/1000 [==============================] - 63s 63ms/step - loss: 0.1503 - acc: 0.9340\n",
      "Epoch 10/10\n",
      "1000/1000 [==============================] - 63s 63ms/step - loss: 0.1468 - acc: 0.9360\n",
      "Training on Epoch  4 batch  5  Files [5] start  125 / 459\n",
      "Epoch 1/10\n",
      "1000/1000 [==============================] - 72s 72ms/step - loss: 0.3162 - acc: 0.8660\n",
      "Epoch 2/10\n",
      "1000/1000 [==============================] - 73s 73ms/step - loss: 0.2420 - acc: 0.8860\n",
      "Epoch 3/10\n",
      "1000/1000 [==============================] - 72s 72ms/step - loss: 0.2149 - acc: 0.8960\n",
      "Epoch 4/10\n",
      "1000/1000 [==============================] - 74s 74ms/step - loss: 0.1954 - acc: 0.9030\n",
      "Epoch 5/10\n",
      "1000/1000 [==============================] - 73s 73ms/step - loss: 0.1787 - acc: 0.9160\n",
      "Epoch 6/10\n",
      "1000/1000 [==============================] - 73s 73ms/step - loss: 0.1738 - acc: 0.9190\n",
      "Epoch 7/10\n",
      "1000/1000 [==============================] - 72s 72ms/step - loss: 0.1651 - acc: 0.9270\n",
      "Epoch 8/10\n",
      "1000/1000 [==============================] - 72s 72ms/step - loss: 0.1572 - acc: 0.9300\n",
      "Epoch 9/10\n",
      "1000/1000 [==============================] - 68s 68ms/step - loss: 0.1518 - acc: 0.9270\n",
      "Epoch 10/10\n",
      "1000/1000 [==============================] - 68s 68ms/step - loss: 0.1479 - acc: 0.9280\n",
      "Training on Epoch  4 batch  5  Files [5] start  130 / 459\n",
      "Epoch 1/10\n",
      "1000/1000 [==============================] - 69s 69ms/step - loss: 0.3582 - acc: 0.8490\n",
      "Epoch 2/10\n",
      "1000/1000 [==============================] - 69s 69ms/step - loss: 0.2936 - acc: 0.8620\n",
      "Epoch 3/10\n",
      "1000/1000 [==============================] - 69s 69ms/step - loss: 0.2503 - acc: 0.8840\n",
      "Epoch 4/10\n",
      "1000/1000 [==============================] - 71s 71ms/step - loss: 0.2300 - acc: 0.8990\n",
      "Epoch 5/10\n",
      "1000/1000 [==============================] - 70s 70ms/step - loss: 0.2127 - acc: 0.9080\n",
      "Epoch 6/10\n",
      "1000/1000 [==============================] - 71s 71ms/step - loss: 0.1986 - acc: 0.9170\n",
      "Epoch 7/10\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000/1000 [==============================] - 71s 71ms/step - loss: 0.1872 - acc: 0.9190\n",
      "Epoch 8/10\n",
      "1000/1000 [==============================] - 70s 70ms/step - loss: 0.1791 - acc: 0.9220\n",
      "Epoch 9/10\n",
      "1000/1000 [==============================] - 70s 70ms/step - loss: 0.1752 - acc: 0.9240\n",
      "Epoch 10/10\n",
      "1000/1000 [==============================] - 71s 71ms/step - loss: 0.1673 - acc: 0.9260\n",
      "Training on Epoch  4 batch  5  Files [5] start  135 / 459\n",
      "Epoch 1/10\n",
      "1000/1000 [==============================] - 68s 68ms/step - loss: 0.3545 - acc: 0.8520\n",
      "Epoch 2/10\n",
      "1000/1000 [==============================] - 69s 69ms/step - loss: 0.2955 - acc: 0.8540\n",
      "Epoch 3/10\n",
      "1000/1000 [==============================] - 70s 70ms/step - loss: 0.2609 - acc: 0.8740\n",
      "Epoch 4/10\n",
      "1000/1000 [==============================] - 70s 70ms/step - loss: 0.2383 - acc: 0.8960\n",
      "Epoch 5/10\n",
      "1000/1000 [==============================] - 69s 69ms/step - loss: 0.2202 - acc: 0.9000\n",
      "Epoch 6/10\n",
      "1000/1000 [==============================] - 69s 69ms/step - loss: 0.2056 - acc: 0.9040\n",
      "Epoch 7/10\n",
      "1000/1000 [==============================] - 70s 70ms/step - loss: 0.1970 - acc: 0.9050\n",
      "Epoch 8/10\n",
      "1000/1000 [==============================] - 69s 69ms/step - loss: 0.1904 - acc: 0.9080\n",
      "Epoch 9/10\n",
      "1000/1000 [==============================] - 70s 70ms/step - loss: 0.1843 - acc: 0.9060\n",
      "Epoch 10/10\n",
      "1000/1000 [==============================] - 68s 68ms/step - loss: 0.1795 - acc: 0.9070\n",
      "Training on Epoch  4 batch  5  Files [5] start  140 / 459\n",
      "Epoch 1/10\n",
      "1000/1000 [==============================] - 66s 66ms/step - loss: 0.3245 - acc: 0.8620\n",
      "Epoch 2/10\n",
      "1000/1000 [==============================] - 67s 67ms/step - loss: 0.2492 - acc: 0.8990\n",
      "Epoch 3/10\n",
      "1000/1000 [==============================] - 68s 68ms/step - loss: 0.2015 - acc: 0.9120\n",
      "Epoch 4/10\n",
      "1000/1000 [==============================] - 68s 68ms/step - loss: 0.1807 - acc: 0.9170\n",
      "Epoch 5/10\n",
      "1000/1000 [==============================] - 67s 67ms/step - loss: 0.1544 - acc: 0.9310\n",
      "Epoch 6/10\n",
      "1000/1000 [==============================] - 66s 66ms/step - loss: 0.1406 - acc: 0.9360\n",
      "Epoch 7/10\n",
      "1000/1000 [==============================] - 66s 66ms/step - loss: 0.1309 - acc: 0.9360\n",
      "Epoch 8/10\n",
      "1000/1000 [==============================] - 63s 63ms/step - loss: 0.1229 - acc: 0.9400\n",
      "Epoch 9/10\n",
      "1000/1000 [==============================] - 64s 64ms/step - loss: 0.1192 - acc: 0.9390\n",
      "Epoch 10/10\n",
      "1000/1000 [==============================] - 64s 64ms/step - loss: 0.1154 - acc: 0.9420\n",
      "Training on Epoch  4 batch  5  Files [5] start  145 / 459\n",
      "Epoch 1/10\n",
      "1000/1000 [==============================] - 62s 62ms/step - loss: 0.2631 - acc: 0.8990\n",
      "Epoch 2/10\n",
      "1000/1000 [==============================] - 63s 63ms/step - loss: 0.1891 - acc: 0.9280\n",
      "Epoch 3/10\n",
      "1000/1000 [==============================] - 62s 62ms/step - loss: 0.1417 - acc: 0.9380\n",
      "Epoch 4/10\n",
      "1000/1000 [==============================] - 62s 62ms/step - loss: 0.1107 - acc: 0.9600\n",
      "Epoch 5/10\n",
      "1000/1000 [==============================] - 63s 63ms/step - loss: 0.0997 - acc: 0.9650\n",
      "Epoch 6/10\n",
      "1000/1000 [==============================] - 66s 66ms/step - loss: 0.0803 - acc: 0.9740\n",
      "Epoch 7/10\n",
      "1000/1000 [==============================] - 63s 63ms/step - loss: 0.0685 - acc: 0.9800\n",
      "Epoch 8/10\n",
      "1000/1000 [==============================] - 66s 66ms/step - loss: 0.0596 - acc: 0.9820\n",
      "Epoch 9/10\n",
      "1000/1000 [==============================] - 63s 63ms/step - loss: 0.0512 - acc: 0.9850\n",
      "Epoch 10/10\n",
      "1000/1000 [==============================] - 61s 61ms/step - loss: 0.0446 - acc: 0.9860\n",
      "Training on Epoch  4 batch  5  Files [5] start  150 / 459\n",
      "Epoch 1/10\n",
      "1000/1000 [==============================] - 66s 66ms/step - loss: 0.3183 - acc: 0.8940\n",
      "Epoch 2/10\n",
      "1000/1000 [==============================] - 66s 66ms/step - loss: 0.2406 - acc: 0.9060\n",
      "Epoch 3/10\n",
      "1000/1000 [==============================] - 67s 67ms/step - loss: 0.1791 - acc: 0.9310\n",
      "Epoch 4/10\n",
      "1000/1000 [==============================] - 69s 69ms/step - loss: 0.1522 - acc: 0.9400\n",
      "Epoch 5/10\n",
      "1000/1000 [==============================] - 68s 68ms/step - loss: 0.1249 - acc: 0.9530\n",
      "Epoch 6/10\n",
      "1000/1000 [==============================] - 68s 68ms/step - loss: 0.1120 - acc: 0.9570\n",
      "Epoch 7/10\n",
      "1000/1000 [==============================] - 67s 67ms/step - loss: 0.1007 - acc: 0.9610\n",
      "Epoch 8/10\n",
      "1000/1000 [==============================] - 67s 67ms/step - loss: 0.0931 - acc: 0.9640\n",
      "Epoch 9/10\n",
      "1000/1000 [==============================] - 71s 71ms/step - loss: 0.0863 - acc: 0.9680\n",
      "Epoch 10/10\n",
      "1000/1000 [==============================] - 69s 69ms/step - loss: 0.0805 - acc: 0.9690\n",
      "Training on Epoch  4 batch  5  Files [5] start  155 / 459\n",
      "Epoch 1/10\n",
      "1000/1000 [==============================] - 72s 72ms/step - loss: 0.2139 - acc: 0.9120\n",
      "Epoch 2/10\n",
      "1000/1000 [==============================] - 73s 73ms/step - loss: 0.1703 - acc: 0.9310\n",
      "Epoch 3/10\n",
      "1000/1000 [==============================] - 73s 73ms/step - loss: 0.1400 - acc: 0.9450\n",
      "Epoch 4/10\n",
      "1000/1000 [==============================] - 72s 72ms/step - loss: 0.1219 - acc: 0.9520\n",
      "Epoch 5/10\n",
      "1000/1000 [==============================] - 73s 73ms/step - loss: 0.1102 - acc: 0.9550\n",
      "Epoch 6/10\n",
      "1000/1000 [==============================] - 73s 73ms/step - loss: 0.0976 - acc: 0.9600\n",
      "Epoch 7/10\n",
      "1000/1000 [==============================] - 73s 73ms/step - loss: 0.0905 - acc: 0.9630\n",
      "Epoch 8/10\n",
      "1000/1000 [==============================] - 72s 72ms/step - loss: 0.0853 - acc: 0.9670\n",
      "Epoch 9/10\n",
      "1000/1000 [==============================] - 72s 72ms/step - loss: 0.0817 - acc: 0.9670\n",
      "Epoch 10/10\n",
      "1000/1000 [==============================] - 72s 72ms/step - loss: 0.0777 - acc: 0.9670\n",
      "Training on Epoch  4 batch  5  Files [5] start  160 / 459\n",
      "Epoch 1/10\n",
      "1000/1000 [==============================] - 68s 68ms/step - loss: 0.2212 - acc: 0.9080\n",
      "Epoch 2/10\n",
      "1000/1000 [==============================] - 68s 68ms/step - loss: 0.1661 - acc: 0.9240\n",
      "Epoch 3/10\n",
      "1000/1000 [==============================] - 68s 68ms/step - loss: 0.1289 - acc: 0.9360\n",
      "Epoch 4/10\n",
      "1000/1000 [==============================] - 69s 69ms/step - loss: 0.1089 - acc: 0.9460\n",
      "Epoch 5/10\n",
      "1000/1000 [==============================] - 69s 69ms/step - loss: 0.0933 - acc: 0.9550\n",
      "Epoch 6/10\n",
      "1000/1000 [==============================] - 68s 68ms/step - loss: 0.0850 - acc: 0.9590\n",
      "Epoch 7/10\n",
      "1000/1000 [==============================] - 69s 69ms/step - loss: 0.0782 - acc: 0.9610\n",
      "Epoch 8/10\n",
      "1000/1000 [==============================] - 68s 68ms/step - loss: 0.0727 - acc: 0.9630\n",
      "Epoch 9/10\n",
      "1000/1000 [==============================] - 68s 68ms/step - loss: 0.0684 - acc: 0.9660\n",
      "Epoch 10/10\n",
      "1000/1000 [==============================] - 68s 68ms/step - loss: 0.0642 - acc: 0.9690\n",
      "Training on Epoch  4 batch  5  Files [5] start  165 / 459\n",
      "Epoch 1/10\n",
      "1000/1000 [==============================] - 75s 75ms/step - loss: 0.2022 - acc: 0.9030\n",
      "Epoch 2/10\n",
      "1000/1000 [==============================] - 75s 75ms/step - loss: 0.1694 - acc: 0.9080\n",
      "Epoch 3/10\n",
      "1000/1000 [==============================] - 75s 75ms/step - loss: 0.1420 - acc: 0.9300\n",
      "Epoch 4/10\n",
      "1000/1000 [==============================] - 75s 75ms/step - loss: 0.1227 - acc: 0.9450\n",
      "Epoch 5/10\n",
      "1000/1000 [==============================] - 75s 75ms/step - loss: 0.1113 - acc: 0.9490\n",
      "Epoch 6/10\n",
      "1000/1000 [==============================] - 75s 75ms/step - loss: 0.1021 - acc: 0.9550\n",
      "Epoch 7/10\n",
      "1000/1000 [==============================] - 75s 75ms/step - loss: 0.0957 - acc: 0.9580\n",
      "Epoch 8/10\n",
      "1000/1000 [==============================] - 75s 75ms/step - loss: 0.0892 - acc: 0.9620\n",
      "Epoch 9/10\n",
      "1000/1000 [==============================] - 75s 75ms/step - loss: 0.0839 - acc: 0.9680\n",
      "Epoch 10/10\n",
      "1000/1000 [==============================] - 74s 74ms/step - loss: 0.0797 - acc: 0.9640\n",
      "Training on Epoch  4 batch  5  Files [5] start  170 / 459\n",
      "Epoch 1/10\n",
      "1000/1000 [==============================] - 91s 91ms/step - loss: 0.1617 - acc: 0.9360\n",
      "Epoch 2/10\n",
      "1000/1000 [==============================] - 92s 92ms/step - loss: 0.1166 - acc: 0.9530\n",
      "Epoch 3/10\n",
      "1000/1000 [==============================] - 92s 92ms/step - loss: 0.0962 - acc: 0.9610\n",
      "Epoch 4/10\n",
      "1000/1000 [==============================] - 92s 92ms/step - loss: 0.0816 - acc: 0.9670\n",
      "Epoch 5/10\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000/1000 [==============================] - 90s 90ms/step - loss: 0.0747 - acc: 0.9700\n",
      "Epoch 6/10\n",
      "1000/1000 [==============================] - 90s 90ms/step - loss: 0.0670 - acc: 0.9710\n",
      "Epoch 7/10\n",
      "1000/1000 [==============================] - 90s 90ms/step - loss: 0.0616 - acc: 0.9750\n",
      "Epoch 8/10\n",
      "1000/1000 [==============================] - 90s 90ms/step - loss: 0.0569 - acc: 0.9760\n",
      "Epoch 9/10\n",
      "1000/1000 [==============================] - 89s 89ms/step - loss: 0.0537 - acc: 0.9770\n",
      "Epoch 10/10\n",
      "1000/1000 [==============================] - 89s 89ms/step - loss: 0.0521 - acc: 0.9760\n",
      "Training on Epoch  4 batch  5  Files [5] start  175 / 459\n",
      "Epoch 1/10\n",
      "1000/1000 [==============================] - 79s 79ms/step - loss: 0.2162 - acc: 0.9090\n",
      "Epoch 2/10\n",
      "1000/1000 [==============================] - 79s 79ms/step - loss: 0.1563 - acc: 0.9270\n",
      "Epoch 3/10\n",
      "1000/1000 [==============================] - 79s 79ms/step - loss: 0.1223 - acc: 0.9400\n",
      "Epoch 4/10\n",
      "1000/1000 [==============================] - 80s 80ms/step - loss: 0.1038 - acc: 0.9520\n",
      "Epoch 5/10\n",
      "1000/1000 [==============================] - 79s 79ms/step - loss: 0.0934 - acc: 0.9580\n",
      "Epoch 6/10\n",
      "1000/1000 [==============================] - 79s 79ms/step - loss: 0.0851 - acc: 0.9620\n",
      "Epoch 7/10\n",
      "1000/1000 [==============================] - 79s 79ms/step - loss: 0.0811 - acc: 0.9710\n",
      "Epoch 8/10\n",
      "1000/1000 [==============================] - 79s 79ms/step - loss: 0.0749 - acc: 0.9730\n",
      "Epoch 9/10\n",
      "1000/1000 [==============================] - 78s 78ms/step - loss: 0.0712 - acc: 0.9720\n",
      "Epoch 10/10\n",
      "1000/1000 [==============================] - 78s 78ms/step - loss: 0.0674 - acc: 0.9720\n",
      "Training on Epoch  4 batch  5  Files [5] start  180 / 459\n",
      "Epoch 1/10\n",
      "1000/1000 [==============================] - 84s 84ms/step - loss: 0.1347 - acc: 0.9290\n",
      "Epoch 2/10\n",
      "1000/1000 [==============================] - 85s 85ms/step - loss: 0.1126 - acc: 0.9440\n",
      "Epoch 3/10\n",
      "1000/1000 [==============================] - 85s 85ms/step - loss: 0.0975 - acc: 0.9490\n",
      "Epoch 4/10\n",
      "1000/1000 [==============================] - 84s 84ms/step - loss: 0.0861 - acc: 0.9570\n",
      "Epoch 5/10\n",
      "1000/1000 [==============================] - 84s 84ms/step - loss: 0.0786 - acc: 0.9640\n",
      "Epoch 6/10\n",
      "1000/1000 [==============================] - 84s 84ms/step - loss: 0.0731 - acc: 0.9650\n",
      "Epoch 7/10\n",
      "1000/1000 [==============================] - 84s 84ms/step - loss: 0.0687 - acc: 0.9680\n",
      "Epoch 8/10\n",
      "1000/1000 [==============================] - 86s 86ms/step - loss: 0.0670 - acc: 0.9700\n",
      "Epoch 9/10\n",
      "1000/1000 [==============================] - 79s 79ms/step - loss: 0.0633 - acc: 0.9740\n",
      "Epoch 10/10\n",
      "1000/1000 [==============================] - 80s 80ms/step - loss: 0.0615 - acc: 0.9730\n",
      "Training on Epoch  4 batch  5  Files [5] start  185 / 459\n",
      "Epoch 1/10\n",
      "1000/1000 [==============================] - 70s 70ms/step - loss: 0.1593 - acc: 0.9300\n",
      "Epoch 2/10\n",
      "1000/1000 [==============================] - 70s 70ms/step - loss: 0.1447 - acc: 0.9290\n",
      "Epoch 3/10\n",
      "1000/1000 [==============================] - 70s 70ms/step - loss: 0.1294 - acc: 0.9360\n",
      "Epoch 4/10\n",
      "1000/1000 [==============================] - 69s 69ms/step - loss: 0.1174 - acc: 0.9480\n",
      "Epoch 5/10\n",
      "1000/1000 [==============================] - 68s 68ms/step - loss: 0.1144 - acc: 0.9440\n",
      "Epoch 6/10\n",
      "1000/1000 [==============================] - 69s 69ms/step - loss: 0.1080 - acc: 0.9470\n",
      "Epoch 7/10\n",
      "1000/1000 [==============================] - 69s 69ms/step - loss: 0.1050 - acc: 0.9470\n",
      "Epoch 8/10\n",
      "1000/1000 [==============================] - 69s 69ms/step - loss: 0.1011 - acc: 0.9510\n",
      "Epoch 9/10\n",
      "1000/1000 [==============================] - 69s 69ms/step - loss: 0.0987 - acc: 0.9530\n",
      "Epoch 10/10\n",
      "1000/1000 [==============================] - 68s 68ms/step - loss: 0.0973 - acc: 0.9530\n",
      "Training on Epoch  4 batch  5  Files [5] start  190 / 459\n",
      "Epoch 1/10\n",
      "1000/1000 [==============================] - 56s 56ms/step - loss: 0.1685 - acc: 0.9220\n",
      "Epoch 2/10\n",
      "1000/1000 [==============================] - 56s 56ms/step - loss: 0.1397 - acc: 0.9310\n",
      "Epoch 3/10\n",
      "1000/1000 [==============================] - 56s 56ms/step - loss: 0.1180 - acc: 0.9400\n",
      "Epoch 4/10\n",
      "1000/1000 [==============================] - 56s 56ms/step - loss: 0.1087 - acc: 0.9440\n",
      "Epoch 5/10\n",
      "1000/1000 [==============================] - 56s 56ms/step - loss: 0.1032 - acc: 0.9460\n",
      "Epoch 6/10\n",
      "1000/1000 [==============================] - 56s 56ms/step - loss: 0.0964 - acc: 0.9490\n",
      "Epoch 7/10\n",
      "1000/1000 [==============================] - 56s 56ms/step - loss: 0.0924 - acc: 0.9520\n",
      "Epoch 8/10\n",
      "1000/1000 [==============================] - 56s 56ms/step - loss: 0.0878 - acc: 0.9540\n",
      "Epoch 9/10\n",
      "1000/1000 [==============================] - 56s 56ms/step - loss: 0.0851 - acc: 0.9540\n",
      "Epoch 10/10\n",
      "1000/1000 [==============================] - 56s 56ms/step - loss: 0.0837 - acc: 0.9580\n",
      "Training on Epoch  4 batch  5  Files [5] start  195 / 459\n",
      "Epoch 1/10\n",
      "1000/1000 [==============================] - 83s 83ms/step - loss: 0.2106 - acc: 0.9070\n",
      "Epoch 2/10\n",
      "1000/1000 [==============================] - 84s 84ms/step - loss: 0.1888 - acc: 0.9110\n",
      "Epoch 3/10\n",
      "1000/1000 [==============================] - 83s 83ms/step - loss: 0.1621 - acc: 0.9260\n",
      "Epoch 4/10\n",
      "1000/1000 [==============================] - 83s 83ms/step - loss: 0.1520 - acc: 0.9170\n",
      "Epoch 5/10\n",
      "1000/1000 [==============================] - 83s 83ms/step - loss: 0.1401 - acc: 0.9200\n",
      "Epoch 6/10\n",
      "1000/1000 [==============================] - 83s 83ms/step - loss: 0.1334 - acc: 0.9250\n",
      "Epoch 7/10\n",
      "1000/1000 [==============================] - 83s 83ms/step - loss: 0.1285 - acc: 0.9230\n",
      "Epoch 8/10\n",
      "1000/1000 [==============================] - 83s 83ms/step - loss: 0.1248 - acc: 0.9290\n",
      "Epoch 9/10\n",
      "1000/1000 [==============================] - 82s 82ms/step - loss: 0.1214 - acc: 0.9320\n",
      "Epoch 10/10\n",
      "1000/1000 [==============================] - 83s 83ms/step - loss: 0.1187 - acc: 0.9340\n",
      "Training on Epoch  4 batch  5  Files [5] start  200 / 459\n",
      "Epoch 1/10\n",
      "1000/1000 [==============================] - 78s 78ms/step - loss: 0.1913 - acc: 0.9130\n",
      "Epoch 2/10\n",
      "1000/1000 [==============================] - 78s 78ms/step - loss: 0.1590 - acc: 0.9230\n",
      "Epoch 3/10\n",
      "1000/1000 [==============================] - 78s 78ms/step - loss: 0.1411 - acc: 0.9240\n",
      "Epoch 4/10\n",
      "1000/1000 [==============================] - 77s 77ms/step - loss: 0.1272 - acc: 0.9300\n",
      "Epoch 5/10\n",
      "1000/1000 [==============================] - 78s 78ms/step - loss: 0.1172 - acc: 0.9360\n",
      "Epoch 6/10\n",
      "1000/1000 [==============================] - 78s 78ms/step - loss: 0.1115 - acc: 0.9410\n",
      "Epoch 7/10\n",
      "1000/1000 [==============================] - 78s 78ms/step - loss: 0.1061 - acc: 0.9430\n",
      "Epoch 8/10\n",
      "1000/1000 [==============================] - 78s 78ms/step - loss: 0.1030 - acc: 0.9490\n",
      "Epoch 9/10\n",
      "1000/1000 [==============================] - 77s 77ms/step - loss: 0.0998 - acc: 0.9480\n",
      "Epoch 10/10\n",
      "1000/1000 [==============================] - 78s 78ms/step - loss: 0.0974 - acc: 0.9470\n",
      "Training on Epoch  4 batch  5  Files [5] start  205 / 459\n",
      "Epoch 1/10\n",
      "1000/1000 [==============================] - 72s 72ms/step - loss: 0.1581 - acc: 0.9060\n",
      "Epoch 2/10\n",
      "1000/1000 [==============================] - 72s 72ms/step - loss: 0.1432 - acc: 0.9120\n",
      "Epoch 3/10\n",
      "1000/1000 [==============================] - 71s 71ms/step - loss: 0.1224 - acc: 0.9300\n",
      "Epoch 4/10\n",
      "1000/1000 [==============================] - 71s 71ms/step - loss: 0.1132 - acc: 0.9430\n",
      "Epoch 5/10\n",
      "1000/1000 [==============================] - 72s 72ms/step - loss: 0.1075 - acc: 0.9420\n",
      "Epoch 6/10\n",
      "1000/1000 [==============================] - 72s 72ms/step - loss: 0.1015 - acc: 0.9480\n",
      "Epoch 7/10\n",
      "1000/1000 [==============================] - 71s 71ms/step - loss: 0.0991 - acc: 0.9540\n",
      "Epoch 8/10\n",
      "1000/1000 [==============================] - 72s 72ms/step - loss: 0.0974 - acc: 0.9510\n",
      "Epoch 9/10\n",
      "1000/1000 [==============================] - 93s 93ms/step - loss: 0.0949 - acc: 0.9510\n",
      "Epoch 10/10\n",
      "1000/1000 [==============================] - 105s 105ms/step - loss: 0.0949 - acc: 0.9510\n",
      "Training on Epoch  4 batch  5  Files [5] start  210 / 459\n",
      "Epoch 1/10\n",
      "1000/1000 [==============================] - 98s 98ms/step - loss: 0.1751 - acc: 0.9280\n",
      "Epoch 2/10\n",
      "1000/1000 [==============================] - 76s 76ms/step - loss: 0.1307 - acc: 0.9360\n",
      "Epoch 3/10\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000/1000 [==============================] - 71s 71ms/step - loss: 0.1054 - acc: 0.9600\n",
      "Epoch 4/10\n",
      "1000/1000 [==============================] - 68s 68ms/step - loss: 0.0850 - acc: 0.9680\n",
      "Epoch 5/10\n",
      "1000/1000 [==============================] - 69s 69ms/step - loss: 0.0721 - acc: 0.9760\n",
      "Epoch 6/10\n",
      "1000/1000 [==============================] - 69s 69ms/step - loss: 0.0606 - acc: 0.9770\n",
      "Epoch 7/10\n",
      "1000/1000 [==============================] - 65s 65ms/step - loss: 0.0516 - acc: 0.9800\n",
      "Epoch 8/10\n",
      "1000/1000 [==============================] - 65s 65ms/step - loss: 0.0457 - acc: 0.9850\n",
      "Epoch 9/10\n",
      "1000/1000 [==============================] - 65s 65ms/step - loss: 0.0414 - acc: 0.9860\n",
      "Epoch 10/10\n",
      "1000/1000 [==============================] - 65s 65ms/step - loss: 0.0395 - acc: 0.9860\n",
      "Training on Epoch  4 batch  5  Files [5] start  215 / 459\n",
      "Epoch 1/10\n",
      "1000/1000 [==============================] - 89s 89ms/step - loss: 0.2366 - acc: 0.8980\n",
      "Epoch 2/10\n",
      "1000/1000 [==============================] - 87s 87ms/step - loss: 0.1937 - acc: 0.9120\n",
      "Epoch 3/10\n",
      "1000/1000 [==============================] - 81s 81ms/step - loss: 0.1647 - acc: 0.9240\n",
      "Epoch 4/10\n",
      "1000/1000 [==============================] - 82s 82ms/step - loss: 0.1514 - acc: 0.9290\n",
      "Epoch 5/10\n",
      "1000/1000 [==============================] - 82s 82ms/step - loss: 0.1395 - acc: 0.9390\n",
      "Epoch 6/10\n",
      "1000/1000 [==============================] - 84s 84ms/step - loss: 0.1285 - acc: 0.9410\n",
      "Epoch 7/10\n",
      "1000/1000 [==============================] - 85s 85ms/step - loss: 0.1222 - acc: 0.9430\n",
      "Epoch 8/10\n",
      "1000/1000 [==============================] - 83s 83ms/step - loss: 0.1201 - acc: 0.9440\n",
      "Epoch 9/10\n",
      "1000/1000 [==============================] - 81s 81ms/step - loss: 0.1149 - acc: 0.9450\n",
      "Epoch 10/10\n",
      "1000/1000 [==============================] - 81s 81ms/step - loss: 0.1145 - acc: 0.9470\n",
      "Training on Epoch  4 batch  5  Files [5] start  220 / 459\n",
      "Epoch 1/10\n",
      "1000/1000 [==============================] - 70s 70ms/step - loss: 0.2432 - acc: 0.9050\n",
      "Epoch 2/10\n",
      "1000/1000 [==============================] - 70s 70ms/step - loss: 0.1923 - acc: 0.9200\n",
      "Epoch 3/10\n",
      "1000/1000 [==============================] - 70s 70ms/step - loss: 0.1539 - acc: 0.9450\n",
      "Epoch 4/10\n",
      "1000/1000 [==============================] - 70s 70ms/step - loss: 0.1259 - acc: 0.9530\n",
      "Epoch 5/10\n",
      "1000/1000 [==============================] - 70s 70ms/step - loss: 0.1091 - acc: 0.9610\n",
      "Epoch 6/10\n",
      "1000/1000 [==============================] - 70s 70ms/step - loss: 0.1020 - acc: 0.9630\n",
      "Epoch 7/10\n",
      "1000/1000 [==============================] - 70s 70ms/step - loss: 0.0896 - acc: 0.9650\n",
      "Epoch 8/10\n",
      "1000/1000 [==============================] - 70s 70ms/step - loss: 0.0836 - acc: 0.9710\n",
      "Epoch 9/10\n",
      "1000/1000 [==============================] - 70s 70ms/step - loss: 0.0787 - acc: 0.9720\n",
      "Epoch 10/10\n",
      "1000/1000 [==============================] - 69s 69ms/step - loss: 0.0730 - acc: 0.9730\n",
      "Training on Epoch  4 batch  5  Files [5] start  225 / 459\n",
      "Epoch 1/10\n",
      "1000/1000 [==============================] - 83s 83ms/step - loss: 0.1345 - acc: 0.9430\n",
      "Epoch 2/10\n",
      "1000/1000 [==============================] - 83s 83ms/step - loss: 0.1032 - acc: 0.9540\n",
      "Epoch 3/10\n",
      "1000/1000 [==============================] - 83s 83ms/step - loss: 0.0875 - acc: 0.9620\n",
      "Epoch 4/10\n",
      "1000/1000 [==============================] - 83s 83ms/step - loss: 0.0766 - acc: 0.9650\n",
      "Epoch 5/10\n",
      "1000/1000 [==============================] - 83s 83ms/step - loss: 0.0698 - acc: 0.9700\n",
      "Epoch 6/10\n",
      "1000/1000 [==============================] - 83s 83ms/step - loss: 0.0634 - acc: 0.9730\n",
      "Epoch 7/10\n",
      "1000/1000 [==============================] - 83s 83ms/step - loss: 0.0596 - acc: 0.9770\n",
      "Epoch 8/10\n",
      "1000/1000 [==============================] - 82s 82ms/step - loss: 0.0563 - acc: 0.9750\n",
      "Epoch 9/10\n",
      "1000/1000 [==============================] - 82s 82ms/step - loss: 0.0532 - acc: 0.9750\n",
      "Epoch 10/10\n",
      "1000/1000 [==============================] - 82s 82ms/step - loss: 0.0507 - acc: 0.9760\n",
      "Training on Epoch  4 batch  5  Files [5] start  230 / 459\n",
      "Epoch 1/10\n",
      "1000/1000 [==============================] - 71s 71ms/step - loss: 0.1196 - acc: 0.9350\n",
      "Epoch 2/10\n",
      "1000/1000 [==============================] - 70s 70ms/step - loss: 0.1093 - acc: 0.9410\n",
      "Epoch 3/10\n",
      "1000/1000 [==============================] - 71s 71ms/step - loss: 0.1014 - acc: 0.9380\n",
      "Epoch 4/10\n",
      "1000/1000 [==============================] - 70s 70ms/step - loss: 0.0931 - acc: 0.9460\n",
      "Epoch 5/10\n",
      "1000/1000 [==============================] - 70s 70ms/step - loss: 0.0893 - acc: 0.9490\n",
      "Epoch 6/10\n",
      "1000/1000 [==============================] - 70s 70ms/step - loss: 0.0857 - acc: 0.9530\n",
      "Epoch 7/10\n",
      "1000/1000 [==============================] - 68s 68ms/step - loss: 0.0823 - acc: 0.9610\n",
      "Epoch 8/10\n",
      "1000/1000 [==============================] - 69s 69ms/step - loss: 0.0797 - acc: 0.9600\n",
      "Epoch 9/10\n",
      "1000/1000 [==============================] - 70s 70ms/step - loss: 0.0777 - acc: 0.9620\n",
      "Epoch 10/10\n",
      "1000/1000 [==============================] - 70s 70ms/step - loss: 0.0751 - acc: 0.9610\n",
      "Training on Epoch  4 batch  5  Files [5] start  235 / 459\n",
      "Epoch 1/10\n",
      "1000/1000 [==============================] - 74s 74ms/step - loss: 0.1593 - acc: 0.9390\n",
      "Epoch 2/10\n",
      "1000/1000 [==============================] - 74s 74ms/step - loss: 0.1262 - acc: 0.9440\n",
      "Epoch 3/10\n",
      "1000/1000 [==============================] - 74s 74ms/step - loss: 0.0972 - acc: 0.9580\n",
      "Epoch 4/10\n",
      "1000/1000 [==============================] - 72s 72ms/step - loss: 0.0824 - acc: 0.9630\n",
      "Epoch 5/10\n",
      "1000/1000 [==============================] - 74s 74ms/step - loss: 0.0784 - acc: 0.9640\n",
      "Epoch 6/10\n",
      "1000/1000 [==============================] - 79s 79ms/step - loss: 0.0724 - acc: 0.9670\n",
      "Epoch 7/10\n",
      "1000/1000 [==============================] - 78s 78ms/step - loss: 0.0681 - acc: 0.9670\n",
      "Epoch 8/10\n",
      "1000/1000 [==============================] - 81s 81ms/step - loss: 0.0654 - acc: 0.9690\n",
      "Epoch 9/10\n",
      "1000/1000 [==============================] - 80s 80ms/step - loss: 0.0627 - acc: 0.9700\n",
      "Epoch 10/10\n",
      "1000/1000 [==============================] - 88s 88ms/step - loss: 0.0603 - acc: 0.9730\n",
      "Training on Epoch  4 batch  5  Files [5] start  240 / 459\n",
      "Epoch 1/10\n",
      "1000/1000 [==============================] - 83s 83ms/step - loss: 0.1163 - acc: 0.9480\n",
      "Epoch 2/10\n",
      "1000/1000 [==============================] - 82s 82ms/step - loss: 0.0970 - acc: 0.9560\n",
      "Epoch 3/10\n",
      "1000/1000 [==============================] - 80s 80ms/step - loss: 0.0774 - acc: 0.9680\n",
      "Epoch 4/10\n",
      "1000/1000 [==============================] - 73s 73ms/step - loss: 0.0649 - acc: 0.9760\n",
      "Epoch 5/10\n",
      "1000/1000 [==============================] - 75s 75ms/step - loss: 0.0588 - acc: 0.9770\n",
      "Epoch 6/10\n",
      "1000/1000 [==============================] - 76s 76ms/step - loss: 0.0542 - acc: 0.9780\n",
      "Epoch 7/10\n",
      "1000/1000 [==============================] - 79s 79ms/step - loss: 0.0510 - acc: 0.9790\n",
      "Epoch 8/10\n",
      "1000/1000 [==============================] - 74s 74ms/step - loss: 0.0491 - acc: 0.9790\n",
      "Epoch 9/10\n",
      "1000/1000 [==============================] - 76s 76ms/step - loss: 0.0454 - acc: 0.9800\n",
      "Epoch 10/10\n",
      "1000/1000 [==============================] - 76s 76ms/step - loss: 0.0450 - acc: 0.9810\n",
      "Training on Epoch  4 batch  5  Files [5] start  245 / 459\n",
      "Epoch 1/10\n",
      "1000/1000 [==============================] - 85s 85ms/step - loss: 0.1567 - acc: 0.9310\n",
      "Epoch 2/10\n",
      "1000/1000 [==============================] - 79s 79ms/step - loss: 0.1186 - acc: 0.9430\n",
      "Epoch 3/10\n",
      "1000/1000 [==============================] - 80s 80ms/step - loss: 0.0924 - acc: 0.9520\n",
      "Epoch 4/10\n",
      "1000/1000 [==============================] - 77s 77ms/step - loss: 0.0827 - acc: 0.9600\n",
      "Epoch 5/10\n",
      "1000/1000 [==============================] - 80s 80ms/step - loss: 0.0751 - acc: 0.9650\n",
      "Epoch 6/10\n",
      "1000/1000 [==============================] - 77s 77ms/step - loss: 0.0700 - acc: 0.9670\n",
      "Epoch 7/10\n",
      "1000/1000 [==============================] - 91s 91ms/step - loss: 0.0672 - acc: 0.9680\n",
      "Epoch 8/10\n",
      "1000/1000 [==============================] - 99s 99ms/step - loss: 0.0647 - acc: 0.9660\n",
      "Epoch 9/10\n",
      "1000/1000 [==============================] - 89s 89ms/step - loss: 0.0624 - acc: 0.9690\n",
      "Epoch 10/10\n",
      "1000/1000 [==============================] - 88s 88ms/step - loss: 0.0602 - acc: 0.9730\n",
      "Training on Epoch  4 batch  5  Files [5] start  250 / 459\n",
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000/1000 [==============================] - 93s 93ms/step - loss: 0.1646 - acc: 0.9210\n",
      "Epoch 2/10\n",
      "1000/1000 [==============================] - 130s 130ms/step - loss: 0.1329 - acc: 0.9310\n",
      "Epoch 3/10\n",
      "1000/1000 [==============================] - 134s 134ms/step - loss: 0.1182 - acc: 0.9400\n",
      "Epoch 4/10\n",
      "1000/1000 [==============================] - 106s 106ms/step - loss: 0.1074 - acc: 0.9500\n",
      "Epoch 5/10\n",
      "1000/1000 [==============================] - 107s 107ms/step - loss: 0.1039 - acc: 0.9500\n",
      "Epoch 6/10\n",
      "1000/1000 [==============================] - 100s 100ms/step - loss: 0.1081 - acc: 0.9460\n",
      "Epoch 7/10\n",
      "1000/1000 [==============================] - 99s 99ms/step - loss: 0.0945 - acc: 0.9560\n",
      "Epoch 8/10\n",
      "1000/1000 [==============================] - 137s 137ms/step - loss: 0.0959 - acc: 0.9510\n",
      "Epoch 9/10\n",
      "1000/1000 [==============================] - 180s 180ms/step - loss: 0.0937 - acc: 0.9530\n",
      "Epoch 10/10\n",
      "1000/1000 [==============================] - 112s 112ms/step - loss: 0.0921 - acc: 0.9550\n",
      "Training on Epoch  4 batch  5  Files [5] start  255 / 459\n",
      "Epoch 1/10\n",
      "1000/1000 [==============================] - 136s 136ms/step - loss: 0.1382 - acc: 0.9360\n",
      "Epoch 2/10\n",
      "1000/1000 [==============================] - 144s 144ms/step - loss: 0.1162 - acc: 0.9420\n",
      "Epoch 3/10\n",
      "1000/1000 [==============================] - 138s 138ms/step - loss: 0.1035 - acc: 0.9430\n",
      "Epoch 4/10\n",
      "1000/1000 [==============================] - 119s 119ms/step - loss: 0.0926 - acc: 0.9510\n",
      "Epoch 5/10\n",
      "1000/1000 [==============================] - 134s 134ms/step - loss: 0.0870 - acc: 0.9530\n",
      "Epoch 6/10\n",
      "1000/1000 [==============================] - 108s 108ms/step - loss: 0.0819 - acc: 0.9570\n",
      "Epoch 7/10\n",
      "1000/1000 [==============================] - 111s 111ms/step - loss: 0.0780 - acc: 0.9610\n",
      "Epoch 8/10\n",
      "1000/1000 [==============================] - 114s 114ms/step - loss: 0.0757 - acc: 0.9620\n",
      "Epoch 9/10\n",
      "1000/1000 [==============================] - 106s 106ms/step - loss: 0.0743 - acc: 0.9620\n",
      "Epoch 10/10\n",
      "1000/1000 [==============================] - 114s 114ms/step - loss: 0.0726 - acc: 0.9620\n",
      "Training on Epoch  4 batch  5  Files [5] start  260 / 459\n",
      "Epoch 1/10\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 0.1900 - acc: 0.9190\n",
      "Epoch 2/10\n",
      "1000/1000 [==============================] - 116s 116ms/step - loss: 0.1470 - acc: 0.9380\n",
      "Epoch 3/10\n",
      "1000/1000 [==============================] - 144s 144ms/step - loss: 0.1217 - acc: 0.9430\n",
      "Epoch 4/10\n",
      "1000/1000 [==============================] - 172s 172ms/step - loss: 0.1103 - acc: 0.9480\n",
      "Epoch 5/10\n",
      "1000/1000 [==============================] - 130s 130ms/step - loss: 0.0991 - acc: 0.9530\n",
      "Epoch 6/10\n",
      "1000/1000 [==============================] - 124s 124ms/step - loss: 0.0928 - acc: 0.9630\n",
      "Epoch 7/10\n",
      "1000/1000 [==============================] - 113s 113ms/step - loss: 0.0879 - acc: 0.9590\n",
      "Epoch 8/10\n",
      "1000/1000 [==============================] - 114s 114ms/step - loss: 0.0815 - acc: 0.9620\n",
      "Epoch 9/10\n",
      "1000/1000 [==============================] - 119s 119ms/step - loss: 0.0784 - acc: 0.9610\n",
      "Epoch 10/10\n",
      "1000/1000 [==============================] - 112s 112ms/step - loss: 0.0738 - acc: 0.9640\n",
      "Training on Epoch  4 batch  5  Files [5] start  265 / 459\n",
      "Epoch 1/10\n",
      "1000/1000 [==============================] - 79s 79ms/step - loss: 0.2003 - acc: 0.9220\n",
      "Epoch 2/10\n",
      "1000/1000 [==============================] - 71s 71ms/step - loss: 0.1358 - acc: 0.9360\n",
      "Epoch 3/10\n",
      "1000/1000 [==============================] - 67s 67ms/step - loss: 0.1065 - acc: 0.9590\n",
      "Epoch 4/10\n",
      "1000/1000 [==============================] - 67s 67ms/step - loss: 0.0919 - acc: 0.9650\n",
      "Epoch 5/10\n",
      "1000/1000 [==============================] - 67s 67ms/step - loss: 0.0821 - acc: 0.9660\n",
      "Epoch 6/10\n",
      "1000/1000 [==============================] - 66s 66ms/step - loss: 0.0748 - acc: 0.9710\n",
      "Epoch 7/10\n",
      "1000/1000 [==============================] - 69s 69ms/step - loss: 0.0692 - acc: 0.9740\n",
      "Epoch 8/10\n",
      "1000/1000 [==============================] - 68s 68ms/step - loss: 0.0658 - acc: 0.9750\n",
      "Epoch 9/10\n",
      "1000/1000 [==============================] - 73s 73ms/step - loss: 0.0618 - acc: 0.9730\n",
      "Epoch 10/10\n",
      "1000/1000 [==============================] - 94s 94ms/step - loss: 0.0594 - acc: 0.9740\n",
      "Training on Epoch  4 batch  5  Files [5] start  270 / 459\n",
      "Epoch 1/10\n",
      "1000/1000 [==============================] - 93s 93ms/step - loss: 0.1729 - acc: 0.9210\n",
      "Epoch 2/10\n",
      "1000/1000 [==============================] - 98s 98ms/step - loss: 0.1381 - acc: 0.9470\n",
      "Epoch 3/10\n",
      "1000/1000 [==============================] - 101s 101ms/step - loss: 0.1240 - acc: 0.9470\n",
      "Epoch 4/10\n",
      "1000/1000 [==============================] - 128s 128ms/step - loss: 0.1127 - acc: 0.9540\n",
      "Epoch 5/10\n",
      "1000/1000 [==============================] - 128s 128ms/step - loss: 0.1006 - acc: 0.9570\n",
      "Epoch 6/10\n",
      "1000/1000 [==============================] - 82s 82ms/step - loss: 0.0970 - acc: 0.9600\n",
      "Epoch 7/10\n",
      "1000/1000 [==============================] - 74s 74ms/step - loss: 0.0930 - acc: 0.9600\n",
      "Epoch 8/10\n",
      "1000/1000 [==============================] - 72s 72ms/step - loss: 0.0877 - acc: 0.9610\n",
      "Epoch 9/10\n",
      "1000/1000 [==============================] - 73s 73ms/step - loss: 0.0861 - acc: 0.9580\n",
      "Epoch 10/10\n",
      "1000/1000 [==============================] - 73s 73ms/step - loss: 0.0829 - acc: 0.9610\n",
      "Training on Epoch  4 batch  5  Files [5] start  275 / 459\n",
      "Epoch 1/10\n",
      "1000/1000 [==============================] - 67s 67ms/step - loss: 0.1976 - acc: 0.9320\n",
      "Epoch 2/10\n",
      "1000/1000 [==============================] - 67s 67ms/step - loss: 0.1488 - acc: 0.9440\n",
      "Epoch 3/10\n",
      "1000/1000 [==============================] - 67s 67ms/step - loss: 0.1074 - acc: 0.9610\n",
      "Epoch 4/10\n",
      "1000/1000 [==============================] - 66s 66ms/step - loss: 0.0858 - acc: 0.9720\n",
      "Epoch 5/10\n",
      "1000/1000 [==============================] - 65s 65ms/step - loss: 0.0751 - acc: 0.9730\n",
      "Epoch 6/10\n",
      "1000/1000 [==============================] - 65s 65ms/step - loss: 0.0689 - acc: 0.9760\n",
      "Epoch 7/10\n",
      "1000/1000 [==============================] - 65s 65ms/step - loss: 0.0631 - acc: 0.9770\n",
      "Epoch 8/10\n",
      "1000/1000 [==============================] - 65s 65ms/step - loss: 0.0562 - acc: 0.9800\n",
      "Epoch 9/10\n",
      "1000/1000 [==============================] - 65s 65ms/step - loss: 0.0521 - acc: 0.9820\n",
      "Epoch 10/10\n",
      "1000/1000 [==============================] - 65s 65ms/step - loss: 0.0500 - acc: 0.9820\n",
      "Training on Epoch  4 batch  5  Files [5] start  280 / 459\n",
      "Epoch 1/10\n",
      "1000/1000 [==============================] - 61s 61ms/step - loss: 0.1751 - acc: 0.9170\n",
      "Epoch 2/10\n",
      "1000/1000 [==============================] - 60s 60ms/step - loss: 0.1264 - acc: 0.9400\n",
      "Epoch 3/10\n",
      "1000/1000 [==============================] - 61s 61ms/step - loss: 0.0985 - acc: 0.9490\n",
      "Epoch 4/10\n",
      "1000/1000 [==============================] - 60s 60ms/step - loss: 0.0838 - acc: 0.9580\n",
      "Epoch 5/10\n",
      "1000/1000 [==============================] - 61s 61ms/step - loss: 0.0753 - acc: 0.9650\n",
      "Epoch 6/10\n",
      "1000/1000 [==============================] - 60s 60ms/step - loss: 0.0690 - acc: 0.9700\n",
      "Epoch 7/10\n",
      "1000/1000 [==============================] - 60s 60ms/step - loss: 0.0660 - acc: 0.9700\n",
      "Epoch 8/10\n",
      "1000/1000 [==============================] - 60s 60ms/step - loss: 0.0634 - acc: 0.9710\n",
      "Epoch 9/10\n",
      "1000/1000 [==============================] - 60s 60ms/step - loss: 0.0600 - acc: 0.9710\n",
      "Epoch 10/10\n",
      "1000/1000 [==============================] - 60s 60ms/step - loss: 0.0584 - acc: 0.9720\n",
      "Training on Epoch  4 batch  5  Files [5] start  285 / 459\n",
      "Epoch 1/10\n",
      "1000/1000 [==============================] - 79s 79ms/step - loss: 0.1829 - acc: 0.9070\n",
      "Epoch 2/10\n",
      "1000/1000 [==============================] - 78s 78ms/step - loss: 0.1528 - acc: 0.9170\n",
      "Epoch 3/10\n",
      "1000/1000 [==============================] - 78s 78ms/step - loss: 0.1394 - acc: 0.9240\n",
      "Epoch 4/10\n",
      "1000/1000 [==============================] - 78s 78ms/step - loss: 0.1265 - acc: 0.9380\n",
      "Epoch 5/10\n",
      "1000/1000 [==============================] - 77s 77ms/step - loss: 0.1180 - acc: 0.9400\n",
      "Epoch 6/10\n",
      "1000/1000 [==============================] - 78s 78ms/step - loss: 0.1128 - acc: 0.9420\n",
      "Epoch 7/10\n",
      "1000/1000 [==============================] - 77s 77ms/step - loss: 0.1101 - acc: 0.9420\n",
      "Epoch 8/10\n",
      "1000/1000 [==============================] - 78s 78ms/step - loss: 0.1050 - acc: 0.9460\n",
      "Epoch 9/10\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000/1000 [==============================] - 78s 78ms/step - loss: 0.1020 - acc: 0.9460\n",
      "Epoch 10/10\n",
      "1000/1000 [==============================] - 78s 78ms/step - loss: 0.1001 - acc: 0.9470\n",
      "Training on Epoch  4 batch  5  Files [5] start  290 / 459\n",
      "Epoch 1/10\n",
      "1000/1000 [==============================] - 77s 77ms/step - loss: 0.2145 - acc: 0.9150\n",
      "Epoch 2/10\n",
      "1000/1000 [==============================] - 76s 76ms/step - loss: 0.1532 - acc: 0.9200\n",
      "Epoch 3/10\n",
      "1000/1000 [==============================] - 76s 76ms/step - loss: 0.1296 - acc: 0.9340\n",
      "Epoch 4/10\n",
      "1000/1000 [==============================] - 76s 76ms/step - loss: 0.1131 - acc: 0.9410\n",
      "Epoch 5/10\n",
      "1000/1000 [==============================] - 76s 76ms/step - loss: 0.1055 - acc: 0.9460\n",
      "Epoch 6/10\n",
      "1000/1000 [==============================] - 76s 76ms/step - loss: 0.0967 - acc: 0.9480\n",
      "Epoch 7/10\n",
      "1000/1000 [==============================] - 76s 76ms/step - loss: 0.0921 - acc: 0.9520\n",
      "Epoch 8/10\n",
      "1000/1000 [==============================] - 76s 76ms/step - loss: 0.0886 - acc: 0.9540\n",
      "Epoch 9/10\n",
      "1000/1000 [==============================] - 75s 75ms/step - loss: 0.0847 - acc: 0.9560\n",
      "Epoch 10/10\n",
      "1000/1000 [==============================] - 76s 76ms/step - loss: 0.0819 - acc: 0.9530\n",
      "Training on Epoch  4 batch  5  Files [5] start  295 / 459\n",
      "Epoch 1/10\n",
      "1000/1000 [==============================] - 71s 71ms/step - loss: 0.0942 - acc: 0.9530\n",
      "Epoch 2/10\n",
      "1000/1000 [==============================] - 70s 70ms/step - loss: 0.0807 - acc: 0.9690\n",
      "Epoch 3/10\n",
      "1000/1000 [==============================] - 70s 70ms/step - loss: 0.0722 - acc: 0.9710\n",
      "Epoch 4/10\n",
      "1000/1000 [==============================] - 70s 70ms/step - loss: 0.0651 - acc: 0.9730\n",
      "Epoch 5/10\n",
      "1000/1000 [==============================] - 70s 70ms/step - loss: 0.0606 - acc: 0.9710\n",
      "Epoch 6/10\n",
      "1000/1000 [==============================] - 70s 70ms/step - loss: 0.0565 - acc: 0.9720\n",
      "Epoch 7/10\n",
      "1000/1000 [==============================] - 70s 70ms/step - loss: 0.0536 - acc: 0.9750\n",
      "Epoch 8/10\n",
      "1000/1000 [==============================] - 71s 71ms/step - loss: 0.0479 - acc: 0.9790\n",
      "Epoch 9/10\n",
      "1000/1000 [==============================] - 75s 75ms/step - loss: 0.0469 - acc: 0.9770\n",
      "Epoch 10/10\n",
      "1000/1000 [==============================] - 74s 74ms/step - loss: 0.0444 - acc: 0.9770\n",
      "Training on Epoch  4 batch  5  Files [5] start  300 / 459\n",
      "Epoch 1/10\n",
      "1000/1000 [==============================] - 60s 60ms/step - loss: 0.2098 - acc: 0.9180\n",
      "Epoch 2/10\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 0.1429 - acc: 0.9430\n",
      "Epoch 3/10\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 0.1054 - acc: 0.9630\n",
      "Epoch 4/10\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 0.0834 - acc: 0.9720\n",
      "Epoch 5/10\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 0.0738 - acc: 0.9740\n",
      "Epoch 6/10\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 0.0661 - acc: 0.9790\n",
      "Epoch 7/10\n",
      "1000/1000 [==============================] - 58s 58ms/step - loss: 0.0611 - acc: 0.9780\n",
      "Epoch 8/10\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 0.0610 - acc: 0.9750\n",
      "Epoch 9/10\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 0.0597 - acc: 0.9770\n",
      "Epoch 10/10\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 0.0596 - acc: 0.9790\n",
      "Training on Epoch  4 batch  5  Files [5] start  305 / 459\n",
      "Epoch 1/10\n",
      "1000/1000 [==============================] - 68s 68ms/step - loss: 0.1503 - acc: 0.9410\n",
      "Epoch 2/10\n",
      "1000/1000 [==============================] - 67s 67ms/step - loss: 0.1095 - acc: 0.9570\n",
      "Epoch 3/10\n",
      "1000/1000 [==============================] - 67s 67ms/step - loss: 0.0899 - acc: 0.9580\n",
      "Epoch 4/10\n",
      "1000/1000 [==============================] - 67s 67ms/step - loss: 0.0746 - acc: 0.9640\n",
      "Epoch 5/10\n",
      "1000/1000 [==============================] - 67s 67ms/step - loss: 0.0655 - acc: 0.9700\n",
      "Epoch 6/10\n",
      "1000/1000 [==============================] - 68s 68ms/step - loss: 0.0561 - acc: 0.9750\n",
      "Epoch 7/10\n",
      "1000/1000 [==============================] - 68s 68ms/step - loss: 0.0508 - acc: 0.9820\n",
      "Epoch 8/10\n",
      "1000/1000 [==============================] - 67s 67ms/step - loss: 0.0476 - acc: 0.9830\n",
      "Epoch 9/10\n",
      "1000/1000 [==============================] - 67s 67ms/step - loss: 0.0437 - acc: 0.9840\n",
      "Epoch 10/10\n",
      "1000/1000 [==============================] - 68s 68ms/step - loss: 0.0410 - acc: 0.9860\n",
      "Training on Epoch  4 batch  5  Files [5] start  310 / 459\n",
      "Epoch 1/10\n",
      "1000/1000 [==============================] - 71s 71ms/step - loss: 0.2416 - acc: 0.9160\n",
      "Epoch 2/10\n",
      "1000/1000 [==============================] - 71s 71ms/step - loss: 0.1674 - acc: 0.9240\n",
      "Epoch 3/10\n",
      "1000/1000 [==============================] - 71s 71ms/step - loss: 0.1360 - acc: 0.9320\n",
      "Epoch 4/10\n",
      "1000/1000 [==============================] - 70s 70ms/step - loss: 0.1145 - acc: 0.9470\n",
      "Epoch 5/10\n",
      "1000/1000 [==============================] - 70s 70ms/step - loss: 0.1025 - acc: 0.9550\n",
      "Epoch 6/10\n",
      "1000/1000 [==============================] - 71s 71ms/step - loss: 0.0937 - acc: 0.9640\n",
      "Epoch 7/10\n",
      "1000/1000 [==============================] - 71s 71ms/step - loss: 0.0882 - acc: 0.9600\n",
      "Epoch 8/10\n",
      "1000/1000 [==============================] - 71s 71ms/step - loss: 0.0840 - acc: 0.9570\n",
      "Epoch 9/10\n",
      "1000/1000 [==============================] - 71s 71ms/step - loss: 0.0792 - acc: 0.9640\n",
      "Epoch 10/10\n",
      "1000/1000 [==============================] - 71s 71ms/step - loss: 0.0765 - acc: 0.9690\n",
      "Training on Epoch  4 batch  5  Files [5] start  315 / 459\n",
      "Epoch 1/10\n",
      "1000/1000 [==============================] - 73s 73ms/step - loss: 0.1549 - acc: 0.9210\n",
      "Epoch 2/10\n",
      "1000/1000 [==============================] - 71s 71ms/step - loss: 0.1314 - acc: 0.9240\n",
      "Epoch 3/10\n",
      "1000/1000 [==============================] - 71s 71ms/step - loss: 0.1128 - acc: 0.9330\n",
      "Epoch 4/10\n",
      "1000/1000 [==============================] - 73s 73ms/step - loss: 0.1025 - acc: 0.9380\n",
      "Epoch 5/10\n",
      "1000/1000 [==============================] - 72s 72ms/step - loss: 0.0955 - acc: 0.9410\n",
      "Epoch 6/10\n",
      "1000/1000 [==============================] - 72s 72ms/step - loss: 0.0932 - acc: 0.9410\n",
      "Epoch 7/10\n",
      "1000/1000 [==============================] - 72s 72ms/step - loss: 0.0930 - acc: 0.9500\n",
      "Epoch 8/10\n",
      "1000/1000 [==============================] - 72s 72ms/step - loss: 0.0876 - acc: 0.9520\n",
      "Epoch 9/10\n",
      "1000/1000 [==============================] - 72s 72ms/step - loss: 0.0869 - acc: 0.9470\n",
      "Epoch 10/10\n",
      "1000/1000 [==============================] - 72s 72ms/step - loss: 0.0833 - acc: 0.9510\n",
      "Training on Epoch  4 batch  5  Files [5] start  320 / 459\n",
      "Epoch 1/10\n",
      "1000/1000 [==============================] - 79s 79ms/step - loss: 0.1675 - acc: 0.9330\n",
      "Epoch 2/10\n",
      "1000/1000 [==============================] - 79s 79ms/step - loss: 0.1279 - acc: 0.9480\n",
      "Epoch 3/10\n",
      "1000/1000 [==============================] - 79s 79ms/step - loss: 0.0985 - acc: 0.9560\n",
      "Epoch 4/10\n",
      "1000/1000 [==============================] - 78s 78ms/step - loss: 0.0844 - acc: 0.9560\n",
      "Epoch 5/10\n",
      "1000/1000 [==============================] - 79s 79ms/step - loss: 0.0763 - acc: 0.9630\n",
      "Epoch 6/10\n",
      "1000/1000 [==============================] - 78s 78ms/step - loss: 0.0686 - acc: 0.9650\n",
      "Epoch 7/10\n",
      "1000/1000 [==============================] - 78s 78ms/step - loss: 0.0625 - acc: 0.9680\n",
      "Epoch 8/10\n",
      "1000/1000 [==============================] - 78s 78ms/step - loss: 0.0582 - acc: 0.9760\n",
      "Epoch 9/10\n",
      "1000/1000 [==============================] - 78s 78ms/step - loss: 0.0543 - acc: 0.9760\n",
      "Epoch 10/10\n",
      "1000/1000 [==============================] - 78s 78ms/step - loss: 0.0522 - acc: 0.9770\n",
      "Training on Epoch  4 batch  5  Files [5] start  325 / 459\n",
      "Epoch 1/10\n",
      "1000/1000 [==============================] - 68s 68ms/step - loss: 0.1126 - acc: 0.9460\n",
      "Epoch 2/10\n",
      "1000/1000 [==============================] - 67s 67ms/step - loss: 0.0876 - acc: 0.9560\n",
      "Epoch 3/10\n",
      "1000/1000 [==============================] - 70s 70ms/step - loss: 0.0712 - acc: 0.9650\n",
      "Epoch 4/10\n",
      "1000/1000 [==============================] - 68s 68ms/step - loss: 0.0672 - acc: 0.9680\n",
      "Epoch 5/10\n",
      "1000/1000 [==============================] - 68s 68ms/step - loss: 0.0633 - acc: 0.9720\n",
      "Epoch 6/10\n",
      "1000/1000 [==============================] - 68s 68ms/step - loss: 0.0584 - acc: 0.9720\n",
      "Epoch 7/10\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000/1000 [==============================] - 68s 68ms/step - loss: 0.0557 - acc: 0.9710\n",
      "Epoch 8/10\n",
      "1000/1000 [==============================] - 69s 69ms/step - loss: 0.0532 - acc: 0.9740\n",
      "Epoch 9/10\n",
      "1000/1000 [==============================] - 68s 68ms/step - loss: 0.0513 - acc: 0.9750\n",
      "Epoch 10/10\n",
      "1000/1000 [==============================] - 68s 68ms/step - loss: 0.0491 - acc: 0.9740\n",
      "Training on Epoch  4 batch  5  Files [5] start  330 / 459\n",
      "Epoch 1/10\n",
      "1000/1000 [==============================] - 67s 67ms/step - loss: 0.2207 - acc: 0.9080\n",
      "Epoch 2/10\n",
      "1000/1000 [==============================] - 65s 65ms/step - loss: 0.1613 - acc: 0.9290\n",
      "Epoch 3/10\n",
      "1000/1000 [==============================] - 66s 66ms/step - loss: 0.1223 - acc: 0.9400\n",
      "Epoch 4/10\n",
      "1000/1000 [==============================] - 66s 66ms/step - loss: 0.1036 - acc: 0.9570\n",
      "Epoch 5/10\n",
      "1000/1000 [==============================] - 66s 66ms/step - loss: 0.0923 - acc: 0.9580\n",
      "Epoch 6/10\n",
      "1000/1000 [==============================] - 66s 66ms/step - loss: 0.0834 - acc: 0.9610\n",
      "Epoch 7/10\n",
      "1000/1000 [==============================] - 68s 68ms/step - loss: 0.0788 - acc: 0.9650\n",
      "Epoch 8/10\n",
      "1000/1000 [==============================] - 66s 66ms/step - loss: 0.0736 - acc: 0.9650\n",
      "Epoch 9/10\n",
      "1000/1000 [==============================] - 66s 66ms/step - loss: 0.0721 - acc: 0.9640\n",
      "Epoch 10/10\n",
      "1000/1000 [==============================] - 67s 67ms/step - loss: 0.0669 - acc: 0.9660\n",
      "Training on Epoch  4 batch  5  Files [5] start  335 / 459\n",
      "Epoch 1/10\n",
      "1000/1000 [==============================] - 57s 57ms/step - loss: 0.1619 - acc: 0.9190\n",
      "Epoch 2/10\n",
      "1000/1000 [==============================] - 57s 57ms/step - loss: 0.1228 - acc: 0.9390\n",
      "Epoch 3/10\n",
      "1000/1000 [==============================] - 57s 57ms/step - loss: 0.1116 - acc: 0.9430\n",
      "Epoch 4/10\n",
      "1000/1000 [==============================] - 57s 57ms/step - loss: 0.1003 - acc: 0.9460\n",
      "Epoch 5/10\n",
      "1000/1000 [==============================] - 57s 57ms/step - loss: 0.0918 - acc: 0.9540\n",
      "Epoch 6/10\n",
      "1000/1000 [==============================] - 57s 57ms/step - loss: 0.0891 - acc: 0.9570\n",
      "Epoch 7/10\n",
      "1000/1000 [==============================] - 57s 57ms/step - loss: 0.0857 - acc: 0.9580\n",
      "Epoch 8/10\n",
      "1000/1000 [==============================] - 58s 58ms/step - loss: 0.0870 - acc: 0.9510\n",
      "Epoch 9/10\n",
      "1000/1000 [==============================] - 57s 57ms/step - loss: 0.0809 - acc: 0.9550\n",
      "Epoch 10/10\n",
      "1000/1000 [==============================] - 57s 57ms/step - loss: 0.0811 - acc: 0.9570\n",
      "Training on Epoch  4 batch  5  Files [5] start  340 / 459\n",
      "Epoch 1/10\n",
      "1000/1000 [==============================] - 84s 84ms/step - loss: 0.1114 - acc: 0.9530\n",
      "Epoch 2/10\n",
      "1000/1000 [==============================] - 85s 85ms/step - loss: 0.0806 - acc: 0.9610\n",
      "Epoch 3/10\n",
      "1000/1000 [==============================] - 85s 85ms/step - loss: 0.0719 - acc: 0.9650\n",
      "Epoch 4/10\n",
      "1000/1000 [==============================] - 84s 84ms/step - loss: 0.0642 - acc: 0.9710\n",
      "Epoch 5/10\n",
      "1000/1000 [==============================] - 85s 85ms/step - loss: 0.0615 - acc: 0.9680\n",
      "Epoch 6/10\n",
      "1000/1000 [==============================] - 84s 84ms/step - loss: 0.0605 - acc: 0.9660\n",
      "Epoch 7/10\n",
      "1000/1000 [==============================] - 84s 84ms/step - loss: 0.0583 - acc: 0.9690\n",
      "Epoch 8/10\n",
      "1000/1000 [==============================] - 83s 83ms/step - loss: 0.0568 - acc: 0.9740\n",
      "Epoch 9/10\n",
      "1000/1000 [==============================] - 84s 84ms/step - loss: 0.0559 - acc: 0.9750\n",
      "Epoch 10/10\n",
      "1000/1000 [==============================] - 84s 84ms/step - loss: 0.0545 - acc: 0.9740\n",
      "Training on Epoch  4 batch  5  Files [5] start  345 / 459\n",
      "Epoch 1/10\n",
      "1000/1000 [==============================] - 56s 56ms/step - loss: 0.2606 - acc: 0.9080\n",
      "Epoch 2/10\n",
      "1000/1000 [==============================] - 57s 57ms/step - loss: 0.1564 - acc: 0.9320\n",
      "Epoch 3/10\n",
      "1000/1000 [==============================] - 56s 56ms/step - loss: 0.1139 - acc: 0.9480\n",
      "Epoch 4/10\n",
      "1000/1000 [==============================] - 56s 56ms/step - loss: 0.0865 - acc: 0.9630\n",
      "Epoch 5/10\n",
      "1000/1000 [==============================] - 56s 56ms/step - loss: 0.0690 - acc: 0.9700\n",
      "Epoch 6/10\n",
      "1000/1000 [==============================] - 57s 57ms/step - loss: 0.0589 - acc: 0.9770\n",
      "Epoch 7/10\n",
      "1000/1000 [==============================] - 6613s 7s/step - loss: 0.0519 - acc: 0.9800\n",
      "Epoch 8/10\n",
      "1000/1000 [==============================] - 56s 56ms/step - loss: 0.0452 - acc: 0.9800\n",
      "Epoch 9/10\n",
      "1000/1000 [==============================] - 57s 57ms/step - loss: 0.0419 - acc: 0.9820\n",
      "Epoch 10/10\n",
      "1000/1000 [==============================] - 56s 56ms/step - loss: 0.0392 - acc: 0.9810\n",
      "Training on Epoch  4 batch  5  Files [5] start  350 / 459\n",
      "Epoch 1/10\n",
      "1000/1000 [==============================] - 58s 58ms/step - loss: 0.3355 - acc: 0.8820\n",
      "Epoch 2/10\n",
      "1000/1000 [==============================] - 58s 58ms/step - loss: 0.2178 - acc: 0.9160\n",
      "Epoch 3/10\n",
      "1000/1000 [==============================] - 58s 58ms/step - loss: 0.1850 - acc: 0.9340\n",
      "Epoch 4/10\n",
      "1000/1000 [==============================] - 58s 58ms/step - loss: 0.1543 - acc: 0.9310\n",
      "Epoch 5/10\n",
      "1000/1000 [==============================] - 58s 58ms/step - loss: 0.1250 - acc: 0.9550\n",
      "Epoch 6/10\n",
      "1000/1000 [==============================] - 58s 58ms/step - loss: 0.1041 - acc: 0.9670\n",
      "Epoch 7/10\n",
      "1000/1000 [==============================] - 58s 58ms/step - loss: 0.0884 - acc: 0.9680\n",
      "Epoch 8/10\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 0.0752 - acc: 0.9720\n",
      "Epoch 9/10\n",
      "1000/1000 [==============================] - 58s 58ms/step - loss: 0.0677 - acc: 0.9720\n",
      "Epoch 10/10\n",
      "1000/1000 [==============================] - 58s 58ms/step - loss: 0.0603 - acc: 0.9770\n",
      "Training on Epoch  4 batch  5  Files [5] start  355 / 459\n",
      "Epoch 1/10\n",
      "1000/1000 [==============================] - 67s 67ms/step - loss: 0.2769 - acc: 0.9040\n",
      "Epoch 2/10\n",
      "1000/1000 [==============================] - 66s 66ms/step - loss: 0.1840 - acc: 0.9300\n",
      "Epoch 3/10\n",
      "1000/1000 [==============================] - 66s 66ms/step - loss: 0.1281 - acc: 0.9510\n",
      "Epoch 4/10\n",
      "1000/1000 [==============================] - 65s 65ms/step - loss: 0.1006 - acc: 0.9620\n",
      "Epoch 5/10\n",
      "1000/1000 [==============================] - 71s 71ms/step - loss: 0.0797 - acc: 0.9690\n",
      "Epoch 6/10\n",
      "1000/1000 [==============================] - 68s 68ms/step - loss: 0.0659 - acc: 0.9760\n",
      "Epoch 7/10\n",
      "1000/1000 [==============================] - 69s 69ms/step - loss: 0.0629 - acc: 0.9770\n",
      "Epoch 8/10\n",
      "1000/1000 [==============================] - 72s 72ms/step - loss: 0.0521 - acc: 0.9820\n",
      "Epoch 9/10\n",
      "1000/1000 [==============================] - 71s 71ms/step - loss: 0.0417 - acc: 0.9870\n",
      "Epoch 10/10\n",
      "1000/1000 [==============================] - 70s 70ms/step - loss: 0.0351 - acc: 0.9900\n",
      "Training on Epoch  4 batch  5  Files [5] start  360 / 459\n",
      "Epoch 1/10\n",
      "1000/1000 [==============================] - 70s 70ms/step - loss: 0.3014 - acc: 0.9020\n",
      "Epoch 2/10\n",
      "1000/1000 [==============================] - 70s 70ms/step - loss: 0.1463 - acc: 0.9450\n",
      "Epoch 3/10\n",
      "1000/1000 [==============================] - 70s 70ms/step - loss: 0.0931 - acc: 0.9700\n",
      "Epoch 4/10\n",
      "1000/1000 [==============================] - 67s 67ms/step - loss: 0.0673 - acc: 0.9830\n",
      "Epoch 5/10\n",
      "1000/1000 [==============================] - 67s 67ms/step - loss: 0.0434 - acc: 0.9920\n",
      "Epoch 6/10\n",
      "1000/1000 [==============================] - 66s 66ms/step - loss: 0.0342 - acc: 0.9930\n",
      "Epoch 7/10\n",
      "1000/1000 [==============================] - 66s 66ms/step - loss: 0.0282 - acc: 0.9950\n",
      "Epoch 8/10\n",
      "1000/1000 [==============================] - 66s 66ms/step - loss: 0.0241 - acc: 0.9950\n",
      "Epoch 9/10\n",
      "1000/1000 [==============================] - 66s 66ms/step - loss: 0.0200 - acc: 0.9960\n",
      "Epoch 10/10\n",
      "1000/1000 [==============================] - 65s 65ms/step - loss: 0.0176 - acc: 0.9970\n",
      "Training on Epoch  4 batch  5  Files [5] start  365 / 459\n",
      "Epoch 1/10\n",
      "1000/1000 [==============================] - 68s 68ms/step - loss: 0.3389 - acc: 0.8920\n",
      "Epoch 2/10\n",
      "1000/1000 [==============================] - 67s 67ms/step - loss: 0.1953 - acc: 0.9300\n",
      "Epoch 3/10\n",
      "1000/1000 [==============================] - 66s 66ms/step - loss: 0.1379 - acc: 0.9570\n",
      "Epoch 4/10\n",
      "1000/1000 [==============================] - 66s 66ms/step - loss: 0.1121 - acc: 0.9610\n",
      "Epoch 5/10\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000/1000 [==============================] - 66s 66ms/step - loss: 0.0904 - acc: 0.9700\n",
      "Epoch 6/10\n",
      "1000/1000 [==============================] - 66s 66ms/step - loss: 0.0763 - acc: 0.9770\n",
      "Epoch 7/10\n",
      "1000/1000 [==============================] - 67s 67ms/step - loss: 0.0635 - acc: 0.9840\n",
      "Epoch 8/10\n",
      "1000/1000 [==============================] - 67s 67ms/step - loss: 0.0547 - acc: 0.9840\n",
      "Epoch 9/10\n",
      "1000/1000 [==============================] - 67s 67ms/step - loss: 0.0476 - acc: 0.9880\n",
      "Epoch 10/10\n",
      "1000/1000 [==============================] - 66s 66ms/step - loss: 0.0536 - acc: 0.9840\n",
      "Training on Epoch  4 batch  5  Files [5] start  370 / 459\n",
      "Epoch 1/10\n",
      "1000/1000 [==============================] - 78s 78ms/step - loss: 0.3319 - acc: 0.8980\n",
      "Epoch 2/10\n",
      "1000/1000 [==============================] - 79s 79ms/step - loss: 0.2384 - acc: 0.9130\n",
      "Epoch 3/10\n",
      "1000/1000 [==============================] - 78s 78ms/step - loss: 0.1693 - acc: 0.9350\n",
      "Epoch 4/10\n",
      "1000/1000 [==============================] - 81s 81ms/step - loss: 0.1405 - acc: 0.9400\n",
      "Epoch 5/10\n",
      "1000/1000 [==============================] - 79s 79ms/step - loss: 0.1109 - acc: 0.9530\n",
      "Epoch 6/10\n",
      "1000/1000 [==============================] - 78s 78ms/step - loss: 0.0946 - acc: 0.9590\n",
      "Epoch 7/10\n",
      "1000/1000 [==============================] - 78s 78ms/step - loss: 0.0858 - acc: 0.9600\n",
      "Epoch 8/10\n",
      "1000/1000 [==============================] - 79s 79ms/step - loss: 0.0772 - acc: 0.9650\n",
      "Epoch 9/10\n",
      "1000/1000 [==============================] - 79s 79ms/step - loss: 0.0715 - acc: 0.9670\n",
      "Epoch 10/10\n",
      "1000/1000 [==============================] - 78s 78ms/step - loss: 0.0689 - acc: 0.9670\n",
      "Training on Epoch  4 batch  5  Files [5] start  375 / 459\n",
      "Epoch 1/10\n",
      "1000/1000 [==============================] - 56s 56ms/step - loss: 0.3262 - acc: 0.8790\n",
      "Epoch 2/10\n",
      "1000/1000 [==============================] - 56s 56ms/step - loss: 0.2220 - acc: 0.9140\n",
      "Epoch 3/10\n",
      "1000/1000 [==============================] - 55s 55ms/step - loss: 0.1734 - acc: 0.9340\n",
      "Epoch 4/10\n",
      "1000/1000 [==============================] - 56s 56ms/step - loss: 0.1371 - acc: 0.9480\n",
      "Epoch 5/10\n",
      "1000/1000 [==============================] - 55s 55ms/step - loss: 0.1187 - acc: 0.9580\n",
      "Epoch 6/10\n",
      "1000/1000 [==============================] - 56s 56ms/step - loss: 0.1007 - acc: 0.9630\n",
      "Epoch 7/10\n",
      "1000/1000 [==============================] - 55s 55ms/step - loss: 0.0885 - acc: 0.9700\n",
      "Epoch 8/10\n",
      "1000/1000 [==============================] - 58s 58ms/step - loss: 0.0785 - acc: 0.9730\n",
      "Epoch 9/10\n",
      "1000/1000 [==============================] - 56s 56ms/step - loss: 0.0710 - acc: 0.9760\n",
      "Epoch 10/10\n",
      "1000/1000 [==============================] - 56s 56ms/step - loss: 0.0655 - acc: 0.9750\n",
      "Training on Epoch  4 batch  5  Files [5] start  380 / 459\n",
      "Epoch 1/10\n",
      "1000/1000 [==============================] - 56s 56ms/step - loss: 0.2912 - acc: 0.8930\n",
      "Epoch 2/10\n",
      "1000/1000 [==============================] - 57s 57ms/step - loss: 0.1898 - acc: 0.9110\n",
      "Epoch 3/10\n",
      "1000/1000 [==============================] - 56s 56ms/step - loss: 0.1366 - acc: 0.9460\n",
      "Epoch 4/10\n",
      "1000/1000 [==============================] - 57s 57ms/step - loss: 0.1057 - acc: 0.9600\n",
      "Epoch 5/10\n",
      "1000/1000 [==============================] - 57s 57ms/step - loss: 0.0867 - acc: 0.9720\n",
      "Epoch 6/10\n",
      "1000/1000 [==============================] - 57s 57ms/step - loss: 0.0722 - acc: 0.9800\n",
      "Epoch 7/10\n",
      "1000/1000 [==============================] - 58s 58ms/step - loss: 0.0600 - acc: 0.9850\n",
      "Epoch 8/10\n",
      "1000/1000 [==============================] - 57s 57ms/step - loss: 0.0529 - acc: 0.9870\n",
      "Epoch 9/10\n",
      "1000/1000 [==============================] - 57s 57ms/step - loss: 0.0473 - acc: 0.9880\n",
      "Epoch 10/10\n",
      "1000/1000 [==============================] - 57s 57ms/step - loss: 0.0427 - acc: 0.9890\n",
      "Training on Epoch  4 batch  5  Files [5] start  385 / 459\n",
      "Epoch 1/10\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 0.2927 - acc: 0.8960\n",
      "Epoch 2/10\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 0.1848 - acc: 0.9270\n",
      "Epoch 3/10\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 0.1391 - acc: 0.9480\n",
      "Epoch 4/10\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 0.1136 - acc: 0.9570\n",
      "Epoch 5/10\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 0.0911 - acc: 0.9680\n",
      "Epoch 6/10\n",
      "1000/1000 [==============================] - 60s 60ms/step - loss: 0.0754 - acc: 0.9720\n",
      "Epoch 7/10\n",
      "1000/1000 [==============================] - 60s 60ms/step - loss: 0.0661 - acc: 0.9750\n",
      "Epoch 8/10\n",
      "1000/1000 [==============================] - 60s 60ms/step - loss: 0.0579 - acc: 0.9780\n",
      "Epoch 9/10\n",
      "1000/1000 [==============================] - 60s 60ms/step - loss: 0.0512 - acc: 0.9790\n",
      "Epoch 10/10\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 0.0474 - acc: 0.9810\n",
      "Training on Epoch  4 batch  5  Files [5] start  390 / 459\n",
      "Epoch 1/10\n",
      "1000/1000 [==============================] - 55s 55ms/step - loss: 0.3375 - acc: 0.8910\n",
      "Epoch 2/10\n",
      "1000/1000 [==============================] - 55s 55ms/step - loss: 0.2350 - acc: 0.9220\n",
      "Epoch 3/10\n",
      "1000/1000 [==============================] - 56s 56ms/step - loss: 0.1758 - acc: 0.9450\n",
      "Epoch 4/10\n",
      "1000/1000 [==============================] - 55s 55ms/step - loss: 0.1296 - acc: 0.9570\n",
      "Epoch 5/10\n",
      "1000/1000 [==============================] - 56s 56ms/step - loss: 0.0981 - acc: 0.9700\n",
      "Epoch 6/10\n",
      "1000/1000 [==============================] - 56s 56ms/step - loss: 0.0799 - acc: 0.9760\n",
      "Epoch 7/10\n",
      "1000/1000 [==============================] - 56s 56ms/step - loss: 0.0699 - acc: 0.9830\n",
      "Epoch 8/10\n",
      "1000/1000 [==============================] - 55s 55ms/step - loss: 0.0605 - acc: 0.9860\n",
      "Epoch 9/10\n",
      "1000/1000 [==============================] - 55s 55ms/step - loss: 0.0486 - acc: 0.9870\n",
      "Epoch 10/10\n",
      "1000/1000 [==============================] - 55s 55ms/step - loss: 0.0431 - acc: 0.9900\n",
      "Training on Epoch  4 batch  5  Files [5] start  395 / 459\n",
      "Epoch 1/10\n",
      "1000/1000 [==============================] - 54s 54ms/step - loss: 0.2547 - acc: 0.9070\n",
      "Epoch 2/10\n",
      "1000/1000 [==============================] - 53s 53ms/step - loss: 0.1878 - acc: 0.9190\n",
      "Epoch 3/10\n",
      "1000/1000 [==============================] - 53s 53ms/step - loss: 0.1488 - acc: 0.9400\n",
      "Epoch 4/10\n",
      "1000/1000 [==============================] - 53s 53ms/step - loss: 0.1101 - acc: 0.9510\n",
      "Epoch 5/10\n",
      "1000/1000 [==============================] - 54s 54ms/step - loss: 0.0873 - acc: 0.9610\n",
      "Epoch 6/10\n",
      "1000/1000 [==============================] - 54s 54ms/step - loss: 0.0741 - acc: 0.9720\n",
      "Epoch 7/10\n",
      "1000/1000 [==============================] - 54s 54ms/step - loss: 0.0634 - acc: 0.9770\n",
      "Epoch 8/10\n",
      "1000/1000 [==============================] - 53s 53ms/step - loss: 0.0567 - acc: 0.9810\n",
      "Epoch 9/10\n",
      "1000/1000 [==============================] - 53s 53ms/step - loss: 0.0532 - acc: 0.9780\n",
      "Epoch 10/10\n",
      "1000/1000 [==============================] - 54s 54ms/step - loss: 0.0489 - acc: 0.9780\n",
      "Training on Epoch  4 batch  5  Files [5] start  400 / 459\n",
      "Epoch 1/10\n",
      "1000/1000 [==============================] - 70s 70ms/step - loss: 0.3235 - acc: 0.8910\n",
      "Epoch 2/10\n",
      "1000/1000 [==============================] - 70s 70ms/step - loss: 0.1987 - acc: 0.9230\n",
      "Epoch 3/10\n",
      "1000/1000 [==============================] - 71s 71ms/step - loss: 0.1424 - acc: 0.9450\n",
      "Epoch 4/10\n",
      "1000/1000 [==============================] - 70s 70ms/step - loss: 0.1123 - acc: 0.9600\n",
      "Epoch 5/10\n",
      "1000/1000 [==============================] - 72s 72ms/step - loss: 0.0941 - acc: 0.9710\n",
      "Epoch 6/10\n",
      "1000/1000 [==============================] - 70s 70ms/step - loss: 0.0814 - acc: 0.9730\n",
      "Epoch 7/10\n",
      "1000/1000 [==============================] - 71s 71ms/step - loss: 0.0731 - acc: 0.9770\n",
      "Epoch 8/10\n",
      "1000/1000 [==============================] - 70s 70ms/step - loss: 0.0656 - acc: 0.9790\n",
      "Epoch 9/10\n",
      "1000/1000 [==============================] - 70s 70ms/step - loss: 0.0593 - acc: 0.9820\n",
      "Epoch 10/10\n",
      "1000/1000 [==============================] - 70s 70ms/step - loss: 0.0542 - acc: 0.9810\n",
      "Training on Epoch  4 batch  5  Files [5] start  405 / 459\n",
      "Epoch 1/10\n",
      "1000/1000 [==============================] - 73s 73ms/step - loss: 0.2764 - acc: 0.8990\n",
      "Epoch 2/10\n",
      "1000/1000 [==============================] - 75s 75ms/step - loss: 0.1980 - acc: 0.9250\n",
      "Epoch 3/10\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000/1000 [==============================] - 73s 73ms/step - loss: 0.1375 - acc: 0.9470\n",
      "Epoch 4/10\n",
      "1000/1000 [==============================] - 74s 74ms/step - loss: 0.1161 - acc: 0.9550\n",
      "Epoch 5/10\n",
      "1000/1000 [==============================] - 73s 73ms/step - loss: 0.0938 - acc: 0.9660\n",
      "Epoch 6/10\n",
      "1000/1000 [==============================] - 73s 73ms/step - loss: 0.0795 - acc: 0.9720\n",
      "Epoch 7/10\n",
      "1000/1000 [==============================] - 74s 74ms/step - loss: 0.0666 - acc: 0.9780\n",
      "Epoch 8/10\n",
      "1000/1000 [==============================] - 74s 74ms/step - loss: 0.0583 - acc: 0.9820\n",
      "Epoch 9/10\n",
      "1000/1000 [==============================] - 72s 72ms/step - loss: 0.0520 - acc: 0.9830\n",
      "Epoch 10/10\n",
      "1000/1000 [==============================] - 73s 73ms/step - loss: 0.0464 - acc: 0.9870\n",
      "Training on Epoch  4 batch  5  Files [5] start  410 / 459\n",
      "Epoch 1/10\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 0.2817 - acc: 0.8960\n",
      "Epoch 2/10\n",
      "1000/1000 [==============================] - 58s 58ms/step - loss: 0.2019 - acc: 0.9240\n",
      "Epoch 3/10\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 0.1415 - acc: 0.9380\n",
      "Epoch 4/10\n",
      "1000/1000 [==============================] - 58s 58ms/step - loss: 0.1123 - acc: 0.9560\n",
      "Epoch 5/10\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 0.0893 - acc: 0.9680\n",
      "Epoch 6/10\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 0.0731 - acc: 0.9750\n",
      "Epoch 7/10\n",
      "1000/1000 [==============================] - 58s 58ms/step - loss: 0.0636 - acc: 0.9790\n",
      "Epoch 8/10\n",
      "1000/1000 [==============================] - 60s 60ms/step - loss: 0.0571 - acc: 0.9820\n",
      "Epoch 9/10\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 0.0517 - acc: 0.9830\n",
      "Epoch 10/10\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 0.0468 - acc: 0.9830\n",
      "Training on Epoch  4 batch  5  Files [5] start  415 / 459\n",
      "Epoch 1/10\n",
      "1000/1000 [==============================] - 55s 55ms/step - loss: 0.3436 - acc: 0.8960\n",
      "Epoch 2/10\n",
      "1000/1000 [==============================] - 55s 55ms/step - loss: 0.2494 - acc: 0.9210\n",
      "Epoch 3/10\n",
      "1000/1000 [==============================] - 56s 56ms/step - loss: 0.1883 - acc: 0.9320\n",
      "Epoch 4/10\n",
      "1000/1000 [==============================] - 56s 56ms/step - loss: 0.1449 - acc: 0.9520\n",
      "Epoch 5/10\n",
      "1000/1000 [==============================] - 55s 55ms/step - loss: 0.1150 - acc: 0.9600\n",
      "Epoch 6/10\n",
      "1000/1000 [==============================] - 55s 55ms/step - loss: 0.0969 - acc: 0.9650\n",
      "Epoch 7/10\n",
      "1000/1000 [==============================] - 55s 55ms/step - loss: 0.0830 - acc: 0.9740\n",
      "Epoch 8/10\n",
      "1000/1000 [==============================] - 56s 56ms/step - loss: 0.0712 - acc: 0.9810\n",
      "Epoch 9/10\n",
      "1000/1000 [==============================] - 55s 55ms/step - loss: 0.0614 - acc: 0.9870\n",
      "Epoch 10/10\n",
      "1000/1000 [==============================] - 56s 56ms/step - loss: 0.0554 - acc: 0.9870\n",
      "Training on Epoch  4 batch  5  Files [5] start  420 / 459\n",
      "Epoch 1/10\n",
      "1000/1000 [==============================] - 70s 70ms/step - loss: 0.2988 - acc: 0.8900\n",
      "Epoch 2/10\n",
      "1000/1000 [==============================] - 70s 70ms/step - loss: 0.2130 - acc: 0.9110\n",
      "Epoch 3/10\n",
      "1000/1000 [==============================] - 70s 70ms/step - loss: 0.1661 - acc: 0.9360\n",
      "Epoch 4/10\n",
      "1000/1000 [==============================] - 70s 70ms/step - loss: 0.1303 - acc: 0.9520\n",
      "Epoch 5/10\n",
      "1000/1000 [==============================] - 70s 70ms/step - loss: 0.1041 - acc: 0.9680\n",
      "Epoch 6/10\n",
      "1000/1000 [==============================] - 71s 71ms/step - loss: 0.0873 - acc: 0.9720\n",
      "Epoch 7/10\n",
      "1000/1000 [==============================] - 71s 71ms/step - loss: 0.0743 - acc: 0.9750\n",
      "Epoch 8/10\n",
      "1000/1000 [==============================] - 70s 70ms/step - loss: 0.0658 - acc: 0.9790\n",
      "Epoch 9/10\n",
      "1000/1000 [==============================] - 71s 71ms/step - loss: 0.0563 - acc: 0.9790\n",
      "Epoch 10/10\n",
      "1000/1000 [==============================] - 71s 71ms/step - loss: 0.0501 - acc: 0.9810\n",
      "Training on Epoch  4 batch  5  Files [5] start  425 / 459\n",
      "Epoch 1/10\n",
      "1000/1000 [==============================] - 62s 62ms/step - loss: 0.3188 - acc: 0.8940\n",
      "Epoch 2/10\n",
      "1000/1000 [==============================] - 62s 62ms/step - loss: 0.2086 - acc: 0.9170\n",
      "Epoch 3/10\n",
      "1000/1000 [==============================] - 62s 62ms/step - loss: 0.1486 - acc: 0.9470\n",
      "Epoch 4/10\n",
      "1000/1000 [==============================] - 63s 63ms/step - loss: 0.1179 - acc: 0.9600\n",
      "Epoch 5/10\n",
      "1000/1000 [==============================] - 62s 62ms/step - loss: 0.0950 - acc: 0.9680\n",
      "Epoch 6/10\n",
      "1000/1000 [==============================] - 62s 62ms/step - loss: 0.0778 - acc: 0.9760\n",
      "Epoch 7/10\n",
      "1000/1000 [==============================] - 62s 62ms/step - loss: 0.0643 - acc: 0.9800\n",
      "Epoch 8/10\n",
      "1000/1000 [==============================] - 62s 62ms/step - loss: 0.0533 - acc: 0.9860\n",
      "Epoch 9/10\n",
      "1000/1000 [==============================] - 62s 62ms/step - loss: 0.0454 - acc: 0.9860\n",
      "Epoch 10/10\n",
      "1000/1000 [==============================] - 63s 63ms/step - loss: 0.0404 - acc: 0.9890\n",
      "Training on Epoch  4 batch  5  Files [5] start  430 / 459\n",
      "Epoch 1/10\n",
      "1000/1000 [==============================] - 61s 61ms/step - loss: 0.2900 - acc: 0.9090\n",
      "Epoch 2/10\n",
      "1000/1000 [==============================] - 60s 60ms/step - loss: 0.2080 - acc: 0.9270\n",
      "Epoch 3/10\n",
      "1000/1000 [==============================] - 60s 60ms/step - loss: 0.1579 - acc: 0.9440\n",
      "Epoch 4/10\n",
      "1000/1000 [==============================] - 60s 60ms/step - loss: 0.1228 - acc: 0.9620\n",
      "Epoch 5/10\n",
      "1000/1000 [==============================] - 60s 60ms/step - loss: 0.1032 - acc: 0.9690\n",
      "Epoch 6/10\n",
      "1000/1000 [==============================] - 60s 60ms/step - loss: 0.0876 - acc: 0.9730\n",
      "Epoch 7/10\n",
      "1000/1000 [==============================] - 60s 60ms/step - loss: 0.0742 - acc: 0.9730\n",
      "Epoch 8/10\n",
      "1000/1000 [==============================] - 60s 60ms/step - loss: 0.0656 - acc: 0.9780\n",
      "Epoch 9/10\n",
      "1000/1000 [==============================] - 60s 60ms/step - loss: 0.0595 - acc: 0.9770\n",
      "Epoch 10/10\n",
      "1000/1000 [==============================] - 60s 60ms/step - loss: 0.0540 - acc: 0.9780\n",
      "Training on Epoch  4 batch  5  Files [5] start  435 / 459\n",
      "Epoch 1/10\n",
      "1000/1000 [==============================] - 58s 58ms/step - loss: 0.2568 - acc: 0.9090\n",
      "Epoch 2/10\n",
      "1000/1000 [==============================] - 56s 56ms/step - loss: 0.1881 - acc: 0.9370\n",
      "Epoch 3/10\n",
      "1000/1000 [==============================] - 57s 57ms/step - loss: 0.1348 - acc: 0.9530\n",
      "Epoch 4/10\n",
      "1000/1000 [==============================] - 56s 56ms/step - loss: 0.1057 - acc: 0.9690\n",
      "Epoch 5/10\n",
      "1000/1000 [==============================] - 57s 57ms/step - loss: 0.0849 - acc: 0.9750\n",
      "Epoch 6/10\n",
      "1000/1000 [==============================] - 57s 57ms/step - loss: 0.0707 - acc: 0.9790\n",
      "Epoch 7/10\n",
      "1000/1000 [==============================] - 57s 57ms/step - loss: 0.0604 - acc: 0.9800\n",
      "Epoch 8/10\n",
      "1000/1000 [==============================] - 57s 57ms/step - loss: 0.0517 - acc: 0.9850\n",
      "Epoch 9/10\n",
      "1000/1000 [==============================] - 57s 57ms/step - loss: 0.0433 - acc: 0.9870\n",
      "Epoch 10/10\n",
      "1000/1000 [==============================] - 57s 57ms/step - loss: 0.0371 - acc: 0.9890\n",
      "Training on Epoch  4 batch  5  Files [5] start  440 / 459\n",
      "Epoch 1/10\n",
      "1000/1000 [==============================] - 60s 60ms/step - loss: 0.2282 - acc: 0.9390\n",
      "Epoch 2/10\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 0.1481 - acc: 0.9510\n",
      "Epoch 3/10\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 0.0915 - acc: 0.9700\n",
      "Epoch 4/10\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 0.0739 - acc: 0.9770\n",
      "Epoch 5/10\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 0.0573 - acc: 0.9820\n",
      "Epoch 6/10\n",
      "1000/1000 [==============================] - 60s 60ms/step - loss: 0.0452 - acc: 0.9880\n",
      "Epoch 7/10\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 0.0357 - acc: 0.9940\n",
      "Epoch 8/10\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 0.0301 - acc: 0.9950\n",
      "Epoch 9/10\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 0.0250 - acc: 0.9960\n",
      "Epoch 10/10\n",
      "1000/1000 [==============================] - 60s 60ms/step - loss: 0.0216 - acc: 0.9960\n",
      "Training on Epoch  4 batch  5  Files [5] start  445 / 459\n",
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000/1000 [==============================] - 61s 61ms/step - loss: 0.1969 - acc: 0.9370\n",
      "Epoch 2/10\n",
      "1000/1000 [==============================] - 60s 60ms/step - loss: 0.1300 - acc: 0.9540\n",
      "Epoch 3/10\n",
      "1000/1000 [==============================] - 61s 61ms/step - loss: 0.0890 - acc: 0.9680\n",
      "Epoch 4/10\n",
      "1000/1000 [==============================] - 61s 61ms/step - loss: 0.0694 - acc: 0.9720\n",
      "Epoch 5/10\n",
      "1000/1000 [==============================] - 61s 61ms/step - loss: 0.0544 - acc: 0.9810\n",
      "Epoch 6/10\n",
      "1000/1000 [==============================] - 60s 60ms/step - loss: 0.0436 - acc: 0.9840\n",
      "Epoch 7/10\n",
      "1000/1000 [==============================] - 60s 60ms/step - loss: 0.0360 - acc: 0.9890\n",
      "Epoch 8/10\n",
      "1000/1000 [==============================] - 60s 60ms/step - loss: 0.0310 - acc: 0.9910\n",
      "Epoch 9/10\n",
      "1000/1000 [==============================] - 60s 60ms/step - loss: 0.0280 - acc: 0.9930\n",
      "Epoch 10/10\n",
      "1000/1000 [==============================] - 61s 61ms/step - loss: 0.0249 - acc: 0.9930\n",
      "Training on Epoch  4 batch  5  Files [5] start  450 / 459\n",
      "Epoch 1/10\n",
      "1000/1000 [==============================] - 66s 66ms/step - loss: 0.2619 - acc: 0.9100\n",
      "Epoch 2/10\n",
      "1000/1000 [==============================] - 64s 64ms/step - loss: 0.1727 - acc: 0.9380\n",
      "Epoch 3/10\n",
      "1000/1000 [==============================] - 65s 65ms/step - loss: 0.1180 - acc: 0.9560\n",
      "Epoch 4/10\n",
      "1000/1000 [==============================] - 66s 66ms/step - loss: 0.0905 - acc: 0.9710\n",
      "Epoch 5/10\n",
      "1000/1000 [==============================] - 65s 65ms/step - loss: 0.0749 - acc: 0.9810\n",
      "Epoch 6/10\n",
      "1000/1000 [==============================] - 65s 65ms/step - loss: 0.0631 - acc: 0.9820\n",
      "Epoch 7/10\n",
      "1000/1000 [==============================] - 65s 65ms/step - loss: 0.0611 - acc: 0.9840\n",
      "Epoch 8/10\n",
      "1000/1000 [==============================] - 64s 64ms/step - loss: 0.0523 - acc: 0.9840\n",
      "Epoch 9/10\n",
      "1000/1000 [==============================] - 65s 65ms/step - loss: 0.0464 - acc: 0.9870\n",
      "Epoch 10/10\n",
      "1000/1000 [==============================] - 65s 65ms/step - loss: 0.0395 - acc: 0.9880\n",
      "Training on Epoch  4 batch  4  Files [5] start  455 / 459\n",
      "Epoch 1/10\n",
      "800/800 [==============================] - 55s 69ms/step - loss: 0.2641 - acc: 0.9175\n",
      "Epoch 2/10\n",
      "800/800 [==============================] - 54s 68ms/step - loss: 0.1959 - acc: 0.9338\n",
      "Epoch 3/10\n",
      "800/800 [==============================] - 55s 69ms/step - loss: 0.1392 - acc: 0.9487\n",
      "Epoch 4/10\n",
      "800/800 [==============================] - 997s 1s/step - loss: 0.1095 - acc: 0.9650\n",
      "Epoch 5/10\n",
      "800/800 [==============================] - 55s 69ms/step - loss: 0.0964 - acc: 0.9688\n",
      "Epoch 6/10\n",
      "800/800 [==============================] - 55s 68ms/step - loss: 0.0848 - acc: 0.9712\n",
      "Epoch 7/10\n",
      "800/800 [==============================] - 55s 69ms/step - loss: 0.0759 - acc: 0.9750\n",
      "Epoch 8/10\n",
      "800/800 [==============================] - 55s 69ms/step - loss: 0.0691 - acc: 0.9788\n",
      "Epoch 9/10\n",
      "800/800 [==============================] - 56s 70ms/step - loss: 0.0638 - acc: 0.9788\n",
      "Epoch 10/10\n",
      "800/800 [==============================] - 57s 71ms/step - loss: 0.0579 - acc: 0.9788\n"
     ]
    }
   ],
   "source": [
    "for ep in range(2,s_NumEpocs):\n",
    "    if ep != 0:\n",
    "        file_name = \"train_epoch_\" + str(ep-1) + \".save\"\n",
    "        model.load_weights(file_name)\n",
    "    \n",
    "    file_index       = 0\n",
    "    batch_file_index = 0\n",
    "    \n",
    "    data = []\n",
    "    # train on batches of files\n",
    "    for file_index in range(0, file_list_count) :\n",
    "        inputFile = file_list[file_index]\n",
    "        file_index       += 1\n",
    "        batch_file_index += 1\n",
    "        # print(inputFile)\n",
    "        f = open(inputFile, 'rb')\n",
    "        test = pickle.load(f)\n",
    "        data = np.append(data, test)\n",
    "        f.close()\n",
    "    \n",
    "        if batch_file_index == s_NumFilesInBatch or file_index == file_list_count:\n",
    "            print(\"Training on Epoch \", str(ep), \"batch \", str(batch_file_index), \" Files [\" + str(s_NumFilesInBatch) + \"] start \", str(file_index - batch_file_index), \"/\", str(file_list_count) )\n",
    "            question_vectors, question_masks, triplet_vectors, Y = prepare_data(data, \n",
    "                                                                                question_max_words   = s_QuestionMaxWords, \n",
    "                                                                                triplets_max_numbers = s_TripletsMaxNumbers, \n",
    "                                                                                dimOfQuestionVector  = s_DimOfQuestionVector, \n",
    "                                                                                dimOfTripletVector   = s_DimOfTripletVector, \n",
    "                                                                                dimOfMask            = s_DimOfMask )\n",
    "            # train on this batch\n",
    "            model.fit([question_vectors, question_masks, triplet_vectors], Y, epochs = 10, batch_size = 200, shuffle=True)\n",
    "            # rest for next batch\n",
    "            batch_file_index = 0;\n",
    "            data = []\n",
    "            \n",
    "    # save the mode for the epoch\n",
    "    file_name = \"train_epoch_\" + str(ep) + \".save\"\n",
    "    model.save_weights(file_name)\n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from keras.layers import Dense, Input, Dropout, LSTM, Activation, SimpleRNN, GRU, Concatenate, Multiply, Reshape, Flatten, Bidirectional\n",
    "\n",
    "# # layers\n",
    "# s1_bilstm = Bidirectional(GRU(128, return_sequences = True), name = \"s1_bilstm\")\n",
    "# s2_bilstm = Bidirectional(GRU(128, return_sequences = False), name = \"s2_bilstm\")\n",
    "# t_bilstm = Bidirectional(GRU(128, return_sequences = False), name = \"t_bilstm\")\n",
    "# embedding_layer = pretrained_embedding_layer(word_to_vec_map, words_to_index)\n",
    "# unstack_layer = Lambda(lambda xin: myUnstack(xin), name=\"AUnstackLayer\")\n",
    "\n",
    "# # sentence inputs\n",
    "# sentence_indices = Input(shape=(maxWordsPerSentence,), dtype='int32', name=\"sentence_indices\")   \n",
    "# sentence_masks = Input(shape=(2*lstm_dim,), dtype='float32', name=\"sentence_masks\")\n",
    "\n",
    "# # sentence embeddings\n",
    "# sentence_embeddings = embedding_layer(sentence_indices)       \n",
    "# # X_sentence = Reshape((maxWordsPerSentence, -1), name=\"s_reshape\")(sentence_embeddings)\n",
    "# X_sentence = s1_bilstm(sentence_embeddings)\n",
    "# X_sentence = Multiply()([sentence_masks, X_sentence]) # (None, 60, 256)\n",
    "# X_sentence = s2_bilstm(X_sentence)\n",
    "\n",
    "# # triplets\n",
    "# triplets_input = Input(shape=(maxTriplets, maxWordsPerSentence,), dtype='int32', name=\"tripletz\") \n",
    "# triplet_embeddings = embedding_layer(triplets_input)\n",
    "\n",
    "# X_triplets = Reshape((maxTriplets, -1))(triplet_embeddings)\n",
    "# X_triplets = t_bilstm(X_triplets)\n",
    "\n",
    "# X_concatenated = Concatenate()([X_sentence, X_triplets])\n",
    "# X_concatenated = Dense(256, activation='relu', name=\"Dense256\")(X_concatenated)\n",
    "# X_concatenated = Dense(64, activation='relu', name=\"Dense64\")(X_concatenated)\n",
    "# Y_pred = Dense(1, activation='sigmoid', name=\"Dense1\")(X_concatenated)\n",
    "\n",
    "# m.v2 = Model(inputs=[sentence_indices, sentence_masks, triplets_input], outputs=X_concatenated)\n",
    "# print(m.v2.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
