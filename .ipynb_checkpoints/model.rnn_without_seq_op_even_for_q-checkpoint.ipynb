{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "#import import_ipynb\n",
    "#from model import *\n",
    "import numpy as np\n",
    "import itertools\n",
    "import glob\n",
    "import os\n",
    "import json\n",
    "import re\n",
    "import pickle\n",
    "import math\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from keras.models import Model\n",
    "from keras.backend import mean, sum\n",
    "from keras.layers import Dense, Input, Dropout, LSTM, Activation, GRU, Concatenate, Multiply, Reshape, Bidirectional\n",
    "from keras.layers.embeddings import Embedding\n",
    "from keras.preprocessing import sequence\n",
    "from keras.initializers import glorot_uniform\n",
    "from keras.layers import Lambda\n",
    "from keras.optimizers import Adam\n",
    "np.random.seed(1)\n",
    "from keras.models import Sequential\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# given x (?,dim) always return (max_len, dim) by padding with zeros\n",
    "def padding(max_len, x, dim ):\n",
    "    x_len = x.shape[0]\n",
    "    # truncate if more than max_len else pad with zeros\n",
    "    if(x_len >= max_len):\n",
    "        return x[0:max_len]\n",
    "    else:   \n",
    "        padding = np.zeros((max_len-x_len, dim))     \n",
    "        if(len(x.shape) > 1):\n",
    "            assert dim == x.shape[1],\"dimensions didnt match in padding\"   \n",
    "            return np.concatenate((x, padding))\n",
    "        else:\n",
    "            return padding\n",
    "        \n",
    "# given 1D array x, we return array of shape (max_len, dim) by replicating each element dim times and apdding with zeros at end\n",
    "def reshape_mask(max_len, x, dim):\n",
    "    # mask is a 1D array so padd with dim == 1\n",
    "    padded_question_mask = np.squeeze(padding(max_len, x, 1))\n",
    "    final_question_mask = []\n",
    "    for qm in padded_question_mask:\n",
    "        # make each mask index into array of dimension dim\n",
    "        final_question_mask.append(np.array([qm]*dim))\n",
    "    return np.asarray(final_question_mask)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "s_DimOfQuestionVector = 300\n",
    "s_DimOfTripletVector  = 900\n",
    "s_DimOfMask           = 50\n",
    "s_QuestionMaxWords    = 60\n",
    "s_TripletsMaxNumbers  = 500"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X:/cs230/proj0/ned-graphs/data_wiki_encoded/train/train_8.ipwk\n"
     ]
    }
   ],
   "source": [
    "def prepare_data(data, \n",
    "                 question_max_words, \n",
    "                 triplets_max_numbers, \n",
    "                 dimOfQuestionVector, \n",
    "                 dimOfTripletVector, \n",
    "                 dimOfMask):\n",
    "    question_vectors = []\n",
    "    question_masks = []\n",
    "    triplet_vectors = []\n",
    "    Y = []\n",
    "    for elem in data:\n",
    "        item_question             = elem[\"question\"]\n",
    "        padded_item_question      = padding(question_max_words, item_question, dimOfQuestionVector)\n",
    "        item_question_mask        = np.reshape(elem[\"question_mask\"], (len(elem[\"question_mask\"]), 1) )\n",
    "        padded_item_question_mask = reshape_mask(question_max_words, item_question_mask, dimOfMask)\n",
    "        item_correct_triplets     = elem[\"correct_triplets\"]\n",
    "        item_wrong_triplets       = elem[\"wrong_triplets\"]\n",
    "        \n",
    "        # for triplets take mean of each S, P  and 0 to get 3,300 vectors which are then concatenated to dimOfTripletVector vector\n",
    "        item_correct_triplets_vectors = [] \n",
    "        for tr in item_correct_triplets: # There are triplets_max_numbers triplets\n",
    "            # Each tr has s, p and o. Each of the _s, _p and _o's are (num_tokens, dimOfTripletVector) size\n",
    "            _s = np.mean(tr[0], axis=0)\n",
    "            _p = np.mean(tr[1], axis=0)\n",
    "            _o = np.mean(tr[2], axis=0)\n",
    "            item_correct_triplets_vectors.append(np.concatenate((_s, _p, _o))) # adding (900,) vector for each triplet\n",
    "        #pad triplet vectors so we have (triplets_max_numbers, dimOfTripletVector)  encoding for all triplets\n",
    "        padded_item_triplets_vectors = padding(triplets_max_numbers, np.asarray(item_correct_triplets_vectors), dimOfTripletVector)\n",
    "        \n",
    "        triplet_vectors.append(padded_item_triplets_vectors)\n",
    "        question_vectors.append(padded_item_question)\n",
    "        question_masks.append(padded_item_question_mask)\n",
    "        Y.append(1)\n",
    "\n",
    "        # for wrong triplets\n",
    "        item_wrong_triplets_vectors = []\n",
    "        for tr in item_wrong_triplets:\n",
    "            _s = np.mean(tr[0], axis=0)\n",
    "            _p = np.mean(tr[1], axis=0)\n",
    "            _o = np.mean(tr[2], axis=0)\n",
    "            item_wrong_triplets_vectors.append(np.concatenate((_s, _p, _o)))\n",
    "        padded_item_wrong_triplets_vectors = padding(triplets_max_numbers, np.asarray(item_wrong_triplets_vectors), dimOfTripletVector)\n",
    "                \n",
    "        triplet_vectors.append(padded_item_wrong_triplets_vectors)\n",
    "        question_vectors.append(padded_item_question)\n",
    "        question_masks.append(padded_item_question_mask)\n",
    "        Y.append(0)\n",
    "        \n",
    "        \n",
    "        \n",
    "    question_vectors = np.asarray(question_vectors)\n",
    "    question_masks   = np.asarray(question_masks)\n",
    "    triplet_vectors  = np.asarray(triplet_vectors)\n",
    "    Y                = np.asarray(Y)\n",
    "    return question_vectors, question_masks, triplet_vectors, Y\n",
    "\n",
    "def generate_model_inputs():\n",
    "    file_list = glob.glob('X:/cs230/proj0/ned-graphs/data_wiki_encoded/train/train_8.ipwk')\n",
    "    data = []\n",
    "    num = 0\n",
    "    for inputFile in file_list:\n",
    "        print(inputFile)\n",
    "        f = open(inputFile, 'rb')\n",
    "        test = pickle.load(f)\n",
    "        data = np.append(data, test)\n",
    "        f.close()\n",
    "        num += 1\n",
    "        if num == 1:\n",
    "            break\n",
    "    \n",
    "    return prepare_data(data, \n",
    "                        question_max_words   = s_QuestionMaxWords, \n",
    "                        triplets_max_numbers = s_TripletsMaxNumbers, \n",
    "                        dimOfQuestionVector  = s_DimOfQuestionVector, \n",
    "                        dimOfTripletVector   = s_DimOfTripletVector, \n",
    "                        dimOfMask            = s_DimOfMask )\n",
    "\n",
    "question_vectors, question_masks, triplet_vectors, Y = generate_model_inputs()#prepare_data(data, question_max_words=60, triplets_max_numbers=500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(200, 60, 300)\n",
      "(200, 60, 50)\n",
      "(200, 500, 900)\n",
      "(200,)\n"
     ]
    }
   ],
   "source": [
    "print(question_vectors.shape)\n",
    "print(question_masks.shape)\n",
    "print(triplet_vectors.shape)\n",
    "print(Y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "questions_input_shape      = (None,   s_DimOfQuestionVector)\n",
    "questions_mask_input_shape = (None,   s_DimOfMask )\n",
    "triplets_input_shape       = (None, s_DimOfTripletVector )\n",
    "# question_vectors(, 60, 300), question_masks(, 60, 300), triplet_vectors (,500,900), Y\n",
    "\n",
    "gru_dimension = s_DimOfMask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "question_vectors_input (InputLa (None, None, 300)    0                                            \n",
      "__________________________________________________________________________________________________\n",
      "bidirectional_17 (Bidirectional (None, None, 100)    105300      question_vectors_input[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "triplets_input (InputLayer)     (None, None, 900)    0                                            \n",
      "__________________________________________________________________________________________________\n",
      "question_masks_input (InputLaye (None, None, 50)     0                                            \n",
      "__________________________________________________________________________________________________\n",
      "bidirectional_18 (Bidirectional (None, None, 50)     45300       bidirectional_17[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "Dense50T (Dense)                (None, None, 50)     45050       triplets_input[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "multiply_2 (Multiply)           (None, None, 50)     0           question_masks_input[0][0]       \n",
      "                                                                 bidirectional_18[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "bidirectional_19 (Bidirectional (None, None, 100)    40400       Dense50T[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "AMeanLayer (Lambda)             (None, 50)           0           multiply_2[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "bidirectional_20 (Bidirectional (None, 100)          60400       bidirectional_19[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_5 (Concatenate)     (None, 150)          0           AMeanLayer[0][0]                 \n",
      "                                                                 bidirectional_20[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "Dense64 (Dense)                 (None, 64)           9664        concatenate_5[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "Dense1 (Dense)                  (None, 1)            65          Dense64[0][0]                    \n",
      "==================================================================================================\n",
      "Total params: 306,179\n",
      "Trainable params: 306,179\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "# question inputs\n",
    "question_vectors_input = Input(shape=questions_input_shape,      dtype='float32', name=\"question_vectors_input\")   \n",
    "question_masks_input   = Input(shape=questions_mask_input_shape, dtype='float32', name=\"question_masks_input\")\n",
    "\n",
    "# triplets input\n",
    "triplets_input = Input(shape=triplets_input_shape, dtype='float32', name=\"triplets_input\")  #(None, 500, 900)\n",
    "\n",
    "# layers\n",
    "# gru1 = Bidirectional(GRU( 50, return_sequences=True, name=\"Sentence_GRU1\"))\n",
    "# gru2 = Bidirectional(GRU( 50, return_sequences=False, name=\"Sentence_GRU2\"))\n",
    "# tgru1 = Bidirectional(GRU( 50, return_sequences=True, name=\"Triplet_GRU1\"))\n",
    "# tgru2 = Bidirectional(GRU( 50, return_sequences=False, name=\"Triplet_GRU2\"))\n",
    "\n",
    "gru1 =  Bidirectional(GRU( gru_dimension,  return_sequences=True,  name=\"Sentence_GRU1\"), merge_mode=\"concat\")\n",
    "gru2 =  Bidirectional(GRU( gru_dimension,  return_sequences=True,  name=\"Sentence_GRU2\"), merge_mode=\"sum\")\n",
    "tgru1 = Bidirectional(LSTM( gru_dimension,  return_sequences=True,  name=\"Triplet_GRU1\"), merge_mode=\"concat\")\n",
    "tgru2 = Bidirectional(LSTM( gru_dimension,  return_sequences=False, name=\"Triplet_GRU2\"))\n",
    "mean_layer = Lambda(lambda xin: mean(xin, axis=1), name=\"AMeanLayer\")\n",
    "#tmean_layer = Lambda(lambda xin: mean(xin, axis=1), name=\"TAMeanLayer\")\n",
    "\n",
    "X_question = gru2(gru1(question_vectors_input))             # (None, 3000, 50) -> (None, 60, 50)\n",
    "X_question = Multiply()([question_masks_input, X_question]) # (None, 60, 50)\n",
    "X_question = mean_layer(X_question)                         # (None, 60, 50) -> (None, 50)\n",
    "\n",
    "X_triplets = Dense(50, activation='relu', name=\"Dense50T\")(triplets_input)    # (None,500,900) -> (None,500,50)\n",
    "X_triplets = tgru2(tgru1(X_triplets))                                         # (None,500,50)  -> (None,50)\n",
    "#X_triplets = tmean_layer(X_triplets)                                          # (None, 500, 50) -> (None, 50)\n",
    "X_concatenated = Concatenate()([X_question, X_triplets])                      # (None,100)\n",
    "X_concatenated = Dense(64, activation='relu', name=\"Dense64\")(X_concatenated) # (None,100) -> (None,64)        \n",
    "Y_pred = Dense(1, activation='sigmoid', name=\"Dense1\")(X_concatenated)        # (None,64)  -> sigmoid    \n",
    "\n",
    "model = Model(inputs=[question_vectors_input, question_masks_input, triplets_input], outputs=Y_pred)\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "200/200 [==============================] - 20s 99ms/step - loss: 0.6910 - acc: 0.5200\n",
      "Epoch 2/30\n",
      "200/200 [==============================] - 9s 46ms/step - loss: 0.6341 - acc: 0.7250\n",
      "Epoch 3/30\n",
      "200/200 [==============================] - 9s 47ms/step - loss: 0.5014 - acc: 0.8100\n",
      "Epoch 4/30\n",
      "200/200 [==============================] - 10s 48ms/step - loss: 0.3870 - acc: 0.8600\n",
      "Epoch 5/30\n",
      "120/200 [=================>............] - ETA: 3s - loss: 0.3126 - acc: 0.8833"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-18-413f9c4cd99f>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcompile\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'binary_crossentropy'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'adam'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmetrics\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'accuracy'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mquestion_vectors\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mquestion_masks\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtriplet_vectors\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mY\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mepochs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m30\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch_size\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m20\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mx:\\cs230\\alpha\\.env\\lib\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, **kwargs)\u001b[0m\n\u001b[0;32m   1037\u001b[0m                                         \u001b[0minitial_epoch\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0minitial_epoch\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1038\u001b[0m                                         \u001b[0msteps_per_epoch\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1039\u001b[1;33m                                         validation_steps=validation_steps)\n\u001b[0m\u001b[0;32m   1040\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1041\u001b[0m     def evaluate(self, x=None, y=None,\n",
      "\u001b[1;32mx:\\cs230\\alpha\\.env\\lib\\site-packages\\keras\\engine\\training_arrays.py\u001b[0m in \u001b[0;36mfit_loop\u001b[1;34m(model, f, ins, out_labels, batch_size, epochs, verbose, callbacks, val_f, val_ins, shuffle, callback_metrics, initial_epoch, steps_per_epoch, validation_steps)\u001b[0m\n\u001b[0;32m    197\u001b[0m                     \u001b[0mins_batch\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mins_batch\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtoarray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    198\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 199\u001b[1;33m                 \u001b[0mouts\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    200\u001b[0m                 \u001b[0mouts\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mto_list\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    201\u001b[0m                 \u001b[1;32mfor\u001b[0m \u001b[0ml\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mo\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mout_labels\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mouts\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mx:\\cs230\\alpha\\.env\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, inputs)\u001b[0m\n\u001b[0;32m   2713\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_legacy_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2714\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2715\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2716\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2717\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mpy_any\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mis_tensor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[1;32min\u001b[0m \u001b[0minputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mx:\\cs230\\alpha\\.env\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py\u001b[0m in \u001b[0;36m_call\u001b[1;34m(self, inputs)\u001b[0m\n\u001b[0;32m   2673\u001b[0m             \u001b[0mfetched\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_callable_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0marray_vals\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrun_metadata\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2674\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2675\u001b[1;33m             \u001b[0mfetched\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_callable_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0marray_vals\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2676\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mfetched\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2677\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mx:\\cs230\\alpha\\.env\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1437\u001b[0m           ret = tf_session.TF_SessionRunCallable(\n\u001b[0;32m   1438\u001b[0m               \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_handle\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstatus\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1439\u001b[1;33m               run_metadata_ptr)\n\u001b[0m\u001b[0;32m   1440\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1441\u001b[0m           \u001b[0mproto_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "model.fit([question_vectors, question_masks, triplet_vectors], Y, epochs = 30, batch_size = 20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "459\n",
      "92\n"
     ]
    }
   ],
   "source": [
    "#TRAIN\n",
    "s_NumEpocs        = 5\n",
    "s_NumFilesInBatch = 5\n",
    "file_list         = glob.glob('X:/cs230/proj0/ned-graphs/data_wiki_encoded/train/train_*.ipwk')\n",
    "file_list_count   = len(file_list)\n",
    "file_batch_count  = math.ceil(( file_list_count / s_NumFilesInBatch ))\n",
    "\n",
    "print(file_list_count)\n",
    "print(file_batch_count)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training on Epoch  0 batch  5  Files [5] start  0 / 459\n",
      "Epoch 1/10\n",
      "1000/1000 [==============================] - 18s 18ms/step - loss: 0.2982 - acc: 0.8790\n",
      "Epoch 2/10\n",
      "1000/1000 [==============================] - 16s 16ms/step - loss: 0.2805 - acc: 0.8830\n",
      "Epoch 3/10\n",
      "1000/1000 [==============================] - 17s 17ms/step - loss: 0.2623 - acc: 0.8890\n",
      "Epoch 4/10\n",
      "1000/1000 [==============================] - 16s 16ms/step - loss: 0.2512 - acc: 0.8940\n",
      "Epoch 5/10\n",
      "1000/1000 [==============================] - 17s 17ms/step - loss: 0.2433 - acc: 0.9020\n",
      "Epoch 6/10\n",
      "1000/1000 [==============================] - 18s 18ms/step - loss: 0.2336 - acc: 0.9010\n",
      "Epoch 7/10\n",
      "1000/1000 [==============================] - 20s 20ms/step - loss: 0.2236 - acc: 0.9060\n",
      "Epoch 8/10\n",
      "1000/1000 [==============================] - 20s 20ms/step - loss: 0.2148 - acc: 0.9090\n",
      "Epoch 9/10\n",
      "1000/1000 [==============================] - 19s 19ms/step - loss: 0.2070 - acc: 0.9110\n",
      "Epoch 10/10\n",
      "1000/1000 [==============================] - 19s 19ms/step - loss: 0.2005 - acc: 0.9120\n",
      "Training on Epoch  0 batch  5  Files [5] start  5 / 459\n",
      "Epoch 1/10\n",
      "1000/1000 [==============================] - 23s 23ms/step - loss: 0.5290 - acc: 0.8130\n",
      "Epoch 2/10\n",
      "1000/1000 [==============================] - 24s 24ms/step - loss: 0.4409 - acc: 0.8100\n",
      "Epoch 3/10\n",
      "1000/1000 [==============================] - 23s 23ms/step - loss: 0.3920 - acc: 0.8320\n",
      "Epoch 4/10\n",
      "1000/1000 [==============================] - 23s 23ms/step - loss: 0.3644 - acc: 0.8520\n",
      "Epoch 5/10\n",
      "1000/1000 [==============================] - 23s 23ms/step - loss: 0.3407 - acc: 0.8610\n",
      "Epoch 6/10\n",
      "1000/1000 [==============================] - 23s 23ms/step - loss: 0.3209 - acc: 0.8680\n",
      "Epoch 7/10\n",
      "1000/1000 [==============================] - 23s 23ms/step - loss: 0.3075 - acc: 0.8740\n",
      "Epoch 8/10\n",
      "1000/1000 [==============================] - 23s 23ms/step - loss: 0.2959 - acc: 0.8760\n",
      "Epoch 9/10\n",
      "1000/1000 [==============================] - 23s 23ms/step - loss: 0.2850 - acc: 0.8770\n",
      "Epoch 10/10\n",
      "1000/1000 [==============================] - 23s 23ms/step - loss: 0.2704 - acc: 0.8830\n",
      "Training on Epoch  0 batch  5  Files [5] start  10 / 459\n",
      "Epoch 1/10\n",
      "1000/1000 [==============================] - 25s 25ms/step - loss: 0.4512 - acc: 0.8120\n",
      "Epoch 2/10\n",
      "1000/1000 [==============================] - 26s 26ms/step - loss: 0.4128 - acc: 0.8150\n",
      "Epoch 3/10\n",
      "1000/1000 [==============================] - 26s 26ms/step - loss: 0.3768 - acc: 0.8300\n",
      "Epoch 4/10\n",
      "1000/1000 [==============================] - 26s 26ms/step - loss: 0.3520 - acc: 0.8400\n",
      "Epoch 5/10\n",
      "1000/1000 [==============================] - 27s 27ms/step - loss: 0.3413 - acc: 0.8530\n",
      "Epoch 6/10\n",
      "1000/1000 [==============================] - 27s 27ms/step - loss: 0.3234 - acc: 0.8600\n",
      "Epoch 7/10\n",
      "1000/1000 [==============================] - 27s 27ms/step - loss: 0.3098 - acc: 0.8670\n",
      "Epoch 8/10\n",
      "1000/1000 [==============================] - 27s 27ms/step - loss: 0.2962 - acc: 0.8740\n",
      "Epoch 9/10\n",
      "1000/1000 [==============================] - 27s 27ms/step - loss: 0.2837 - acc: 0.8740\n",
      "Epoch 10/10\n",
      "1000/1000 [==============================] - 27s 27ms/step - loss: 0.2675 - acc: 0.8850\n",
      "Training on Epoch  0 batch  5  Files [5] start  15 / 459\n",
      "Epoch 1/10\n",
      "1000/1000 [==============================] - 27s 27ms/step - loss: 0.4316 - acc: 0.8120\n",
      "Epoch 2/10\n",
      "1000/1000 [==============================] - 28s 28ms/step - loss: 0.3905 - acc: 0.8310\n",
      "Epoch 3/10\n",
      "1000/1000 [==============================] - 28s 28ms/step - loss: 0.3595 - acc: 0.8450\n",
      "Epoch 4/10\n",
      "1000/1000 [==============================] - 28s 28ms/step - loss: 0.3527 - acc: 0.8420\n",
      "Epoch 5/10\n",
      "1000/1000 [==============================] - 29s 29ms/step - loss: 0.3316 - acc: 0.8580\n",
      "Epoch 6/10\n",
      "1000/1000 [==============================] - 28s 28ms/step - loss: 0.3125 - acc: 0.8700\n",
      "Epoch 7/10\n",
      "1000/1000 [==============================] - 27s 27ms/step - loss: 0.2947 - acc: 0.8700\n",
      "Epoch 8/10\n",
      "1000/1000 [==============================] - 28s 28ms/step - loss: 0.2815 - acc: 0.8840\n",
      "Epoch 9/10\n",
      "1000/1000 [==============================] - 28s 28ms/step - loss: 0.2705 - acc: 0.8890\n",
      "Epoch 10/10\n",
      "1000/1000 [==============================] - 28s 28ms/step - loss: 0.2593 - acc: 0.8940\n",
      "Training on Epoch  0 batch  5  Files [5] start  20 / 459\n",
      "Epoch 1/10\n",
      "1000/1000 [==============================] - 23s 23ms/step - loss: 0.4088 - acc: 0.8150\n",
      "Epoch 2/10\n",
      "1000/1000 [==============================] - 25s 25ms/step - loss: 0.3815 - acc: 0.8200\n",
      "Epoch 3/10\n",
      "1000/1000 [==============================] - 25s 25ms/step - loss: 0.3565 - acc: 0.8360\n",
      "Epoch 4/10\n",
      "1000/1000 [==============================] - 25s 25ms/step - loss: 0.3370 - acc: 0.8540\n",
      "Epoch 5/10\n",
      "1000/1000 [==============================] - 25s 25ms/step - loss: 0.3192 - acc: 0.8580\n",
      "Epoch 6/10\n",
      "1000/1000 [==============================] - 25s 25ms/step - loss: 0.3058 - acc: 0.8590\n",
      "Epoch 7/10\n",
      "1000/1000 [==============================] - 25s 25ms/step - loss: 0.2963 - acc: 0.8740\n",
      "Epoch 8/10\n",
      "1000/1000 [==============================] - 26s 26ms/step - loss: 0.2822 - acc: 0.8820\n",
      "Epoch 9/10\n",
      "1000/1000 [==============================] - 25s 25ms/step - loss: 0.2732 - acc: 0.8830\n",
      "Epoch 10/10\n",
      "1000/1000 [==============================] - 26s 26ms/step - loss: 0.2638 - acc: 0.8840\n",
      "Training on Epoch  0 batch  5  Files [5] start  25 / 459\n",
      "Epoch 1/10\n",
      "1000/1000 [==============================] - 28s 28ms/step - loss: 0.4369 - acc: 0.8250\n",
      "Epoch 2/10\n",
      "1000/1000 [==============================] - 29s 29ms/step - loss: 0.4009 - acc: 0.8290\n",
      "Epoch 3/10\n",
      "1000/1000 [==============================] - 29s 29ms/step - loss: 0.3683 - acc: 0.8400\n",
      "Epoch 4/10\n",
      "1000/1000 [==============================] - 30s 30ms/step - loss: 0.3489 - acc: 0.8470\n",
      "Epoch 5/10\n",
      "1000/1000 [==============================] - 30s 30ms/step - loss: 0.3399 - acc: 0.8530\n",
      "Epoch 6/10\n",
      "1000/1000 [==============================] - 30s 30ms/step - loss: 0.3157 - acc: 0.8600\n",
      "Epoch 7/10\n",
      "1000/1000 [==============================] - 30s 30ms/step - loss: 0.3108 - acc: 0.8670\n",
      "Epoch 8/10\n",
      "1000/1000 [==============================] - 30s 30ms/step - loss: 0.2958 - acc: 0.8770\n",
      "Epoch 9/10\n",
      "1000/1000 [==============================] - 30s 30ms/step - loss: 0.2817 - acc: 0.8830\n",
      "Epoch 10/10\n",
      "1000/1000 [==============================] - 30s 30ms/step - loss: 0.2713 - acc: 0.8900\n",
      "Training on Epoch  0 batch  5  Files [5] start  30 / 459\n",
      "Epoch 1/10\n",
      "1000/1000 [==============================] - 27s 27ms/step - loss: 0.4206 - acc: 0.8250\n",
      "Epoch 2/10\n",
      "1000/1000 [==============================] - 31s 31ms/step - loss: 0.3907 - acc: 0.8340\n",
      "Epoch 3/10\n",
      "1000/1000 [==============================] - 28s 28ms/step - loss: 0.3621 - acc: 0.8470\n",
      "Epoch 4/10\n",
      "1000/1000 [==============================] - 29s 29ms/step - loss: 0.3446 - acc: 0.8570\n",
      "Epoch 5/10\n",
      "1000/1000 [==============================] - 29s 29ms/step - loss: 0.3290 - acc: 0.8550\n",
      "Epoch 6/10\n",
      "1000/1000 [==============================] - 29s 29ms/step - loss: 0.3103 - acc: 0.8630\n",
      "Epoch 7/10\n",
      "1000/1000 [==============================] - 29s 29ms/step - loss: 0.2944 - acc: 0.8790\n",
      "Epoch 8/10\n",
      "1000/1000 [==============================] - 32s 32ms/step - loss: 0.2819 - acc: 0.8860\n",
      "Epoch 9/10\n",
      "1000/1000 [==============================] - 29s 29ms/step - loss: 0.2671 - acc: 0.8870\n",
      "Epoch 10/10\n",
      "1000/1000 [==============================] - 29s 29ms/step - loss: 0.2575 - acc: 0.9000\n",
      "Training on Epoch  0 batch  5  Files [5] start  35 / 459\n",
      "Epoch 1/10\n",
      "1000/1000 [==============================] - 29s 29ms/step - loss: 0.3766 - acc: 0.8440\n",
      "Epoch 2/10\n",
      "1000/1000 [==============================] - 30s 30ms/step - loss: 0.3468 - acc: 0.8650\n",
      "Epoch 3/10\n",
      "1000/1000 [==============================] - 30s 30ms/step - loss: 0.3221 - acc: 0.8680\n",
      "Epoch 4/10\n",
      "1000/1000 [==============================] - 30s 30ms/step - loss: 0.3066 - acc: 0.8670\n",
      "Epoch 5/10\n",
      "1000/1000 [==============================] - 30s 30ms/step - loss: 0.2910 - acc: 0.8800\n",
      "Epoch 6/10\n",
      "1000/1000 [==============================] - 30s 30ms/step - loss: 0.2790 - acc: 0.8910\n",
      "Epoch 7/10\n",
      "1000/1000 [==============================] - 30s 30ms/step - loss: 0.2629 - acc: 0.8930\n",
      "Epoch 8/10\n",
      "1000/1000 [==============================] - 30s 30ms/step - loss: 0.2492 - acc: 0.9020\n",
      "Epoch 9/10\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000/1000 [==============================] - 30s 30ms/step - loss: 0.2390 - acc: 0.9010\n",
      "Epoch 10/10\n",
      "1000/1000 [==============================] - 30s 30ms/step - loss: 0.2299 - acc: 0.9130\n",
      "Training on Epoch  0 batch  5  Files [5] start  40 / 459\n",
      "Epoch 1/10\n",
      "1000/1000 [==============================] - 29s 29ms/step - loss: 0.3481 - acc: 0.8660\n",
      "Epoch 2/10\n",
      "1000/1000 [==============================] - 30s 30ms/step - loss: 0.3111 - acc: 0.8780\n",
      "Epoch 3/10\n",
      "1000/1000 [==============================] - 30s 30ms/step - loss: 0.2977 - acc: 0.8850\n",
      "Epoch 4/10\n",
      "1000/1000 [==============================] - 30s 30ms/step - loss: 0.2861 - acc: 0.8930\n",
      "Epoch 5/10\n",
      "1000/1000 [==============================] - 30s 30ms/step - loss: 0.2712 - acc: 0.8950\n",
      "Epoch 6/10\n",
      "1000/1000 [==============================] - 38s 38ms/step - loss: 0.2477 - acc: 0.8970\n",
      "Epoch 7/10\n",
      "1000/1000 [==============================] - 41s 41ms/step - loss: 0.2297 - acc: 0.9060\n",
      "Epoch 8/10\n",
      "1000/1000 [==============================] - 41s 41ms/step - loss: 0.2157 - acc: 0.9100\n",
      "Epoch 9/10\n",
      "1000/1000 [==============================] - 41s 41ms/step - loss: 0.2006 - acc: 0.9210\n",
      "Epoch 10/10\n",
      "1000/1000 [==============================] - 40s 40ms/step - loss: 0.1859 - acc: 0.9240\n",
      "Training on Epoch  0 batch  5  Files [5] start  45 / 459\n",
      "Epoch 1/10\n",
      "1000/1000 [==============================] - 35s 35ms/step - loss: 0.4136 - acc: 0.8300\n",
      "Epoch 2/10\n",
      "1000/1000 [==============================] - 36s 36ms/step - loss: 0.3471 - acc: 0.8580\n",
      "Epoch 3/10\n",
      "1000/1000 [==============================] - 36s 36ms/step - loss: 0.3240 - acc: 0.8530\n",
      "Epoch 4/10\n",
      "1000/1000 [==============================] - 37s 37ms/step - loss: 0.2834 - acc: 0.8740\n",
      "Epoch 5/10\n",
      "1000/1000 [==============================] - 36s 36ms/step - loss: 0.2678 - acc: 0.8860\n",
      "Epoch 6/10\n",
      "1000/1000 [==============================] - 37s 37ms/step - loss: 0.2450 - acc: 0.8960\n",
      "Epoch 7/10\n",
      "1000/1000 [==============================] - 36s 36ms/step - loss: 0.2291 - acc: 0.9030\n",
      "Epoch 8/10\n",
      "1000/1000 [==============================] - 37s 37ms/step - loss: 0.2090 - acc: 0.9130\n",
      "Epoch 9/10\n",
      "1000/1000 [==============================] - 37s 37ms/step - loss: 0.1962 - acc: 0.9150\n",
      "Epoch 10/10\n",
      "1000/1000 [==============================] - 37s 37ms/step - loss: 0.1890 - acc: 0.9200\n",
      "Training on Epoch  0 batch  5  Files [5] start  50 / 459\n",
      "Epoch 1/10\n",
      "1000/1000 [==============================] - 40s 40ms/step - loss: 0.4371 - acc: 0.8220\n",
      "Epoch 2/10\n",
      "1000/1000 [==============================] - 40s 40ms/step - loss: 0.3737 - acc: 0.8350\n",
      "Epoch 3/10\n",
      "1000/1000 [==============================] - 40s 40ms/step - loss: 0.3207 - acc: 0.8680\n",
      "Epoch 4/10\n",
      "1000/1000 [==============================] - 40s 40ms/step - loss: 0.2973 - acc: 0.8680\n",
      "Epoch 5/10\n",
      "1000/1000 [==============================] - 40s 40ms/step - loss: 0.2743 - acc: 0.8860\n",
      "Epoch 6/10\n",
      "1000/1000 [==============================] - 40s 40ms/step - loss: 0.2592 - acc: 0.8970\n",
      "Epoch 7/10\n",
      "1000/1000 [==============================] - 40s 40ms/step - loss: 0.2426 - acc: 0.9010\n",
      "Epoch 8/10\n",
      "1000/1000 [==============================] - 41s 41ms/step - loss: 0.2295 - acc: 0.9040\n",
      "Epoch 9/10\n",
      "1000/1000 [==============================] - 41s 41ms/step - loss: 0.2177 - acc: 0.9120\n",
      "Epoch 10/10\n",
      "1000/1000 [==============================] - 41s 41ms/step - loss: 0.2069 - acc: 0.9190\n",
      "Training on Epoch  0 batch  5  Files [5] start  55 / 459\n",
      "Epoch 1/10\n",
      "1000/1000 [==============================] - 38s 38ms/step - loss: 0.4088 - acc: 0.8340\n",
      "Epoch 2/10\n",
      "1000/1000 [==============================] - 38s 38ms/step - loss: 0.3562 - acc: 0.8540\n",
      "Epoch 3/10\n",
      "1000/1000 [==============================] - 39s 39ms/step - loss: 0.3208 - acc: 0.8670\n",
      "Epoch 4/10\n",
      "1000/1000 [==============================] - 38s 38ms/step - loss: 0.2932 - acc: 0.8810\n",
      "Epoch 5/10\n",
      "1000/1000 [==============================] - 39s 39ms/step - loss: 0.2735 - acc: 0.8910\n",
      "Epoch 6/10\n",
      "1000/1000 [==============================] - 38s 38ms/step - loss: 0.2616 - acc: 0.8840\n",
      "Epoch 7/10\n",
      "1000/1000 [==============================] - 39s 39ms/step - loss: 0.2434 - acc: 0.8950\n",
      "Epoch 8/10\n",
      "1000/1000 [==============================] - 39s 39ms/step - loss: 0.2359 - acc: 0.9030\n",
      "Epoch 9/10\n",
      "1000/1000 [==============================] - 39s 39ms/step - loss: 0.2200 - acc: 0.9080\n",
      "Epoch 10/10\n",
      "1000/1000 [==============================] - 39s 39ms/step - loss: 0.2126 - acc: 0.9100\n",
      "Training on Epoch  0 batch  5  Files [5] start  60 / 459\n",
      "Epoch 1/10\n",
      "1000/1000 [==============================] - 33s 33ms/step - loss: 0.4615 - acc: 0.8140\n",
      "Epoch 2/10\n",
      "1000/1000 [==============================] - 34s 34ms/step - loss: 0.3774 - acc: 0.8400\n",
      "Epoch 3/10\n",
      "1000/1000 [==============================] - 33s 33ms/step - loss: 0.3172 - acc: 0.8580\n",
      "Epoch 4/10\n",
      "1000/1000 [==============================] - 33s 33ms/step - loss: 0.3261 - acc: 0.8460\n",
      "Epoch 5/10\n",
      "1000/1000 [==============================] - 34s 34ms/step - loss: 0.2779 - acc: 0.8720\n",
      "Epoch 6/10\n",
      "1000/1000 [==============================] - 34s 34ms/step - loss: 0.2699 - acc: 0.8770\n",
      "Epoch 7/10\n",
      "1000/1000 [==============================] - 34s 34ms/step - loss: 0.2410 - acc: 0.8980\n",
      "Epoch 8/10\n",
      "1000/1000 [==============================] - 38s 38ms/step - loss: 0.2213 - acc: 0.9010\n",
      "Epoch 9/10\n",
      "1000/1000 [==============================] - 35s 35ms/step - loss: 0.2114 - acc: 0.9040\n",
      "Epoch 10/10\n",
      "1000/1000 [==============================] - 36s 36ms/step - loss: 0.1986 - acc: 0.9170\n",
      "Training on Epoch  0 batch  5  Files [5] start  65 / 459\n",
      "Epoch 1/10\n",
      "1000/1000 [==============================] - 41s 41ms/step - loss: 0.3768 - acc: 0.8660\n",
      "Epoch 2/10\n",
      "1000/1000 [==============================] - 42s 42ms/step - loss: 0.3273 - acc: 0.8820\n",
      "Epoch 3/10\n",
      "1000/1000 [==============================] - 42s 42ms/step - loss: 0.2876 - acc: 0.8950\n",
      "Epoch 4/10\n",
      "1000/1000 [==============================] - 42s 42ms/step - loss: 0.2662 - acc: 0.9070\n",
      "Epoch 5/10\n",
      "1000/1000 [==============================] - 42s 42ms/step - loss: 0.2459 - acc: 0.9080\n",
      "Epoch 6/10\n",
      "1000/1000 [==============================] - 42s 42ms/step - loss: 0.2340 - acc: 0.9150\n",
      "Epoch 7/10\n",
      "1000/1000 [==============================] - 42s 42ms/step - loss: 0.2182 - acc: 0.9270\n",
      "Epoch 8/10\n",
      "1000/1000 [==============================] - 42s 42ms/step - loss: 0.2018 - acc: 0.9290\n",
      "Epoch 9/10\n",
      "1000/1000 [==============================] - 42s 42ms/step - loss: 0.1920 - acc: 0.9300\n",
      "Epoch 10/10\n",
      "1000/1000 [==============================] - 42s 42ms/step - loss: 0.1787 - acc: 0.9330\n",
      "Training on Epoch  0 batch  5  Files [5] start  70 / 459\n",
      "Epoch 1/10\n",
      "1000/1000 [==============================] - 41s 41ms/step - loss: 0.3837 - acc: 0.8530\n",
      "Epoch 2/10\n",
      "1000/1000 [==============================] - 42s 42ms/step - loss: 0.3181 - acc: 0.8680\n",
      "Epoch 3/10\n",
      "1000/1000 [==============================] - 42s 42ms/step - loss: 0.2867 - acc: 0.8890\n",
      "Epoch 4/10\n",
      "1000/1000 [==============================] - 42s 42ms/step - loss: 0.2553 - acc: 0.8920\n",
      "Epoch 5/10\n",
      "1000/1000 [==============================] - 42s 42ms/step - loss: 0.2311 - acc: 0.9020\n",
      "Epoch 6/10\n",
      "1000/1000 [==============================] - 42s 42ms/step - loss: 0.2153 - acc: 0.9220\n",
      "Epoch 7/10\n",
      "1000/1000 [==============================] - 42s 42ms/step - loss: 0.2146 - acc: 0.9260\n",
      "Epoch 8/10\n",
      "1000/1000 [==============================] - 42s 42ms/step - loss: 0.1943 - acc: 0.9330\n",
      "Epoch 9/10\n",
      "1000/1000 [==============================] - 42s 42ms/step - loss: 0.1759 - acc: 0.9350\n",
      "Epoch 10/10\n",
      "1000/1000 [==============================] - 42s 42ms/step - loss: 0.1616 - acc: 0.9430\n",
      "Training on Epoch  0 batch  5  Files [5] start  75 / 459\n",
      "Epoch 1/10\n",
      "1000/1000 [==============================] - 40s 40ms/step - loss: 0.4453 - acc: 0.8160\n",
      "Epoch 2/10\n",
      "1000/1000 [==============================] - 41s 41ms/step - loss: 0.3653 - acc: 0.8410\n",
      "Epoch 3/10\n",
      "1000/1000 [==============================] - 41s 41ms/step - loss: 0.3375 - acc: 0.8430\n",
      "Epoch 4/10\n",
      "1000/1000 [==============================] - 42s 42ms/step - loss: 0.3211 - acc: 0.8470\n",
      "Epoch 5/10\n",
      "1000/1000 [==============================] - 41s 41ms/step - loss: 0.2851 - acc: 0.8710\n",
      "Epoch 6/10\n",
      "1000/1000 [==============================] - 42s 42ms/step - loss: 0.2742 - acc: 0.8740\n",
      "Epoch 7/10\n",
      "1000/1000 [==============================] - 42s 42ms/step - loss: 0.2915 - acc: 0.8790\n",
      "Epoch 8/10\n",
      "1000/1000 [==============================] - 42s 42ms/step - loss: 0.2733 - acc: 0.8790\n",
      "Epoch 9/10\n",
      "1000/1000 [==============================] - 42s 42ms/step - loss: 0.2562 - acc: 0.8810\n",
      "Epoch 10/10\n",
      "1000/1000 [==============================] - 41s 41ms/step - loss: 0.2401 - acc: 0.8990\n",
      "Training on Epoch  0 batch  5  Files [5] start  80 / 459\n",
      "Epoch 1/10\n",
      "1000/1000 [==============================] - 42s 42ms/step - loss: 0.4775 - acc: 0.7980\n",
      "Epoch 2/10\n",
      "1000/1000 [==============================] - 42s 42ms/step - loss: 0.4176 - acc: 0.8170\n",
      "Epoch 3/10\n",
      "1000/1000 [==============================] - 42s 42ms/step - loss: 0.3794 - acc: 0.8340\n",
      "Epoch 4/10\n",
      "1000/1000 [==============================] - 42s 42ms/step - loss: 0.3538 - acc: 0.8360\n",
      "Epoch 5/10\n",
      "1000/1000 [==============================] - 42s 42ms/step - loss: 0.3244 - acc: 0.8620\n",
      "Epoch 6/10\n",
      "1000/1000 [==============================] - 42s 42ms/step - loss: 0.3037 - acc: 0.8740\n",
      "Epoch 7/10\n",
      "1000/1000 [==============================] - 42s 42ms/step - loss: 0.2858 - acc: 0.8830\n",
      "Epoch 8/10\n",
      "1000/1000 [==============================] - 42s 42ms/step - loss: 0.2730 - acc: 0.8840\n",
      "Epoch 9/10\n",
      "1000/1000 [==============================] - 43s 43ms/step - loss: 0.2562 - acc: 0.8900\n",
      "Epoch 10/10\n",
      "1000/1000 [==============================] - 42s 42ms/step - loss: 0.2503 - acc: 0.8920\n",
      "Training on Epoch  0 batch  5  Files [5] start  85 / 459\n",
      "Epoch 1/10\n",
      "1000/1000 [==============================] - 42s 42ms/step - loss: 0.4592 - acc: 0.8040\n",
      "Epoch 2/10\n",
      "1000/1000 [==============================] - 42s 42ms/step - loss: 0.4604 - acc: 0.7890\n",
      "Epoch 3/10\n",
      "1000/1000 [==============================] - 42s 42ms/step - loss: 0.3822 - acc: 0.8440\n",
      "Epoch 4/10\n",
      "1000/1000 [==============================] - 41s 41ms/step - loss: 0.3618 - acc: 0.8390\n",
      "Epoch 5/10\n",
      "1000/1000 [==============================] - 42s 42ms/step - loss: 0.3308 - acc: 0.8510\n",
      "Epoch 6/10\n",
      "1000/1000 [==============================] - 43s 43ms/step - loss: 0.2996 - acc: 0.8770\n",
      "Epoch 7/10\n",
      "1000/1000 [==============================] - 42s 42ms/step - loss: 0.3014 - acc: 0.8710\n",
      "Epoch 8/10\n",
      "1000/1000 [==============================] - 42s 42ms/step - loss: 0.2837 - acc: 0.8780\n",
      "Epoch 9/10\n",
      "1000/1000 [==============================] - 42s 42ms/step - loss: 0.2641 - acc: 0.8940\n",
      "Epoch 10/10\n",
      "1000/1000 [==============================] - 41s 41ms/step - loss: 0.2406 - acc: 0.9000\n",
      "Training on Epoch  0 batch  5  Files [5] start  90 / 459\n",
      "Epoch 1/10\n",
      "1000/1000 [==============================] - 38s 38ms/step - loss: 0.4211 - acc: 0.8240\n",
      "Epoch 2/10\n",
      "1000/1000 [==============================] - 39s 39ms/step - loss: 0.3613 - acc: 0.8460\n",
      "Epoch 3/10\n",
      "1000/1000 [==============================] - 39s 39ms/step - loss: 0.3276 - acc: 0.8600\n",
      "Epoch 4/10\n",
      "1000/1000 [==============================] - 39s 39ms/step - loss: 0.2965 - acc: 0.8730\n",
      "Epoch 5/10\n",
      "1000/1000 [==============================] - 39s 39ms/step - loss: 0.2762 - acc: 0.8860\n",
      "Epoch 6/10\n",
      "1000/1000 [==============================] - 39s 39ms/step - loss: 0.2562 - acc: 0.8920\n",
      "Epoch 7/10\n",
      "1000/1000 [==============================] - 39s 39ms/step - loss: 0.2395 - acc: 0.9000\n",
      "Epoch 8/10\n",
      "1000/1000 [==============================] - 39s 39ms/step - loss: 0.2284 - acc: 0.9100\n",
      "Epoch 9/10\n",
      "1000/1000 [==============================] - 39s 39ms/step - loss: 0.2138 - acc: 0.9250\n",
      "Epoch 10/10\n",
      "1000/1000 [==============================] - 39s 39ms/step - loss: 0.2035 - acc: 0.9220\n",
      "Training on Epoch  0 batch  5  Files [5] start  95 / 459\n",
      "Epoch 1/10\n",
      "1000/1000 [==============================] - 36s 36ms/step - loss: 0.3818 - acc: 0.8260\n",
      "Epoch 2/10\n",
      "1000/1000 [==============================] - 37s 37ms/step - loss: 0.3343 - acc: 0.8530\n",
      "Epoch 3/10\n",
      "1000/1000 [==============================] - 38s 38ms/step - loss: 0.2959 - acc: 0.8790\n",
      "Epoch 4/10\n",
      "1000/1000 [==============================] - 37s 37ms/step - loss: 0.2668 - acc: 0.8840\n",
      "Epoch 5/10\n",
      "1000/1000 [==============================] - 38s 38ms/step - loss: 0.2543 - acc: 0.8970\n",
      "Epoch 6/10\n",
      "1000/1000 [==============================] - 38s 38ms/step - loss: 0.5593 - acc: 0.7650\n",
      "Epoch 7/10\n",
      "1000/1000 [==============================] - 38s 38ms/step - loss: 0.4790 - acc: 0.7700\n",
      "Epoch 8/10\n",
      "1000/1000 [==============================] - 38s 38ms/step - loss: 0.4044 - acc: 0.8180\n",
      "Epoch 9/10\n",
      "1000/1000 [==============================] - 39s 39ms/step - loss: 0.3853 - acc: 0.8180\n",
      "Epoch 10/10\n",
      "1000/1000 [==============================] - 38s 38ms/step - loss: 0.3639 - acc: 0.8340\n",
      "Training on Epoch  0 batch  5  Files [5] start  100 / 459\n",
      "Epoch 1/10\n",
      "1000/1000 [==============================] - 38s 38ms/step - loss: 0.4188 - acc: 0.8190\n",
      "Epoch 2/10\n",
      "1000/1000 [==============================] - 39s 39ms/step - loss: 0.3937 - acc: 0.8260\n",
      "Epoch 3/10\n",
      "1000/1000 [==============================] - 40s 40ms/step - loss: 0.3725 - acc: 0.8270\n",
      "Epoch 4/10\n",
      "1000/1000 [==============================] - 40s 40ms/step - loss: 0.3507 - acc: 0.8390\n",
      "Epoch 5/10\n",
      "1000/1000 [==============================] - 40s 40ms/step - loss: 0.3297 - acc: 0.8490\n",
      "Epoch 6/10\n",
      "1000/1000 [==============================] - 40s 40ms/step - loss: 0.3139 - acc: 0.8540\n",
      "Epoch 7/10\n",
      "1000/1000 [==============================] - 39s 39ms/step - loss: 0.3026 - acc: 0.8720\n",
      "Epoch 8/10\n",
      "1000/1000 [==============================] - 40s 40ms/step - loss: 0.2882 - acc: 0.8810\n",
      "Epoch 9/10\n",
      "1000/1000 [==============================] - 40s 40ms/step - loss: 0.2757 - acc: 0.8830\n",
      "Epoch 10/10\n",
      "1000/1000 [==============================] - 40s 40ms/step - loss: 0.2626 - acc: 0.8900\n",
      "Training on Epoch  0 batch  5  Files [5] start  105 / 459\n",
      "Epoch 1/10\n",
      "1000/1000 [==============================] - 41s 41ms/step - loss: 0.3813 - acc: 0.8300\n",
      "Epoch 2/10\n",
      "1000/1000 [==============================] - 41s 41ms/step - loss: 0.3517 - acc: 0.8540\n",
      "Epoch 3/10\n",
      "1000/1000 [==============================] - 41s 41ms/step - loss: 0.3167 - acc: 0.8730\n",
      "Epoch 4/10\n",
      "1000/1000 [==============================] - 41s 41ms/step - loss: 0.2925 - acc: 0.8750\n",
      "Epoch 5/10\n",
      "1000/1000 [==============================] - 41s 41ms/step - loss: 0.2756 - acc: 0.8800\n",
      "Epoch 6/10\n",
      "1000/1000 [==============================] - 41s 41ms/step - loss: 0.2603 - acc: 0.8810\n",
      "Epoch 7/10\n",
      "1000/1000 [==============================] - 40s 40ms/step - loss: 0.2459 - acc: 0.8980\n",
      "Epoch 8/10\n",
      "1000/1000 [==============================] - 41s 41ms/step - loss: 0.2340 - acc: 0.9040\n",
      "Epoch 9/10\n",
      "1000/1000 [==============================] - 40s 40ms/step - loss: 0.2220 - acc: 0.9090\n",
      "Epoch 10/10\n",
      "1000/1000 [==============================] - 40s 40ms/step - loss: 0.2145 - acc: 0.9170\n",
      "Training on Epoch  0 batch  5  Files [5] start  110 / 459\n",
      "Epoch 1/10\n",
      "1000/1000 [==============================] - 45s 45ms/step - loss: 0.4643 - acc: 0.8090\n",
      "Epoch 2/10\n",
      "1000/1000 [==============================] - 45s 45ms/step - loss: 0.4046 - acc: 0.8110\n",
      "Epoch 3/10\n",
      "1000/1000 [==============================] - 46s 46ms/step - loss: 0.3750 - acc: 0.8320\n",
      "Epoch 4/10\n",
      "1000/1000 [==============================] - 46s 46ms/step - loss: 0.3435 - acc: 0.8460\n",
      "Epoch 5/10\n",
      "1000/1000 [==============================] - 46s 46ms/step - loss: 0.3278 - acc: 0.8470\n",
      "Epoch 6/10\n",
      "1000/1000 [==============================] - 46s 46ms/step - loss: 0.3050 - acc: 0.8540\n",
      "Epoch 7/10\n",
      "1000/1000 [==============================] - 46s 46ms/step - loss: 0.2890 - acc: 0.8630\n",
      "Epoch 8/10\n",
      "1000/1000 [==============================] - 46s 46ms/step - loss: 0.2710 - acc: 0.8820\n",
      "Epoch 9/10\n",
      "1000/1000 [==============================] - 46s 46ms/step - loss: 0.2607 - acc: 0.8830\n",
      "Epoch 10/10\n",
      "1000/1000 [==============================] - 46s 46ms/step - loss: 0.2485 - acc: 0.8870\n",
      "Training on Epoch  0 batch  5  Files [5] start  115 / 459\n",
      "Epoch 1/10\n",
      "1000/1000 [==============================] - 44s 44ms/step - loss: 0.4205 - acc: 0.8120\n",
      "Epoch 2/10\n",
      "1000/1000 [==============================] - 45s 45ms/step - loss: 0.3888 - acc: 0.8250\n",
      "Epoch 3/10\n",
      "1000/1000 [==============================] - 45s 45ms/step - loss: 0.3554 - acc: 0.8410\n",
      "Epoch 4/10\n",
      "1000/1000 [==============================] - 45s 45ms/step - loss: 0.3300 - acc: 0.8550\n",
      "Epoch 5/10\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000/1000 [==============================] - 45s 45ms/step - loss: 0.3144 - acc: 0.8630\n",
      "Epoch 6/10\n",
      "1000/1000 [==============================] - 45s 45ms/step - loss: 0.2966 - acc: 0.8740\n",
      "Epoch 7/10\n",
      "1000/1000 [==============================] - 45s 45ms/step - loss: 0.2795 - acc: 0.8790\n",
      "Epoch 8/10\n",
      "1000/1000 [==============================] - 45s 45ms/step - loss: 0.2653 - acc: 0.8870\n",
      "Epoch 9/10\n",
      "1000/1000 [==============================] - 45s 45ms/step - loss: 0.2534 - acc: 0.8930\n",
      "Epoch 10/10\n",
      "1000/1000 [==============================] - 46s 46ms/step - loss: 0.2466 - acc: 0.8920\n",
      "Training on Epoch  0 batch  5  Files [5] start  120 / 459\n",
      "Epoch 1/10\n",
      "1000/1000 [==============================] - 46s 46ms/step - loss: 0.3682 - acc: 0.8210\n",
      "Epoch 2/10\n",
      "1000/1000 [==============================] - 47s 47ms/step - loss: 0.3346 - acc: 0.8410\n",
      "Epoch 3/10\n",
      "1000/1000 [==============================] - 46s 46ms/step - loss: 0.3190 - acc: 0.8450\n",
      "Epoch 4/10\n",
      "1000/1000 [==============================] - 47s 47ms/step - loss: 0.3042 - acc: 0.8510\n",
      "Epoch 5/10\n",
      "1000/1000 [==============================] - 46s 46ms/step - loss: 0.2895 - acc: 0.8520\n",
      "Epoch 6/10\n",
      "1000/1000 [==============================] - 47s 47ms/step - loss: 0.2698 - acc: 0.8650\n",
      "Epoch 7/10\n",
      "1000/1000 [==============================] - 47s 47ms/step - loss: 0.2526 - acc: 0.8900\n",
      "Epoch 8/10\n",
      "1000/1000 [==============================] - 47s 47ms/step - loss: 0.2440 - acc: 0.8830\n",
      "Epoch 9/10\n",
      "1000/1000 [==============================] - 47s 47ms/step - loss: 0.2331 - acc: 0.8940\n",
      "Epoch 10/10\n",
      "1000/1000 [==============================] - 47s 47ms/step - loss: 0.2231 - acc: 0.9030\n",
      "Training on Epoch  0 batch  5  Files [5] start  125 / 459\n",
      "Epoch 1/10\n",
      "1000/1000 [==============================] - 47s 47ms/step - loss: 0.3902 - acc: 0.8330\n",
      "Epoch 2/10\n",
      "1000/1000 [==============================] - 47s 47ms/step - loss: 0.3587 - acc: 0.8380\n",
      "Epoch 3/10\n",
      "1000/1000 [==============================] - 47s 47ms/step - loss: 0.3255 - acc: 0.8480\n",
      "Epoch 4/10\n",
      "1000/1000 [==============================] - 47s 47ms/step - loss: 0.3040 - acc: 0.8630\n",
      "Epoch 5/10\n",
      "1000/1000 [==============================] - 47s 47ms/step - loss: 0.2852 - acc: 0.8670\n",
      "Epoch 6/10\n",
      "1000/1000 [==============================] - 47s 47ms/step - loss: 0.2709 - acc: 0.8740\n",
      "Epoch 7/10\n",
      "1000/1000 [==============================] - 47s 47ms/step - loss: 0.2582 - acc: 0.8830\n",
      "Epoch 8/10\n",
      "1000/1000 [==============================] - 47s 47ms/step - loss: 0.2489 - acc: 0.8890\n",
      "Epoch 9/10\n",
      "1000/1000 [==============================] - 48s 48ms/step - loss: 0.2390 - acc: 0.9000\n",
      "Epoch 10/10\n",
      "1000/1000 [==============================] - 47s 47ms/step - loss: 0.2343 - acc: 0.9030\n",
      "Training on Epoch  0 batch  5  Files [5] start  130 / 459\n",
      "Epoch 1/10\n",
      "1000/1000 [==============================] - 46s 46ms/step - loss: 0.4000 - acc: 0.8370\n",
      "Epoch 2/10\n",
      "1000/1000 [==============================] - 46s 46ms/step - loss: 0.3700 - acc: 0.8390\n",
      "Epoch 3/10\n",
      "1000/1000 [==============================] - 47s 47ms/step - loss: 0.3497 - acc: 0.8370\n",
      "Epoch 4/10\n",
      "1000/1000 [==============================] - 47s 47ms/step - loss: 0.3315 - acc: 0.8430\n",
      "Epoch 5/10\n",
      "1000/1000 [==============================] - 47s 47ms/step - loss: 0.3136 - acc: 0.8480\n",
      "Epoch 6/10\n",
      "1000/1000 [==============================] - 47s 47ms/step - loss: 0.3021 - acc: 0.8540\n",
      "Epoch 7/10\n",
      "1000/1000 [==============================] - 48s 48ms/step - loss: 0.2918 - acc: 0.8590\n",
      "Epoch 8/10\n",
      "1000/1000 [==============================] - 48s 48ms/step - loss: 0.2800 - acc: 0.8660\n",
      "Epoch 9/10\n",
      "1000/1000 [==============================] - 48s 48ms/step - loss: 0.2727 - acc: 0.8720\n",
      "Epoch 10/10\n",
      "1000/1000 [==============================] - 48s 48ms/step - loss: 0.2649 - acc: 0.8770\n",
      "Training on Epoch  0 batch  5  Files [5] start  135 / 459\n",
      "Epoch 1/10\n",
      "1000/1000 [==============================] - 41s 41ms/step - loss: 0.3556 - acc: 0.8330\n",
      "Epoch 2/10\n",
      "1000/1000 [==============================] - 42s 42ms/step - loss: 0.3260 - acc: 0.8410\n",
      "Epoch 3/10\n",
      "1000/1000 [==============================] - 42s 42ms/step - loss: 0.3088 - acc: 0.8490\n",
      "Epoch 4/10\n",
      "1000/1000 [==============================] - 43s 43ms/step - loss: 0.2886 - acc: 0.8720\n",
      "Epoch 5/10\n",
      "1000/1000 [==============================] - 43s 43ms/step - loss: 0.2799 - acc: 0.8750\n",
      "Epoch 6/10\n",
      "1000/1000 [==============================] - 43s 43ms/step - loss: 0.2722 - acc: 0.8750\n",
      "Epoch 7/10\n",
      "1000/1000 [==============================] - 43s 43ms/step - loss: 0.2617 - acc: 0.8810\n",
      "Epoch 8/10\n",
      "1000/1000 [==============================] - 43s 43ms/step - loss: 0.2568 - acc: 0.8820\n",
      "Epoch 9/10\n",
      "1000/1000 [==============================] - 43s 43ms/step - loss: 0.2506 - acc: 0.8870\n",
      "Epoch 10/10\n",
      "1000/1000 [==============================] - 43s 43ms/step - loss: 0.2455 - acc: 0.8860\n",
      "Training on Epoch  0 batch  5  Files [5] start  140 / 459\n",
      "Epoch 1/10\n",
      "1000/1000 [==============================] - 43s 43ms/step - loss: 0.3710 - acc: 0.8330\n",
      "Epoch 2/10\n",
      "1000/1000 [==============================] - 44s 44ms/step - loss: 0.3340 - acc: 0.8460\n",
      "Epoch 3/10\n",
      "1000/1000 [==============================] - 44s 44ms/step - loss: 0.3051 - acc: 0.8550\n",
      "Epoch 4/10\n",
      "1000/1000 [==============================] - 44s 44ms/step - loss: 0.2780 - acc: 0.8700\n",
      "Epoch 5/10\n",
      "1000/1000 [==============================] - 44s 44ms/step - loss: 0.2591 - acc: 0.8770\n",
      "Epoch 6/10\n",
      "1000/1000 [==============================] - 44s 44ms/step - loss: 0.2429 - acc: 0.8820\n",
      "Epoch 7/10\n",
      "1000/1000 [==============================] - 44s 44ms/step - loss: 0.2289 - acc: 0.8910\n",
      "Epoch 8/10\n",
      "1000/1000 [==============================] - 44s 44ms/step - loss: 0.2171 - acc: 0.8950\n",
      "Epoch 9/10\n",
      "1000/1000 [==============================] - 44s 44ms/step - loss: 0.2048 - acc: 0.9030\n",
      "Epoch 10/10\n",
      "1000/1000 [==============================] - 44s 44ms/step - loss: 0.1960 - acc: 0.9070\n",
      "Training on Epoch  0 batch  5  Files [5] start  145 / 459\n",
      "Epoch 1/10\n",
      "1000/1000 [==============================] - 40s 40ms/step - loss: 0.3528 - acc: 0.8620\n",
      "Epoch 2/10\n",
      "1000/1000 [==============================] - 40s 40ms/step - loss: 0.3026 - acc: 0.8740\n",
      "Epoch 3/10\n",
      "1000/1000 [==============================] - 40s 40ms/step - loss: 0.2608 - acc: 0.9010\n",
      "Epoch 4/10\n",
      "1000/1000 [==============================] - 42s 42ms/step - loss: 0.2233 - acc: 0.9040\n",
      "Epoch 5/10\n",
      "1000/1000 [==============================] - 43s 43ms/step - loss: 0.1995 - acc: 0.9190\n",
      "Epoch 6/10\n",
      "1000/1000 [==============================] - 41s 41ms/step - loss: 0.1811 - acc: 0.9270\n",
      "Epoch 7/10\n",
      "1000/1000 [==============================] - 42s 42ms/step - loss: 0.1655 - acc: 0.9410\n",
      "Epoch 8/10\n",
      "1000/1000 [==============================] - 42s 42ms/step - loss: 0.1529 - acc: 0.9400\n",
      "Epoch 9/10\n",
      "1000/1000 [==============================] - 42s 42ms/step - loss: 0.1374 - acc: 0.9440\n",
      "Epoch 10/10\n",
      "1000/1000 [==============================] - 41s 41ms/step - loss: 0.1302 - acc: 0.9450\n",
      "Training on Epoch  0 batch  5  Files [5] start  150 / 459\n",
      "Epoch 1/10\n",
      "1000/1000 [==============================] - 49s 49ms/step - loss: 0.4234 - acc: 0.8470\n",
      "Epoch 2/10\n",
      "1000/1000 [==============================] - 49s 49ms/step - loss: 0.4079 - acc: 0.8120\n",
      "Epoch 3/10\n",
      "1000/1000 [==============================] - 49s 49ms/step - loss: 0.3539 - acc: 0.8370\n",
      "Epoch 4/10\n",
      "1000/1000 [==============================] - 49s 49ms/step - loss: 0.3448 - acc: 0.8540\n",
      "Epoch 5/10\n",
      "1000/1000 [==============================] - 49s 49ms/step - loss: 0.3033 - acc: 0.8470\n",
      "Epoch 6/10\n",
      "1000/1000 [==============================] - 47s 47ms/step - loss: 0.2705 - acc: 0.8840\n",
      "Epoch 7/10\n",
      "1000/1000 [==============================] - 47s 47ms/step - loss: 0.2559 - acc: 0.8890\n",
      "Epoch 8/10\n",
      "1000/1000 [==============================] - 47s 47ms/step - loss: 0.2368 - acc: 0.8970\n",
      "Epoch 9/10\n",
      "1000/1000 [==============================] - 48s 48ms/step - loss: 0.2235 - acc: 0.9020\n",
      "Epoch 10/10\n",
      "1000/1000 [==============================] - 48s 48ms/step - loss: 0.2117 - acc: 0.9080\n",
      "Training on Epoch  0 batch  5  Files [5] start  155 / 459\n",
      "Epoch 1/10\n",
      "1000/1000 [==============================] - 47s 47ms/step - loss: 0.2996 - acc: 0.8720\n",
      "Epoch 2/10\n",
      "1000/1000 [==============================] - 49s 49ms/step - loss: 0.2586 - acc: 0.8860\n",
      "Epoch 3/10\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000/1000 [==============================] - 48s 48ms/step - loss: 0.2350 - acc: 0.8970\n",
      "Epoch 4/10\n",
      "1000/1000 [==============================] - 47s 47ms/step - loss: 0.1988 - acc: 0.9090\n",
      "Epoch 5/10\n",
      "1000/1000 [==============================] - 49s 49ms/step - loss: 0.1788 - acc: 0.9240\n",
      "Epoch 6/10\n",
      "1000/1000 [==============================] - 51s 51ms/step - loss: 0.1659 - acc: 0.9270\n",
      "Epoch 7/10\n",
      "1000/1000 [==============================] - 52s 52ms/step - loss: 0.1551 - acc: 0.9420\n",
      "Epoch 8/10\n",
      "1000/1000 [==============================] - 49s 49ms/step - loss: 0.1439 - acc: 0.9430\n",
      "Epoch 9/10\n",
      "1000/1000 [==============================] - 52s 52ms/step - loss: 0.1366 - acc: 0.9430\n",
      "Epoch 10/10\n",
      "1000/1000 [==============================] - 50s 50ms/step - loss: 0.1293 - acc: 0.9510\n",
      "Training on Epoch  0 batch  5  Files [5] start  160 / 459\n",
      "Epoch 1/10\n",
      "1000/1000 [==============================] - 46s 46ms/step - loss: 0.2482 - acc: 0.8960\n",
      "Epoch 2/10\n",
      "1000/1000 [==============================] - 47s 47ms/step - loss: 0.2225 - acc: 0.9050\n",
      "Epoch 3/10\n",
      "1000/1000 [==============================] - 47s 47ms/step - loss: 0.1914 - acc: 0.9170\n",
      "Epoch 4/10\n",
      "1000/1000 [==============================] - 47s 47ms/step - loss: 0.1707 - acc: 0.9240\n",
      "Epoch 5/10\n",
      "1000/1000 [==============================] - 47s 47ms/step - loss: 0.1655 - acc: 0.9320\n",
      "Epoch 6/10\n",
      "1000/1000 [==============================] - 47s 47ms/step - loss: 0.1455 - acc: 0.9410\n",
      "Epoch 7/10\n",
      "1000/1000 [==============================] - 47s 47ms/step - loss: 0.1351 - acc: 0.9450\n",
      "Epoch 8/10\n",
      "1000/1000 [==============================] - 47s 47ms/step - loss: 0.1253 - acc: 0.9480\n",
      "Epoch 9/10\n",
      "1000/1000 [==============================] - 47s 47ms/step - loss: 0.1176 - acc: 0.9420\n",
      "Epoch 10/10\n",
      "1000/1000 [==============================] - 47s 47ms/step - loss: 0.1114 - acc: 0.9480\n",
      "Training on Epoch  0 batch  5  Files [5] start  165 / 459\n",
      "Epoch 1/10\n",
      "1000/1000 [==============================] - 48s 48ms/step - loss: 0.2632 - acc: 0.8890\n",
      "Epoch 2/10\n",
      "1000/1000 [==============================] - 50s 50ms/step - loss: 0.2291 - acc: 0.8950\n",
      "Epoch 3/10\n",
      "1000/1000 [==============================] - 51s 51ms/step - loss: 0.2032 - acc: 0.9140\n",
      "Epoch 4/10\n",
      "1000/1000 [==============================] - 49s 49ms/step - loss: 0.1849 - acc: 0.9170\n",
      "Epoch 5/10\n",
      "1000/1000 [==============================] - 49s 49ms/step - loss: 0.1711 - acc: 0.9250\n",
      "Epoch 6/10\n",
      "1000/1000 [==============================] - 48s 48ms/step - loss: 0.1585 - acc: 0.9330\n",
      "Epoch 7/10\n",
      "1000/1000 [==============================] - 50s 50ms/step - loss: 0.1517 - acc: 0.9350\n",
      "Epoch 8/10\n",
      "1000/1000 [==============================] - 50s 50ms/step - loss: 0.1429 - acc: 0.9440\n",
      "Epoch 9/10\n",
      "1000/1000 [==============================] - 49s 49ms/step - loss: 0.1367 - acc: 0.9410\n",
      "Epoch 10/10\n",
      "1000/1000 [==============================] - 50s 50ms/step - loss: 0.1273 - acc: 0.9500\n",
      "Training on Epoch  0 batch  5  Files [5] start  170 / 459\n",
      "Epoch 1/10\n",
      "1000/1000 [==============================] - 51s 51ms/step - loss: 0.2808 - acc: 0.9090\n",
      "Epoch 2/10\n",
      "1000/1000 [==============================] - 51s 51ms/step - loss: 0.2209 - acc: 0.9130\n",
      "Epoch 3/10\n",
      "1000/1000 [==============================] - 51s 51ms/step - loss: 0.1680 - acc: 0.9270\n",
      "Epoch 4/10\n",
      "1000/1000 [==============================] - 50s 50ms/step - loss: 0.1511 - acc: 0.9350\n",
      "Epoch 5/10\n",
      "1000/1000 [==============================] - 51s 51ms/step - loss: 0.1321 - acc: 0.9430\n",
      "Epoch 6/10\n",
      "1000/1000 [==============================] - 52s 52ms/step - loss: 0.1145 - acc: 0.9490\n",
      "Epoch 7/10\n",
      "1000/1000 [==============================] - 51s 51ms/step - loss: 0.1074 - acc: 0.9510\n",
      "Epoch 8/10\n",
      "1000/1000 [==============================] - 50s 50ms/step - loss: 0.0978 - acc: 0.9570\n",
      "Epoch 9/10\n",
      "1000/1000 [==============================] - 51s 51ms/step - loss: 0.0913 - acc: 0.9610\n",
      "Epoch 10/10\n",
      "1000/1000 [==============================] - 50s 50ms/step - loss: 0.0835 - acc: 0.9650\n",
      "Training on Epoch  0 batch  5  Files [5] start  175 / 459\n",
      "Epoch 1/10\n",
      "1000/1000 [==============================] - 50s 50ms/step - loss: 0.2659 - acc: 0.8880\n",
      "Epoch 2/10\n",
      "1000/1000 [==============================] - 49s 49ms/step - loss: 0.1886 - acc: 0.9150\n",
      "Epoch 3/10\n",
      "1000/1000 [==============================] - 50s 50ms/step - loss: 0.1581 - acc: 0.9280\n",
      "Epoch 4/10\n",
      "1000/1000 [==============================] - 49s 49ms/step - loss: 0.1387 - acc: 0.9370\n",
      "Epoch 5/10\n",
      "1000/1000 [==============================] - 50s 50ms/step - loss: 0.1175 - acc: 0.9530\n",
      "Epoch 6/10\n",
      "1000/1000 [==============================] - 50s 50ms/step - loss: 0.1045 - acc: 0.9530\n",
      "Epoch 7/10\n",
      "1000/1000 [==============================] - 50s 50ms/step - loss: 0.0922 - acc: 0.9650\n",
      "Epoch 8/10\n",
      "1000/1000 [==============================] - 50s 50ms/step - loss: 0.0878 - acc: 0.9700\n",
      "Epoch 9/10\n",
      "1000/1000 [==============================] - 51s 51ms/step - loss: 0.0798 - acc: 0.9690\n",
      "Epoch 10/10\n",
      "1000/1000 [==============================] - 49s 49ms/step - loss: 0.0745 - acc: 0.9720\n",
      "Training on Epoch  0 batch  5  Files [5] start  180 / 459\n",
      "Epoch 1/10\n",
      "1000/1000 [==============================] - 51s 51ms/step - loss: 0.1838 - acc: 0.9370\n",
      "Epoch 2/10\n",
      "1000/1000 [==============================] - 50s 50ms/step - loss: 0.1378 - acc: 0.9400\n",
      "Epoch 3/10\n",
      "1000/1000 [==============================] - 50s 50ms/step - loss: 0.1242 - acc: 0.9360\n",
      "Epoch 4/10\n",
      "1000/1000 [==============================] - 50s 50ms/step - loss: 0.1156 - acc: 0.9470\n",
      "Epoch 5/10\n",
      "1000/1000 [==============================] - 51s 51ms/step - loss: 0.0999 - acc: 0.9580\n",
      "Epoch 6/10\n",
      "1000/1000 [==============================] - 50s 50ms/step - loss: 0.0916 - acc: 0.9560\n",
      "Epoch 7/10\n",
      "1000/1000 [==============================] - 48s 48ms/step - loss: 0.0879 - acc: 0.9600\n",
      "Epoch 8/10\n",
      "1000/1000 [==============================] - 47s 47ms/step - loss: 0.0809 - acc: 0.9570\n",
      "Epoch 9/10\n",
      "1000/1000 [==============================] - 48s 48ms/step - loss: 0.0759 - acc: 0.9630\n",
      "Epoch 10/10\n",
      "1000/1000 [==============================] - 48s 48ms/step - loss: 0.0712 - acc: 0.9670\n",
      "Training on Epoch  0 batch  5  Files [5] start  185 / 459\n",
      "Epoch 1/10\n",
      "1000/1000 [==============================] - 53s 53ms/step - loss: 0.1935 - acc: 0.9060\n",
      "Epoch 2/10\n",
      "1000/1000 [==============================] - 53s 53ms/step - loss: 0.1574 - acc: 0.9210\n",
      "Epoch 3/10\n",
      "1000/1000 [==============================] - 54s 54ms/step - loss: 0.1445 - acc: 0.9240\n",
      "Epoch 4/10\n",
      "1000/1000 [==============================] - 54s 54ms/step - loss: 0.1321 - acc: 0.9330\n",
      "Epoch 5/10\n",
      "1000/1000 [==============================] - 53s 53ms/step - loss: 0.1259 - acc: 0.9340\n",
      "Epoch 6/10\n",
      "1000/1000 [==============================] - 53s 53ms/step - loss: 0.1204 - acc: 0.9340\n",
      "Epoch 7/10\n",
      "1000/1000 [==============================] - 55s 55ms/step - loss: 0.1129 - acc: 0.9370\n",
      "Epoch 8/10\n",
      "1000/1000 [==============================] - 53s 53ms/step - loss: 0.1083 - acc: 0.9390\n",
      "Epoch 9/10\n",
      "1000/1000 [==============================] - 53s 53ms/step - loss: 0.1047 - acc: 0.9390\n",
      "Epoch 10/10\n",
      "1000/1000 [==============================] - 53s 53ms/step - loss: 0.1034 - acc: 0.9390\n",
      "Training on Epoch  0 batch  5  Files [5] start  190 / 459\n",
      "Epoch 1/10\n",
      "1000/1000 [==============================] - 47s 47ms/step - loss: 0.2472 - acc: 0.9020\n",
      "Epoch 2/10\n",
      "1000/1000 [==============================] - 47s 47ms/step - loss: 0.1916 - acc: 0.8990\n",
      "Epoch 3/10\n",
      "1000/1000 [==============================] - 47s 47ms/step - loss: 0.1618 - acc: 0.9120\n",
      "Epoch 4/10\n",
      "1000/1000 [==============================] - 47s 47ms/step - loss: 0.1466 - acc: 0.9200\n",
      "Epoch 5/10\n",
      "1000/1000 [==============================] - 47s 47ms/step - loss: 0.1387 - acc: 0.9320\n",
      "Epoch 6/10\n",
      "1000/1000 [==============================] - 46s 46ms/step - loss: 0.1292 - acc: 0.9290\n",
      "Epoch 7/10\n",
      "1000/1000 [==============================] - 45s 45ms/step - loss: 0.1225 - acc: 0.9310\n",
      "Epoch 8/10\n",
      "1000/1000 [==============================] - 47s 47ms/step - loss: 0.1166 - acc: 0.9350\n",
      "Epoch 9/10\n",
      "1000/1000 [==============================] - 49s 49ms/step - loss: 0.1124 - acc: 0.9350\n",
      "Epoch 10/10\n",
      "1000/1000 [==============================] - 48s 48ms/step - loss: 0.1105 - acc: 0.9370\n",
      "Training on Epoch  0 batch  5  Files [5] start  195 / 459\n",
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000/1000 [==============================] - 53s 53ms/step - loss: 0.2633 - acc: 0.8840\n",
      "Epoch 2/10\n",
      "1000/1000 [==============================] - 54s 54ms/step - loss: 0.2182 - acc: 0.8960\n",
      "Epoch 3/10\n",
      "1000/1000 [==============================] - 54s 54ms/step - loss: 0.2063 - acc: 0.8990\n",
      "Epoch 4/10\n",
      "1000/1000 [==============================] - 54s 54ms/step - loss: 0.1886 - acc: 0.9040\n",
      "Epoch 5/10\n",
      "1000/1000 [==============================] - 54s 54ms/step - loss: 0.1786 - acc: 0.9030\n",
      "Epoch 6/10\n",
      "1000/1000 [==============================] - 54s 54ms/step - loss: 0.1714 - acc: 0.9090\n",
      "Epoch 7/10\n",
      "1000/1000 [==============================] - 55s 55ms/step - loss: 0.1639 - acc: 0.9140\n",
      "Epoch 8/10\n",
      "1000/1000 [==============================] - 55s 55ms/step - loss: 0.1594 - acc: 0.9150\n",
      "Epoch 9/10\n",
      "1000/1000 [==============================] - 55s 55ms/step - loss: 0.1528 - acc: 0.9220\n",
      "Epoch 10/10\n",
      "1000/1000 [==============================] - 56s 56ms/step - loss: 0.1502 - acc: 0.9190\n",
      "Training on Epoch  0 batch  5  Files [5] start  200 / 459\n",
      "Epoch 1/10\n",
      "1000/1000 [==============================] - 50s 50ms/step - loss: 0.2418 - acc: 0.8820\n",
      "Epoch 2/10\n",
      "1000/1000 [==============================] - 49s 49ms/step - loss: 0.2115 - acc: 0.8940\n",
      "Epoch 3/10\n",
      "1000/1000 [==============================] - 49s 49ms/step - loss: 0.1824 - acc: 0.9050\n",
      "Epoch 4/10\n",
      "1000/1000 [==============================] - 49s 49ms/step - loss: 0.1615 - acc: 0.9160\n",
      "Epoch 5/10\n",
      "1000/1000 [==============================] - 49s 49ms/step - loss: 0.1496 - acc: 0.9250\n",
      "Epoch 6/10\n",
      "1000/1000 [==============================] - 49s 49ms/step - loss: 0.1408 - acc: 0.9290\n",
      "Epoch 7/10\n",
      "1000/1000 [==============================] - 50s 50ms/step - loss: 0.1336 - acc: 0.9370\n",
      "Epoch 8/10\n",
      "1000/1000 [==============================] - 50s 50ms/step - loss: 0.1276 - acc: 0.9380\n",
      "Epoch 9/10\n",
      "1000/1000 [==============================] - 50s 50ms/step - loss: 0.1222 - acc: 0.9390\n",
      "Epoch 10/10\n",
      "1000/1000 [==============================] - 50s 50ms/step - loss: 0.1170 - acc: 0.9430\n",
      "Training on Epoch  0 batch  5  Files [5] start  205 / 459\n",
      "Epoch 1/10\n",
      "1000/1000 [==============================] - 51s 51ms/step - loss: 0.1896 - acc: 0.9000\n",
      "Epoch 2/10\n",
      "1000/1000 [==============================] - 52s 52ms/step - loss: 0.1640 - acc: 0.8980\n",
      "Epoch 3/10\n",
      "1000/1000 [==============================] - 51s 51ms/step - loss: 0.1489 - acc: 0.9100\n",
      "Epoch 4/10\n",
      "1000/1000 [==============================] - 51s 51ms/step - loss: 0.1417 - acc: 0.9100\n",
      "Epoch 5/10\n",
      "1000/1000 [==============================] - 52s 52ms/step - loss: 0.1362 - acc: 0.9110\n",
      "Epoch 6/10\n",
      "1000/1000 [==============================] - 52s 52ms/step - loss: 0.1315 - acc: 0.9170\n",
      "Epoch 7/10\n",
      "1000/1000 [==============================] - 53s 53ms/step - loss: 0.1265 - acc: 0.9180\n",
      "Epoch 8/10\n",
      "1000/1000 [==============================] - 53s 53ms/step - loss: 0.1224 - acc: 0.9160\n",
      "Epoch 9/10\n",
      "1000/1000 [==============================] - 53s 53ms/step - loss: 0.1206 - acc: 0.9190\n",
      "Epoch 10/10\n",
      "1000/1000 [==============================] - 53s 53ms/step - loss: 0.1176 - acc: 0.9250\n",
      "Training on Epoch  0 batch  5  Files [5] start  210 / 459\n",
      "Epoch 1/10\n",
      "1000/1000 [==============================] - 52s 52ms/step - loss: 0.2823 - acc: 0.9060\n",
      "Epoch 2/10\n",
      "1000/1000 [==============================] - 52s 52ms/step - loss: 0.2159 - acc: 0.9270\n",
      "Epoch 3/10\n",
      "1000/1000 [==============================] - 49s 49ms/step - loss: 0.1776 - acc: 0.9270\n",
      "Epoch 4/10\n",
      "1000/1000 [==============================] - 48s 48ms/step - loss: 0.1436 - acc: 0.9470\n",
      "Epoch 5/10\n",
      "1000/1000 [==============================] - 52s 52ms/step - loss: 0.1297 - acc: 0.9550\n",
      "Epoch 6/10\n",
      "1000/1000 [==============================] - 52s 52ms/step - loss: 0.1173 - acc: 0.9580\n",
      "Epoch 7/10\n",
      "1000/1000 [==============================] - 52s 52ms/step - loss: 0.1089 - acc: 0.9570\n",
      "Epoch 8/10\n",
      "1000/1000 [==============================] - 53s 53ms/step - loss: 0.1001 - acc: 0.9640\n",
      "Epoch 9/10\n",
      "1000/1000 [==============================] - 51s 51ms/step - loss: 0.0942 - acc: 0.9640\n",
      "Epoch 10/10\n",
      "1000/1000 [==============================] - 48s 48ms/step - loss: 0.0878 - acc: 0.9680\n",
      "Training on Epoch  0 batch  5  Files [5] start  215 / 459\n",
      "Epoch 1/10\n",
      "1000/1000 [==============================] - 55s 55ms/step - loss: 0.2756 - acc: 0.8760\n",
      "Epoch 2/10\n",
      "1000/1000 [==============================] - 53s 53ms/step - loss: 0.2340 - acc: 0.8820\n",
      "Epoch 3/10\n",
      "1000/1000 [==============================] - 56s 56ms/step - loss: 0.2050 - acc: 0.8910\n",
      "Epoch 4/10\n",
      "1000/1000 [==============================] - 54s 54ms/step - loss: 0.1934 - acc: 0.8910\n",
      "Epoch 5/10\n",
      "1000/1000 [==============================] - 54s 54ms/step - loss: 0.1826 - acc: 0.9060\n",
      "Epoch 6/10\n",
      "1000/1000 [==============================] - 51s 51ms/step - loss: 0.1728 - acc: 0.9130\n",
      "Epoch 7/10\n",
      "1000/1000 [==============================] - 51s 51ms/step - loss: 0.1632 - acc: 0.9150\n",
      "Epoch 8/10\n",
      "1000/1000 [==============================] - 51s 51ms/step - loss: 0.1599 - acc: 0.9180\n",
      "Epoch 9/10\n",
      "1000/1000 [==============================] - 52s 52ms/step - loss: 0.1552 - acc: 0.9220\n",
      "Epoch 10/10\n",
      "1000/1000 [==============================] - 52s 52ms/step - loss: 0.1473 - acc: 0.9270\n",
      "Training on Epoch  0 batch  5  Files [5] start  220 / 459\n",
      "Epoch 1/10\n",
      "1000/1000 [==============================] - 48s 48ms/step - loss: 0.3352 - acc: 0.8870\n",
      "Epoch 2/10\n",
      "1000/1000 [==============================] - 48s 48ms/step - loss: 0.2704 - acc: 0.8890\n",
      "Epoch 3/10\n",
      "1000/1000 [==============================] - 48s 48ms/step - loss: 0.2219 - acc: 0.9080\n",
      "Epoch 4/10\n",
      "1000/1000 [==============================] - 48s 48ms/step - loss: 0.1966 - acc: 0.9140\n",
      "Epoch 5/10\n",
      "1000/1000 [==============================] - 49s 49ms/step - loss: 0.1797 - acc: 0.9190\n",
      "Epoch 6/10\n",
      "1000/1000 [==============================] - 48s 48ms/step - loss: 0.1603 - acc: 0.9260\n",
      "Epoch 7/10\n",
      "1000/1000 [==============================] - 49s 49ms/step - loss: 0.1510 - acc: 0.9280\n",
      "Epoch 8/10\n",
      "1000/1000 [==============================] - 48s 48ms/step - loss: 0.1417 - acc: 0.9340\n",
      "Epoch 9/10\n",
      "1000/1000 [==============================] - 48s 48ms/step - loss: 0.1337 - acc: 0.9330\n",
      "Epoch 10/10\n",
      "1000/1000 [==============================] - 48s 48ms/step - loss: 0.1260 - acc: 0.9370\n",
      "Training on Epoch  0 batch  5  Files [5] start  225 / 459\n",
      "Epoch 1/10\n",
      "1000/1000 [==============================] - 49s 49ms/step - loss: 0.2247 - acc: 0.8950\n",
      "Epoch 2/10\n",
      "1000/1000 [==============================] - 49s 49ms/step - loss: 0.1932 - acc: 0.9190\n",
      "Epoch 3/10\n",
      "1000/1000 [==============================] - 50s 50ms/step - loss: 0.1664 - acc: 0.9230\n",
      "Epoch 4/10\n",
      "1000/1000 [==============================] - 50s 50ms/step - loss: 0.1426 - acc: 0.9330\n",
      "Epoch 5/10\n",
      "1000/1000 [==============================] - 50s 50ms/step - loss: 0.1295 - acc: 0.9380\n",
      "Epoch 6/10\n",
      "1000/1000 [==============================] - 49s 49ms/step - loss: 0.1159 - acc: 0.9510\n",
      "Epoch 7/10\n",
      "1000/1000 [==============================] - 50s 50ms/step - loss: 0.1102 - acc: 0.9460\n",
      "Epoch 8/10\n",
      "1000/1000 [==============================] - 50s 50ms/step - loss: 0.1009 - acc: 0.9610\n",
      "Epoch 9/10\n",
      "1000/1000 [==============================] - 50s 50ms/step - loss: 0.0979 - acc: 0.9550\n",
      "Epoch 10/10\n",
      "1000/1000 [==============================] - 50s 50ms/step - loss: 0.0882 - acc: 0.9670\n",
      "Training on Epoch  0 batch  5  Files [5] start  230 / 459\n",
      "Epoch 1/10\n",
      "1000/1000 [==============================] - 47s 47ms/step - loss: 0.1571 - acc: 0.9240\n",
      "Epoch 2/10\n",
      "1000/1000 [==============================] - 47s 47ms/step - loss: 0.1305 - acc: 0.9330\n",
      "Epoch 3/10\n",
      "1000/1000 [==============================] - 54s 54ms/step - loss: 0.1195 - acc: 0.9380\n",
      "Epoch 4/10\n",
      "1000/1000 [==============================] - 48s 48ms/step - loss: 0.1076 - acc: 0.9470\n",
      "Epoch 5/10\n",
      "1000/1000 [==============================] - 48s 48ms/step - loss: 0.1046 - acc: 0.9460\n",
      "Epoch 6/10\n",
      "1000/1000 [==============================] - 49s 49ms/step - loss: 0.0993 - acc: 0.9530\n",
      "Epoch 7/10\n",
      "1000/1000 [==============================] - 49s 49ms/step - loss: 0.0947 - acc: 0.9550\n",
      "Epoch 8/10\n",
      "1000/1000 [==============================] - 50s 50ms/step - loss: 0.0907 - acc: 0.9560\n",
      "Epoch 9/10\n",
      "1000/1000 [==============================] - 49s 49ms/step - loss: 0.0886 - acc: 0.9580\n",
      "Epoch 10/10\n",
      "1000/1000 [==============================] - 49s 49ms/step - loss: 0.0870 - acc: 0.9530\n",
      "Training on Epoch  0 batch  5  Files [5] start  235 / 459\n",
      "Epoch 1/10\n",
      "1000/1000 [==============================] - 47s 47ms/step - loss: 0.2114 - acc: 0.9130\n",
      "Epoch 2/10\n",
      "1000/1000 [==============================] - 47s 47ms/step - loss: 0.1410 - acc: 0.9380\n",
      "Epoch 3/10\n",
      "1000/1000 [==============================] - 46s 46ms/step - loss: 0.1278 - acc: 0.9390\n",
      "Epoch 4/10\n",
      "1000/1000 [==============================] - 47s 47ms/step - loss: 0.1175 - acc: 0.9410\n",
      "Epoch 5/10\n",
      "1000/1000 [==============================] - 46s 46ms/step - loss: 0.1080 - acc: 0.9520\n",
      "Epoch 6/10\n",
      "1000/1000 [==============================] - 45s 45ms/step - loss: 0.1032 - acc: 0.9550\n",
      "Epoch 7/10\n",
      "1000/1000 [==============================] - 46s 46ms/step - loss: 0.0953 - acc: 0.9540\n",
      "Epoch 8/10\n",
      "1000/1000 [==============================] - 47s 47ms/step - loss: 0.0911 - acc: 0.9570\n",
      "Epoch 9/10\n",
      "1000/1000 [==============================] - 46s 46ms/step - loss: 0.0873 - acc: 0.9580\n",
      "Epoch 10/10\n",
      "1000/1000 [==============================] - 44s 44ms/step - loss: 0.0837 - acc: 0.9580\n",
      "Training on Epoch  0 batch  5  Files [5] start  240 / 459\n",
      "Epoch 1/10\n",
      "1000/1000 [==============================] - 44s 44ms/step - loss: 0.1508 - acc: 0.9280\n",
      "Epoch 2/10\n",
      "1000/1000 [==============================] - 46s 46ms/step - loss: 0.1252 - acc: 0.9390\n",
      "Epoch 3/10\n",
      "1000/1000 [==============================] - 49s 49ms/step - loss: 0.1064 - acc: 0.9510\n",
      "Epoch 4/10\n",
      "1000/1000 [==============================] - 44s 44ms/step - loss: 0.0918 - acc: 0.9550\n",
      "Epoch 5/10\n",
      "1000/1000 [==============================] - 45s 45ms/step - loss: 0.0873 - acc: 0.9600\n",
      "Epoch 6/10\n",
      "1000/1000 [==============================] - 43s 43ms/step - loss: 0.0812 - acc: 0.9610\n",
      "Epoch 7/10\n",
      "1000/1000 [==============================] - 44s 44ms/step - loss: 0.0775 - acc: 0.9600\n",
      "Epoch 8/10\n",
      "1000/1000 [==============================] - 44s 44ms/step - loss: 0.0743 - acc: 0.9620\n",
      "Epoch 9/10\n",
      "1000/1000 [==============================] - 44s 44ms/step - loss: 0.0686 - acc: 0.9670\n",
      "Epoch 10/10\n",
      "1000/1000 [==============================] - 46s 46ms/step - loss: 0.0660 - acc: 0.9650\n",
      "Training on Epoch  0 batch  5  Files [5] start  245 / 459\n",
      "Epoch 1/10\n",
      "1000/1000 [==============================] - 48s 48ms/step - loss: 0.1847 - acc: 0.9170\n",
      "Epoch 2/10\n",
      "1000/1000 [==============================] - 52s 52ms/step - loss: 0.1478 - acc: 0.9310\n",
      "Epoch 3/10\n",
      "1000/1000 [==============================] - 52s 52ms/step - loss: 0.1236 - acc: 0.9410\n",
      "Epoch 4/10\n",
      "1000/1000 [==============================] - 51s 51ms/step - loss: 0.1124 - acc: 0.9460\n",
      "Epoch 5/10\n",
      "1000/1000 [==============================] - 53s 53ms/step - loss: 0.1021 - acc: 0.9510\n",
      "Epoch 6/10\n",
      "1000/1000 [==============================] - 54s 54ms/step - loss: 0.0963 - acc: 0.9530\n",
      "Epoch 7/10\n",
      "1000/1000 [==============================] - 51s 51ms/step - loss: 0.0914 - acc: 0.9510\n",
      "Epoch 8/10\n",
      "1000/1000 [==============================] - 51s 51ms/step - loss: 0.0883 - acc: 0.9530\n",
      "Epoch 9/10\n",
      "1000/1000 [==============================] - 51s 51ms/step - loss: 0.0847 - acc: 0.9550\n",
      "Epoch 10/10\n",
      "1000/1000 [==============================] - 51s 51ms/step - loss: 0.0828 - acc: 0.9560\n",
      "Training on Epoch  0 batch  5  Files [5] start  250 / 459\n",
      "Epoch 1/10\n",
      "1000/1000 [==============================] - 55s 55ms/step - loss: 0.2154 - acc: 0.9060\n",
      "Epoch 2/10\n",
      "1000/1000 [==============================] - 56s 56ms/step - loss: 0.1557 - acc: 0.9170\n",
      "Epoch 3/10\n",
      "1000/1000 [==============================] - 56s 56ms/step - loss: 0.1312 - acc: 0.9380\n",
      "Epoch 4/10\n",
      "1000/1000 [==============================] - 56s 56ms/step - loss: 0.1229 - acc: 0.9440\n",
      "Epoch 5/10\n",
      "1000/1000 [==============================] - 57s 57ms/step - loss: 0.1177 - acc: 0.9420\n",
      "Epoch 6/10\n",
      "1000/1000 [==============================] - 56s 56ms/step - loss: 0.1121 - acc: 0.9440\n",
      "Epoch 7/10\n",
      "1000/1000 [==============================] - 56s 56ms/step - loss: 0.1082 - acc: 0.9450\n",
      "Epoch 8/10\n",
      "1000/1000 [==============================] - 56s 56ms/step - loss: 0.1049 - acc: 0.9490\n",
      "Epoch 9/10\n",
      "1000/1000 [==============================] - 57s 57ms/step - loss: 0.1038 - acc: 0.9500\n",
      "Epoch 10/10\n",
      "1000/1000 [==============================] - 56s 56ms/step - loss: 0.1012 - acc: 0.9510\n",
      "Training on Epoch  0 batch  5  Files [5] start  255 / 459\n",
      "Epoch 1/10\n",
      "1000/1000 [==============================] - 53s 53ms/step - loss: 0.1803 - acc: 0.9250\n",
      "Epoch 2/10\n",
      "1000/1000 [==============================] - 52s 52ms/step - loss: 0.1480 - acc: 0.9320\n",
      "Epoch 3/10\n",
      "1000/1000 [==============================] - 55s 55ms/step - loss: 0.1318 - acc: 0.9370\n",
      "Epoch 4/10\n",
      "1000/1000 [==============================] - 54s 54ms/step - loss: 0.1182 - acc: 0.9440\n",
      "Epoch 5/10\n",
      "1000/1000 [==============================] - 53s 53ms/step - loss: 0.1087 - acc: 0.9480\n",
      "Epoch 6/10\n",
      "1000/1000 [==============================] - 53s 53ms/step - loss: 0.1035 - acc: 0.9490\n",
      "Epoch 7/10\n",
      "1000/1000 [==============================] - 52s 52ms/step - loss: 0.0998 - acc: 0.9550\n",
      "Epoch 8/10\n",
      "1000/1000 [==============================] - 52s 52ms/step - loss: 0.0971 - acc: 0.9520\n",
      "Epoch 9/10\n",
      "1000/1000 [==============================] - 52s 52ms/step - loss: 0.0943 - acc: 0.9520\n",
      "Epoch 10/10\n",
      "1000/1000 [==============================] - 53s 53ms/step - loss: 0.0922 - acc: 0.9540\n",
      "Training on Epoch  0 batch  5  Files [5] start  260 / 459\n",
      "Epoch 1/10\n",
      "1000/1000 [==============================] - 56s 56ms/step - loss: 0.2375 - acc: 0.8990\n",
      "Epoch 2/10\n",
      "1000/1000 [==============================] - 56s 56ms/step - loss: 0.2056 - acc: 0.9100\n",
      "Epoch 3/10\n",
      "1000/1000 [==============================] - 57s 57ms/step - loss: 0.1626 - acc: 0.9280\n",
      "Epoch 4/10\n",
      "1000/1000 [==============================] - 58s 58ms/step - loss: 0.1425 - acc: 0.9350\n",
      "Epoch 5/10\n",
      "1000/1000 [==============================] - 56s 56ms/step - loss: 0.1264 - acc: 0.9380\n",
      "Epoch 6/10\n",
      "1000/1000 [==============================] - 56s 56ms/step - loss: 0.1171 - acc: 0.9460\n",
      "Epoch 7/10\n",
      "1000/1000 [==============================] - 57s 57ms/step - loss: 0.1082 - acc: 0.9480\n",
      "Epoch 8/10\n",
      "1000/1000 [==============================] - 57s 57ms/step - loss: 0.1015 - acc: 0.9560\n",
      "Epoch 9/10\n",
      "1000/1000 [==============================] - 57s 57ms/step - loss: 0.0953 - acc: 0.9600\n",
      "Epoch 10/10\n",
      "1000/1000 [==============================] - 58s 58ms/step - loss: 0.0911 - acc: 0.9620\n",
      "Training on Epoch  0 batch  5  Files [5] start  265 / 459\n",
      "Epoch 1/10\n",
      "1000/1000 [==============================] - 54s 54ms/step - loss: 0.2809 - acc: 0.8940\n",
      "Epoch 2/10\n",
      "1000/1000 [==============================] - 54s 54ms/step - loss: 0.2117 - acc: 0.9020\n",
      "Epoch 3/10\n",
      "1000/1000 [==============================] - 55s 55ms/step - loss: 0.1887 - acc: 0.9030\n",
      "Epoch 4/10\n",
      "1000/1000 [==============================] - 55s 55ms/step - loss: 0.1665 - acc: 0.9190\n",
      "Epoch 5/10\n",
      "1000/1000 [==============================] - 54s 54ms/step - loss: 0.1464 - acc: 0.9360\n",
      "Epoch 6/10\n",
      "1000/1000 [==============================] - 53s 53ms/step - loss: 0.1329 - acc: 0.9380\n",
      "Epoch 7/10\n",
      "1000/1000 [==============================] - 53s 53ms/step - loss: 0.1276 - acc: 0.9360\n",
      "Epoch 8/10\n",
      "1000/1000 [==============================] - 53s 53ms/step - loss: 0.1149 - acc: 0.9470\n",
      "Epoch 9/10\n",
      "1000/1000 [==============================] - 54s 54ms/step - loss: 0.1060 - acc: 0.9540\n",
      "Epoch 10/10\n",
      "1000/1000 [==============================] - 53s 53ms/step - loss: 0.0980 - acc: 0.9560\n",
      "Training on Epoch  0 batch  5  Files [5] start  270 / 459\n",
      "Epoch 1/10\n",
      "1000/1000 [==============================] - 60s 60ms/step - loss: 0.2235 - acc: 0.8960\n",
      "Epoch 2/10\n",
      "1000/1000 [==============================] - 61s 61ms/step - loss: 0.1808 - acc: 0.9050\n",
      "Epoch 3/10\n",
      "1000/1000 [==============================] - 62s 62ms/step - loss: 0.1555 - acc: 0.9240\n",
      "Epoch 4/10\n",
      "1000/1000 [==============================] - 61s 61ms/step - loss: 0.1423 - acc: 0.9360\n",
      "Epoch 5/10\n",
      "1000/1000 [==============================] - 61s 61ms/step - loss: 0.1396 - acc: 0.9400\n",
      "Epoch 6/10\n",
      "1000/1000 [==============================] - 62s 62ms/step - loss: 0.1325 - acc: 0.9380\n",
      "Epoch 7/10\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000/1000 [==============================] - 62s 62ms/step - loss: 0.1266 - acc: 0.9390\n",
      "Epoch 8/10\n",
      "1000/1000 [==============================] - 62s 62ms/step - loss: 0.1132 - acc: 0.9490\n",
      "Epoch 9/10\n",
      "1000/1000 [==============================] - 62s 62ms/step - loss: 0.1088 - acc: 0.9510\n",
      "Epoch 10/10\n",
      "1000/1000 [==============================] - 62s 62ms/step - loss: 0.1052 - acc: 0.9530\n",
      "Training on Epoch  0 batch  5  Files [5] start  275 / 459\n",
      "Epoch 1/10\n",
      "1000/1000 [==============================] - 54s 54ms/step - loss: 0.2181 - acc: 0.9200\n",
      "Epoch 2/10\n",
      "1000/1000 [==============================] - 54s 54ms/step - loss: 0.1822 - acc: 0.9250\n",
      "Epoch 3/10\n",
      "1000/1000 [==============================] - 55s 55ms/step - loss: 0.1595 - acc: 0.9290\n",
      "Epoch 4/10\n",
      "1000/1000 [==============================] - 56s 56ms/step - loss: 0.1423 - acc: 0.9380\n",
      "Epoch 5/10\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 0.1268 - acc: 0.9450\n",
      "Epoch 6/10\n",
      "1000/1000 [==============================] - 56s 56ms/step - loss: 0.1178 - acc: 0.9510\n",
      "Epoch 7/10\n",
      "1000/1000 [==============================] - 56s 56ms/step - loss: 0.1098 - acc: 0.9590\n",
      "Epoch 8/10\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 0.1039 - acc: 0.9580\n",
      "Epoch 9/10\n",
      "1000/1000 [==============================] - 57s 57ms/step - loss: 0.0946 - acc: 0.9610\n",
      "Epoch 10/10\n",
      "1000/1000 [==============================] - 56s 56ms/step - loss: 0.0887 - acc: 0.9640\n",
      "Training on Epoch  0 batch  5  Files [5] start  280 / 459\n",
      "Epoch 1/10\n",
      "1000/1000 [==============================] - 54s 54ms/step - loss: 0.1915 - acc: 0.9100\n",
      "Epoch 2/10\n",
      "1000/1000 [==============================] - 53s 53ms/step - loss: 0.1636 - acc: 0.9260\n",
      "Epoch 3/10\n",
      "1000/1000 [==============================] - 50s 50ms/step - loss: 0.1394 - acc: 0.9380\n",
      "Epoch 4/10\n",
      "1000/1000 [==============================] - 50s 50ms/step - loss: 0.1278 - acc: 0.9470\n",
      "Epoch 5/10\n",
      "1000/1000 [==============================] - 51s 51ms/step - loss: 0.1141 - acc: 0.9520\n",
      "Epoch 6/10\n",
      "1000/1000 [==============================] - 51s 51ms/step - loss: 0.1058 - acc: 0.9540\n",
      "Epoch 7/10\n",
      "1000/1000 [==============================] - 52s 52ms/step - loss: 0.1011 - acc: 0.9580\n",
      "Epoch 8/10\n",
      "1000/1000 [==============================] - 51s 51ms/step - loss: 0.0949 - acc: 0.9620\n",
      "Epoch 9/10\n",
      "1000/1000 [==============================] - 52s 52ms/step - loss: 0.0916 - acc: 0.9610\n",
      "Epoch 10/10\n",
      "1000/1000 [==============================] - 51s 51ms/step - loss: 0.0870 - acc: 0.9640\n",
      "Training on Epoch  0 batch  5  Files [5] start  285 / 459\n",
      "Epoch 1/10\n",
      "1000/1000 [==============================] - 55s 55ms/step - loss: 0.1991 - acc: 0.8960\n",
      "Epoch 2/10\n",
      "1000/1000 [==============================] - 57s 57ms/step - loss: 0.1826 - acc: 0.8870\n",
      "Epoch 3/10\n",
      "1000/1000 [==============================] - 57s 57ms/step - loss: 0.1657 - acc: 0.9010\n",
      "Epoch 4/10\n",
      "1000/1000 [==============================] - 56s 56ms/step - loss: 0.1560 - acc: 0.9170\n",
      "Epoch 5/10\n",
      "1000/1000 [==============================] - 55s 55ms/step - loss: 0.1488 - acc: 0.9160\n",
      "Epoch 6/10\n",
      "1000/1000 [==============================] - 55s 55ms/step - loss: 0.1431 - acc: 0.9260\n",
      "Epoch 7/10\n",
      "1000/1000 [==============================] - 55s 55ms/step - loss: 0.1394 - acc: 0.9250\n",
      "Epoch 8/10\n",
      "1000/1000 [==============================] - 55s 55ms/step - loss: 0.1359 - acc: 0.9280\n",
      "Epoch 9/10\n",
      "1000/1000 [==============================] - 55s 55ms/step - loss: 0.1318 - acc: 0.9310\n",
      "Epoch 10/10\n",
      "1000/1000 [==============================] - 55s 55ms/step - loss: 0.1295 - acc: 0.9320\n",
      "Training on Epoch  0 batch  5  Files [5] start  290 / 459\n",
      "Epoch 1/10\n",
      "1000/1000 [==============================] - 56s 56ms/step - loss: 0.2982 - acc: 0.8950\n",
      "Epoch 2/10\n",
      "1000/1000 [==============================] - 57s 57ms/step - loss: 0.2129 - acc: 0.9020\n",
      "Epoch 3/10\n",
      "1000/1000 [==============================] - 56s 56ms/step - loss: 0.1863 - acc: 0.9060\n",
      "Epoch 4/10\n",
      "1000/1000 [==============================] - 57s 57ms/step - loss: 0.1688 - acc: 0.9140\n",
      "Epoch 5/10\n",
      "1000/1000 [==============================] - 56s 56ms/step - loss: 0.1550 - acc: 0.9240\n",
      "Epoch 6/10\n",
      "1000/1000 [==============================] - 56s 56ms/step - loss: 0.1450 - acc: 0.9330\n",
      "Epoch 7/10\n",
      "1000/1000 [==============================] - 57s 57ms/step - loss: 0.1373 - acc: 0.9330\n",
      "Epoch 8/10\n",
      "1000/1000 [==============================] - 55s 55ms/step - loss: 0.1309 - acc: 0.9370\n",
      "Epoch 9/10\n",
      "1000/1000 [==============================] - 56s 56ms/step - loss: 0.1245 - acc: 0.9390\n",
      "Epoch 10/10\n",
      "1000/1000 [==============================] - 57s 57ms/step - loss: 0.1182 - acc: 0.9430\n",
      "Training on Epoch  0 batch  5  Files [5] start  295 / 459\n",
      "Epoch 1/10\n",
      "1000/1000 [==============================] - 68s 68ms/step - loss: 0.1510 - acc: 0.9330\n",
      "Epoch 2/10\n",
      "1000/1000 [==============================] - 49s 49ms/step - loss: 0.1291 - acc: 0.9510\n",
      "Epoch 3/10\n",
      "1000/1000 [==============================] - 49s 49ms/step - loss: 0.1149 - acc: 0.9580\n",
      "Epoch 4/10\n",
      "1000/1000 [==============================] - 49s 49ms/step - loss: 0.1040 - acc: 0.9570\n",
      "Epoch 5/10\n",
      "1000/1000 [==============================] - 49s 49ms/step - loss: 0.0943 - acc: 0.9600\n",
      "Epoch 6/10\n",
      "1000/1000 [==============================] - 50s 50ms/step - loss: 0.0885 - acc: 0.9580\n",
      "Epoch 7/10\n",
      "1000/1000 [==============================] - 49s 49ms/step - loss: 0.0832 - acc: 0.9620\n",
      "Epoch 8/10\n",
      "1000/1000 [==============================] - 49s 49ms/step - loss: 0.0783 - acc: 0.9640\n",
      "Epoch 9/10\n",
      "1000/1000 [==============================] - 49s 49ms/step - loss: 0.0763 - acc: 0.9640\n",
      "Epoch 10/10\n",
      "1000/1000 [==============================] - 48s 48ms/step - loss: 0.0744 - acc: 0.9680\n",
      "Training on Epoch  0 batch  5  Files [5] start  300 / 459\n",
      "Epoch 1/10\n",
      "1000/1000 [==============================] - 51s 51ms/step - loss: 0.2565 - acc: 0.8960\n",
      "Epoch 2/10\n",
      "1000/1000 [==============================] - 51s 51ms/step - loss: 0.2067 - acc: 0.9130\n",
      "Epoch 3/10\n",
      "1000/1000 [==============================] - 52s 52ms/step - loss: 0.1722 - acc: 0.9250\n",
      "Epoch 4/10\n",
      "1000/1000 [==============================] - 52s 52ms/step - loss: 0.1526 - acc: 0.9340\n",
      "Epoch 5/10\n",
      "1000/1000 [==============================] - 53s 53ms/step - loss: 0.1381 - acc: 0.9390\n",
      "Epoch 6/10\n",
      "1000/1000 [==============================] - 52s 52ms/step - loss: 0.1268 - acc: 0.9500\n",
      "Epoch 7/10\n",
      "1000/1000 [==============================] - 51s 51ms/step - loss: 0.1211 - acc: 0.9540\n",
      "Epoch 8/10\n",
      "1000/1000 [==============================] - 52s 52ms/step - loss: 0.1133 - acc: 0.9570\n",
      "Epoch 9/10\n",
      "1000/1000 [==============================] - 53s 53ms/step - loss: 0.1109 - acc: 0.9590\n",
      "Epoch 10/10\n",
      "1000/1000 [==============================] - 52s 52ms/step - loss: 0.1055 - acc: 0.9600\n",
      "Training on Epoch  0 batch  5  Files [5] start  305 / 459\n",
      "Epoch 1/10\n",
      "1000/1000 [==============================] - 53s 53ms/step - loss: 0.1988 - acc: 0.9260\n",
      "Epoch 2/10\n",
      "1000/1000 [==============================] - 53s 53ms/step - loss: 0.1558 - acc: 0.9270\n",
      "Epoch 3/10\n",
      "1000/1000 [==============================] - 54s 54ms/step - loss: 0.1262 - acc: 0.9430\n",
      "Epoch 4/10\n",
      "1000/1000 [==============================] - 54s 54ms/step - loss: 0.1124 - acc: 0.9530\n",
      "Epoch 5/10\n",
      "1000/1000 [==============================] - 53s 53ms/step - loss: 0.1053 - acc: 0.9490\n",
      "Epoch 6/10\n",
      "1000/1000 [==============================] - 53s 53ms/step - loss: 0.0966 - acc: 0.9620\n",
      "Epoch 7/10\n",
      "1000/1000 [==============================] - 53s 53ms/step - loss: 0.0890 - acc: 0.9620\n",
      "Epoch 8/10\n",
      "1000/1000 [==============================] - 53s 53ms/step - loss: 0.0814 - acc: 0.9710\n",
      "Epoch 9/10\n",
      "1000/1000 [==============================] - 53s 53ms/step - loss: 0.0935 - acc: 0.9630\n",
      "Epoch 10/10\n",
      "1000/1000 [==============================] - 54s 54ms/step - loss: 0.1177 - acc: 0.9460\n",
      "Training on Epoch  0 batch  5  Files [5] start  310 / 459\n",
      "Epoch 1/10\n",
      "1000/1000 [==============================] - 49s 49ms/step - loss: 0.2521 - acc: 0.8940\n",
      "Epoch 2/10\n",
      "1000/1000 [==============================] - 49s 49ms/step - loss: 0.2159 - acc: 0.8920\n",
      "Epoch 3/10\n",
      "1000/1000 [==============================] - 51s 51ms/step - loss: 0.1831 - acc: 0.9190\n",
      "Epoch 4/10\n",
      "1000/1000 [==============================] - 50s 50ms/step - loss: 0.1670 - acc: 0.9240\n",
      "Epoch 5/10\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000/1000 [==============================] - 51s 51ms/step - loss: 0.1586 - acc: 0.9240\n",
      "Epoch 6/10\n",
      "1000/1000 [==============================] - 50s 50ms/step - loss: 0.1438 - acc: 0.9350\n",
      "Epoch 7/10\n",
      "1000/1000 [==============================] - 49s 49ms/step - loss: 0.1538 - acc: 0.9310\n",
      "Epoch 8/10\n",
      "1000/1000 [==============================] - 50s 50ms/step - loss: 0.1702 - acc: 0.9160\n",
      "Epoch 9/10\n",
      "1000/1000 [==============================] - 50s 50ms/step - loss: 0.1517 - acc: 0.9280\n",
      "Epoch 10/10\n",
      "1000/1000 [==============================] - 51s 51ms/step - loss: 0.1334 - acc: 0.9360\n",
      "Training on Epoch  0 batch  5  Files [5] start  315 / 459\n",
      "Epoch 1/10\n",
      "1000/1000 [==============================] - 54s 54ms/step - loss: 0.1791 - acc: 0.9120\n",
      "Epoch 2/10\n",
      "1000/1000 [==============================] - 54s 54ms/step - loss: 0.1540 - acc: 0.9190\n",
      "Epoch 3/10\n",
      "1000/1000 [==============================] - 55s 55ms/step - loss: 0.1372 - acc: 0.9180\n",
      "Epoch 4/10\n",
      "1000/1000 [==============================] - 55s 55ms/step - loss: 0.1273 - acc: 0.9240\n",
      "Epoch 5/10\n",
      "1000/1000 [==============================] - 55s 55ms/step - loss: 0.1219 - acc: 0.9330\n",
      "Epoch 6/10\n",
      "1000/1000 [==============================] - 55s 55ms/step - loss: 0.1149 - acc: 0.9380\n",
      "Epoch 7/10\n",
      "1000/1000 [==============================] - 55s 55ms/step - loss: 0.1118 - acc: 0.9400\n",
      "Epoch 8/10\n",
      "1000/1000 [==============================] - 54s 54ms/step - loss: 0.1099 - acc: 0.9360\n",
      "Epoch 9/10\n",
      "1000/1000 [==============================] - 53s 53ms/step - loss: 0.1045 - acc: 0.9420\n",
      "Epoch 10/10\n",
      "1000/1000 [==============================] - 55s 55ms/step - loss: 0.1036 - acc: 0.9460\n",
      "Training on Epoch  0 batch  5  Files [5] start  320 / 459\n",
      "Epoch 1/10\n",
      "1000/1000 [==============================] - 52s 52ms/step - loss: 0.2257 - acc: 0.9070\n",
      "Epoch 2/10\n",
      "1000/1000 [==============================] - 54s 54ms/step - loss: 0.1862 - acc: 0.9170\n",
      "Epoch 3/10\n",
      "1000/1000 [==============================] - 53s 53ms/step - loss: 0.1609 - acc: 0.9290\n",
      "Epoch 4/10\n",
      "1000/1000 [==============================] - 53s 53ms/step - loss: 0.1468 - acc: 0.9310\n",
      "Epoch 5/10\n",
      "1000/1000 [==============================] - 52s 52ms/step - loss: 0.1373 - acc: 0.9390\n",
      "Epoch 6/10\n",
      "1000/1000 [==============================] - 52s 52ms/step - loss: 0.1321 - acc: 0.9400\n",
      "Epoch 7/10\n",
      "1000/1000 [==============================] - 56s 56ms/step - loss: 0.1209 - acc: 0.9470\n",
      "Epoch 8/10\n",
      "1000/1000 [==============================] - 57s 57ms/step - loss: 0.1096 - acc: 0.9510\n",
      "Epoch 9/10\n",
      "1000/1000 [==============================] - 58s 58ms/step - loss: 0.1012 - acc: 0.9520\n",
      "Epoch 10/10\n",
      "1000/1000 [==============================] - 58s 58ms/step - loss: 0.0933 - acc: 0.9540\n",
      "Training on Epoch  0 batch  5  Files [5] start  325 / 459\n",
      "Epoch 1/10\n",
      "1000/1000 [==============================] - 58s 58ms/step - loss: 0.1681 - acc: 0.9300\n",
      "Epoch 2/10\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 0.1459 - acc: 0.9350\n",
      "Epoch 3/10\n",
      "1000/1000 [==============================] - 57s 57ms/step - loss: 0.1322 - acc: 0.9360\n",
      "Epoch 4/10\n",
      "1000/1000 [==============================] - 57s 57ms/step - loss: 0.1400 - acc: 0.9400\n",
      "Epoch 5/10\n",
      "1000/1000 [==============================] - 56s 56ms/step - loss: 0.1257 - acc: 0.9470\n",
      "Epoch 6/10\n",
      "1000/1000 [==============================] - 55s 55ms/step - loss: 0.1038 - acc: 0.9560\n",
      "Epoch 7/10\n",
      "1000/1000 [==============================] - 53s 53ms/step - loss: 0.0988 - acc: 0.9550\n",
      "Epoch 8/10\n",
      "1000/1000 [==============================] - 55s 55ms/step - loss: 0.0832 - acc: 0.9610\n",
      "Epoch 9/10\n",
      "1000/1000 [==============================] - 56s 56ms/step - loss: 0.0812 - acc: 0.9570\n",
      "Epoch 10/10\n",
      "1000/1000 [==============================] - 54s 54ms/step - loss: 0.0770 - acc: 0.9610\n",
      "Training on Epoch  0 batch  5  Files [5] start  330 / 459\n",
      "Epoch 1/10\n",
      "1000/1000 [==============================] - 52s 52ms/step - loss: 0.3089 - acc: 0.8650\n",
      "Epoch 2/10\n",
      "1000/1000 [==============================] - 51s 51ms/step - loss: 0.2439 - acc: 0.8800\n",
      "Epoch 3/10\n",
      "1000/1000 [==============================] - 51s 51ms/step - loss: 0.2190 - acc: 0.8930\n",
      "Epoch 4/10\n",
      "1000/1000 [==============================] - 51s 51ms/step - loss: 0.1960 - acc: 0.9030\n",
      "Epoch 5/10\n",
      "1000/1000 [==============================] - 53s 53ms/step - loss: 0.2141 - acc: 0.8930\n",
      "Epoch 6/10\n",
      "1000/1000 [==============================] - 52s 52ms/step - loss: 0.1877 - acc: 0.9090\n",
      "Epoch 7/10\n",
      "1000/1000 [==============================] - 56s 56ms/step - loss: 0.1707 - acc: 0.9150\n",
      "Epoch 8/10\n",
      "1000/1000 [==============================] - 52s 52ms/step - loss: 0.1547 - acc: 0.9260\n",
      "Epoch 9/10\n",
      "1000/1000 [==============================] - 52s 52ms/step - loss: 0.1441 - acc: 0.9360\n",
      "Epoch 10/10\n",
      "1000/1000 [==============================] - 52s 52ms/step - loss: 0.1368 - acc: 0.9380\n",
      "Training on Epoch  0 batch  5  Files [5] start  335 / 459\n",
      "Epoch 1/10\n",
      "1000/1000 [==============================] - 50s 50ms/step - loss: 0.2318 - acc: 0.8950\n",
      "Epoch 2/10\n",
      "1000/1000 [==============================] - 51s 51ms/step - loss: 0.1966 - acc: 0.9010\n",
      "Epoch 3/10\n",
      "1000/1000 [==============================] - 50s 50ms/step - loss: 0.1780 - acc: 0.9070\n",
      "Epoch 4/10\n",
      "1000/1000 [==============================] - 52s 52ms/step - loss: 0.1657 - acc: 0.9180\n",
      "Epoch 5/10\n",
      "1000/1000 [==============================] - 50s 50ms/step - loss: 0.1533 - acc: 0.9290\n",
      "Epoch 6/10\n",
      "1000/1000 [==============================] - 49s 49ms/step - loss: 0.1445 - acc: 0.9280\n",
      "Epoch 7/10\n",
      "1000/1000 [==============================] - 50s 50ms/step - loss: 0.1379 - acc: 0.9220\n",
      "Epoch 8/10\n",
      "1000/1000 [==============================] - 51s 51ms/step - loss: 0.1321 - acc: 0.9320\n",
      "Epoch 9/10\n",
      "1000/1000 [==============================] - 51s 51ms/step - loss: 0.1271 - acc: 0.9390\n",
      "Epoch 10/10\n",
      "1000/1000 [==============================] - 50s 50ms/step - loss: 0.1228 - acc: 0.9380\n",
      "Training on Epoch  0 batch  5  Files [5] start  340 / 459\n",
      "Epoch 1/10\n",
      "1000/1000 [==============================] - 48s 48ms/step - loss: 0.1167 - acc: 0.9390\n",
      "Epoch 2/10\n",
      "1000/1000 [==============================] - 49s 49ms/step - loss: 0.1046 - acc: 0.9460\n",
      "Epoch 3/10\n",
      "1000/1000 [==============================] - 50s 50ms/step - loss: 0.0975 - acc: 0.9500\n",
      "Epoch 4/10\n",
      "1000/1000 [==============================] - 49s 49ms/step - loss: 0.0962 - acc: 0.9540\n",
      "Epoch 5/10\n",
      "1000/1000 [==============================] - 50s 50ms/step - loss: 0.0920 - acc: 0.9530\n",
      "Epoch 6/10\n",
      "1000/1000 [==============================] - 50s 50ms/step - loss: 0.0883 - acc: 0.9530\n",
      "Epoch 7/10\n",
      "1000/1000 [==============================] - 50s 50ms/step - loss: 0.0858 - acc: 0.9520\n",
      "Epoch 8/10\n",
      "1000/1000 [==============================] - 50s 50ms/step - loss: 0.0834 - acc: 0.9560\n",
      "Epoch 9/10\n",
      "1000/1000 [==============================] - 50s 50ms/step - loss: 0.0821 - acc: 0.9570\n",
      "Epoch 10/10\n",
      "1000/1000 [==============================] - 50s 50ms/step - loss: 0.0803 - acc: 0.9620\n",
      "Training on Epoch  0 batch  5  Files [5] start  345 / 459\n",
      "Epoch 1/10\n",
      "1000/1000 [==============================] - 52s 52ms/step - loss: 0.3130 - acc: 0.8780\n",
      "Epoch 2/10\n",
      "1000/1000 [==============================] - 50s 50ms/step - loss: 0.2375 - acc: 0.8990\n",
      "Epoch 3/10\n",
      "1000/1000 [==============================] - 53s 53ms/step - loss: 0.1920 - acc: 0.9190\n",
      "Epoch 4/10\n",
      "1000/1000 [==============================] - 53s 53ms/step - loss: 0.1720 - acc: 0.9280\n",
      "Epoch 5/10\n",
      "1000/1000 [==============================] - 53s 53ms/step - loss: 0.1563 - acc: 0.9310\n",
      "Epoch 6/10\n",
      "1000/1000 [==============================] - 53s 53ms/step - loss: 0.1459 - acc: 0.9360\n",
      "Epoch 7/10\n",
      "1000/1000 [==============================] - 54s 54ms/step - loss: 0.1341 - acc: 0.9370\n",
      "Epoch 8/10\n",
      "1000/1000 [==============================] - 54s 54ms/step - loss: 0.1240 - acc: 0.9460\n",
      "Epoch 9/10\n",
      "1000/1000 [==============================] - 53s 53ms/step - loss: 0.1154 - acc: 0.9500\n",
      "Epoch 10/10\n",
      "1000/1000 [==============================] - 52s 52ms/step - loss: 0.1074 - acc: 0.9480\n",
      "Training on Epoch  0 batch  5  Files [5] start  350 / 459\n",
      "Epoch 1/10\n",
      "1000/1000 [==============================] - 46s 46ms/step - loss: 0.4629 - acc: 0.8220\n",
      "Epoch 2/10\n",
      "1000/1000 [==============================] - 46s 46ms/step - loss: 0.3856 - acc: 0.8430\n",
      "Epoch 3/10\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000/1000 [==============================] - 47s 47ms/step - loss: 0.3828 - acc: 0.8210\n",
      "Epoch 4/10\n",
      "1000/1000 [==============================] - 46s 46ms/step - loss: 0.3659 - acc: 0.8390\n",
      "Epoch 5/10\n",
      "1000/1000 [==============================] - 46s 46ms/step - loss: 0.3246 - acc: 0.8570\n",
      "Epoch 6/10\n",
      "1000/1000 [==============================] - 46s 46ms/step - loss: 0.2891 - acc: 0.8680\n",
      "Epoch 7/10\n",
      "1000/1000 [==============================] - 46s 46ms/step - loss: 0.2611 - acc: 0.8930\n",
      "Epoch 8/10\n",
      "1000/1000 [==============================] - 46s 46ms/step - loss: 0.2345 - acc: 0.8980\n",
      "Epoch 9/10\n",
      "1000/1000 [==============================] - 46s 46ms/step - loss: 0.2114 - acc: 0.9120\n",
      "Epoch 10/10\n",
      "1000/1000 [==============================] - 45s 45ms/step - loss: 0.1994 - acc: 0.9250\n",
      "Training on Epoch  0 batch  5  Files [5] start  355 / 459\n",
      "Epoch 1/10\n",
      "1000/1000 [==============================] - 44s 44ms/step - loss: 0.3731 - acc: 0.8520\n",
      "Epoch 2/10\n",
      "1000/1000 [==============================] - 45s 45ms/step - loss: 0.3247 - acc: 0.8720\n",
      "Epoch 3/10\n",
      "1000/1000 [==============================] - 46s 46ms/step - loss: 0.2813 - acc: 0.8830\n",
      "Epoch 4/10\n",
      "1000/1000 [==============================] - 46s 46ms/step - loss: 0.2404 - acc: 0.8990\n",
      "Epoch 5/10\n",
      "1000/1000 [==============================] - 46s 46ms/step - loss: 0.2146 - acc: 0.9120\n",
      "Epoch 6/10\n",
      "1000/1000 [==============================] - 46s 46ms/step - loss: 0.1986 - acc: 0.9170\n",
      "Epoch 7/10\n",
      "1000/1000 [==============================] - 45s 45ms/step - loss: 0.1846 - acc: 0.9250\n",
      "Epoch 8/10\n",
      "1000/1000 [==============================] - 46s 46ms/step - loss: 0.1692 - acc: 0.9380\n",
      "Epoch 9/10\n",
      "1000/1000 [==============================] - 45s 45ms/step - loss: 0.1567 - acc: 0.9360\n",
      "Epoch 10/10\n",
      "1000/1000 [==============================] - 46s 46ms/step - loss: 0.1458 - acc: 0.9420\n",
      "Training on Epoch  0 batch  5  Files [5] start  360 / 459\n",
      "Epoch 1/10\n",
      "1000/1000 [==============================] - 51s 51ms/step - loss: 0.3551 - acc: 0.8580\n",
      "Epoch 2/10\n",
      "1000/1000 [==============================] - 50s 50ms/step - loss: 0.2840 - acc: 0.8770\n",
      "Epoch 3/10\n",
      "1000/1000 [==============================] - 50s 50ms/step - loss: 0.2406 - acc: 0.8900\n",
      "Epoch 4/10\n",
      "1000/1000 [==============================] - 51s 51ms/step - loss: 0.2022 - acc: 0.9150\n",
      "Epoch 5/10\n",
      "1000/1000 [==============================] - 51s 51ms/step - loss: 0.1743 - acc: 0.9330\n",
      "Epoch 6/10\n",
      "1000/1000 [==============================] - 50s 50ms/step - loss: 0.1497 - acc: 0.9430\n",
      "Epoch 7/10\n",
      "1000/1000 [==============================] - 51s 51ms/step - loss: 0.1311 - acc: 0.9480\n",
      "Epoch 8/10\n",
      "1000/1000 [==============================] - 49s 49ms/step - loss: 0.1159 - acc: 0.9600\n",
      "Epoch 9/10\n",
      "1000/1000 [==============================] - 51s 51ms/step - loss: 0.1013 - acc: 0.9630\n",
      "Epoch 10/10\n",
      "1000/1000 [==============================] - 50s 50ms/step - loss: 0.0941 - acc: 0.9630\n",
      "Training on Epoch  0 batch  5  Files [5] start  365 / 459\n",
      "Epoch 1/10\n",
      "1000/1000 [==============================] - 51s 51ms/step - loss: 0.4822 - acc: 0.8260\n",
      "Epoch 2/10\n",
      "1000/1000 [==============================] - 51s 51ms/step - loss: 0.3595 - acc: 0.8550\n",
      "Epoch 3/10\n",
      "1000/1000 [==============================] - 51s 51ms/step - loss: 0.3058 - acc: 0.8740\n",
      "Epoch 4/10\n",
      "1000/1000 [==============================] - 51s 51ms/step - loss: 0.2737 - acc: 0.8980\n",
      "Epoch 5/10\n",
      "1000/1000 [==============================] - 52s 52ms/step - loss: 0.2473 - acc: 0.9000\n",
      "Epoch 6/10\n",
      "1000/1000 [==============================] - 51s 51ms/step - loss: 0.2251 - acc: 0.9130\n",
      "Epoch 7/10\n",
      "1000/1000 [==============================] - 52s 52ms/step - loss: 0.2062 - acc: 0.9260\n",
      "Epoch 8/10\n",
      "1000/1000 [==============================] - 51s 51ms/step - loss: 0.1862 - acc: 0.9370\n",
      "Epoch 9/10\n",
      "1000/1000 [==============================] - 52s 52ms/step - loss: 0.1721 - acc: 0.9450\n",
      "Epoch 10/10\n",
      "1000/1000 [==============================] - 52s 52ms/step - loss: 0.1588 - acc: 0.9490\n",
      "Training on Epoch  0 batch  5  Files [5] start  370 / 459\n",
      "Epoch 1/10\n",
      "1000/1000 [==============================] - 54s 54ms/step - loss: 0.2738 - acc: 0.8980\n",
      "Epoch 2/10\n",
      "1000/1000 [==============================] - 54s 54ms/step - loss: 0.2320 - acc: 0.9040\n",
      "Epoch 3/10\n",
      "1000/1000 [==============================] - 54s 54ms/step - loss: 0.1939 - acc: 0.9240\n",
      "Epoch 4/10\n",
      "1000/1000 [==============================] - 54s 54ms/step - loss: 0.1723 - acc: 0.9350\n",
      "Epoch 5/10\n",
      "1000/1000 [==============================] - 53s 53ms/step - loss: 0.1613 - acc: 0.9290\n",
      "Epoch 6/10\n",
      "1000/1000 [==============================] - 54s 54ms/step - loss: 0.1486 - acc: 0.9410\n",
      "Epoch 7/10\n",
      "1000/1000 [==============================] - 54s 54ms/step - loss: 0.1363 - acc: 0.9420\n",
      "Epoch 8/10\n",
      "1000/1000 [==============================] - 54s 54ms/step - loss: 0.1303 - acc: 0.9450\n",
      "Epoch 9/10\n",
      "1000/1000 [==============================] - 54s 54ms/step - loss: 0.1184 - acc: 0.9460\n",
      "Epoch 10/10\n",
      "1000/1000 [==============================] - 54s 54ms/step - loss: 0.1120 - acc: 0.9510\n",
      "Training on Epoch  0 batch  5  Files [5] start  375 / 459\n",
      "Epoch 1/10\n",
      "1000/1000 [==============================] - 52s 52ms/step - loss: 0.4438 - acc: 0.8260\n",
      "Epoch 2/10\n",
      "1000/1000 [==============================] - 51s 51ms/step - loss: 0.3249 - acc: 0.8610\n",
      "Epoch 3/10\n",
      "1000/1000 [==============================] - 52s 52ms/step - loss: 0.2785 - acc: 0.8810\n",
      "Epoch 4/10\n",
      "1000/1000 [==============================] - 51s 51ms/step - loss: 0.2455 - acc: 0.8990\n",
      "Epoch 5/10\n",
      "1000/1000 [==============================] - 51s 51ms/step - loss: 0.2219 - acc: 0.9100\n",
      "Epoch 6/10\n",
      "1000/1000 [==============================] - 50s 50ms/step - loss: 0.1994 - acc: 0.9130\n",
      "Epoch 7/10\n",
      "1000/1000 [==============================] - 54s 54ms/step - loss: 0.1778 - acc: 0.9320\n",
      "Epoch 8/10\n",
      "1000/1000 [==============================] - 54s 54ms/step - loss: 0.1639 - acc: 0.9380\n",
      "Epoch 9/10\n",
      "1000/1000 [==============================] - 56s 56ms/step - loss: 0.1446 - acc: 0.9470\n",
      "Epoch 10/10\n",
      "1000/1000 [==============================] - 55s 55ms/step - loss: 0.1337 - acc: 0.9550\n",
      "Training on Epoch  0 batch  5  Files [5] start  380 / 459\n",
      "Epoch 1/10\n",
      "1000/1000 [==============================] - 50s 50ms/step - loss: 0.3281 - acc: 0.8690\n",
      "Epoch 2/10\n",
      "1000/1000 [==============================] - 53s 53ms/step - loss: 0.2642 - acc: 0.8860\n",
      "Epoch 3/10\n",
      "1000/1000 [==============================] - 52s 52ms/step - loss: 0.2431 - acc: 0.8960\n",
      "Epoch 4/10\n",
      "1000/1000 [==============================] - 51s 51ms/step - loss: 0.2209 - acc: 0.9140\n",
      "Epoch 5/10\n",
      "1000/1000 [==============================] - 54s 54ms/step - loss: 0.1924 - acc: 0.9150\n",
      "Epoch 6/10\n",
      "1000/1000 [==============================] - 53s 53ms/step - loss: 0.1700 - acc: 0.9210\n",
      "Epoch 7/10\n",
      "1000/1000 [==============================] - 52s 52ms/step - loss: 0.1559 - acc: 0.9320\n",
      "Epoch 8/10\n",
      "1000/1000 [==============================] - 53s 53ms/step - loss: 0.1319 - acc: 0.9420\n",
      "Epoch 9/10\n",
      "1000/1000 [==============================] - 51s 51ms/step - loss: 0.1187 - acc: 0.9450\n",
      "Epoch 10/10\n",
      "1000/1000 [==============================] - 51s 51ms/step - loss: 0.1070 - acc: 0.9530\n",
      "Training on Epoch  0 batch  5  Files [5] start  385 / 459\n",
      "Epoch 1/10\n",
      "1000/1000 [==============================] - 51s 51ms/step - loss: 0.3455 - acc: 0.8790\n",
      "Epoch 2/10\n",
      "1000/1000 [==============================] - 51s 51ms/step - loss: 0.2745 - acc: 0.8920\n",
      "Epoch 3/10\n",
      "1000/1000 [==============================] - 53s 53ms/step - loss: 0.2182 - acc: 0.9110\n",
      "Epoch 4/10\n",
      "1000/1000 [==============================] - 53s 53ms/step - loss: 0.1962 - acc: 0.9200\n",
      "Epoch 5/10\n",
      "1000/1000 [==============================] - 57s 57ms/step - loss: 0.1731 - acc: 0.9280\n",
      "Epoch 6/10\n",
      "1000/1000 [==============================] - 53s 53ms/step - loss: 0.1545 - acc: 0.9350\n",
      "Epoch 7/10\n",
      "1000/1000 [==============================] - 58s 58ms/step - loss: 0.1413 - acc: 0.9440\n",
      "Epoch 8/10\n",
      "1000/1000 [==============================] - 64s 64ms/step - loss: 0.1279 - acc: 0.9490\n",
      "Epoch 9/10\n",
      "1000/1000 [==============================] - 62s 62ms/step - loss: 0.1217 - acc: 0.9540\n",
      "Epoch 10/10\n",
      "1000/1000 [==============================] - 54s 54ms/step - loss: 0.1169 - acc: 0.9570\n",
      "Training on Epoch  0 batch  5  Files [5] start  390 / 459\n",
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000/1000 [==============================] - 56s 56ms/step - loss: 0.4398 - acc: 0.8470\n",
      "Epoch 2/10\n",
      "1000/1000 [==============================] - 62s 62ms/step - loss: 0.3499 - acc: 0.8590\n",
      "Epoch 3/10\n",
      "1000/1000 [==============================] - 60s 60ms/step - loss: 0.2929 - acc: 0.8870\n",
      "Epoch 4/10\n",
      "1000/1000 [==============================] - 60s 60ms/step - loss: 0.2670 - acc: 0.8940\n",
      "Epoch 5/10\n",
      "1000/1000 [==============================] - 57s 57ms/step - loss: 0.2314 - acc: 0.9020\n",
      "Epoch 6/10\n",
      "1000/1000 [==============================] - 55s 55ms/step - loss: 0.2016 - acc: 0.9230\n",
      "Epoch 7/10\n",
      "1000/1000 [==============================] - 57s 57ms/step - loss: 0.1755 - acc: 0.9310\n",
      "Epoch 8/10\n",
      "1000/1000 [==============================] - 66s 66ms/step - loss: 0.1591 - acc: 0.9380\n",
      "Epoch 9/10\n",
      "1000/1000 [==============================] - 63s 63ms/step - loss: 0.1451 - acc: 0.9480\n",
      "Epoch 10/10\n",
      "1000/1000 [==============================] - 65s 65ms/step - loss: 0.1318 - acc: 0.9530\n",
      "Training on Epoch  0 batch  5  Files [5] start  395 / 459\n",
      "Epoch 1/10\n",
      "1000/1000 [==============================] - 70s 70ms/step - loss: 0.3339 - acc: 0.8680\n",
      "Epoch 2/10\n",
      "1000/1000 [==============================] - 69s 69ms/step - loss: 0.2736 - acc: 0.8830\n",
      "Epoch 3/10\n",
      "1000/1000 [==============================] - 67s 67ms/step - loss: 0.2379 - acc: 0.9100\n",
      "Epoch 4/10\n",
      "1000/1000 [==============================] - 66s 66ms/step - loss: 0.2076 - acc: 0.9170\n",
      "Epoch 5/10\n",
      "1000/1000 [==============================] - 66s 66ms/step - loss: 0.1839 - acc: 0.9260\n",
      "Epoch 6/10\n",
      "1000/1000 [==============================] - 67s 67ms/step - loss: 0.1644 - acc: 0.9390\n",
      "Epoch 7/10\n",
      "1000/1000 [==============================] - 66s 66ms/step - loss: 0.1520 - acc: 0.9390\n",
      "Epoch 8/10\n",
      "1000/1000 [==============================] - 68s 68ms/step - loss: 0.1403 - acc: 0.9440\n",
      "Epoch 9/10\n",
      "1000/1000 [==============================] - 68s 68ms/step - loss: 0.1253 - acc: 0.9510\n",
      "Epoch 10/10\n",
      "1000/1000 [==============================] - 67s 67ms/step - loss: 0.1152 - acc: 0.9590\n",
      "Training on Epoch  0 batch  5  Files [5] start  400 / 459\n",
      "Epoch 1/10\n",
      "1000/1000 [==============================] - 68s 68ms/step - loss: 0.3916 - acc: 0.8650\n",
      "Epoch 2/10\n",
      "1000/1000 [==============================] - 71s 71ms/step - loss: 0.3506 - acc: 0.8580\n",
      "Epoch 3/10\n",
      "1000/1000 [==============================] - 67s 67ms/step - loss: 0.2929 - acc: 0.8800\n",
      "Epoch 4/10\n",
      "1000/1000 [==============================] - 67s 67ms/step - loss: 0.2614 - acc: 0.8920\n",
      "Epoch 5/10\n",
      "1000/1000 [==============================] - 69s 69ms/step - loss: 0.2365 - acc: 0.8960\n",
      "Epoch 6/10\n",
      "1000/1000 [==============================] - 69s 69ms/step - loss: 0.2166 - acc: 0.9130\n",
      "Epoch 7/10\n",
      "1000/1000 [==============================] - 66s 66ms/step - loss: 0.1972 - acc: 0.9200\n",
      "Epoch 8/10\n",
      "1000/1000 [==============================] - 65s 65ms/step - loss: 0.1774 - acc: 0.9370\n",
      "Epoch 9/10\n",
      "1000/1000 [==============================] - 65s 65ms/step - loss: 0.1645 - acc: 0.9420\n",
      "Epoch 10/10\n",
      "1000/1000 [==============================] - 68s 68ms/step - loss: 0.1521 - acc: 0.9420\n",
      "Training on Epoch  0 batch  5  Files [5] start  405 / 459\n",
      "Epoch 1/10\n",
      "1000/1000 [==============================] - 63s 63ms/step - loss: 0.3619 - acc: 0.8700\n",
      "Epoch 2/10\n",
      "1000/1000 [==============================] - 65s 65ms/step - loss: 0.2969 - acc: 0.8900\n",
      "Epoch 3/10\n",
      "1000/1000 [==============================] - 65s 65ms/step - loss: 0.2651 - acc: 0.9060\n",
      "Epoch 4/10\n",
      "1000/1000 [==============================] - 61s 61ms/step - loss: 0.2285 - acc: 0.9140\n",
      "Epoch 5/10\n",
      "1000/1000 [==============================] - 60s 60ms/step - loss: 0.1995 - acc: 0.9240\n",
      "Epoch 6/10\n",
      "1000/1000 [==============================] - 58s 58ms/step - loss: 0.1782 - acc: 0.9290\n",
      "Epoch 7/10\n",
      "1000/1000 [==============================] - 58s 58ms/step - loss: 0.1602 - acc: 0.9400\n",
      "Epoch 8/10\n",
      "1000/1000 [==============================] - 56s 56ms/step - loss: 0.1432 - acc: 0.9490\n",
      "Epoch 9/10\n",
      "1000/1000 [==============================] - 57s 57ms/step - loss: 0.1294 - acc: 0.9560\n",
      "Epoch 10/10\n",
      "1000/1000 [==============================] - 57s 57ms/step - loss: 0.1189 - acc: 0.9580\n",
      "Training on Epoch  0 batch  5  Files [5] start  410 / 459\n",
      "Epoch 1/10\n",
      "1000/1000 [==============================] - 52s 52ms/step - loss: 0.3862 - acc: 0.8600\n",
      "Epoch 2/10\n",
      "1000/1000 [==============================] - 51s 51ms/step - loss: 0.2961 - acc: 0.8670\n",
      "Epoch 3/10\n",
      "1000/1000 [==============================] - 51s 51ms/step - loss: 0.2504 - acc: 0.8960\n",
      "Epoch 4/10\n",
      "1000/1000 [==============================] - 52s 52ms/step - loss: 0.2099 - acc: 0.9150\n",
      "Epoch 5/10\n",
      "1000/1000 [==============================] - 53s 53ms/step - loss: 0.1787 - acc: 0.9250\n",
      "Epoch 6/10\n",
      "1000/1000 [==============================] - 57s 57ms/step - loss: 0.1536 - acc: 0.9370\n",
      "Epoch 7/10\n",
      "1000/1000 [==============================] - 118s 118ms/step - loss: 0.1345 - acc: 0.9480\n",
      "Epoch 8/10\n",
      "1000/1000 [==============================] - 150s 150ms/step - loss: 0.1168 - acc: 0.9490\n",
      "Epoch 9/10\n",
      "1000/1000 [==============================] - 119s 119ms/step - loss: 0.1053 - acc: 0.9600\n",
      "Epoch 10/10\n",
      "1000/1000 [==============================] - 115s 115ms/step - loss: 0.0918 - acc: 0.9650\n",
      "Training on Epoch  0 batch  5  Files [5] start  415 / 459\n",
      "Epoch 1/10\n",
      "1000/1000 [==============================] - 57s 57ms/step - loss: 0.4815 - acc: 0.8430\n",
      "Epoch 2/10\n",
      "1000/1000 [==============================] - 81s 81ms/step - loss: 0.3705 - acc: 0.8610\n",
      "Epoch 3/10\n",
      "1000/1000 [==============================] - 58s 58ms/step - loss: 0.3080 - acc: 0.8790\n",
      "Epoch 4/10\n",
      "1000/1000 [==============================] - 112s 112ms/step - loss: 0.2843 - acc: 0.8770\n",
      "Epoch 5/10\n",
      "1000/1000 [==============================] - 115s 115ms/step - loss: 0.2604 - acc: 0.9010\n",
      "Epoch 6/10\n",
      "1000/1000 [==============================] - 118s 118ms/step - loss: 0.2317 - acc: 0.9020\n",
      "Epoch 7/10\n",
      "1000/1000 [==============================] - 97s 97ms/step - loss: 0.2077 - acc: 0.9110\n",
      "Epoch 8/10\n",
      "1000/1000 [==============================] - 58s 58ms/step - loss: 0.1893 - acc: 0.9180\n",
      "Epoch 9/10\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 0.1750 - acc: 0.9300\n",
      "Epoch 10/10\n",
      "1000/1000 [==============================] - 64s 64ms/step - loss: 0.1627 - acc: 0.9370\n",
      "Training on Epoch  0 batch  5  Files [5] start  420 / 459\n",
      "Epoch 1/10\n",
      "1000/1000 [==============================] - 128s 128ms/step - loss: 0.3135 - acc: 0.8800\n",
      "Epoch 2/10\n",
      "1000/1000 [==============================] - 129s 129ms/step - loss: 0.2697 - acc: 0.8920\n",
      "Epoch 3/10\n",
      "1000/1000 [==============================] - 113s 113ms/step - loss: 0.2364 - acc: 0.9030\n",
      "Epoch 4/10\n",
      "1000/1000 [==============================] - 57s 57ms/step - loss: 0.2016 - acc: 0.9190\n",
      "Epoch 5/10\n",
      "1000/1000 [==============================] - 58s 58ms/step - loss: 0.1758 - acc: 0.9360\n",
      "Epoch 6/10\n",
      "1000/1000 [==============================] - 58s 58ms/step - loss: 0.1550 - acc: 0.9420\n",
      "Epoch 7/10\n",
      "1000/1000 [==============================] - 58s 58ms/step - loss: 0.1421 - acc: 0.9490\n",
      "Epoch 8/10\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 0.1270 - acc: 0.9580\n",
      "Epoch 9/10\n",
      "1000/1000 [==============================] - 58s 58ms/step - loss: 0.1166 - acc: 0.9600\n",
      "Epoch 10/10\n",
      "1000/1000 [==============================] - 58s 58ms/step - loss: 0.1057 - acc: 0.9610\n",
      "Training on Epoch  0 batch  5  Files [5] start  425 / 459\n",
      "Epoch 1/10\n",
      "1000/1000 [==============================] - 52s 52ms/step - loss: 0.3931 - acc: 0.8750\n",
      "Epoch 2/10\n",
      "1000/1000 [==============================] - 51s 51ms/step - loss: 0.2975 - acc: 0.8930\n",
      "Epoch 3/10\n",
      "1000/1000 [==============================] - 51s 51ms/step - loss: 0.2529 - acc: 0.9080\n",
      "Epoch 4/10\n",
      "1000/1000 [==============================] - 52s 52ms/step - loss: 0.2202 - acc: 0.9270\n",
      "Epoch 5/10\n",
      "1000/1000 [==============================] - 52s 52ms/step - loss: 0.1938 - acc: 0.9370\n",
      "Epoch 6/10\n",
      "1000/1000 [==============================] - 52s 52ms/step - loss: 0.1745 - acc: 0.9430\n",
      "Epoch 7/10\n",
      "1000/1000 [==============================] - 53s 53ms/step - loss: 0.1601 - acc: 0.9440\n",
      "Epoch 8/10\n",
      "1000/1000 [==============================] - 78s 78ms/step - loss: 0.1460 - acc: 0.9540\n",
      "Epoch 9/10\n",
      "1000/1000 [==============================] - 53s 53ms/step - loss: 0.1274 - acc: 0.9600\n",
      "Epoch 10/10\n",
      "1000/1000 [==============================] - 52s 52ms/step - loss: 0.1146 - acc: 0.9620\n",
      "Training on Epoch  0 batch  5  Files [5] start  430 / 459\n",
      "Epoch 1/10\n",
      "1000/1000 [==============================] - 56s 56ms/step - loss: 0.3885 - acc: 0.8660\n",
      "Epoch 2/10\n",
      "1000/1000 [==============================] - 57s 57ms/step - loss: 0.3051 - acc: 0.8850\n",
      "Epoch 3/10\n",
      "1000/1000 [==============================] - 56s 56ms/step - loss: 0.2576 - acc: 0.8890\n",
      "Epoch 4/10\n",
      "1000/1000 [==============================] - 58s 58ms/step - loss: 0.2225 - acc: 0.8940\n",
      "Epoch 5/10\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 0.1959 - acc: 0.9140\n",
      "Epoch 6/10\n",
      "1000/1000 [==============================] - 58s 58ms/step - loss: 0.1705 - acc: 0.9230\n",
      "Epoch 7/10\n",
      "1000/1000 [==============================] - 58s 58ms/step - loss: 0.1536 - acc: 0.9340\n",
      "Epoch 8/10\n",
      "1000/1000 [==============================] - 56s 56ms/step - loss: 0.1391 - acc: 0.9460\n",
      "Epoch 9/10\n",
      "1000/1000 [==============================] - 57s 57ms/step - loss: 0.1267 - acc: 0.9500\n",
      "Epoch 10/10\n",
      "1000/1000 [==============================] - 57s 57ms/step - loss: 0.1139 - acc: 0.9570\n",
      "Training on Epoch  0 batch  5  Files [5] start  435 / 459\n",
      "Epoch 1/10\n",
      "1000/1000 [==============================] - 53s 53ms/step - loss: 0.3720 - acc: 0.8760\n",
      "Epoch 2/10\n",
      "1000/1000 [==============================] - 54s 54ms/step - loss: 0.2871 - acc: 0.8920\n",
      "Epoch 3/10\n",
      "1000/1000 [==============================] - 54s 54ms/step - loss: 0.2409 - acc: 0.9090\n",
      "Epoch 4/10\n",
      "1000/1000 [==============================] - 53s 53ms/step - loss: 0.2031 - acc: 0.9320\n",
      "Epoch 5/10\n",
      "1000/1000 [==============================] - 54s 54ms/step - loss: 0.1785 - acc: 0.9270\n",
      "Epoch 6/10\n",
      "1000/1000 [==============================] - 54s 54ms/step - loss: 0.1615 - acc: 0.9310\n",
      "Epoch 7/10\n",
      "1000/1000 [==============================] - 53s 53ms/step - loss: 0.1428 - acc: 0.9390\n",
      "Epoch 8/10\n",
      "1000/1000 [==============================] - 54s 54ms/step - loss: 0.1283 - acc: 0.9530\n",
      "Epoch 9/10\n",
      "1000/1000 [==============================] - 55s 55ms/step - loss: 0.1113 - acc: 0.9590\n",
      "Epoch 10/10\n",
      "1000/1000 [==============================] - 55s 55ms/step - loss: 0.1002 - acc: 0.9630\n",
      "Training on Epoch  0 batch  5  Files [5] start  440 / 459\n",
      "Epoch 1/10\n",
      "1000/1000 [==============================] - 50s 50ms/step - loss: 0.2468 - acc: 0.9210\n",
      "Epoch 2/10\n",
      "1000/1000 [==============================] - 49s 49ms/step - loss: 0.1952 - acc: 0.9350\n",
      "Epoch 3/10\n",
      "1000/1000 [==============================] - 50s 50ms/step - loss: 0.1542 - acc: 0.9470\n",
      "Epoch 4/10\n",
      "1000/1000 [==============================] - 50s 50ms/step - loss: 0.1237 - acc: 0.9580\n",
      "Epoch 5/10\n",
      "1000/1000 [==============================] - 49s 49ms/step - loss: 0.1064 - acc: 0.9650\n",
      "Epoch 6/10\n",
      "1000/1000 [==============================] - 50s 50ms/step - loss: 0.0944 - acc: 0.9700\n",
      "Epoch 7/10\n",
      "1000/1000 [==============================] - 51s 51ms/step - loss: 0.0840 - acc: 0.9720\n",
      "Epoch 8/10\n",
      "1000/1000 [==============================] - 52s 52ms/step - loss: 0.0736 - acc: 0.9760\n",
      "Epoch 9/10\n",
      "1000/1000 [==============================] - 53s 53ms/step - loss: 0.0637 - acc: 0.9810\n",
      "Epoch 10/10\n",
      "1000/1000 [==============================] - 53s 53ms/step - loss: 0.0577 - acc: 0.9810\n",
      "Training on Epoch  0 batch  5  Files [5] start  445 / 459\n",
      "Epoch 1/10\n",
      "1000/1000 [==============================] - 52s 52ms/step - loss: 0.2656 - acc: 0.9000\n",
      "Epoch 2/10\n",
      "1000/1000 [==============================] - 52s 52ms/step - loss: 0.1938 - acc: 0.9230\n",
      "Epoch 3/10\n",
      "1000/1000 [==============================] - 52s 52ms/step - loss: 0.1654 - acc: 0.9340\n",
      "Epoch 4/10\n",
      "1000/1000 [==============================] - 51s 51ms/step - loss: 0.1401 - acc: 0.9450\n",
      "Epoch 5/10\n",
      "1000/1000 [==============================] - 51s 51ms/step - loss: 0.1200 - acc: 0.9480\n",
      "Epoch 6/10\n",
      "1000/1000 [==============================] - 52s 52ms/step - loss: 0.0949 - acc: 0.9590\n",
      "Epoch 7/10\n",
      "1000/1000 [==============================] - 50s 50ms/step - loss: 0.0833 - acc: 0.9660\n",
      "Epoch 8/10\n",
      "1000/1000 [==============================] - 50s 50ms/step - loss: 0.0676 - acc: 0.9770\n",
      "Epoch 9/10\n",
      "1000/1000 [==============================] - 50s 50ms/step - loss: 0.0561 - acc: 0.9780\n",
      "Epoch 10/10\n",
      "1000/1000 [==============================] - 51s 51ms/step - loss: 0.0499 - acc: 0.9810\n",
      "Training on Epoch  0 batch  5  Files [5] start  450 / 459\n",
      "Epoch 1/10\n",
      "1000/1000 [==============================] - 57s 57ms/step - loss: 0.3289 - acc: 0.8760\n",
      "Epoch 2/10\n",
      "1000/1000 [==============================] - 58s 58ms/step - loss: 0.2799 - acc: 0.8930\n",
      "Epoch 3/10\n",
      "1000/1000 [==============================] - 58s 58ms/step - loss: 0.2152 - acc: 0.9060\n",
      "Epoch 4/10\n",
      "1000/1000 [==============================] - 58s 58ms/step - loss: 0.1734 - acc: 0.9250\n",
      "Epoch 5/10\n",
      "1000/1000 [==============================] - 58s 58ms/step - loss: 0.1543 - acc: 0.9340\n",
      "Epoch 6/10\n",
      "1000/1000 [==============================] - 57s 57ms/step - loss: 0.1393 - acc: 0.9440\n",
      "Epoch 7/10\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 0.1234 - acc: 0.9490\n",
      "Epoch 8/10\n",
      "1000/1000 [==============================] - 58s 58ms/step - loss: 0.1071 - acc: 0.9600\n",
      "Epoch 9/10\n",
      "1000/1000 [==============================] - 57s 57ms/step - loss: 0.0966 - acc: 0.9660\n",
      "Epoch 10/10\n",
      "1000/1000 [==============================] - 57s 57ms/step - loss: 0.0836 - acc: 0.9720\n",
      "Training on Epoch  0 batch  4  Files [5] start  455 / 459\n",
      "Epoch 1/10\n",
      "800/800 [==============================] - 49s 61ms/step - loss: 0.3101 - acc: 0.9025\n",
      "Epoch 2/10\n",
      "800/800 [==============================] - 49s 61ms/step - loss: 0.2675 - acc: 0.9163\n",
      "Epoch 3/10\n",
      "800/800 [==============================] - 52s 65ms/step - loss: 0.2092 - acc: 0.9363\n",
      "Epoch 4/10\n",
      "800/800 [==============================] - 49s 61ms/step - loss: 0.1834 - acc: 0.9350\n",
      "Epoch 5/10\n",
      "800/800 [==============================] - 48s 60ms/step - loss: 0.1550 - acc: 0.9450\n",
      "Epoch 6/10\n",
      "800/800 [==============================] - 48s 60ms/step - loss: 0.1398 - acc: 0.9513\n",
      "Epoch 7/10\n",
      "800/800 [==============================] - 49s 61ms/step - loss: 0.1253 - acc: 0.9600\n",
      "Epoch 8/10\n",
      "800/800 [==============================] - 49s 61ms/step - loss: 0.1128 - acc: 0.9612\n",
      "Epoch 9/10\n",
      "800/800 [==============================] - 48s 60ms/step - loss: 0.1046 - acc: 0.9663\n",
      "Epoch 10/10\n",
      "800/800 [==============================] - 49s 61ms/step - loss: 0.0935 - acc: 0.9700\n",
      "Training on Epoch  1 batch  5  Files [5] start  0 / 459\n",
      "Epoch 1/10\n",
      "1000/1000 [==============================] - 52s 52ms/step - loss: 0.3492 - acc: 0.8690\n",
      "Epoch 2/10\n",
      "1000/1000 [==============================] - 53s 53ms/step - loss: 0.3257 - acc: 0.8760\n",
      "Epoch 3/10\n",
      "1000/1000 [==============================] - 53s 53ms/step - loss: 0.2700 - acc: 0.8910\n",
      "Epoch 4/10\n",
      "1000/1000 [==============================] - 52s 52ms/step - loss: 0.2372 - acc: 0.9010\n",
      "Epoch 5/10\n",
      "1000/1000 [==============================] - 53s 53ms/step - loss: 0.2098 - acc: 0.9220\n",
      "Epoch 6/10\n",
      "1000/1000 [==============================] - 53s 53ms/step - loss: 0.1770 - acc: 0.9360\n",
      "Epoch 7/10\n",
      "1000/1000 [==============================] - 52s 52ms/step - loss: 0.1618 - acc: 0.9410\n",
      "Epoch 8/10\n",
      "1000/1000 [==============================] - 54s 54ms/step - loss: 0.1464 - acc: 0.9470\n",
      "Epoch 9/10\n",
      "1000/1000 [==============================] - 54s 54ms/step - loss: 0.1339 - acc: 0.9490\n",
      "Epoch 10/10\n",
      "1000/1000 [==============================] - 53s 53ms/step - loss: 0.1204 - acc: 0.9560\n",
      "Training on Epoch  1 batch  5  Files [5] start  5 / 459\n",
      "Epoch 1/10\n",
      "1000/1000 [==============================] - 55s 55ms/step - loss: 0.2956 - acc: 0.8860\n",
      "Epoch 2/10\n",
      "1000/1000 [==============================] - 54s 54ms/step - loss: 0.2563 - acc: 0.9120\n",
      "Epoch 3/10\n",
      "1000/1000 [==============================] - 53s 53ms/step - loss: 0.2204 - acc: 0.9210\n",
      "Epoch 4/10\n",
      "1000/1000 [==============================] - 52s 52ms/step - loss: 0.1957 - acc: 0.9340\n",
      "Epoch 5/10\n",
      "1000/1000 [==============================] - 52s 52ms/step - loss: 0.1787 - acc: 0.9390\n",
      "Epoch 6/10\n",
      "1000/1000 [==============================] - 52s 52ms/step - loss: 0.1625 - acc: 0.9480\n",
      "Epoch 7/10\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000/1000 [==============================] - 52s 52ms/step - loss: 0.1497 - acc: 0.9550\n",
      "Epoch 8/10\n",
      "1000/1000 [==============================] - 58s 58ms/step - loss: 0.1384 - acc: 0.9590\n",
      "Epoch 9/10\n",
      "1000/1000 [==============================] - 83s 83ms/step - loss: 0.1281 - acc: 0.9620\n",
      "Epoch 10/10\n",
      "1000/1000 [==============================] - 88s 88ms/step - loss: 0.1200 - acc: 0.9660\n",
      "Training on Epoch  1 batch  5  Files [5] start  10 / 459\n",
      "Epoch 1/10\n",
      "1000/1000 [==============================] - 90s 90ms/step - loss: 0.3465 - acc: 0.8570\n",
      "Epoch 2/10\n",
      "1000/1000 [==============================] - 97s 97ms/step - loss: 0.2723 - acc: 0.8900\n",
      "Epoch 3/10\n",
      "1000/1000 [==============================] - 96s 96ms/step - loss: 0.2234 - acc: 0.9090\n",
      "Epoch 4/10\n",
      "1000/1000 [==============================] - 58s 58ms/step - loss: 0.1902 - acc: 0.9170\n",
      "Epoch 5/10\n",
      "1000/1000 [==============================] - 55s 55ms/step - loss: 0.1671 - acc: 0.9360\n",
      "Epoch 6/10\n",
      "1000/1000 [==============================] - 54s 54ms/step - loss: 0.1466 - acc: 0.9500\n",
      "Epoch 7/10\n",
      "1000/1000 [==============================] - 55s 55ms/step - loss: 0.1326 - acc: 0.9560\n",
      "Epoch 8/10\n",
      "1000/1000 [==============================] - 53s 53ms/step - loss: 0.1163 - acc: 0.9630\n",
      "Epoch 9/10\n",
      "1000/1000 [==============================] - 54s 54ms/step - loss: 0.1060 - acc: 0.9660\n",
      "Epoch 10/10\n",
      "1000/1000 [==============================] - 54s 54ms/step - loss: 0.1000 - acc: 0.9680\n",
      "Training on Epoch  1 batch  5  Files [5] start  15 / 459\n",
      "Epoch 1/10\n",
      "1000/1000 [==============================] - 54s 54ms/step - loss: 0.3279 - acc: 0.8870\n",
      "Epoch 2/10\n",
      "1000/1000 [==============================] - 54s 54ms/step - loss: 0.2869 - acc: 0.8930\n",
      "Epoch 3/10\n",
      "1000/1000 [==============================] - 56s 56ms/step - loss: 0.2397 - acc: 0.9130\n",
      "Epoch 4/10\n",
      "1000/1000 [==============================] - 55s 55ms/step - loss: 0.2031 - acc: 0.9260\n",
      "Epoch 5/10\n",
      "1000/1000 [==============================] - 87s 87ms/step - loss: 0.1801 - acc: 0.9390\n",
      "Epoch 6/10\n",
      "1000/1000 [==============================] - 89s 89ms/step - loss: 0.1602 - acc: 0.9480\n",
      "Epoch 7/10\n",
      "1000/1000 [==============================] - 85s 85ms/step - loss: 0.1374 - acc: 0.9590\n",
      "Epoch 8/10\n",
      "1000/1000 [==============================] - 95s 95ms/step - loss: 0.1243 - acc: 0.9640\n",
      "Epoch 9/10\n",
      "1000/1000 [==============================] - 93s 93ms/step - loss: 0.1157 - acc: 0.9600\n",
      "Epoch 10/10\n",
      "1000/1000 [==============================] - 60s 60ms/step - loss: 0.1045 - acc: 0.9690\n",
      "Training on Epoch  1 batch  5  Files [5] start  20 / 459\n",
      "Epoch 1/10\n",
      "1000/1000 [==============================] - 51s 51ms/step - loss: 0.3725 - acc: 0.8770\n",
      "Epoch 2/10\n",
      "1000/1000 [==============================] - 52s 52ms/step - loss: 0.2905 - acc: 0.8930\n",
      "Epoch 3/10\n",
      "1000/1000 [==============================] - 52s 52ms/step - loss: 0.2395 - acc: 0.9070\n",
      "Epoch 4/10\n",
      "1000/1000 [==============================] - 52s 52ms/step - loss: 0.2133 - acc: 0.9150\n",
      "Epoch 5/10\n",
      "1000/1000 [==============================] - 51s 51ms/step - loss: 0.2043 - acc: 0.9190\n",
      "Epoch 6/10\n",
      "1000/1000 [==============================] - 51s 51ms/step - loss: 0.1833 - acc: 0.9310\n",
      "Epoch 7/10\n",
      "1000/1000 [==============================] - 51s 51ms/step - loss: 0.1637 - acc: 0.9390\n",
      "Epoch 8/10\n",
      "1000/1000 [==============================] - 51s 51ms/step - loss: 0.1463 - acc: 0.9430\n",
      "Epoch 9/10\n",
      "1000/1000 [==============================] - 52s 52ms/step - loss: 0.1303 - acc: 0.9570\n",
      "Epoch 10/10\n",
      "1000/1000 [==============================] - 51s 51ms/step - loss: 0.1175 - acc: 0.9660\n",
      "Training on Epoch  1 batch  5  Files [5] start  25 / 459\n",
      "Epoch 1/10\n",
      "1000/1000 [==============================] - 53s 53ms/step - loss: 0.3417 - acc: 0.8720\n",
      "Epoch 2/10\n",
      "1000/1000 [==============================] - 55s 55ms/step - loss: 0.2775 - acc: 0.8950\n",
      "Epoch 3/10\n",
      "1000/1000 [==============================] - 54s 54ms/step - loss: 0.2373 - acc: 0.9050\n",
      "Epoch 4/10\n",
      "1000/1000 [==============================] - 54s 54ms/step - loss: 0.2045 - acc: 0.9230\n",
      "Epoch 5/10\n",
      "1000/1000 [==============================] - 54s 54ms/step - loss: 0.1788 - acc: 0.9310\n",
      "Epoch 6/10\n",
      "1000/1000 [==============================] - 53s 53ms/step - loss: 0.1661 - acc: 0.9340\n",
      "Epoch 7/10\n",
      "1000/1000 [==============================] - 53s 53ms/step - loss: 0.1501 - acc: 0.9420\n",
      "Epoch 8/10\n",
      "1000/1000 [==============================] - 53s 53ms/step - loss: 0.1360 - acc: 0.9470\n",
      "Epoch 9/10\n",
      "1000/1000 [==============================] - 54s 54ms/step - loss: 0.1239 - acc: 0.9560\n",
      "Epoch 10/10\n",
      "1000/1000 [==============================] - 53s 53ms/step - loss: 0.1134 - acc: 0.9590\n",
      "Training on Epoch  1 batch  5  Files [5] start  30 / 459\n",
      "Epoch 1/10\n",
      "1000/1000 [==============================] - 52s 52ms/step - loss: 0.3108 - acc: 0.8820\n",
      "Epoch 2/10\n",
      "1000/1000 [==============================] - 52s 52ms/step - loss: 0.2693 - acc: 0.8920\n",
      "Epoch 3/10\n",
      "1000/1000 [==============================] - 52s 52ms/step - loss: 0.2234 - acc: 0.9150\n",
      "Epoch 4/10\n",
      "1000/1000 [==============================] - 53s 53ms/step - loss: 0.2054 - acc: 0.9240\n",
      "Epoch 5/10\n",
      "1000/1000 [==============================] - 53s 53ms/step - loss: 0.1846 - acc: 0.9310\n",
      "Epoch 6/10\n",
      "1000/1000 [==============================] - 53s 53ms/step - loss: 0.1571 - acc: 0.9390\n",
      "Epoch 7/10\n",
      "1000/1000 [==============================] - 53s 53ms/step - loss: 0.1356 - acc: 0.9510\n",
      "Epoch 8/10\n",
      "1000/1000 [==============================] - 53s 53ms/step - loss: 0.1201 - acc: 0.9560\n",
      "Epoch 9/10\n",
      "1000/1000 [==============================] - 54s 54ms/step - loss: 0.1074 - acc: 0.9600\n",
      "Epoch 10/10\n",
      "1000/1000 [==============================] - 53s 53ms/step - loss: 0.0964 - acc: 0.9650\n",
      "Training on Epoch  1 batch  5  Files [5] start  35 / 459\n",
      "Epoch 1/10\n",
      "1000/1000 [==============================] - 51s 51ms/step - loss: 0.3126 - acc: 0.8900\n",
      "Epoch 2/10\n",
      "1000/1000 [==============================] - 52s 52ms/step - loss: 0.2494 - acc: 0.9060\n",
      "Epoch 3/10\n",
      "1000/1000 [==============================] - 51s 51ms/step - loss: 0.2032 - acc: 0.9190\n",
      "Epoch 4/10\n",
      "1000/1000 [==============================] - 51s 51ms/step - loss: 0.1746 - acc: 0.9350\n",
      "Epoch 5/10\n",
      "1000/1000 [==============================] - 52s 52ms/step - loss: 0.1557 - acc: 0.9410\n",
      "Epoch 6/10\n",
      "1000/1000 [==============================] - 51s 51ms/step - loss: 0.1391 - acc: 0.9520\n",
      "Epoch 7/10\n",
      "1000/1000 [==============================] - 51s 51ms/step - loss: 0.1274 - acc: 0.9520\n",
      "Epoch 8/10\n",
      "1000/1000 [==============================] - 52s 52ms/step - loss: 0.1162 - acc: 0.9580\n",
      "Epoch 9/10\n",
      "1000/1000 [==============================] - 51s 51ms/step - loss: 0.1082 - acc: 0.9600\n",
      "Epoch 10/10\n",
      "1000/1000 [==============================] - 52s 52ms/step - loss: 0.1011 - acc: 0.9630\n",
      "Training on Epoch  1 batch  5  Files [5] start  40 / 459\n",
      "Epoch 1/10\n",
      "1000/1000 [==============================] - 52s 52ms/step - loss: 0.3184 - acc: 0.8740\n",
      "Epoch 2/10\n",
      "1000/1000 [==============================] - 52s 52ms/step - loss: 0.2370 - acc: 0.9130\n",
      "Epoch 3/10\n",
      "1000/1000 [==============================] - 52s 52ms/step - loss: 0.1819 - acc: 0.9320\n",
      "Epoch 4/10\n",
      "1000/1000 [==============================] - 52s 52ms/step - loss: 0.1547 - acc: 0.9450\n",
      "Epoch 5/10\n",
      "1000/1000 [==============================] - 52s 52ms/step - loss: 0.1300 - acc: 0.9550\n",
      "Epoch 6/10\n",
      "1000/1000 [==============================] - 53s 53ms/step - loss: 0.1114 - acc: 0.9580\n",
      "Epoch 7/10\n",
      "1000/1000 [==============================] - 53s 53ms/step - loss: 0.0991 - acc: 0.9620\n",
      "Epoch 8/10\n",
      "1000/1000 [==============================] - 52s 52ms/step - loss: 0.0874 - acc: 0.9660\n",
      "Epoch 9/10\n",
      "1000/1000 [==============================] - 52s 52ms/step - loss: 0.0793 - acc: 0.9710\n",
      "Epoch 10/10\n",
      "1000/1000 [==============================] - 52s 52ms/step - loss: 0.0709 - acc: 0.9770\n",
      "Training on Epoch  1 batch  5  Files [5] start  45 / 459\n",
      "Epoch 1/10\n",
      "1000/1000 [==============================] - 48s 48ms/step - loss: 0.3219 - acc: 0.8810\n",
      "Epoch 2/10\n",
      "1000/1000 [==============================] - 48s 48ms/step - loss: 0.2510 - acc: 0.9050\n",
      "Epoch 3/10\n",
      "1000/1000 [==============================] - 47s 47ms/step - loss: 0.2049 - acc: 0.9220\n",
      "Epoch 4/10\n",
      "1000/1000 [==============================] - 48s 48ms/step - loss: 0.1764 - acc: 0.9280\n",
      "Epoch 5/10\n",
      "1000/1000 [==============================] - 48s 48ms/step - loss: 0.1534 - acc: 0.9450\n",
      "Epoch 6/10\n",
      "1000/1000 [==============================] - 47s 47ms/step - loss: 0.1341 - acc: 0.9480\n",
      "Epoch 7/10\n",
      "1000/1000 [==============================] - 48s 48ms/step - loss: 0.1202 - acc: 0.9540\n",
      "Epoch 8/10\n",
      "1000/1000 [==============================] - 48s 48ms/step - loss: 0.1091 - acc: 0.9620\n",
      "Epoch 9/10\n",
      "1000/1000 [==============================] - 48s 48ms/step - loss: 0.0999 - acc: 0.9650\n",
      "Epoch 10/10\n",
      "1000/1000 [==============================] - 48s 48ms/step - loss: 0.0927 - acc: 0.9690\n",
      "Training on Epoch  1 batch  5  Files [5] start  50 / 459\n",
      "Epoch 1/10\n",
      "1000/1000 [==============================] - 58s 58ms/step - loss: 0.3484 - acc: 0.8740\n",
      "Epoch 2/10\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 0.2776 - acc: 0.8950\n",
      "Epoch 3/10\n",
      "1000/1000 [==============================] - 58s 58ms/step - loss: 0.2386 - acc: 0.8910\n",
      "Epoch 4/10\n",
      "1000/1000 [==============================] - 58s 58ms/step - loss: 0.2021 - acc: 0.9150\n",
      "Epoch 5/10\n",
      "1000/1000 [==============================] - 58s 58ms/step - loss: 0.1800 - acc: 0.9260\n",
      "Epoch 6/10\n",
      "1000/1000 [==============================] - 57s 57ms/step - loss: 0.1586 - acc: 0.9450\n",
      "Epoch 7/10\n",
      "1000/1000 [==============================] - 58s 58ms/step - loss: 0.1414 - acc: 0.9480\n",
      "Epoch 8/10\n",
      "1000/1000 [==============================] - 57s 57ms/step - loss: 0.1290 - acc: 0.9510\n",
      "Epoch 9/10\n",
      "1000/1000 [==============================] - 57s 57ms/step - loss: 0.1192 - acc: 0.9570\n",
      "Epoch 10/10\n",
      "1000/1000 [==============================] - 57s 57ms/step - loss: 0.1114 - acc: 0.9590\n",
      "Training on Epoch  1 batch  5  Files [5] start  55 / 459\n",
      "Epoch 1/10\n",
      "1000/1000 [==============================] - 54s 54ms/step - loss: 0.2943 - acc: 0.8900\n",
      "Epoch 2/10\n",
      "1000/1000 [==============================] - 53s 53ms/step - loss: 0.2472 - acc: 0.9050\n",
      "Epoch 3/10\n",
      "1000/1000 [==============================] - 53s 53ms/step - loss: 0.2105 - acc: 0.9230\n",
      "Epoch 4/10\n",
      "1000/1000 [==============================] - 53s 53ms/step - loss: 0.1835 - acc: 0.9390\n",
      "Epoch 5/10\n",
      "1000/1000 [==============================] - 53s 53ms/step - loss: 0.1633 - acc: 0.9410\n",
      "Epoch 6/10\n",
      "1000/1000 [==============================] - 52s 52ms/step - loss: 0.1437 - acc: 0.9460\n",
      "Epoch 7/10\n",
      "1000/1000 [==============================] - 53s 53ms/step - loss: 0.1290 - acc: 0.9570\n",
      "Epoch 8/10\n",
      "1000/1000 [==============================] - 53s 53ms/step - loss: 0.1191 - acc: 0.9600\n",
      "Epoch 9/10\n",
      "1000/1000 [==============================] - 53s 53ms/step - loss: 0.1066 - acc: 0.9640\n",
      "Epoch 10/10\n",
      "1000/1000 [==============================] - 53s 53ms/step - loss: 0.0974 - acc: 0.9670\n",
      "Training on Epoch  1 batch  5  Files [5] start  60 / 459\n",
      "Epoch 1/10\n",
      "1000/1000 [==============================] - 51s 51ms/step - loss: 0.3714 - acc: 0.8660\n",
      "Epoch 2/10\n",
      "1000/1000 [==============================] - 51s 51ms/step - loss: 0.3134 - acc: 0.8820\n",
      "Epoch 3/10\n",
      "1000/1000 [==============================] - 52s 52ms/step - loss: 0.2467 - acc: 0.8980\n",
      "Epoch 4/10\n",
      "1000/1000 [==============================] - 52s 52ms/step - loss: 0.2028 - acc: 0.9100\n",
      "Epoch 5/10\n",
      "1000/1000 [==============================] - 51s 51ms/step - loss: 0.1750 - acc: 0.9300\n",
      "Epoch 6/10\n",
      "1000/1000 [==============================] - 51s 51ms/step - loss: 0.1536 - acc: 0.9370\n",
      "Epoch 7/10\n",
      "1000/1000 [==============================] - 51s 51ms/step - loss: 0.1376 - acc: 0.9460\n",
      "Epoch 8/10\n",
      "1000/1000 [==============================] - 52s 52ms/step - loss: 0.1222 - acc: 0.9540\n",
      "Epoch 9/10\n",
      "1000/1000 [==============================] - 51s 51ms/step - loss: 0.1121 - acc: 0.9600\n",
      "Epoch 10/10\n",
      "1000/1000 [==============================] - 52s 52ms/step - loss: 0.1061 - acc: 0.9620\n",
      "Training on Epoch  1 batch  5  Files [5] start  65 / 459\n",
      "Epoch 1/10\n",
      "1000/1000 [==============================] - 51s 51ms/step - loss: 0.2966 - acc: 0.8920\n",
      "Epoch 2/10\n",
      "1000/1000 [==============================] - 51s 51ms/step - loss: 0.2417 - acc: 0.9070\n",
      "Epoch 3/10\n",
      "1000/1000 [==============================] - 51s 51ms/step - loss: 0.1958 - acc: 0.9230\n",
      "Epoch 4/10\n",
      "1000/1000 [==============================] - 50s 50ms/step - loss: 0.1681 - acc: 0.9380\n",
      "Epoch 5/10\n",
      "1000/1000 [==============================] - 51s 51ms/step - loss: 0.1512 - acc: 0.9440\n",
      "Epoch 6/10\n",
      "1000/1000 [==============================] - 50s 50ms/step - loss: 0.1346 - acc: 0.9540\n",
      "Epoch 7/10\n",
      "1000/1000 [==============================] - 51s 51ms/step - loss: 0.1227 - acc: 0.9560\n",
      "Epoch 8/10\n",
      "1000/1000 [==============================] - 51s 51ms/step - loss: 0.1116 - acc: 0.9580\n",
      "Epoch 9/10\n",
      "1000/1000 [==============================] - 51s 51ms/step - loss: 0.1006 - acc: 0.9650\n",
      "Epoch 10/10\n",
      "1000/1000 [==============================] - 51s 51ms/step - loss: 0.0928 - acc: 0.9660\n",
      "Training on Epoch  1 batch  5  Files [5] start  70 / 459\n",
      "Epoch 1/10\n",
      "1000/1000 [==============================] - 49s 49ms/step - loss: 0.3503 - acc: 0.8790\n",
      "Epoch 2/10\n",
      "1000/1000 [==============================] - 50s 50ms/step - loss: 0.2599 - acc: 0.8960\n",
      "Epoch 3/10\n",
      "1000/1000 [==============================] - 50s 50ms/step - loss: 0.2132 - acc: 0.9150\n",
      "Epoch 4/10\n",
      "1000/1000 [==============================] - 50s 50ms/step - loss: 0.1807 - acc: 0.9360\n",
      "Epoch 5/10\n",
      "1000/1000 [==============================] - 50s 50ms/step - loss: 0.1658 - acc: 0.9450\n",
      "Epoch 6/10\n",
      "1000/1000 [==============================] - 50s 50ms/step - loss: 0.1483 - acc: 0.9590\n",
      "Epoch 7/10\n",
      "1000/1000 [==============================] - 51s 51ms/step - loss: 0.1354 - acc: 0.9610\n",
      "Epoch 8/10\n",
      "1000/1000 [==============================] - 51s 51ms/step - loss: 0.1237 - acc: 0.9660\n",
      "Epoch 9/10\n",
      "1000/1000 [==============================] - 50s 50ms/step - loss: 0.1139 - acc: 0.9690\n",
      "Epoch 10/10\n",
      "1000/1000 [==============================] - 50s 50ms/step - loss: 0.1072 - acc: 0.9690\n",
      "Training on Epoch  1 batch  5  Files [5] start  75 / 459\n",
      "Epoch 1/10\n",
      "1000/1000 [==============================] - 56s 56ms/step - loss: 0.3782 - acc: 0.8520\n",
      "Epoch 2/10\n",
      "1000/1000 [==============================] - 55s 55ms/step - loss: 0.2816 - acc: 0.8930\n",
      "Epoch 3/10\n",
      "1000/1000 [==============================] - 55s 55ms/step - loss: 0.2427 - acc: 0.9060\n",
      "Epoch 4/10\n",
      "1000/1000 [==============================] - 55s 55ms/step - loss: 0.2165 - acc: 0.9130\n",
      "Epoch 5/10\n",
      "1000/1000 [==============================] - 56s 56ms/step - loss: 0.1967 - acc: 0.9220\n",
      "Epoch 6/10\n",
      "1000/1000 [==============================] - 54s 54ms/step - loss: 0.1767 - acc: 0.9300\n",
      "Epoch 7/10\n",
      "1000/1000 [==============================] - 55s 55ms/step - loss: 0.1603 - acc: 0.9320\n",
      "Epoch 8/10\n",
      "1000/1000 [==============================] - 55s 55ms/step - loss: 0.1458 - acc: 0.9440\n",
      "Epoch 9/10\n",
      "1000/1000 [==============================] - 55s 55ms/step - loss: 0.1364 - acc: 0.9450\n",
      "Epoch 10/10\n",
      "1000/1000 [==============================] - 55s 55ms/step - loss: 0.1288 - acc: 0.9510\n",
      "Training on Epoch  1 batch  5  Files [5] start  80 / 459\n",
      "Epoch 1/10\n",
      "1000/1000 [==============================] - 55s 55ms/step - loss: 0.3613 - acc: 0.8690\n",
      "Epoch 2/10\n",
      "1000/1000 [==============================] - 55s 55ms/step - loss: 0.2778 - acc: 0.8930\n",
      "Epoch 3/10\n",
      "1000/1000 [==============================] - 55s 55ms/step - loss: 0.2256 - acc: 0.9170\n",
      "Epoch 4/10\n",
      "1000/1000 [==============================] - 55s 55ms/step - loss: 0.1955 - acc: 0.9320\n",
      "Epoch 5/10\n",
      "1000/1000 [==============================] - 56s 56ms/step - loss: 0.1708 - acc: 0.9430\n",
      "Epoch 6/10\n",
      "1000/1000 [==============================] - 56s 56ms/step - loss: 0.1536 - acc: 0.9500\n",
      "Epoch 7/10\n",
      "1000/1000 [==============================] - 58s 58ms/step - loss: 0.1419 - acc: 0.9460\n",
      "Epoch 8/10\n",
      "1000/1000 [==============================] - 56s 56ms/step - loss: 0.1233 - acc: 0.9550\n",
      "Epoch 9/10\n",
      "1000/1000 [==============================] - 56s 56ms/step - loss: 0.1140 - acc: 0.9590\n",
      "Epoch 10/10\n",
      "1000/1000 [==============================] - 56s 56ms/step - loss: 0.1006 - acc: 0.9680\n",
      "Training on Epoch  1 batch  5  Files [5] start  85 / 459\n",
      "Epoch 1/10\n",
      "1000/1000 [==============================] - 57s 57ms/step - loss: 0.4157 - acc: 0.8470\n",
      "Epoch 2/10\n",
      "1000/1000 [==============================] - 57s 57ms/step - loss: 0.3144 - acc: 0.8840\n",
      "Epoch 3/10\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000/1000 [==============================] - 57s 57ms/step - loss: 0.2615 - acc: 0.9030\n",
      "Epoch 4/10\n",
      "1000/1000 [==============================] - 56s 56ms/step - loss: 0.2238 - acc: 0.9170\n",
      "Epoch 5/10\n",
      "1000/1000 [==============================] - 56s 56ms/step - loss: 0.2019 - acc: 0.9200\n",
      "Epoch 6/10\n",
      "1000/1000 [==============================] - 56s 56ms/step - loss: 0.1803 - acc: 0.9290\n",
      "Epoch 7/10\n",
      "1000/1000 [==============================] - 56s 56ms/step - loss: 0.1641 - acc: 0.9390\n",
      "Epoch 8/10\n",
      "1000/1000 [==============================] - 56s 56ms/step - loss: 0.1504 - acc: 0.9440\n",
      "Epoch 9/10\n",
      "1000/1000 [==============================] - 56s 56ms/step - loss: 0.1386 - acc: 0.9500\n",
      "Epoch 10/10\n",
      "1000/1000 [==============================] - 56s 56ms/step - loss: 0.1291 - acc: 0.9490\n",
      "Training on Epoch  1 batch  5  Files [5] start  90 / 459\n",
      "Epoch 1/10\n",
      "1000/1000 [==============================] - 49s 49ms/step - loss: 0.3562 - acc: 0.8700\n",
      "Epoch 2/10\n",
      "1000/1000 [==============================] - 49s 49ms/step - loss: 0.2798 - acc: 0.8880\n",
      "Epoch 3/10\n",
      "1000/1000 [==============================] - 49s 49ms/step - loss: 0.2309 - acc: 0.9150\n",
      "Epoch 4/10\n",
      "1000/1000 [==============================] - 50s 50ms/step - loss: 0.2023 - acc: 0.9270\n",
      "Epoch 5/10\n",
      "1000/1000 [==============================] - 48s 48ms/step - loss: 0.1817 - acc: 0.9380\n",
      "Epoch 6/10\n",
      "1000/1000 [==============================] - 49s 49ms/step - loss: 0.1616 - acc: 0.9470\n",
      "Epoch 7/10\n",
      "1000/1000 [==============================] - 49s 49ms/step - loss: 0.1488 - acc: 0.9520\n",
      "Epoch 8/10\n",
      "1000/1000 [==============================] - 49s 49ms/step - loss: 0.1354 - acc: 0.9550\n",
      "Epoch 9/10\n",
      "1000/1000 [==============================] - 49s 49ms/step - loss: 0.1263 - acc: 0.9610\n",
      "Epoch 10/10\n",
      "1000/1000 [==============================] - 49s 49ms/step - loss: 0.1165 - acc: 0.9630\n",
      "Training on Epoch  1 batch  5  Files [5] start  95 / 459\n",
      "Epoch 1/10\n",
      "1000/1000 [==============================] - 54s 54ms/step - loss: 0.3510 - acc: 0.8650\n",
      "Epoch 2/10\n",
      "1000/1000 [==============================] - 53s 53ms/step - loss: 0.2631 - acc: 0.8940\n",
      "Epoch 3/10\n",
      "1000/1000 [==============================] - 55s 55ms/step - loss: 0.2272 - acc: 0.9050\n",
      "Epoch 4/10\n",
      "1000/1000 [==============================] - 54s 54ms/step - loss: 0.1943 - acc: 0.9210\n",
      "Epoch 5/10\n",
      "1000/1000 [==============================] - 54s 54ms/step - loss: 0.1737 - acc: 0.9290\n",
      "Epoch 6/10\n",
      "1000/1000 [==============================] - 55s 55ms/step - loss: 0.1518 - acc: 0.9390\n",
      "Epoch 7/10\n",
      "1000/1000 [==============================] - 55s 55ms/step - loss: 0.1371 - acc: 0.9440\n",
      "Epoch 8/10\n",
      "1000/1000 [==============================] - 55s 55ms/step - loss: 0.1272 - acc: 0.9480\n",
      "Epoch 9/10\n",
      "1000/1000 [==============================] - 55s 55ms/step - loss: 0.1180 - acc: 0.9520\n",
      "Epoch 10/10\n",
      "1000/1000 [==============================] - 57s 57ms/step - loss: 0.1114 - acc: 0.9510\n",
      "Training on Epoch  1 batch  5  Files [5] start  100 / 459\n",
      "Epoch 1/10\n",
      "1000/1000 [==============================] - 66s 66ms/step - loss: 0.3244 - acc: 0.8850\n",
      "Epoch 2/10\n",
      "1000/1000 [==============================] - 67s 67ms/step - loss: 0.2316 - acc: 0.9140\n",
      "Epoch 3/10\n",
      "1000/1000 [==============================] - 66s 66ms/step - loss: 0.1778 - acc: 0.9320\n",
      "Epoch 4/10\n",
      "1000/1000 [==============================] - 65s 65ms/step - loss: 0.1511 - acc: 0.9460\n",
      "Epoch 5/10\n",
      "1000/1000 [==============================] - 68s 68ms/step - loss: 0.1296 - acc: 0.9580\n",
      "Epoch 6/10\n",
      "1000/1000 [==============================] - 71s 71ms/step - loss: 0.1102 - acc: 0.9650\n",
      "Epoch 7/10\n",
      "1000/1000 [==============================] - 65s 65ms/step - loss: 0.0974 - acc: 0.9740\n",
      "Epoch 8/10\n",
      "1000/1000 [==============================] - 64s 64ms/step - loss: 0.0834 - acc: 0.9730\n",
      "Epoch 9/10\n",
      "1000/1000 [==============================] - 68s 68ms/step - loss: 0.0720 - acc: 0.9810\n",
      "Epoch 10/10\n",
      "1000/1000 [==============================] - 67s 67ms/step - loss: 0.0667 - acc: 0.9800\n",
      "Training on Epoch  1 batch  5  Files [5] start  105 / 459\n",
      "Epoch 1/10\n",
      "1000/1000 [==============================] - 72s 72ms/step - loss: 0.3946 - acc: 0.8810\n",
      "Epoch 2/10\n",
      "1000/1000 [==============================] - 71s 71ms/step - loss: 0.2924 - acc: 0.9020\n",
      "Epoch 3/10\n",
      "1000/1000 [==============================] - 71s 71ms/step - loss: 0.2277 - acc: 0.9210\n",
      "Epoch 4/10\n",
      "1000/1000 [==============================] - 70s 70ms/step - loss: 0.1935 - acc: 0.9300\n",
      "Epoch 5/10\n",
      "1000/1000 [==============================] - 69s 69ms/step - loss: 0.1604 - acc: 0.9490\n",
      "Epoch 6/10\n",
      "1000/1000 [==============================] - 73s 73ms/step - loss: 0.1410 - acc: 0.9530\n",
      "Epoch 7/10\n",
      "1000/1000 [==============================] - 74s 74ms/step - loss: 0.1206 - acc: 0.9580\n",
      "Epoch 8/10\n",
      "1000/1000 [==============================] - 74s 74ms/step - loss: 0.1065 - acc: 0.9690\n",
      "Epoch 9/10\n",
      "1000/1000 [==============================] - 70s 70ms/step - loss: 0.0937 - acc: 0.9750\n",
      "Epoch 10/10\n",
      "1000/1000 [==============================] - 72s 72ms/step - loss: 0.0847 - acc: 0.9770\n",
      "Training on Epoch  1 batch  5  Files [5] start  110 / 459\n",
      "Epoch 1/10\n",
      "1000/1000 [==============================] - 77s 77ms/step - loss: 0.3776 - acc: 0.8650\n",
      "Epoch 2/10\n",
      "1000/1000 [==============================] - 75s 75ms/step - loss: 0.2791 - acc: 0.8830\n",
      "Epoch 3/10\n",
      "1000/1000 [==============================] - 62s 62ms/step - loss: 0.2227 - acc: 0.9000\n",
      "Epoch 4/10\n",
      "1000/1000 [==============================] - 62s 62ms/step - loss: 0.1870 - acc: 0.9210\n",
      "Epoch 5/10\n",
      "1000/1000 [==============================] - 65s 65ms/step - loss: 0.1700 - acc: 0.9340\n",
      "Epoch 6/10\n",
      "1000/1000 [==============================] - 63s 63ms/step - loss: 0.1530 - acc: 0.9440\n",
      "Epoch 7/10\n",
      "1000/1000 [==============================] - 63s 63ms/step - loss: 0.1368 - acc: 0.9510\n",
      "Epoch 8/10\n",
      "1000/1000 [==============================] - 63s 63ms/step - loss: 0.1339 - acc: 0.9460\n",
      "Epoch 9/10\n",
      "1000/1000 [==============================] - 63s 63ms/step - loss: 0.1234 - acc: 0.9530\n",
      "Epoch 10/10\n",
      "1000/1000 [==============================] - 62s 62ms/step - loss: 0.1170 - acc: 0.9530\n",
      "Training on Epoch  1 batch  5  Files [5] start  115 / 459\n",
      "Epoch 1/10\n",
      "1000/1000 [==============================] - 65s 65ms/step - loss: 0.3373 - acc: 0.8580\n",
      "Epoch 2/10\n",
      "1000/1000 [==============================] - 65s 65ms/step - loss: 0.2777 - acc: 0.8850\n",
      "Epoch 3/10\n",
      "1000/1000 [==============================] - 64s 64ms/step - loss: 0.2357 - acc: 0.9010\n",
      "Epoch 4/10\n",
      "1000/1000 [==============================] - 65s 65ms/step - loss: 0.2076 - acc: 0.9140\n",
      "Epoch 5/10\n",
      "1000/1000 [==============================] - 65s 65ms/step - loss: 0.1925 - acc: 0.9200\n",
      "Epoch 6/10\n",
      "1000/1000 [==============================] - 65s 65ms/step - loss: 0.1780 - acc: 0.9280\n",
      "Epoch 7/10\n",
      "1000/1000 [==============================] - 65s 65ms/step - loss: 0.1666 - acc: 0.9270\n",
      "Epoch 8/10\n",
      "1000/1000 [==============================] - 66s 66ms/step - loss: 0.1552 - acc: 0.9390\n",
      "Epoch 9/10\n",
      "1000/1000 [==============================] - 64s 64ms/step - loss: 0.1515 - acc: 0.9370\n",
      "Epoch 10/10\n",
      "1000/1000 [==============================] - 63s 63ms/step - loss: 0.1444 - acc: 0.9400\n",
      "Training on Epoch  1 batch  5  Files [5] start  120 / 459\n",
      "Epoch 1/10\n",
      "1000/1000 [==============================] - 67s 67ms/step - loss: 0.2744 - acc: 0.8670\n",
      "Epoch 2/10\n",
      "1000/1000 [==============================] - 66s 66ms/step - loss: 0.2455 - acc: 0.8770\n",
      "Epoch 3/10\n",
      "1000/1000 [==============================] - 67s 67ms/step - loss: 0.2242 - acc: 0.8950\n",
      "Epoch 4/10\n",
      "1000/1000 [==============================] - 67s 67ms/step - loss: 0.2103 - acc: 0.9020\n",
      "Epoch 5/10\n",
      "1000/1000 [==============================] - 65s 65ms/step - loss: 0.1998 - acc: 0.9070\n",
      "Epoch 6/10\n",
      "1000/1000 [==============================] - 66s 66ms/step - loss: 0.1923 - acc: 0.9150\n",
      "Epoch 7/10\n",
      "1000/1000 [==============================] - 67s 67ms/step - loss: 0.1869 - acc: 0.9160\n",
      "Epoch 8/10\n",
      "1000/1000 [==============================] - 69s 69ms/step - loss: 0.1803 - acc: 0.9210\n",
      "Epoch 9/10\n",
      "1000/1000 [==============================] - 71s 71ms/step - loss: 0.1774 - acc: 0.9210\n",
      "Epoch 10/10\n",
      "1000/1000 [==============================] - 70s 70ms/step - loss: 0.1741 - acc: 0.9140\n",
      "Training on Epoch  1 batch  5  Files [5] start  125 / 459\n",
      "Epoch 1/10\n",
      "1000/1000 [==============================] - 65s 65ms/step - loss: 0.3671 - acc: 0.8510\n",
      "Epoch 2/10\n",
      "1000/1000 [==============================] - 66s 66ms/step - loss: 0.2901 - acc: 0.8670\n",
      "Epoch 3/10\n",
      "1000/1000 [==============================] - 66s 66ms/step - loss: 0.2539 - acc: 0.8810\n",
      "Epoch 4/10\n",
      "1000/1000 [==============================] - 67s 67ms/step - loss: 0.2265 - acc: 0.8900\n",
      "Epoch 5/10\n",
      "1000/1000 [==============================] - 61s 61ms/step - loss: 0.2194 - acc: 0.8950\n",
      "Epoch 6/10\n",
      "1000/1000 [==============================] - 62s 62ms/step - loss: 0.2055 - acc: 0.9050\n",
      "Epoch 7/10\n",
      "1000/1000 [==============================] - 60s 60ms/step - loss: 0.1953 - acc: 0.9140\n",
      "Epoch 8/10\n",
      "1000/1000 [==============================] - 61s 61ms/step - loss: 0.1872 - acc: 0.9160\n",
      "Epoch 9/10\n",
      "1000/1000 [==============================] - 60s 60ms/step - loss: 0.1818 - acc: 0.9190\n",
      "Epoch 10/10\n",
      "1000/1000 [==============================] - 62s 62ms/step - loss: 0.1772 - acc: 0.9240\n",
      "Training on Epoch  1 batch  5  Files [5] start  130 / 459\n",
      "Epoch 1/10\n",
      "1000/1000 [==============================] - 61s 61ms/step - loss: 0.4066 - acc: 0.8500\n",
      "Epoch 2/10\n",
      "1000/1000 [==============================] - 61s 61ms/step - loss: 0.3358 - acc: 0.8660\n",
      "Epoch 3/10\n",
      "1000/1000 [==============================] - 61s 61ms/step - loss: 0.2967 - acc: 0.8690\n",
      "Epoch 4/10\n",
      "1000/1000 [==============================] - 62s 62ms/step - loss: 0.2712 - acc: 0.8800\n",
      "Epoch 5/10\n",
      "1000/1000 [==============================] - 62s 62ms/step - loss: 0.2556 - acc: 0.8900\n",
      "Epoch 6/10\n",
      "1000/1000 [==============================] - 62s 62ms/step - loss: 0.2455 - acc: 0.8940\n",
      "Epoch 7/10\n",
      "1000/1000 [==============================] - 61s 61ms/step - loss: 0.2305 - acc: 0.9050\n",
      "Epoch 8/10\n",
      "1000/1000 [==============================] - 62s 62ms/step - loss: 0.2206 - acc: 0.9040\n",
      "Epoch 9/10\n",
      "1000/1000 [==============================] - 62s 62ms/step - loss: 0.2138 - acc: 0.9070\n",
      "Epoch 10/10\n",
      "1000/1000 [==============================] - 62s 62ms/step - loss: 0.2168 - acc: 0.9060\n",
      "Training on Epoch  1 batch  5  Files [5] start  135 / 459\n",
      "Epoch 1/10\n",
      "1000/1000 [==============================] - 55s 55ms/step - loss: 0.3556 - acc: 0.8490\n",
      "Epoch 2/10\n",
      "1000/1000 [==============================] - 56s 56ms/step - loss: 0.3096 - acc: 0.8540\n",
      "Epoch 3/10\n",
      "1000/1000 [==============================] - 55s 55ms/step - loss: 0.2825 - acc: 0.8730\n",
      "Epoch 4/10\n",
      "1000/1000 [==============================] - 55s 55ms/step - loss: 0.2674 - acc: 0.8760\n",
      "Epoch 5/10\n",
      "1000/1000 [==============================] - 56s 56ms/step - loss: 0.2501 - acc: 0.8870\n",
      "Epoch 6/10\n",
      "1000/1000 [==============================] - 56s 56ms/step - loss: 0.2385 - acc: 0.8920\n",
      "Epoch 7/10\n",
      "1000/1000 [==============================] - 55s 55ms/step - loss: 0.2283 - acc: 0.8980\n",
      "Epoch 8/10\n",
      "1000/1000 [==============================] - 56s 56ms/step - loss: 0.2187 - acc: 0.9010\n",
      "Epoch 9/10\n",
      "1000/1000 [==============================] - 57s 57ms/step - loss: 0.2111 - acc: 0.9060\n",
      "Epoch 10/10\n",
      "1000/1000 [==============================] - 56s 56ms/step - loss: 0.2050 - acc: 0.9100\n",
      "Training on Epoch  1 batch  5  Files [5] start  140 / 459\n",
      "Epoch 1/10\n",
      "1000/1000 [==============================] - 56s 56ms/step - loss: 0.3616 - acc: 0.8570\n",
      "Epoch 2/10\n",
      "1000/1000 [==============================] - 56s 56ms/step - loss: 0.2936 - acc: 0.8750\n",
      "Epoch 3/10\n",
      "1000/1000 [==============================] - 57s 57ms/step - loss: 0.2473 - acc: 0.8890\n",
      "Epoch 4/10\n",
      "1000/1000 [==============================] - 56s 56ms/step - loss: 0.2216 - acc: 0.9070\n",
      "Epoch 5/10\n",
      "1000/1000 [==============================] - 57s 57ms/step - loss: 0.2000 - acc: 0.9110\n",
      "Epoch 6/10\n",
      "1000/1000 [==============================] - 56s 56ms/step - loss: 0.1806 - acc: 0.9200\n",
      "Epoch 7/10\n",
      "1000/1000 [==============================] - 57s 57ms/step - loss: 0.1660 - acc: 0.9160\n",
      "Epoch 8/10\n",
      "1000/1000 [==============================] - 55s 55ms/step - loss: 0.1575 - acc: 0.9250\n",
      "Epoch 9/10\n",
      "1000/1000 [==============================] - 56s 56ms/step - loss: 0.1505 - acc: 0.9290\n",
      "Epoch 10/10\n",
      "1000/1000 [==============================] - 56s 56ms/step - loss: 0.1444 - acc: 0.9310\n",
      "Training on Epoch  1 batch  5  Files [5] start  145 / 459\n",
      "Epoch 1/10\n",
      "1000/1000 [==============================] - 52s 52ms/step - loss: 0.3032 - acc: 0.8840\n",
      "Epoch 2/10\n",
      "1000/1000 [==============================] - 52s 52ms/step - loss: 0.2438 - acc: 0.9060\n",
      "Epoch 3/10\n",
      "1000/1000 [==============================] - 52s 52ms/step - loss: 0.2076 - acc: 0.9140\n",
      "Epoch 4/10\n",
      "1000/1000 [==============================] - 52s 52ms/step - loss: 0.1743 - acc: 0.9310\n",
      "Epoch 5/10\n",
      "1000/1000 [==============================] - 52s 52ms/step - loss: 0.1510 - acc: 0.9450\n",
      "Epoch 6/10\n",
      "1000/1000 [==============================] - 52s 52ms/step - loss: 0.1325 - acc: 0.9480\n",
      "Epoch 7/10\n",
      "1000/1000 [==============================] - 52s 52ms/step - loss: 0.1184 - acc: 0.9600\n",
      "Epoch 8/10\n",
      "1000/1000 [==============================] - 52s 52ms/step - loss: 0.1066 - acc: 0.9590\n",
      "Epoch 9/10\n",
      "1000/1000 [==============================] - 52s 52ms/step - loss: 0.1007 - acc: 0.9600\n",
      "Epoch 10/10\n",
      "1000/1000 [==============================] - 52s 52ms/step - loss: 0.0891 - acc: 0.9730\n",
      "Training on Epoch  1 batch  5  Files [5] start  150 / 459\n",
      "Epoch 1/10\n",
      "1000/1000 [==============================] - 62s 62ms/step - loss: 0.3410 - acc: 0.8750\n",
      "Epoch 2/10\n",
      "1000/1000 [==============================] - 62s 62ms/step - loss: 0.2710 - acc: 0.8900\n",
      "Epoch 3/10\n",
      "1000/1000 [==============================] - 62s 62ms/step - loss: 0.2135 - acc: 0.9160\n",
      "Epoch 4/10\n",
      "1000/1000 [==============================] - 63s 63ms/step - loss: 0.1852 - acc: 0.9250\n",
      "Epoch 5/10\n",
      "1000/1000 [==============================] - 63s 63ms/step - loss: 0.1638 - acc: 0.9400\n",
      "Epoch 6/10\n",
      "1000/1000 [==============================] - 63s 63ms/step - loss: 0.1492 - acc: 0.9490\n",
      "Epoch 7/10\n",
      "1000/1000 [==============================] - 63s 63ms/step - loss: 0.1389 - acc: 0.9480\n",
      "Epoch 8/10\n",
      "1000/1000 [==============================] - 63s 63ms/step - loss: 0.1248 - acc: 0.9550\n",
      "Epoch 9/10\n",
      "1000/1000 [==============================] - 63s 63ms/step - loss: 0.1125 - acc: 0.9600\n",
      "Epoch 10/10\n",
      "1000/1000 [==============================] - 64s 64ms/step - loss: 0.1043 - acc: 0.9640\n",
      "Training on Epoch  1 batch  5  Files [5] start  155 / 459\n",
      "Epoch 1/10\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 0.2621 - acc: 0.8990\n",
      "Epoch 2/10\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 0.1982 - acc: 0.9220\n",
      "Epoch 3/10\n",
      "1000/1000 [==============================] - 60s 60ms/step - loss: 0.1582 - acc: 0.9330\n",
      "Epoch 4/10\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 0.1398 - acc: 0.9470\n",
      "Epoch 5/10\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 0.1244 - acc: 0.9470\n",
      "Epoch 6/10\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 0.1141 - acc: 0.9530\n",
      "Epoch 7/10\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 0.1045 - acc: 0.9550\n",
      "Epoch 8/10\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 0.0980 - acc: 0.9530\n",
      "Epoch 9/10\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 0.0914 - acc: 0.9610\n",
      "Epoch 10/10\n",
      "1000/1000 [==============================] - 60s 60ms/step - loss: 0.0866 - acc: 0.9620\n",
      "Training on Epoch  1 batch  5  Files [5] start  160 / 459\n",
      "Epoch 1/10\n",
      "1000/1000 [==============================] - 57s 57ms/step - loss: 0.2395 - acc: 0.9060\n",
      "Epoch 2/10\n",
      "1000/1000 [==============================] - 57s 57ms/step - loss: 0.1734 - acc: 0.9310\n",
      "Epoch 3/10\n",
      "1000/1000 [==============================] - 56s 56ms/step - loss: 0.1520 - acc: 0.9330\n",
      "Epoch 4/10\n",
      "1000/1000 [==============================] - 57s 57ms/step - loss: 0.1323 - acc: 0.9410\n",
      "Epoch 5/10\n",
      "1000/1000 [==============================] - 58s 58ms/step - loss: 0.1161 - acc: 0.9490\n",
      "Epoch 6/10\n",
      "1000/1000 [==============================] - 57s 57ms/step - loss: 0.1053 - acc: 0.9520\n",
      "Epoch 7/10\n",
      "1000/1000 [==============================] - 57s 57ms/step - loss: 0.1010 - acc: 0.9630\n",
      "Epoch 8/10\n",
      "1000/1000 [==============================] - 56s 56ms/step - loss: 0.0907 - acc: 0.9580\n",
      "Epoch 9/10\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000/1000 [==============================] - 57s 57ms/step - loss: 0.0843 - acc: 0.9610\n",
      "Epoch 10/10\n",
      "1000/1000 [==============================] - 57s 57ms/step - loss: 0.0794 - acc: 0.9660\n",
      "Training on Epoch  1 batch  5  Files [5] start  165 / 459\n",
      "Epoch 1/10\n",
      "1000/1000 [==============================] - 57s 57ms/step - loss: 0.1916 - acc: 0.9000\n",
      "Epoch 2/10\n",
      "1000/1000 [==============================] - 57s 57ms/step - loss: 0.1586 - acc: 0.9240\n",
      "Epoch 3/10\n",
      "1000/1000 [==============================] - 57s 57ms/step - loss: 0.1468 - acc: 0.9240\n",
      "Epoch 4/10\n",
      "1000/1000 [==============================] - 58s 58ms/step - loss: 0.1323 - acc: 0.9330\n",
      "Epoch 5/10\n",
      "1000/1000 [==============================] - 58s 58ms/step - loss: 0.1203 - acc: 0.9420\n",
      "Epoch 6/10\n",
      "1000/1000 [==============================] - 57s 57ms/step - loss: 0.1092 - acc: 0.9530\n",
      "Epoch 7/10\n",
      "1000/1000 [==============================] - 58s 58ms/step - loss: 0.1043 - acc: 0.9530\n",
      "Epoch 8/10\n",
      "1000/1000 [==============================] - 58s 58ms/step - loss: 0.0969 - acc: 0.9600\n",
      "Epoch 9/10\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 0.0927 - acc: 0.9550\n",
      "Epoch 10/10\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 0.0885 - acc: 0.9580\n",
      "Training on Epoch  1 batch  5  Files [5] start  170 / 459\n",
      "Epoch 1/10\n",
      "1000/1000 [==============================] - 60s 60ms/step - loss: 0.2348 - acc: 0.9210\n",
      "Epoch 2/10\n",
      "1000/1000 [==============================] - 60s 60ms/step - loss: 0.1691 - acc: 0.9220\n",
      "Epoch 3/10\n",
      "1000/1000 [==============================] - 60s 60ms/step - loss: 0.1408 - acc: 0.9380\n",
      "Epoch 4/10\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 0.1219 - acc: 0.9480\n",
      "Epoch 5/10\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 0.1158 - acc: 0.9530\n",
      "Epoch 6/10\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 0.1064 - acc: 0.9530\n",
      "Epoch 7/10\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 0.0978 - acc: 0.9600\n",
      "Epoch 8/10\n",
      "1000/1000 [==============================] - 58s 58ms/step - loss: 0.0907 - acc: 0.9620\n",
      "Epoch 9/10\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 0.0830 - acc: 0.9680\n",
      "Epoch 10/10\n",
      "1000/1000 [==============================] - 60s 60ms/step - loss: 0.0801 - acc: 0.9710\n",
      "Training on Epoch  1 batch  5  Files [5] start  175 / 459\n",
      "Epoch 1/10\n",
      "1000/1000 [==============================] - 58s 58ms/step - loss: 0.2402 - acc: 0.9040\n",
      "Epoch 2/10\n",
      "1000/1000 [==============================] - 58s 58ms/step - loss: 0.1874 - acc: 0.9220\n",
      "Epoch 3/10\n",
      "1000/1000 [==============================] - 58s 58ms/step - loss: 0.1535 - acc: 0.9330\n",
      "Epoch 4/10\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 0.1358 - acc: 0.9370\n",
      "Epoch 5/10\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 0.1202 - acc: 0.9450\n",
      "Epoch 6/10\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 0.1083 - acc: 0.9520\n",
      "Epoch 7/10\n",
      "1000/1000 [==============================] - 58s 58ms/step - loss: 0.1010 - acc: 0.9590\n",
      "Epoch 8/10\n",
      "1000/1000 [==============================] - 58s 58ms/step - loss: 0.0937 - acc: 0.9640\n",
      "Epoch 9/10\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 0.0884 - acc: 0.9630\n",
      "Epoch 10/10\n",
      "1000/1000 [==============================] - 58s 58ms/step - loss: 0.0829 - acc: 0.9680\n",
      "Training on Epoch  1 batch  5  Files [5] start  180 / 459\n",
      "Epoch 1/10\n",
      "1000/1000 [==============================] - 60s 60ms/step - loss: 0.1404 - acc: 0.9280\n",
      "Epoch 2/10\n",
      "1000/1000 [==============================] - 60s 60ms/step - loss: 0.1169 - acc: 0.9430\n",
      "Epoch 3/10\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 0.1048 - acc: 0.9500\n",
      "Epoch 4/10\n",
      "1000/1000 [==============================] - 60s 60ms/step - loss: 0.0958 - acc: 0.9520\n",
      "Epoch 5/10\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 0.0900 - acc: 0.9590\n",
      "Epoch 6/10\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 0.0866 - acc: 0.9580\n",
      "Epoch 7/10\n",
      "1000/1000 [==============================] - 60s 60ms/step - loss: 0.0815 - acc: 0.9630\n",
      "Epoch 8/10\n",
      "1000/1000 [==============================] - 60s 60ms/step - loss: 0.0770 - acc: 0.9650\n",
      "Epoch 9/10\n",
      "1000/1000 [==============================] - 60s 60ms/step - loss: 0.0739 - acc: 0.9660\n",
      "Epoch 10/10\n",
      "1000/1000 [==============================] - 60s 60ms/step - loss: 0.0694 - acc: 0.9680\n",
      "Training on Epoch  1 batch  5  Files [5] start  185 / 459\n",
      "Epoch 1/10\n",
      "1000/1000 [==============================] - 63s 63ms/step - loss: 0.1604 - acc: 0.9160\n",
      "Epoch 2/10\n",
      "1000/1000 [==============================] - 62s 62ms/step - loss: 0.1488 - acc: 0.9220\n",
      "Epoch 3/10\n",
      "1000/1000 [==============================] - 62s 62ms/step - loss: 0.1357 - acc: 0.9330\n",
      "Epoch 4/10\n",
      "1000/1000 [==============================] - 61s 61ms/step - loss: 0.1270 - acc: 0.9310\n",
      "Epoch 5/10\n",
      "1000/1000 [==============================] - 63s 63ms/step - loss: 0.1200 - acc: 0.9410\n",
      "Epoch 6/10\n",
      "1000/1000 [==============================] - 62s 62ms/step - loss: 0.1147 - acc: 0.9440\n",
      "Epoch 7/10\n",
      "1000/1000 [==============================] - 62s 62ms/step - loss: 0.1122 - acc: 0.9440\n",
      "Epoch 8/10\n",
      "1000/1000 [==============================] - 62s 62ms/step - loss: 0.1119 - acc: 0.9420\n",
      "Epoch 9/10\n",
      "1000/1000 [==============================] - 62s 62ms/step - loss: 0.1057 - acc: 0.9410\n",
      "Epoch 10/10\n",
      "1000/1000 [==============================] - 63s 63ms/step - loss: 0.1026 - acc: 0.9450\n",
      "Training on Epoch  1 batch  5  Files [5] start  190 / 459\n",
      "Epoch 1/10\n",
      "1000/1000 [==============================] - 61s 61ms/step - loss: 0.2457 - acc: 0.9020\n",
      "Epoch 2/10\n",
      "1000/1000 [==============================] - 60s 60ms/step - loss: 0.1847 - acc: 0.9250\n",
      "Epoch 3/10\n",
      "1000/1000 [==============================] - 61s 61ms/step - loss: 0.1530 - acc: 0.9270\n",
      "Epoch 4/10\n",
      "1000/1000 [==============================] - 60s 60ms/step - loss: 0.1433 - acc: 0.9330\n",
      "Epoch 5/10\n",
      "1000/1000 [==============================] - 61s 61ms/step - loss: 0.1305 - acc: 0.9250\n",
      "Epoch 6/10\n",
      "1000/1000 [==============================] - 61s 61ms/step - loss: 0.1256 - acc: 0.9310\n",
      "Epoch 7/10\n",
      "1000/1000 [==============================] - 60s 60ms/step - loss: 0.1199 - acc: 0.9370\n",
      "Epoch 8/10\n",
      "1000/1000 [==============================] - 60s 60ms/step - loss: 0.1138 - acc: 0.9360\n",
      "Epoch 9/10\n",
      "1000/1000 [==============================] - 60s 60ms/step - loss: 0.1081 - acc: 0.9430\n",
      "Epoch 10/10\n",
      "1000/1000 [==============================] - 60s 60ms/step - loss: 0.1035 - acc: 0.9460\n",
      "Training on Epoch  1 batch  5  Files [5] start  195 / 459\n",
      "Epoch 1/10\n",
      "1000/1000 [==============================] - 62s 62ms/step - loss: 0.2299 - acc: 0.8920\n",
      "Epoch 2/10\n",
      "1000/1000 [==============================] - 61s 61ms/step - loss: 0.2079 - acc: 0.9000\n",
      "Epoch 3/10\n",
      "1000/1000 [==============================] - 62s 62ms/step - loss: 0.1837 - acc: 0.9010\n",
      "Epoch 4/10\n",
      "1000/1000 [==============================] - 62s 62ms/step - loss: 0.1649 - acc: 0.9150\n",
      "Epoch 5/10\n",
      "1000/1000 [==============================] - 61s 61ms/step - loss: 0.1606 - acc: 0.9180\n",
      "Epoch 6/10\n",
      "1000/1000 [==============================] - 63s 63ms/step - loss: 0.1542 - acc: 0.9250\n",
      "Epoch 7/10\n",
      "1000/1000 [==============================] - 62s 62ms/step - loss: 0.1464 - acc: 0.9260\n",
      "Epoch 8/10\n",
      "1000/1000 [==============================] - 62s 62ms/step - loss: 0.1413 - acc: 0.9260\n",
      "Epoch 9/10\n",
      "1000/1000 [==============================] - 61s 61ms/step - loss: 0.1421 - acc: 0.9310\n",
      "Epoch 10/10\n",
      "1000/1000 [==============================] - 62s 62ms/step - loss: 0.1367 - acc: 0.9290\n",
      "Training on Epoch  1 batch  5  Files [5] start  200 / 459\n",
      "Epoch 1/10\n",
      "1000/1000 [==============================] - 58s 58ms/step - loss: 0.2321 - acc: 0.8860\n",
      "Epoch 2/10\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 0.1884 - acc: 0.9080\n",
      "Epoch 3/10\n",
      "1000/1000 [==============================] - 58s 58ms/step - loss: 0.1545 - acc: 0.9240\n",
      "Epoch 4/10\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 0.1359 - acc: 0.9310\n",
      "Epoch 5/10\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 0.1261 - acc: 0.9380\n",
      "Epoch 6/10\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 0.1172 - acc: 0.9420\n",
      "Epoch 7/10\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000/1000 [==============================] - 59s 59ms/step - loss: 0.1100 - acc: 0.9440\n",
      "Epoch 8/10\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 0.1067 - acc: 0.9500\n",
      "Epoch 9/10\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 0.1028 - acc: 0.9480\n",
      "Epoch 10/10\n",
      "1000/1000 [==============================] - 58s 58ms/step - loss: 0.0990 - acc: 0.9490\n",
      "Training on Epoch  1 batch  5  Files [5] start  205 / 459\n",
      "Epoch 1/10\n",
      "1000/1000 [==============================] - 58s 58ms/step - loss: 0.1780 - acc: 0.9110\n",
      "Epoch 2/10\n",
      "1000/1000 [==============================] - 58s 58ms/step - loss: 0.1498 - acc: 0.9140\n",
      "Epoch 3/10\n",
      "1000/1000 [==============================] - 58s 58ms/step - loss: 0.1358 - acc: 0.9250\n",
      "Epoch 4/10\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 0.1286 - acc: 0.9360\n",
      "Epoch 5/10\n",
      "1000/1000 [==============================] - 58s 58ms/step - loss: 0.1239 - acc: 0.9350\n",
      "Epoch 6/10\n",
      "1000/1000 [==============================] - 58s 58ms/step - loss: 0.1208 - acc: 0.9370\n",
      "Epoch 7/10\n",
      "1000/1000 [==============================] - 58s 58ms/step - loss: 0.1186 - acc: 0.9390\n",
      "Epoch 8/10\n",
      "1000/1000 [==============================] - 58s 58ms/step - loss: 0.1141 - acc: 0.9390\n",
      "Epoch 9/10\n",
      "1000/1000 [==============================] - 58s 58ms/step - loss: 0.1112 - acc: 0.9410\n",
      "Epoch 10/10\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 0.1101 - acc: 0.9440\n",
      "Training on Epoch  1 batch  5  Files [5] start  210 / 459\n",
      "Epoch 1/10\n",
      "1000/1000 [==============================] - 60s 60ms/step - loss: 0.2445 - acc: 0.9100\n",
      "Epoch 2/10\n",
      "1000/1000 [==============================] - 60s 60ms/step - loss: 0.1737 - acc: 0.9240\n",
      "Epoch 3/10\n",
      "1000/1000 [==============================] - 61s 61ms/step - loss: 0.1261 - acc: 0.9480\n",
      "Epoch 4/10\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 0.1130 - acc: 0.9530\n",
      "Epoch 5/10\n",
      "1000/1000 [==============================] - 61s 61ms/step - loss: 0.0949 - acc: 0.9600\n",
      "Epoch 6/10\n",
      "1000/1000 [==============================] - 60s 60ms/step - loss: 0.0801 - acc: 0.9650\n",
      "Epoch 7/10\n",
      "1000/1000 [==============================] - 61s 61ms/step - loss: 0.0746 - acc: 0.9680\n",
      "Epoch 8/10\n",
      "1000/1000 [==============================] - 60s 60ms/step - loss: 0.0719 - acc: 0.9690\n",
      "Epoch 9/10\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 0.0684 - acc: 0.9730\n",
      "Epoch 10/10\n",
      "1000/1000 [==============================] - 60s 60ms/step - loss: 0.0662 - acc: 0.9730\n",
      "Training on Epoch  1 batch  5  Files [5] start  215 / 459\n",
      "Epoch 1/10\n",
      "1000/1000 [==============================] - 68s 68ms/step - loss: 0.2588 - acc: 0.8850\n",
      "Epoch 2/10\n",
      "1000/1000 [==============================] - 64s 64ms/step - loss: 0.2030 - acc: 0.9120\n",
      "Epoch 3/10\n",
      "1000/1000 [==============================] - 64s 64ms/step - loss: 0.1830 - acc: 0.9170\n",
      "Epoch 4/10\n",
      "1000/1000 [==============================] - 65s 65ms/step - loss: 0.1749 - acc: 0.9170\n",
      "Epoch 5/10\n",
      "1000/1000 [==============================] - 64s 64ms/step - loss: 0.1658 - acc: 0.9200\n",
      "Epoch 6/10\n",
      "1000/1000 [==============================] - 64s 64ms/step - loss: 0.1589 - acc: 0.9200\n",
      "Epoch 7/10\n",
      "1000/1000 [==============================] - 63s 63ms/step - loss: 0.1549 - acc: 0.9220\n",
      "Epoch 8/10\n",
      "1000/1000 [==============================] - 64s 64ms/step - loss: 0.1493 - acc: 0.9290\n",
      "Epoch 9/10\n",
      "1000/1000 [==============================] - 64s 64ms/step - loss: 0.1448 - acc: 0.9270\n",
      "Epoch 10/10\n",
      "1000/1000 [==============================] - 64s 64ms/step - loss: 0.1415 - acc: 0.9300\n",
      "Training on Epoch  1 batch  5  Files [5] start  220 / 459\n",
      "Epoch 1/10\n",
      "1000/1000 [==============================] - 63s 63ms/step - loss: 0.2946 - acc: 0.8990\n",
      "Epoch 2/10\n",
      "1000/1000 [==============================] - 63s 63ms/step - loss: 0.2204 - acc: 0.9070\n",
      "Epoch 3/10\n",
      "1000/1000 [==============================] - 63s 63ms/step - loss: 0.1783 - acc: 0.9150\n",
      "Epoch 4/10\n",
      "1000/1000 [==============================] - 63s 63ms/step - loss: 0.1644 - acc: 0.9230\n",
      "Epoch 5/10\n",
      "1000/1000 [==============================] - 63s 63ms/step - loss: 0.1512 - acc: 0.9380\n",
      "Epoch 6/10\n",
      "1000/1000 [==============================] - 63s 63ms/step - loss: 0.1374 - acc: 0.9440\n",
      "Epoch 7/10\n",
      "1000/1000 [==============================] - 63s 63ms/step - loss: 0.1288 - acc: 0.9460\n",
      "Epoch 8/10\n",
      "1000/1000 [==============================] - 63s 63ms/step - loss: 0.1227 - acc: 0.9440\n",
      "Epoch 9/10\n",
      "1000/1000 [==============================] - 62s 62ms/step - loss: 0.1151 - acc: 0.9500\n",
      "Epoch 10/10\n",
      "1000/1000 [==============================] - 62s 62ms/step - loss: 0.1085 - acc: 0.9540\n",
      "Training on Epoch  1 batch  5  Files [5] start  225 / 459\n",
      "Epoch 1/10\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 0.1766 - acc: 0.9220\n",
      "Epoch 2/10\n",
      "1000/1000 [==============================] - 61s 61ms/step - loss: 0.1458 - acc: 0.9330\n",
      "Epoch 3/10\n",
      "1000/1000 [==============================] - 60s 60ms/step - loss: 0.1293 - acc: 0.9480\n",
      "Epoch 4/10\n",
      "1000/1000 [==============================] - 60s 60ms/step - loss: 0.1195 - acc: 0.9530\n",
      "Epoch 5/10\n",
      "1000/1000 [==============================] - 60s 60ms/step - loss: 0.1088 - acc: 0.9590\n",
      "Epoch 6/10\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 0.1001 - acc: 0.9610\n",
      "Epoch 7/10\n",
      "1000/1000 [==============================] - 60s 60ms/step - loss: 0.0930 - acc: 0.9620\n",
      "Epoch 8/10\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 0.0865 - acc: 0.9670\n",
      "Epoch 9/10\n",
      "1000/1000 [==============================] - 61s 61ms/step - loss: 0.0805 - acc: 0.9680\n",
      "Epoch 10/10\n",
      "1000/1000 [==============================] - 60s 60ms/step - loss: 0.0768 - acc: 0.9700\n",
      "Training on Epoch  1 batch  5  Files [5] start  230 / 459\n",
      "Epoch 1/10\n",
      "1000/1000 [==============================] - 60s 60ms/step - loss: 0.1469 - acc: 0.9250\n",
      "Epoch 2/10\n",
      "1000/1000 [==============================] - 61s 61ms/step - loss: 0.1250 - acc: 0.9410\n",
      "Epoch 3/10\n",
      "1000/1000 [==============================] - 61s 61ms/step - loss: 0.1150 - acc: 0.9390\n",
      "Epoch 4/10\n",
      "1000/1000 [==============================] - 61s 61ms/step - loss: 0.1071 - acc: 0.9420\n",
      "Epoch 5/10\n",
      "1000/1000 [==============================] - 61s 61ms/step - loss: 0.1013 - acc: 0.9500\n",
      "Epoch 6/10\n",
      "1000/1000 [==============================] - 62s 62ms/step - loss: 0.0965 - acc: 0.9530\n",
      "Epoch 7/10\n",
      "1000/1000 [==============================] - 62s 62ms/step - loss: 0.0940 - acc: 0.9550\n",
      "Epoch 8/10\n",
      "1000/1000 [==============================] - 62s 62ms/step - loss: 0.0899 - acc: 0.9540\n",
      "Epoch 9/10\n",
      "1000/1000 [==============================] - 61s 61ms/step - loss: 0.0871 - acc: 0.9540\n",
      "Epoch 10/10\n",
      "1000/1000 [==============================] - 62s 62ms/step - loss: 0.0871 - acc: 0.9540\n",
      "Training on Epoch  1 batch  5  Files [5] start  235 / 459\n",
      "Epoch 1/10\n",
      "1000/1000 [==============================] - 58s 58ms/step - loss: 0.1598 - acc: 0.9310\n",
      "Epoch 2/10\n",
      "1000/1000 [==============================] - 57s 57ms/step - loss: 0.1382 - acc: 0.9340\n",
      "Epoch 3/10\n",
      "1000/1000 [==============================] - 57s 57ms/step - loss: 0.1197 - acc: 0.9440\n",
      "Epoch 4/10\n",
      "1000/1000 [==============================] - 57s 57ms/step - loss: 0.1048 - acc: 0.9440\n",
      "Epoch 5/10\n",
      "1000/1000 [==============================] - 57s 57ms/step - loss: 0.0947 - acc: 0.9570\n",
      "Epoch 6/10\n",
      "1000/1000 [==============================] - 57s 57ms/step - loss: 0.0888 - acc: 0.9560\n",
      "Epoch 7/10\n",
      "1000/1000 [==============================] - 57s 57ms/step - loss: 0.0846 - acc: 0.9590\n",
      "Epoch 8/10\n",
      "1000/1000 [==============================] - 57s 57ms/step - loss: 0.0785 - acc: 0.9610\n",
      "Epoch 9/10\n",
      "1000/1000 [==============================] - 57s 57ms/step - loss: 0.0750 - acc: 0.9640\n",
      "Epoch 10/10\n",
      "1000/1000 [==============================] - 57s 57ms/step - loss: 0.0710 - acc: 0.9660\n",
      "Training on Epoch  1 batch  5  Files [5] start  240 / 459\n",
      "Epoch 1/10\n",
      "1000/1000 [==============================] - 56s 56ms/step - loss: 0.1185 - acc: 0.9410\n",
      "Epoch 2/10\n",
      "1000/1000 [==============================] - 56s 56ms/step - loss: 0.0953 - acc: 0.9580\n",
      "Epoch 3/10\n",
      "1000/1000 [==============================] - 56s 56ms/step - loss: 0.0798 - acc: 0.9610\n",
      "Epoch 4/10\n",
      "1000/1000 [==============================] - 56s 56ms/step - loss: 0.0737 - acc: 0.9670\n",
      "Epoch 5/10\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000/1000 [==============================] - 58s 58ms/step - loss: 0.0657 - acc: 0.9730\n",
      "Epoch 6/10\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 0.0607 - acc: 0.9740\n",
      "Epoch 7/10\n",
      "1000/1000 [==============================] - 58s 58ms/step - loss: 0.0577 - acc: 0.9740\n",
      "Epoch 8/10\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 0.0543 - acc: 0.9750\n",
      "Epoch 9/10\n",
      "1000/1000 [==============================] - 56s 56ms/step - loss: 0.0527 - acc: 0.9760\n",
      "Epoch 10/10\n",
      "1000/1000 [==============================] - 57s 57ms/step - loss: 0.0511 - acc: 0.9770\n",
      "Training on Epoch  1 batch  5  Files [5] start  245 / 459\n",
      "Epoch 1/10\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 0.1863 - acc: 0.9290\n",
      "Epoch 2/10\n",
      "1000/1000 [==============================] - 58s 58ms/step - loss: 0.1544 - acc: 0.9380\n",
      "Epoch 3/10\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 0.1221 - acc: 0.9370\n",
      "Epoch 4/10\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 0.1099 - acc: 0.9390\n",
      "Epoch 5/10\n",
      "1000/1000 [==============================] - 62s 62ms/step - loss: 0.1014 - acc: 0.9550\n",
      "Epoch 6/10\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 0.0971 - acc: 0.9530\n",
      "Epoch 7/10\n",
      "1000/1000 [==============================] - 62s 62ms/step - loss: 0.0919 - acc: 0.9530\n",
      "Epoch 8/10\n",
      "1000/1000 [==============================] - 61s 61ms/step - loss: 0.0884 - acc: 0.9550\n",
      "Epoch 9/10\n",
      "1000/1000 [==============================] - 60s 60ms/step - loss: 0.0858 - acc: 0.9580\n",
      "Epoch 10/10\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 0.0835 - acc: 0.9600\n",
      "Training on Epoch  1 batch  5  Files [5] start  250 / 459\n",
      "Epoch 1/10\n",
      "1000/1000 [==============================] - 62s 62ms/step - loss: 0.1758 - acc: 0.9110\n",
      "Epoch 2/10\n",
      "1000/1000 [==============================] - 63s 63ms/step - loss: 0.1507 - acc: 0.9250\n",
      "Epoch 3/10\n",
      "1000/1000 [==============================] - 63s 63ms/step - loss: 0.1323 - acc: 0.9360\n",
      "Epoch 4/10\n",
      "1000/1000 [==============================] - 65s 65ms/step - loss: 0.1215 - acc: 0.9440\n",
      "Epoch 5/10\n",
      "1000/1000 [==============================] - 63s 63ms/step - loss: 0.1153 - acc: 0.9430\n",
      "Epoch 6/10\n",
      "1000/1000 [==============================] - 64s 64ms/step - loss: 0.1101 - acc: 0.9410\n",
      "Epoch 7/10\n",
      "1000/1000 [==============================] - 63s 63ms/step - loss: 0.1061 - acc: 0.9430\n",
      "Epoch 8/10\n",
      "1000/1000 [==============================] - 62s 62ms/step - loss: 0.1037 - acc: 0.9470\n",
      "Epoch 9/10\n",
      "1000/1000 [==============================] - 67s 67ms/step - loss: 0.0999 - acc: 0.9520\n",
      "Epoch 10/10\n",
      "1000/1000 [==============================] - 98s 98ms/step - loss: 0.1010 - acc: 0.9450\n",
      "Training on Epoch  1 batch  5  Files [5] start  255 / 459\n",
      "Epoch 1/10\n",
      "1000/1000 [==============================] - 106s 106ms/step - loss: 0.1378 - acc: 0.9360\n",
      "Epoch 2/10\n",
      "1000/1000 [==============================] - 95s 95ms/step - loss: 0.1176 - acc: 0.9440\n",
      "Epoch 3/10\n",
      "1000/1000 [==============================] - 98s 98ms/step - loss: 0.1030 - acc: 0.9540\n",
      "Epoch 4/10\n",
      "1000/1000 [==============================] - 104s 104ms/step - loss: 0.0933 - acc: 0.9550\n",
      "Epoch 5/10\n",
      "1000/1000 [==============================] - 85s 85ms/step - loss: 0.0867 - acc: 0.9610\n",
      "Epoch 6/10\n",
      "1000/1000 [==============================] - 60s 60ms/step - loss: 0.0833 - acc: 0.9610\n",
      "Epoch 7/10\n",
      "1000/1000 [==============================] - 60s 60ms/step - loss: 0.0811 - acc: 0.9590\n",
      "Epoch 8/10\n",
      "1000/1000 [==============================] - 62s 62ms/step - loss: 0.0786 - acc: 0.9600\n",
      "Epoch 9/10\n",
      "1000/1000 [==============================] - 61s 61ms/step - loss: 0.0773 - acc: 0.9600\n",
      "Epoch 10/10\n",
      "1000/1000 [==============================] - 61s 61ms/step - loss: 0.0748 - acc: 0.9590\n",
      "Training on Epoch  1 batch  5  Files [5] start  260 / 459\n",
      "Epoch 1/10\n",
      "1000/1000 [==============================] - 66s 66ms/step - loss: 0.2206 - acc: 0.9100\n",
      "Epoch 2/10\n",
      "1000/1000 [==============================] - 65s 65ms/step - loss: 0.1779 - acc: 0.9200\n",
      "Epoch 3/10\n",
      "1000/1000 [==============================] - 65s 65ms/step - loss: 0.1510 - acc: 0.9340\n",
      "Epoch 4/10\n",
      "1000/1000 [==============================] - 64s 64ms/step - loss: 0.1390 - acc: 0.9350\n",
      "Epoch 5/10\n",
      "1000/1000 [==============================] - 65s 65ms/step - loss: 0.1304 - acc: 0.9430\n",
      "Epoch 6/10\n",
      "1000/1000 [==============================] - 65s 65ms/step - loss: 0.1204 - acc: 0.9490\n",
      "Epoch 7/10\n",
      "1000/1000 [==============================] - 64s 64ms/step - loss: 0.1139 - acc: 0.9530\n",
      "Epoch 8/10\n",
      "1000/1000 [==============================] - 66s 66ms/step - loss: 0.1081 - acc: 0.9510\n",
      "Epoch 9/10\n",
      "1000/1000 [==============================] - 65s 65ms/step - loss: 0.1018 - acc: 0.9580\n",
      "Epoch 10/10\n",
      "1000/1000 [==============================] - 65s 65ms/step - loss: 0.0981 - acc: 0.9560\n",
      "Training on Epoch  1 batch  5  Files [5] start  265 / 459\n",
      "Epoch 1/10\n",
      "1000/1000 [==============================] - 63s 63ms/step - loss: 0.2214 - acc: 0.9050\n",
      "Epoch 2/10\n",
      "1000/1000 [==============================] - 68s 68ms/step - loss: 0.1610 - acc: 0.9220\n",
      "Epoch 3/10\n",
      "1000/1000 [==============================] - 67s 67ms/step - loss: 0.1355 - acc: 0.9340\n",
      "Epoch 4/10\n",
      "1000/1000 [==============================] - 76s 76ms/step - loss: 0.1150 - acc: 0.9450\n",
      "Epoch 5/10\n",
      "1000/1000 [==============================] - 76s 76ms/step - loss: 0.1049 - acc: 0.9500\n",
      "Epoch 6/10\n",
      "1000/1000 [==============================] - 68s 68ms/step - loss: 0.0956 - acc: 0.9540\n",
      "Epoch 7/10\n",
      "1000/1000 [==============================] - 66s 66ms/step - loss: 0.0908 - acc: 0.9580\n",
      "Epoch 8/10\n",
      "1000/1000 [==============================] - 64s 64ms/step - loss: 0.0859 - acc: 0.9590\n",
      "Epoch 9/10\n",
      "1000/1000 [==============================] - 64s 64ms/step - loss: 0.0793 - acc: 0.9620\n",
      "Epoch 10/10\n",
      "1000/1000 [==============================] - 66s 66ms/step - loss: 0.0755 - acc: 0.9640\n",
      "Training on Epoch  1 batch  5  Files [5] start  270 / 459\n",
      "Epoch 1/10\n",
      "1000/1000 [==============================] - 73s 73ms/step - loss: 0.1987 - acc: 0.9050\n",
      "Epoch 2/10\n",
      "1000/1000 [==============================] - 72s 72ms/step - loss: 0.1557 - acc: 0.9240\n",
      "Epoch 3/10\n",
      "1000/1000 [==============================] - 72s 72ms/step - loss: 0.1362 - acc: 0.9370\n",
      "Epoch 4/10\n",
      "1000/1000 [==============================] - 72s 72ms/step - loss: 0.1268 - acc: 0.9370\n",
      "Epoch 5/10\n",
      "1000/1000 [==============================] - 72s 72ms/step - loss: 0.1124 - acc: 0.9530\n",
      "Epoch 6/10\n",
      "1000/1000 [==============================] - 72s 72ms/step - loss: 0.1073 - acc: 0.9520\n",
      "Epoch 7/10\n",
      "1000/1000 [==============================] - 72s 72ms/step - loss: 0.1036 - acc: 0.9440\n",
      "Epoch 8/10\n",
      "1000/1000 [==============================] - 74s 74ms/step - loss: 0.0960 - acc: 0.9620\n",
      "Epoch 9/10\n",
      "1000/1000 [==============================] - 70s 70ms/step - loss: 0.0904 - acc: 0.9610\n",
      "Epoch 10/10\n",
      "1000/1000 [==============================] - 70s 70ms/step - loss: 0.0860 - acc: 0.9660\n",
      "Training on Epoch  1 batch  5  Files [5] start  275 / 459\n",
      "Epoch 1/10\n",
      "1000/1000 [==============================] - 66s 66ms/step - loss: 0.2262 - acc: 0.9240\n",
      "Epoch 2/10\n",
      "1000/1000 [==============================] - 65s 65ms/step - loss: 0.1601 - acc: 0.9420\n",
      "Epoch 3/10\n",
      "1000/1000 [==============================] - 65s 65ms/step - loss: 0.1258 - acc: 0.9520\n",
      "Epoch 4/10\n",
      "1000/1000 [==============================] - 68s 68ms/step - loss: 0.1127 - acc: 0.9560\n",
      "Epoch 5/10\n",
      "1000/1000 [==============================] - 67s 67ms/step - loss: 0.1010 - acc: 0.9580\n",
      "Epoch 6/10\n",
      "1000/1000 [==============================] - 65s 65ms/step - loss: 0.0960 - acc: 0.9600\n",
      "Epoch 7/10\n",
      "1000/1000 [==============================] - 64s 64ms/step - loss: 0.0867 - acc: 0.9660\n",
      "Epoch 8/10\n",
      "1000/1000 [==============================] - 65s 65ms/step - loss: 0.0790 - acc: 0.9690\n",
      "Epoch 9/10\n",
      "1000/1000 [==============================] - 65s 65ms/step - loss: 0.0752 - acc: 0.9680\n",
      "Epoch 10/10\n",
      "1000/1000 [==============================] - 65s 65ms/step - loss: 0.0714 - acc: 0.9700\n",
      "Training on Epoch  1 batch  5  Files [5] start  280 / 459\n",
      "Epoch 1/10\n",
      "1000/1000 [==============================] - 60s 60ms/step - loss: 0.1848 - acc: 0.9170\n",
      "Epoch 2/10\n",
      "1000/1000 [==============================] - 60s 60ms/step - loss: 0.1429 - acc: 0.9410\n",
      "Epoch 3/10\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000/1000 [==============================] - 60s 60ms/step - loss: 0.1206 - acc: 0.9480\n",
      "Epoch 4/10\n",
      "1000/1000 [==============================] - 60s 60ms/step - loss: 0.1057 - acc: 0.9550\n",
      "Epoch 5/10\n",
      "1000/1000 [==============================] - 60s 60ms/step - loss: 0.0997 - acc: 0.9580\n",
      "Epoch 6/10\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 0.0906 - acc: 0.9630\n",
      "Epoch 7/10\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 0.0858 - acc: 0.9680\n",
      "Epoch 8/10\n",
      "1000/1000 [==============================] - 60s 60ms/step - loss: 0.0804 - acc: 0.9700\n",
      "Epoch 9/10\n",
      "1000/1000 [==============================] - 60s 60ms/step - loss: 0.0772 - acc: 0.9690\n",
      "Epoch 10/10\n",
      "1000/1000 [==============================] - 60s 60ms/step - loss: 0.0747 - acc: 0.9700\n",
      "Training on Epoch  1 batch  5  Files [5] start  285 / 459\n",
      "Epoch 1/10\n",
      "1000/1000 [==============================] - 61s 61ms/step - loss: 0.1912 - acc: 0.8970\n",
      "Epoch 2/10\n",
      "1000/1000 [==============================] - 62s 62ms/step - loss: 0.1691 - acc: 0.9080\n",
      "Epoch 3/10\n",
      "1000/1000 [==============================] - 63s 63ms/step - loss: 0.1568 - acc: 0.9150\n",
      "Epoch 4/10\n",
      "1000/1000 [==============================] - 65s 65ms/step - loss: 0.1503 - acc: 0.9220\n",
      "Epoch 5/10\n",
      "1000/1000 [==============================] - 62s 62ms/step - loss: 0.1473 - acc: 0.9280\n",
      "Epoch 6/10\n",
      "1000/1000 [==============================] - 62s 62ms/step - loss: 0.1406 - acc: 0.9250\n",
      "Epoch 7/10\n",
      "1000/1000 [==============================] - 62s 62ms/step - loss: 0.1378 - acc: 0.9290\n",
      "Epoch 8/10\n",
      "1000/1000 [==============================] - 62s 62ms/step - loss: 0.1330 - acc: 0.9360\n",
      "Epoch 9/10\n",
      "1000/1000 [==============================] - 62s 62ms/step - loss: 0.1328 - acc: 0.9340\n",
      "Epoch 10/10\n",
      "1000/1000 [==============================] - 63s 63ms/step - loss: 0.1278 - acc: 0.9380\n",
      "Training on Epoch  1 batch  5  Files [5] start  290 / 459\n",
      "Epoch 1/10\n",
      "1000/1000 [==============================] - 63s 63ms/step - loss: 0.2244 - acc: 0.9000\n",
      "Epoch 2/10\n",
      "1000/1000 [==============================] - 63s 63ms/step - loss: 0.1856 - acc: 0.9150\n",
      "Epoch 3/10\n",
      "1000/1000 [==============================] - 64s 64ms/step - loss: 0.1609 - acc: 0.9210\n",
      "Epoch 4/10\n",
      "1000/1000 [==============================] - 63s 63ms/step - loss: 0.1452 - acc: 0.9250\n",
      "Epoch 5/10\n",
      "1000/1000 [==============================] - 63s 63ms/step - loss: 0.1346 - acc: 0.9320\n",
      "Epoch 6/10\n",
      "1000/1000 [==============================] - 63s 63ms/step - loss: 0.1294 - acc: 0.9360\n",
      "Epoch 7/10\n",
      "1000/1000 [==============================] - 63s 63ms/step - loss: 0.1253 - acc: 0.9360\n",
      "Epoch 8/10\n",
      "1000/1000 [==============================] - 63s 63ms/step - loss: 0.1233 - acc: 0.9360\n",
      "Epoch 9/10\n",
      "1000/1000 [==============================] - 63s 63ms/step - loss: 0.1195 - acc: 0.9410\n",
      "Epoch 10/10\n",
      "1000/1000 [==============================] - 64s 64ms/step - loss: 0.1135 - acc: 0.9430\n",
      "Training on Epoch  1 batch  5  Files [5] start  295 / 459\n",
      "Epoch 1/10\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 0.1225 - acc: 0.9350\n",
      "Epoch 2/10\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 0.1005 - acc: 0.9550\n",
      "Epoch 3/10\n",
      "1000/1000 [==============================] - 58s 58ms/step - loss: 0.0900 - acc: 0.9620\n",
      "Epoch 4/10\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 0.0822 - acc: 0.9650\n",
      "Epoch 5/10\n",
      "1000/1000 [==============================] - 57s 57ms/step - loss: 0.0745 - acc: 0.9650\n",
      "Epoch 6/10\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 0.0715 - acc: 0.9670\n",
      "Epoch 7/10\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 0.0695 - acc: 0.9700\n",
      "Epoch 8/10\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 0.0654 - acc: 0.9690\n",
      "Epoch 9/10\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 0.0621 - acc: 0.9670\n",
      "Epoch 10/10\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 0.0590 - acc: 0.9720\n",
      "Training on Epoch  1 batch  5  Files [5] start  300 / 459\n",
      "Epoch 1/10\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 0.2025 - acc: 0.9160\n",
      "Epoch 2/10\n",
      "1000/1000 [==============================] - 58s 58ms/step - loss: 0.1751 - acc: 0.9330\n",
      "Epoch 3/10\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 0.1477 - acc: 0.9370\n",
      "Epoch 4/10\n",
      "1000/1000 [==============================] - 58s 58ms/step - loss: 0.1312 - acc: 0.9460\n",
      "Epoch 5/10\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 0.1163 - acc: 0.9510\n",
      "Epoch 6/10\n",
      "1000/1000 [==============================] - 60s 60ms/step - loss: 0.1067 - acc: 0.9600\n",
      "Epoch 7/10\n",
      "1000/1000 [==============================] - 61s 61ms/step - loss: 0.0985 - acc: 0.9660\n",
      "Epoch 8/10\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 0.0936 - acc: 0.9630\n",
      "Epoch 9/10\n",
      "1000/1000 [==============================] - 61s 61ms/step - loss: 0.0856 - acc: 0.9670\n",
      "Epoch 10/10\n",
      "1000/1000 [==============================] - 62s 62ms/step - loss: 0.0794 - acc: 0.9680\n",
      "Training on Epoch  1 batch  5  Files [5] start  305 / 459\n",
      "Epoch 1/10\n",
      "1000/1000 [==============================] - 63s 63ms/step - loss: 0.1747 - acc: 0.9270\n",
      "Epoch 2/10\n",
      "1000/1000 [==============================] - 67s 67ms/step - loss: 0.1359 - acc: 0.9370\n",
      "Epoch 3/10\n",
      "1000/1000 [==============================] - 66s 66ms/step - loss: 0.1081 - acc: 0.9550\n",
      "Epoch 4/10\n",
      "1000/1000 [==============================] - 66s 66ms/step - loss: 0.1108 - acc: 0.9520\n",
      "Epoch 5/10\n",
      "1000/1000 [==============================] - 66s 66ms/step - loss: 0.0977 - acc: 0.9600\n",
      "Epoch 6/10\n",
      "1000/1000 [==============================] - 64s 64ms/step - loss: 0.0932 - acc: 0.9640\n",
      "Epoch 7/10\n",
      "1000/1000 [==============================] - 67s 67ms/step - loss: 0.0824 - acc: 0.9670\n",
      "Epoch 8/10\n",
      "1000/1000 [==============================] - 67s 67ms/step - loss: 0.0765 - acc: 0.9680\n",
      "Epoch 9/10\n",
      "1000/1000 [==============================] - 66s 66ms/step - loss: 0.0703 - acc: 0.9710\n",
      "Epoch 10/10\n",
      "1000/1000 [==============================] - 66s 66ms/step - loss: 0.0665 - acc: 0.9720\n",
      "Training on Epoch  1 batch  5  Files [5] start  310 / 459\n",
      "Epoch 1/10\n",
      "1000/1000 [==============================] - 62s 62ms/step - loss: 0.2339 - acc: 0.9010\n",
      "Epoch 2/10\n",
      "1000/1000 [==============================] - 60s 60ms/step - loss: 0.1789 - acc: 0.9130\n",
      "Epoch 3/10\n",
      "1000/1000 [==============================] - 60s 60ms/step - loss: 0.1451 - acc: 0.9320\n",
      "Epoch 4/10\n",
      "1000/1000 [==============================] - 61s 61ms/step - loss: 0.1310 - acc: 0.9420\n",
      "Epoch 5/10\n",
      "1000/1000 [==============================] - 62s 62ms/step - loss: 0.1230 - acc: 0.9410\n",
      "Epoch 6/10\n",
      "1000/1000 [==============================] - 62s 62ms/step - loss: 0.1080 - acc: 0.9480\n",
      "Epoch 7/10\n",
      "1000/1000 [==============================] - 63s 63ms/step - loss: 0.1029 - acc: 0.9540\n",
      "Epoch 8/10\n",
      "1000/1000 [==============================] - 62s 62ms/step - loss: 0.0955 - acc: 0.9550\n",
      "Epoch 9/10\n",
      "1000/1000 [==============================] - 62s 62ms/step - loss: 0.0910 - acc: 0.9540\n",
      "Epoch 10/10\n",
      "1000/1000 [==============================] - 62s 62ms/step - loss: 0.0841 - acc: 0.9630\n",
      "Training on Epoch  1 batch  5  Files [5] start  315 / 459\n",
      "Epoch 1/10\n",
      "1000/1000 [==============================] - 65s 65ms/step - loss: 0.1519 - acc: 0.9310\n",
      "Epoch 2/10\n",
      "1000/1000 [==============================] - 65s 65ms/step - loss: 0.1315 - acc: 0.9320\n",
      "Epoch 3/10\n",
      "1000/1000 [==============================] - 66s 66ms/step - loss: 0.1197 - acc: 0.9340\n",
      "Epoch 4/10\n",
      "1000/1000 [==============================] - 66s 66ms/step - loss: 0.1105 - acc: 0.9330\n",
      "Epoch 5/10\n",
      "1000/1000 [==============================] - 65s 65ms/step - loss: 0.1027 - acc: 0.9400\n",
      "Epoch 6/10\n",
      "1000/1000 [==============================] - 63s 63ms/step - loss: 0.1004 - acc: 0.9380\n",
      "Epoch 7/10\n",
      "1000/1000 [==============================] - 64s 64ms/step - loss: 0.0980 - acc: 0.9420\n",
      "Epoch 8/10\n",
      "1000/1000 [==============================] - 66s 66ms/step - loss: 0.0953 - acc: 0.9500\n",
      "Epoch 9/10\n",
      "1000/1000 [==============================] - 67s 67ms/step - loss: 0.0911 - acc: 0.9480\n",
      "Epoch 10/10\n",
      "1000/1000 [==============================] - 64s 64ms/step - loss: 0.0883 - acc: 0.9510\n",
      "Training on Epoch  1 batch  5  Files [5] start  320 / 459\n",
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000/1000 [==============================] - 65s 65ms/step - loss: 0.1880 - acc: 0.9290\n",
      "Epoch 2/10\n",
      "1000/1000 [==============================] - 63s 63ms/step - loss: 0.1414 - acc: 0.9390\n",
      "Epoch 3/10\n",
      "1000/1000 [==============================] - 63s 63ms/step - loss: 0.1145 - acc: 0.9460\n",
      "Epoch 4/10\n",
      "1000/1000 [==============================] - 61s 61ms/step - loss: 0.0952 - acc: 0.9570\n",
      "Epoch 5/10\n",
      "1000/1000 [==============================] - 60s 60ms/step - loss: 0.0889 - acc: 0.9630\n",
      "Epoch 6/10\n",
      "1000/1000 [==============================] - 61s 61ms/step - loss: 0.0830 - acc: 0.9660\n",
      "Epoch 7/10\n",
      "1000/1000 [==============================] - 63s 63ms/step - loss: 0.0776 - acc: 0.9680\n",
      "Epoch 8/10\n",
      "1000/1000 [==============================] - 65s 65ms/step - loss: 0.0746 - acc: 0.9690\n",
      "Epoch 9/10\n",
      "1000/1000 [==============================] - 62s 62ms/step - loss: 0.0737 - acc: 0.9670\n",
      "Epoch 10/10\n",
      "1000/1000 [==============================] - 64s 64ms/step - loss: 0.0703 - acc: 0.9690\n",
      "Training on Epoch  1 batch  5  Files [5] start  325 / 459\n",
      "Epoch 1/10\n",
      "1000/1000 [==============================] - 103s 103ms/step - loss: 0.1265 - acc: 0.9470\n",
      "Epoch 2/10\n",
      "1000/1000 [==============================] - 99s 99ms/step - loss: 0.1074 - acc: 0.9570\n",
      "Epoch 3/10\n",
      "1000/1000 [==============================] - 112s 112ms/step - loss: 0.0967 - acc: 0.9580\n",
      "Epoch 4/10\n",
      "1000/1000 [==============================] - 106s 106ms/step - loss: 0.0840 - acc: 0.9640\n",
      "Epoch 5/10\n",
      "1000/1000 [==============================] - 107s 107ms/step - loss: 0.0761 - acc: 0.9690\n",
      "Epoch 6/10\n",
      "1000/1000 [==============================] - 107s 107ms/step - loss: 0.0717 - acc: 0.9670\n",
      "Epoch 7/10\n",
      "1000/1000 [==============================] - 101s 101ms/step - loss: 0.0690 - acc: 0.9690\n",
      "Epoch 8/10\n",
      "1000/1000 [==============================] - 99s 99ms/step - loss: 0.0657 - acc: 0.9700\n",
      "Epoch 9/10\n",
      "1000/1000 [==============================] - 93s 93ms/step - loss: 0.0632 - acc: 0.9680\n",
      "Epoch 10/10\n",
      "1000/1000 [==============================] - 81s 81ms/step - loss: 0.0604 - acc: 0.9730\n",
      "Training on Epoch  1 batch  5  Files [5] start  330 / 459\n",
      "Epoch 1/10\n",
      "1000/1000 [==============================] - 71s 71ms/step - loss: 0.2703 - acc: 0.8970\n",
      "Epoch 2/10\n",
      "1000/1000 [==============================] - 71s 71ms/step - loss: 0.1944 - acc: 0.9200\n",
      "Epoch 3/10\n",
      "1000/1000 [==============================] - 73s 73ms/step - loss: 0.1545 - acc: 0.9340\n",
      "Epoch 4/10\n",
      "1000/1000 [==============================] - 74s 74ms/step - loss: 0.1374 - acc: 0.9460\n",
      "Epoch 5/10\n",
      "1000/1000 [==============================] - 74s 74ms/step - loss: 0.1244 - acc: 0.9530\n",
      "Epoch 6/10\n",
      "1000/1000 [==============================] - 75s 75ms/step - loss: 0.1146 - acc: 0.9550\n",
      "Epoch 7/10\n",
      "1000/1000 [==============================] - 75s 75ms/step - loss: 0.1079 - acc: 0.9580\n",
      "Epoch 8/10\n",
      "1000/1000 [==============================] - 74s 74ms/step - loss: 0.1016 - acc: 0.9570\n",
      "Epoch 9/10\n",
      "1000/1000 [==============================] - 74s 74ms/step - loss: 0.0965 - acc: 0.9610\n",
      "Epoch 10/10\n",
      "1000/1000 [==============================] - 75s 75ms/step - loss: 0.0923 - acc: 0.9630\n",
      "Training on Epoch  1 batch  5  Files [5] start  335 / 459\n",
      "Epoch 1/10\n",
      "1000/1000 [==============================] - 68s 68ms/step - loss: 0.1900 - acc: 0.9020\n",
      "Epoch 2/10\n",
      "1000/1000 [==============================] - 66s 66ms/step - loss: 0.1638 - acc: 0.9170\n",
      "Epoch 3/10\n",
      "1000/1000 [==============================] - 65s 65ms/step - loss: 0.1460 - acc: 0.9250\n",
      "Epoch 4/10\n",
      "1000/1000 [==============================] - 65s 65ms/step - loss: 0.1297 - acc: 0.9280\n",
      "Epoch 5/10\n",
      "1000/1000 [==============================] - 66s 66ms/step - loss: 0.1202 - acc: 0.9360\n",
      "Epoch 6/10\n",
      "1000/1000 [==============================] - 72s 72ms/step - loss: 0.1145 - acc: 0.9380\n",
      "Epoch 7/10\n",
      "1000/1000 [==============================] - 74s 74ms/step - loss: 0.1089 - acc: 0.9450\n",
      "Epoch 8/10\n",
      "1000/1000 [==============================] - 105s 105ms/step - loss: 0.1068 - acc: 0.9450\n",
      "Epoch 9/10\n",
      "1000/1000 [==============================] - 126s 126ms/step - loss: 0.1038 - acc: 0.9460\n",
      "Epoch 10/10\n",
      "1000/1000 [==============================] - 141s 141ms/step - loss: 0.0989 - acc: 0.9510\n",
      "Training on Epoch  1 batch  5  Files [5] start  340 / 459\n",
      "Epoch 1/10\n",
      "1000/1000 [==============================] - 114s 114ms/step - loss: 0.1089 - acc: 0.9440\n",
      "Epoch 2/10\n",
      "1000/1000 [==============================] - 90s 90ms/step - loss: 0.0914 - acc: 0.9550\n",
      "Epoch 3/10\n",
      "1000/1000 [==============================] - 125s 125ms/step - loss: 0.0826 - acc: 0.9620\n",
      "Epoch 4/10\n",
      "1000/1000 [==============================] - 124s 124ms/step - loss: 0.0773 - acc: 0.9650\n",
      "Epoch 5/10\n",
      "1000/1000 [==============================] - 137s 137ms/step - loss: 0.0740 - acc: 0.9650\n",
      "Epoch 6/10\n",
      "1000/1000 [==============================] - 86s 86ms/step - loss: 0.0703 - acc: 0.9690\n",
      "Epoch 7/10\n",
      "1000/1000 [==============================] - 64s 64ms/step - loss: 0.0678 - acc: 0.9690\n",
      "Epoch 8/10\n",
      "1000/1000 [==============================] - 64s 64ms/step - loss: 0.0664 - acc: 0.9690\n",
      "Epoch 9/10\n",
      "1000/1000 [==============================] - 63s 63ms/step - loss: 0.0647 - acc: 0.9710\n",
      "Epoch 10/10\n",
      "1000/1000 [==============================] - 64s 64ms/step - loss: 0.0636 - acc: 0.9710\n",
      "Training on Epoch  1 batch  5  Files [5] start  345 / 459\n",
      "Epoch 1/10\n",
      "1000/1000 [==============================] - 65s 65ms/step - loss: 0.2485 - acc: 0.9030\n",
      "Epoch 2/10\n",
      "1000/1000 [==============================] - 65s 65ms/step - loss: 0.1752 - acc: 0.9300\n",
      "Epoch 3/10\n",
      "1000/1000 [==============================] - 68s 68ms/step - loss: 0.1343 - acc: 0.9500\n",
      "Epoch 4/10\n",
      "1000/1000 [==============================] - 93s 93ms/step - loss: 0.1106 - acc: 0.9480\n",
      "Epoch 5/10\n",
      "1000/1000 [==============================] - 93s 93ms/step - loss: 0.0972 - acc: 0.9580\n",
      "Epoch 6/10\n",
      "1000/1000 [==============================] - 133s 133ms/step - loss: 0.0859 - acc: 0.9620\n",
      "Epoch 7/10\n",
      "1000/1000 [==============================] - 85s 85ms/step - loss: 0.0772 - acc: 0.9670\n",
      "Epoch 8/10\n",
      "1000/1000 [==============================] - 65s 65ms/step - loss: 0.0699 - acc: 0.9720\n",
      "Epoch 9/10\n",
      "1000/1000 [==============================] - 64s 64ms/step - loss: 0.0640 - acc: 0.9700\n",
      "Epoch 10/10\n",
      "1000/1000 [==============================] - 65s 65ms/step - loss: 0.0595 - acc: 0.9740\n",
      "Training on Epoch  1 batch  5  Files [5] start  350 / 459\n",
      "Epoch 1/10\n",
      "1000/1000 [==============================] - 64s 64ms/step - loss: 0.4408 - acc: 0.8500\n",
      "Epoch 2/10\n",
      "1000/1000 [==============================] - 63s 63ms/step - loss: 0.3184 - acc: 0.8640\n",
      "Epoch 3/10\n",
      "1000/1000 [==============================] - 62s 62ms/step - loss: 0.2577 - acc: 0.8990\n",
      "Epoch 4/10\n",
      "1000/1000 [==============================] - 63s 63ms/step - loss: 0.2084 - acc: 0.9250\n",
      "Epoch 5/10\n",
      "1000/1000 [==============================] - 62s 62ms/step - loss: 0.1845 - acc: 0.9310\n",
      "Epoch 6/10\n",
      "1000/1000 [==============================] - 62s 62ms/step - loss: 0.1616 - acc: 0.9350\n",
      "Epoch 7/10\n",
      "1000/1000 [==============================] - 85s 85ms/step - loss: 0.1453 - acc: 0.9480\n",
      "Epoch 8/10\n",
      "1000/1000 [==============================] - 103s 103ms/step - loss: 0.1325 - acc: 0.9530\n",
      "Epoch 9/10\n",
      "1000/1000 [==============================] - 106s 106ms/step - loss: 0.1208 - acc: 0.9550\n",
      "Epoch 10/10\n",
      "1000/1000 [==============================] - 105s 105ms/step - loss: 0.1104 - acc: 0.9600\n",
      "Training on Epoch  1 batch  5  Files [5] start  355 / 459\n",
      "Epoch 1/10\n",
      "1000/1000 [==============================] - 112s 112ms/step - loss: 0.3114 - acc: 0.8840\n",
      "Epoch 2/10\n",
      "1000/1000 [==============================] - 109s 109ms/step - loss: 0.2525 - acc: 0.8840\n",
      "Epoch 3/10\n",
      "1000/1000 [==============================] - 104s 104ms/step - loss: 0.2079 - acc: 0.9100\n",
      "Epoch 4/10\n",
      "1000/1000 [==============================] - 63s 63ms/step - loss: 0.1774 - acc: 0.9290\n",
      "Epoch 5/10\n",
      "1000/1000 [==============================] - 63s 63ms/step - loss: 0.1504 - acc: 0.9420\n",
      "Epoch 6/10\n",
      "1000/1000 [==============================] - 65s 65ms/step - loss: 0.1366 - acc: 0.9460\n",
      "Epoch 7/10\n",
      "1000/1000 [==============================] - 65s 65ms/step - loss: 0.1260 - acc: 0.9530\n",
      "Epoch 8/10\n",
      "1000/1000 [==============================] - 64s 64ms/step - loss: 0.1143 - acc: 0.9540\n",
      "Epoch 9/10\n",
      "1000/1000 [==============================] - 63s 63ms/step - loss: 0.1053 - acc: 0.9520\n",
      "Epoch 10/10\n",
      "1000/1000 [==============================] - 63s 63ms/step - loss: 0.0954 - acc: 0.9640\n",
      "Training on Epoch  1 batch  5  Files [5] start  360 / 459\n",
      "Epoch 1/10\n",
      "1000/1000 [==============================] - 67s 67ms/step - loss: 0.3203 - acc: 0.8850\n",
      "Epoch 2/10\n",
      "1000/1000 [==============================] - 67s 67ms/step - loss: 0.2042 - acc: 0.9180\n",
      "Epoch 3/10\n",
      "1000/1000 [==============================] - 67s 67ms/step - loss: 0.1620 - acc: 0.9470\n",
      "Epoch 4/10\n",
      "1000/1000 [==============================] - 67s 67ms/step - loss: 0.1267 - acc: 0.9520\n",
      "Epoch 5/10\n",
      "1000/1000 [==============================] - 66s 66ms/step - loss: 0.0991 - acc: 0.9610\n",
      "Epoch 6/10\n",
      "1000/1000 [==============================] - 65s 65ms/step - loss: 0.0809 - acc: 0.9710\n",
      "Epoch 7/10\n",
      "1000/1000 [==============================] - 69s 69ms/step - loss: 0.0678 - acc: 0.9770\n",
      "Epoch 8/10\n",
      "1000/1000 [==============================] - 65s 65ms/step - loss: 0.0582 - acc: 0.9780\n",
      "Epoch 9/10\n",
      "1000/1000 [==============================] - 63s 63ms/step - loss: 0.0484 - acc: 0.9820\n",
      "Epoch 10/10\n",
      "1000/1000 [==============================] - 64s 64ms/step - loss: 0.0428 - acc: 0.9870\n",
      "Training on Epoch  1 batch  5  Files [5] start  365 / 459\n",
      "Epoch 1/10\n",
      "1000/1000 [==============================] - 58s 58ms/step - loss: 0.3873 - acc: 0.8640\n",
      "Epoch 2/10\n",
      "1000/1000 [==============================] - 61s 61ms/step - loss: 0.2659 - acc: 0.9080\n",
      "Epoch 3/10\n",
      "1000/1000 [==============================] - 63s 63ms/step - loss: 0.1994 - acc: 0.9200\n",
      "Epoch 4/10\n",
      "1000/1000 [==============================] - 64s 64ms/step - loss: 0.1634 - acc: 0.9430\n",
      "Epoch 5/10\n",
      "1000/1000 [==============================] - 64s 64ms/step - loss: 0.1413 - acc: 0.9510\n",
      "Epoch 6/10\n",
      "1000/1000 [==============================] - 62s 62ms/step - loss: 0.1207 - acc: 0.9580\n",
      "Epoch 7/10\n",
      "1000/1000 [==============================] - 60s 60ms/step - loss: 0.1044 - acc: 0.9650\n",
      "Epoch 8/10\n",
      "1000/1000 [==============================] - 60s 60ms/step - loss: 0.0929 - acc: 0.9730\n",
      "Epoch 9/10\n",
      "1000/1000 [==============================] - 60s 60ms/step - loss: 0.0844 - acc: 0.9760\n",
      "Epoch 10/10\n",
      "1000/1000 [==============================] - 60s 60ms/step - loss: 0.0748 - acc: 0.9780\n",
      "Training on Epoch  1 batch  5  Files [5] start  370 / 459\n",
      "Epoch 1/10\n",
      "1000/1000 [==============================] - 65s 65ms/step - loss: 0.2670 - acc: 0.9060\n",
      "Epoch 2/10\n",
      "1000/1000 [==============================] - 64s 64ms/step - loss: 0.1949 - acc: 0.9200\n",
      "Epoch 3/10\n",
      "1000/1000 [==============================] - 64s 64ms/step - loss: 0.1499 - acc: 0.9370\n",
      "Epoch 4/10\n",
      "1000/1000 [==============================] - 65s 65ms/step - loss: 0.1249 - acc: 0.9450\n",
      "Epoch 5/10\n",
      "1000/1000 [==============================] - 65s 65ms/step - loss: 0.1111 - acc: 0.9450\n",
      "Epoch 6/10\n",
      "1000/1000 [==============================] - 65s 65ms/step - loss: 0.0985 - acc: 0.9580\n",
      "Epoch 7/10\n",
      "1000/1000 [==============================] - 65s 65ms/step - loss: 0.0915 - acc: 0.9630\n",
      "Epoch 8/10\n",
      "1000/1000 [==============================] - 64s 64ms/step - loss: 0.0816 - acc: 0.9660\n",
      "Epoch 9/10\n",
      "1000/1000 [==============================] - 64s 64ms/step - loss: 0.0766 - acc: 0.9680\n",
      "Epoch 10/10\n",
      "1000/1000 [==============================] - 65s 65ms/step - loss: 0.0720 - acc: 0.9700\n",
      "Training on Epoch  1 batch  5  Files [5] start  375 / 459\n",
      "Epoch 1/10\n",
      "1000/1000 [==============================] - 67s 67ms/step - loss: 0.3477 - acc: 0.8720\n",
      "Epoch 2/10\n",
      "1000/1000 [==============================] - 65s 65ms/step - loss: 0.2335 - acc: 0.9010\n",
      "Epoch 3/10\n",
      "1000/1000 [==============================] - 67s 67ms/step - loss: 0.1727 - acc: 0.9230\n",
      "Epoch 4/10\n",
      "1000/1000 [==============================] - 66s 66ms/step - loss: 0.1474 - acc: 0.9440\n",
      "Epoch 5/10\n",
      "1000/1000 [==============================] - 66s 66ms/step - loss: 0.1183 - acc: 0.9600\n",
      "Epoch 6/10\n",
      "1000/1000 [==============================] - 65s 65ms/step - loss: 0.0994 - acc: 0.9660\n",
      "Epoch 7/10\n",
      "1000/1000 [==============================] - 65s 65ms/step - loss: 0.0880 - acc: 0.9690\n",
      "Epoch 8/10\n",
      "1000/1000 [==============================] - 67s 67ms/step - loss: 0.0770 - acc: 0.9780\n",
      "Epoch 9/10\n",
      "1000/1000 [==============================] - 67s 67ms/step - loss: 0.0657 - acc: 0.9810\n",
      "Epoch 10/10\n",
      "1000/1000 [==============================] - 66s 66ms/step - loss: 0.0588 - acc: 0.9820\n",
      "Training on Epoch  1 batch  5  Files [5] start  380 / 459\n",
      "Epoch 1/10\n",
      "1000/1000 [==============================] - 65s 65ms/step - loss: 0.3026 - acc: 0.8770\n",
      "Epoch 2/10\n",
      "1000/1000 [==============================] - 66s 66ms/step - loss: 0.2031 - acc: 0.9130\n",
      "Epoch 3/10\n",
      "1000/1000 [==============================] - 67s 67ms/step - loss: 0.1863 - acc: 0.9220\n",
      "Epoch 4/10\n",
      "1000/1000 [==============================] - 65s 65ms/step - loss: 0.1487 - acc: 0.9490\n",
      "Epoch 5/10\n",
      "1000/1000 [==============================] - 65s 65ms/step - loss: 0.1182 - acc: 0.9540\n",
      "Epoch 6/10\n",
      "1000/1000 [==============================] - 65s 65ms/step - loss: 0.1045 - acc: 0.9590\n",
      "Epoch 7/10\n",
      "1000/1000 [==============================] - 67s 67ms/step - loss: 0.0891 - acc: 0.9670\n",
      "Epoch 8/10\n",
      "1000/1000 [==============================] - 66s 66ms/step - loss: 0.0763 - acc: 0.9730\n",
      "Epoch 9/10\n",
      "1000/1000 [==============================] - 66s 66ms/step - loss: 0.0677 - acc: 0.9750\n",
      "Epoch 10/10\n",
      "1000/1000 [==============================] - 66s 66ms/step - loss: 0.0606 - acc: 0.9780\n",
      "Training on Epoch  1 batch  5  Files [5] start  385 / 459\n",
      "Epoch 1/10\n",
      "1000/1000 [==============================] - 66s 66ms/step - loss: 0.3253 - acc: 0.8820\n",
      "Epoch 2/10\n",
      "1000/1000 [==============================] - 66s 66ms/step - loss: 0.2399 - acc: 0.9020\n",
      "Epoch 3/10\n",
      "1000/1000 [==============================] - 65s 65ms/step - loss: 0.1895 - acc: 0.9160\n",
      "Epoch 4/10\n",
      "1000/1000 [==============================] - 67s 67ms/step - loss: 0.1503 - acc: 0.9350\n",
      "Epoch 5/10\n",
      "1000/1000 [==============================] - 66s 66ms/step - loss: 0.1296 - acc: 0.9520\n",
      "Epoch 6/10\n",
      "1000/1000 [==============================] - 64s 64ms/step - loss: 0.1101 - acc: 0.9610\n",
      "Epoch 7/10\n",
      "1000/1000 [==============================] - 67s 67ms/step - loss: 0.1015 - acc: 0.9640\n",
      "Epoch 8/10\n",
      "1000/1000 [==============================] - 66s 66ms/step - loss: 0.0912 - acc: 0.9640\n",
      "Epoch 9/10\n",
      "1000/1000 [==============================] - 66s 66ms/step - loss: 0.0831 - acc: 0.9680\n",
      "Epoch 10/10\n",
      "1000/1000 [==============================] - 66s 66ms/step - loss: 0.0747 - acc: 0.9720\n",
      "Training on Epoch  1 batch  5  Files [5] start  390 / 459\n",
      "Epoch 1/10\n",
      "1000/1000 [==============================] - 65s 65ms/step - loss: 0.3689 - acc: 0.8730\n",
      "Epoch 2/10\n",
      "1000/1000 [==============================] - 64s 64ms/step - loss: 0.2570 - acc: 0.9050\n",
      "Epoch 3/10\n",
      "1000/1000 [==============================] - 65s 65ms/step - loss: 0.1903 - acc: 0.9220\n",
      "Epoch 4/10\n",
      "1000/1000 [==============================] - 66s 66ms/step - loss: 0.1528 - acc: 0.9480\n",
      "Epoch 5/10\n",
      "1000/1000 [==============================] - 64s 64ms/step - loss: 0.1283 - acc: 0.9510\n",
      "Epoch 6/10\n",
      "1000/1000 [==============================] - 64s 64ms/step - loss: 0.1076 - acc: 0.9650\n",
      "Epoch 7/10\n",
      "1000/1000 [==============================] - 87s 87ms/step - loss: 0.0938 - acc: 0.9730\n",
      "Epoch 8/10\n",
      "1000/1000 [==============================] - 128s 128ms/step - loss: 0.0838 - acc: 0.9770\n",
      "Epoch 9/10\n",
      "1000/1000 [==============================] - 138s 138ms/step - loss: 0.0730 - acc: 0.9790\n",
      "Epoch 10/10\n",
      "1000/1000 [==============================] - 91s 91ms/step - loss: 0.0662 - acc: 0.9810\n",
      "Training on Epoch  1 batch  5  Files [5] start  395 / 459\n",
      "Epoch 1/10\n",
      "1000/1000 [==============================] - 107s 107ms/step - loss: 0.3245 - acc: 0.8860\n",
      "Epoch 2/10\n",
      "1000/1000 [==============================] - 107s 107ms/step - loss: 0.2229 - acc: 0.9180\n",
      "Epoch 3/10\n",
      "1000/1000 [==============================] - 114s 114ms/step - loss: 0.1705 - acc: 0.9380\n",
      "Epoch 4/10\n",
      "1000/1000 [==============================] - 116s 116ms/step - loss: 0.1443 - acc: 0.9410\n",
      "Epoch 5/10\n",
      "1000/1000 [==============================] - 123s 123ms/step - loss: 0.1247 - acc: 0.9510\n",
      "Epoch 6/10\n",
      "1000/1000 [==============================] - 122s 122ms/step - loss: 0.1096 - acc: 0.9600\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7/10\n",
      "1000/1000 [==============================] - 114s 114ms/step - loss: 0.0989 - acc: 0.9650\n",
      "Epoch 8/10\n",
      "1000/1000 [==============================] - 117s 117ms/step - loss: 0.0879 - acc: 0.9690\n",
      "Epoch 9/10\n",
      "1000/1000 [==============================] - 122s 122ms/step - loss: 0.0801 - acc: 0.9730\n",
      "Epoch 10/10\n",
      "1000/1000 [==============================] - 144s 144ms/step - loss: 0.0723 - acc: 0.9730\n",
      "Training on Epoch  1 batch  5  Files [5] start  400 / 459\n",
      "Epoch 1/10\n",
      "1000/1000 [==============================] - 65s 65ms/step - loss: 0.4002 - acc: 0.8800\n",
      "Epoch 2/10\n",
      "1000/1000 [==============================] - 67s 67ms/step - loss: 0.2632 - acc: 0.9030\n",
      "Epoch 3/10\n",
      "1000/1000 [==============================] - 67s 67ms/step - loss: 0.1953 - acc: 0.9240\n",
      "Epoch 4/10\n",
      "1000/1000 [==============================] - 68s 68ms/step - loss: 0.1642 - acc: 0.9440\n",
      "Epoch 5/10\n",
      "1000/1000 [==============================] - 67s 67ms/step - loss: 0.1377 - acc: 0.9540\n",
      "Epoch 6/10\n",
      "1000/1000 [==============================] - 71s 71ms/step - loss: 0.1216 - acc: 0.9570\n",
      "Epoch 7/10\n",
      "1000/1000 [==============================] - 81s 81ms/step - loss: 0.1064 - acc: 0.9570\n",
      "Epoch 8/10\n",
      "1000/1000 [==============================] - 76s 76ms/step - loss: 0.0880 - acc: 0.9700\n",
      "Epoch 9/10\n",
      "1000/1000 [==============================] - 73s 73ms/step - loss: 0.0881 - acc: 0.9720\n",
      "Epoch 10/10\n",
      "1000/1000 [==============================] - 74s 74ms/step - loss: 0.1000 - acc: 0.9580\n",
      "Training on Epoch  1 batch  5  Files [5] start  405 / 459\n",
      "Epoch 1/10\n",
      "1000/1000 [==============================] - 71s 71ms/step - loss: 0.3328 - acc: 0.8850\n",
      "Epoch 2/10\n",
      "1000/1000 [==============================] - 71s 71ms/step - loss: 0.2277 - acc: 0.9140\n",
      "Epoch 3/10\n",
      "1000/1000 [==============================] - 80s 80ms/step - loss: 0.1761 - acc: 0.9370\n",
      "Epoch 4/10\n",
      "1000/1000 [==============================] - 64s 64ms/step - loss: 0.1450 - acc: 0.9540\n",
      "Epoch 5/10\n",
      "1000/1000 [==============================] - 68s 68ms/step - loss: 0.1218 - acc: 0.9630\n",
      "Epoch 6/10\n",
      "1000/1000 [==============================] - 81s 81ms/step - loss: 0.1042 - acc: 0.9670\n",
      "Epoch 7/10\n",
      "1000/1000 [==============================] - 80s 80ms/step - loss: 0.0900 - acc: 0.9760\n",
      "Epoch 8/10\n",
      "1000/1000 [==============================] - 77s 77ms/step - loss: 0.0790 - acc: 0.9770\n",
      "Epoch 9/10\n",
      "1000/1000 [==============================] - 70s 70ms/step - loss: 0.0691 - acc: 0.9780\n",
      "Epoch 10/10\n",
      "1000/1000 [==============================] - 64s 64ms/step - loss: 0.0600 - acc: 0.9810\n",
      "Training on Epoch  1 batch  5  Files [5] start  410 / 459\n",
      "Epoch 1/10\n",
      "1000/1000 [==============================] - 64s 64ms/step - loss: 0.2767 - acc: 0.8800\n",
      "Epoch 2/10\n",
      "1000/1000 [==============================] - 63s 63ms/step - loss: 0.2116 - acc: 0.9140\n",
      "Epoch 3/10\n",
      "1000/1000 [==============================] - 61s 61ms/step - loss: 0.1605 - acc: 0.9360\n",
      "Epoch 4/10\n",
      "1000/1000 [==============================] - 62s 62ms/step - loss: 0.1243 - acc: 0.9560\n",
      "Epoch 5/10\n",
      "1000/1000 [==============================] - 64s 64ms/step - loss: 0.1021 - acc: 0.9610\n",
      "Epoch 6/10\n",
      "1000/1000 [==============================] - 76s 76ms/step - loss: 0.0849 - acc: 0.9690\n",
      "Epoch 7/10\n",
      "1000/1000 [==============================] - 73s 73ms/step - loss: 0.0722 - acc: 0.9700\n",
      "Epoch 8/10\n",
      "1000/1000 [==============================] - 78s 78ms/step - loss: 0.0597 - acc: 0.9800\n",
      "Epoch 9/10\n",
      "1000/1000 [==============================] - 67s 67ms/step - loss: 0.0505 - acc: 0.9840\n",
      "Epoch 10/10\n",
      "1000/1000 [==============================] - 66s 66ms/step - loss: 0.0436 - acc: 0.9890\n",
      "Training on Epoch  1 batch  5  Files [5] start  415 / 459\n",
      "Epoch 1/10\n",
      "1000/1000 [==============================] - 66s 66ms/step - loss: 0.3810 - acc: 0.8770\n",
      "Epoch 2/10\n",
      "1000/1000 [==============================] - 79s 79ms/step - loss: 0.2581 - acc: 0.9080\n",
      "Epoch 3/10\n",
      "1000/1000 [==============================] - 84s 84ms/step - loss: 0.1924 - acc: 0.9220\n",
      "Epoch 4/10\n",
      "1000/1000 [==============================] - 77s 77ms/step - loss: 0.1540 - acc: 0.9400\n",
      "Epoch 5/10\n",
      "1000/1000 [==============================] - 67s 67ms/step - loss: 0.1288 - acc: 0.9520\n",
      "Epoch 6/10\n",
      "1000/1000 [==============================] - 67s 67ms/step - loss: 0.1064 - acc: 0.9650\n",
      "Epoch 7/10\n",
      "1000/1000 [==============================] - 66s 66ms/step - loss: 0.0969 - acc: 0.9700\n",
      "Epoch 8/10\n",
      "1000/1000 [==============================] - 66s 66ms/step - loss: 0.0840 - acc: 0.9730\n",
      "Epoch 9/10\n",
      "1000/1000 [==============================] - 63s 63ms/step - loss: 0.0751 - acc: 0.9760\n",
      "Epoch 10/10\n",
      "1000/1000 [==============================] - 63s 63ms/step - loss: 0.0673 - acc: 0.9760\n",
      "Training on Epoch  1 batch  5  Files [5] start  420 / 459\n",
      "Epoch 1/10\n",
      "1000/1000 [==============================] - 67s 67ms/step - loss: 0.3525 - acc: 0.8680\n",
      "Epoch 2/10\n",
      "1000/1000 [==============================] - 66s 66ms/step - loss: 0.2374 - acc: 0.8980\n",
      "Epoch 3/10\n",
      "1000/1000 [==============================] - 66s 66ms/step - loss: 0.1769 - acc: 0.9340\n",
      "Epoch 4/10\n",
      "1000/1000 [==============================] - 66s 66ms/step - loss: 0.1306 - acc: 0.9520\n",
      "Epoch 5/10\n",
      "1000/1000 [==============================] - 67s 67ms/step - loss: 0.1050 - acc: 0.9670\n",
      "Epoch 6/10\n",
      "1000/1000 [==============================] - 65s 65ms/step - loss: 0.0878 - acc: 0.9730\n",
      "Epoch 7/10\n",
      "1000/1000 [==============================] - 69s 69ms/step - loss: 0.0778 - acc: 0.9730\n",
      "Epoch 8/10\n",
      "1000/1000 [==============================] - 65s 65ms/step - loss: 0.0666 - acc: 0.9760\n",
      "Epoch 9/10\n",
      "1000/1000 [==============================] - 68s 68ms/step - loss: 0.0601 - acc: 0.9770\n",
      "Epoch 10/10\n",
      "1000/1000 [==============================] - 71s 71ms/step - loss: 0.0533 - acc: 0.9790\n",
      "Training on Epoch  1 batch  5  Files [5] start  425 / 459\n",
      "Epoch 1/10\n",
      "1000/1000 [==============================] - 61s 61ms/step - loss: 0.3465 - acc: 0.8770\n",
      "Epoch 2/10\n",
      "1000/1000 [==============================] - 61s 61ms/step - loss: 0.2324 - acc: 0.8930\n",
      "Epoch 3/10\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 0.1708 - acc: 0.9270\n",
      "Epoch 4/10\n",
      "1000/1000 [==============================] - 60s 60ms/step - loss: 0.1340 - acc: 0.9470\n",
      "Epoch 5/10\n",
      "1000/1000 [==============================] - 61s 61ms/step - loss: 0.1079 - acc: 0.9580\n",
      "Epoch 6/10\n",
      "1000/1000 [==============================] - 61s 61ms/step - loss: 0.0861 - acc: 0.9730\n",
      "Epoch 7/10\n",
      "1000/1000 [==============================] - 62s 62ms/step - loss: 0.0735 - acc: 0.9760\n",
      "Epoch 8/10\n",
      "1000/1000 [==============================] - 63s 63ms/step - loss: 0.0617 - acc: 0.9780\n",
      "Epoch 9/10\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 0.0531 - acc: 0.9810\n",
      "Epoch 10/10\n",
      "1000/1000 [==============================] - 62s 62ms/step - loss: 0.0472 - acc: 0.9830\n",
      "Training on Epoch  1 batch  5  Files [5] start  430 / 459\n",
      "Epoch 1/10\n",
      "1000/1000 [==============================] - 75s 75ms/step - loss: 0.3428 - acc: 0.8900\n",
      "Epoch 2/10\n",
      "1000/1000 [==============================] - 61s 61ms/step - loss: 0.2356 - acc: 0.9140\n",
      "Epoch 3/10\n",
      "1000/1000 [==============================] - 60s 60ms/step - loss: 0.1790 - acc: 0.9320\n",
      "Epoch 4/10\n",
      "1000/1000 [==============================] - 64s 64ms/step - loss: 0.1465 - acc: 0.9480\n",
      "Epoch 5/10\n",
      "1000/1000 [==============================] - 64s 64ms/step - loss: 0.1199 - acc: 0.9580\n",
      "Epoch 6/10\n",
      "1000/1000 [==============================] - 64s 64ms/step - loss: 0.1024 - acc: 0.9620\n",
      "Epoch 7/10\n",
      "1000/1000 [==============================] - 62s 62ms/step - loss: 0.0899 - acc: 0.9640\n",
      "Epoch 8/10\n",
      "1000/1000 [==============================] - 62s 62ms/step - loss: 0.0765 - acc: 0.9710\n",
      "Epoch 9/10\n",
      "1000/1000 [==============================] - 63s 63ms/step - loss: 0.0667 - acc: 0.9810\n",
      "Epoch 10/10\n",
      "1000/1000 [==============================] - 62s 62ms/step - loss: 0.0654 - acc: 0.9780\n",
      "Training on Epoch  1 batch  5  Files [5] start  435 / 459\n",
      "Epoch 1/10\n",
      "1000/1000 [==============================] - 61s 61ms/step - loss: 0.3466 - acc: 0.8860\n",
      "Epoch 2/10\n",
      "1000/1000 [==============================] - 61s 61ms/step - loss: 0.2221 - acc: 0.9280\n",
      "Epoch 3/10\n",
      "1000/1000 [==============================] - 62s 62ms/step - loss: 0.1614 - acc: 0.9450\n",
      "Epoch 4/10\n",
      "1000/1000 [==============================] - 63s 63ms/step - loss: 0.1317 - acc: 0.9560\n",
      "Epoch 5/10\n",
      "1000/1000 [==============================] - 62s 62ms/step - loss: 0.1114 - acc: 0.9570\n",
      "Epoch 6/10\n",
      "1000/1000 [==============================] - 61s 61ms/step - loss: 0.0937 - acc: 0.9650\n",
      "Epoch 7/10\n",
      "1000/1000 [==============================] - 61s 61ms/step - loss: 0.0807 - acc: 0.9750\n",
      "Epoch 8/10\n",
      "1000/1000 [==============================] - 61s 61ms/step - loss: 0.0701 - acc: 0.9760\n",
      "Epoch 9/10\n",
      "1000/1000 [==============================] - 61s 61ms/step - loss: 0.0620 - acc: 0.9760\n",
      "Epoch 10/10\n",
      "1000/1000 [==============================] - 61s 61ms/step - loss: 0.0581 - acc: 0.9840\n",
      "Training on Epoch  1 batch  5  Files [5] start  440 / 459\n",
      "Epoch 1/10\n",
      "1000/1000 [==============================] - 64s 64ms/step - loss: 0.2218 - acc: 0.9330\n",
      "Epoch 2/10\n",
      "1000/1000 [==============================] - 64s 64ms/step - loss: 0.1260 - acc: 0.9540\n",
      "Epoch 3/10\n",
      "1000/1000 [==============================] - 65s 65ms/step - loss: 0.0827 - acc: 0.9760\n",
      "Epoch 4/10\n",
      "1000/1000 [==============================] - 67s 67ms/step - loss: 0.0628 - acc: 0.9810\n",
      "Epoch 5/10\n",
      "1000/1000 [==============================] - 65s 65ms/step - loss: 0.0453 - acc: 0.9890\n",
      "Epoch 6/10\n",
      "1000/1000 [==============================] - 65s 65ms/step - loss: 0.0344 - acc: 0.9920\n",
      "Epoch 7/10\n",
      "1000/1000 [==============================] - 64s 64ms/step - loss: 0.0274 - acc: 0.9930\n",
      "Epoch 8/10\n",
      "1000/1000 [==============================] - 67s 67ms/step - loss: 0.0225 - acc: 0.9940\n",
      "Epoch 9/10\n",
      "1000/1000 [==============================] - 65s 65ms/step - loss: 0.0172 - acc: 0.9970\n",
      "Epoch 10/10\n",
      "1000/1000 [==============================] - 64s 64ms/step - loss: 0.0136 - acc: 0.9990\n",
      "Training on Epoch  1 batch  5  Files [5] start  445 / 459\n",
      "Epoch 1/10\n",
      "1000/1000 [==============================] - 61s 61ms/step - loss: 0.2433 - acc: 0.9230\n",
      "Epoch 2/10\n",
      "1000/1000 [==============================] - 60s 60ms/step - loss: 0.1545 - acc: 0.9500\n",
      "Epoch 3/10\n",
      "1000/1000 [==============================] - 60s 60ms/step - loss: 0.1016 - acc: 0.9580\n",
      "Epoch 4/10\n",
      "1000/1000 [==============================] - 61s 61ms/step - loss: 0.0689 - acc: 0.9750\n",
      "Epoch 5/10\n",
      "1000/1000 [==============================] - 57s 57ms/step - loss: 0.0503 - acc: 0.9810\n",
      "Epoch 6/10\n",
      "1000/1000 [==============================] - 62s 62ms/step - loss: 0.0406 - acc: 0.9850\n",
      "Epoch 7/10\n",
      "1000/1000 [==============================] - 63s 63ms/step - loss: 0.0330 - acc: 0.9880\n",
      "Epoch 8/10\n",
      "1000/1000 [==============================] - 61s 61ms/step - loss: 0.0266 - acc: 0.9920\n",
      "Epoch 9/10\n",
      "1000/1000 [==============================] - 61s 61ms/step - loss: 0.0226 - acc: 0.9910\n",
      "Epoch 10/10\n",
      "1000/1000 [==============================] - 62s 62ms/step - loss: 0.0197 - acc: 0.9950\n",
      "Training on Epoch  1 batch  5  Files [5] start  450 / 459\n",
      "Epoch 1/10\n",
      "1000/1000 [==============================] - 65s 65ms/step - loss: 0.2839 - acc: 0.9160\n",
      "Epoch 2/10\n",
      "1000/1000 [==============================] - 64s 64ms/step - loss: 0.2042 - acc: 0.9290\n",
      "Epoch 3/10\n",
      "1000/1000 [==============================] - 66s 66ms/step - loss: 0.1480 - acc: 0.9410\n",
      "Epoch 4/10\n",
      "1000/1000 [==============================] - 67s 67ms/step - loss: 0.1216 - acc: 0.9530\n",
      "Epoch 5/10\n",
      "1000/1000 [==============================] - 62s 62ms/step - loss: 0.0983 - acc: 0.9620\n",
      "Epoch 6/10\n",
      "1000/1000 [==============================] - 64s 64ms/step - loss: 0.0841 - acc: 0.9720\n",
      "Epoch 7/10\n",
      "1000/1000 [==============================] - 62s 62ms/step - loss: 0.0720 - acc: 0.9760\n",
      "Epoch 8/10\n",
      "1000/1000 [==============================] - 66s 66ms/step - loss: 0.0622 - acc: 0.9790\n",
      "Epoch 9/10\n",
      "1000/1000 [==============================] - 63s 63ms/step - loss: 0.0539 - acc: 0.9810\n",
      "Epoch 10/10\n",
      "1000/1000 [==============================] - 62s 62ms/step - loss: 0.0463 - acc: 0.9850\n",
      "Training on Epoch  1 batch  4  Files [5] start  455 / 459\n",
      "Epoch 1/10\n",
      "800/800 [==============================] - 53s 66ms/step - loss: 0.3261 - acc: 0.9162\n",
      "Epoch 2/10\n",
      "800/800 [==============================] - 51s 64ms/step - loss: 0.2278 - acc: 0.9325\n",
      "Epoch 3/10\n",
      "800/800 [==============================] - 51s 64ms/step - loss: 0.1654 - acc: 0.9437\n",
      "Epoch 4/10\n",
      "800/800 [==============================] - 52s 65ms/step - loss: 0.1369 - acc: 0.9550\n",
      "Epoch 5/10\n",
      "800/800 [==============================] - 51s 64ms/step - loss: 0.1123 - acc: 0.9688\n",
      "Epoch 6/10\n",
      "800/800 [==============================] - 53s 66ms/step - loss: 0.0982 - acc: 0.9763\n",
      "Epoch 7/10\n",
      "800/800 [==============================] - 52s 65ms/step - loss: 0.0883 - acc: 0.9788\n",
      "Epoch 8/10\n",
      "800/800 [==============================] - 52s 66ms/step - loss: 0.0795 - acc: 0.9838\n",
      "Epoch 9/10\n",
      "800/800 [==============================] - 53s 66ms/step - loss: 0.0741 - acc: 0.9838\n",
      "Epoch 10/10\n",
      "800/800 [==============================] - 58s 72ms/step - loss: 0.0672 - acc: 0.9863\n",
      "Training on Epoch  2 batch  5  Files [5] start  0 / 459\n",
      "Epoch 1/10\n",
      "1000/1000 [==============================] - 76s 76ms/step - loss: 0.2572 - acc: 0.9070\n",
      "Epoch 2/10\n",
      "1000/1000 [==============================] - 69s 69ms/step - loss: 0.1881 - acc: 0.9290\n",
      "Epoch 3/10\n",
      "1000/1000 [==============================] - 69s 69ms/step - loss: 0.1481 - acc: 0.9490\n",
      "Epoch 4/10\n",
      "1000/1000 [==============================] - 68s 68ms/step - loss: 0.1134 - acc: 0.9610\n",
      "Epoch 5/10\n",
      "1000/1000 [==============================] - 68s 68ms/step - loss: 0.0910 - acc: 0.9690\n",
      "Epoch 6/10\n",
      "1000/1000 [==============================] - 67s 67ms/step - loss: 0.0763 - acc: 0.9730\n",
      "Epoch 7/10\n",
      "1000/1000 [==============================] - 69s 69ms/step - loss: 0.0639 - acc: 0.9770\n",
      "Epoch 8/10\n",
      "1000/1000 [==============================] - 68s 68ms/step - loss: 0.0564 - acc: 0.9780\n",
      "Epoch 9/10\n",
      "1000/1000 [==============================] - 70s 70ms/step - loss: 0.0487 - acc: 0.9840\n",
      "Epoch 10/10\n",
      "1000/1000 [==============================] - 71s 71ms/step - loss: 0.0438 - acc: 0.9880\n",
      "Training on Epoch  2 batch  5  Files [5] start  5 / 459\n",
      "Epoch 1/10\n",
      "1000/1000 [==============================] - 71s 71ms/step - loss: 0.3317 - acc: 0.9030\n",
      "Epoch 2/10\n",
      "1000/1000 [==============================] - 68s 68ms/step - loss: 0.2254 - acc: 0.9230\n",
      "Epoch 3/10\n",
      "1000/1000 [==============================] - 65s 65ms/step - loss: 0.1422 - acc: 0.9490\n",
      "Epoch 4/10\n",
      "1000/1000 [==============================] - 67s 67ms/step - loss: 0.1201 - acc: 0.9590\n",
      "Epoch 5/10\n",
      "1000/1000 [==============================] - 67s 67ms/step - loss: 0.0975 - acc: 0.9670\n",
      "Epoch 6/10\n",
      "1000/1000 [==============================] - 67s 67ms/step - loss: 0.0775 - acc: 0.9720\n",
      "Epoch 7/10\n",
      "1000/1000 [==============================] - 66s 66ms/step - loss: 0.0659 - acc: 0.9790\n",
      "Epoch 8/10\n",
      "1000/1000 [==============================] - 66s 66ms/step - loss: 0.0508 - acc: 0.9830\n",
      "Epoch 9/10\n",
      "1000/1000 [==============================] - 66s 66ms/step - loss: 0.0429 - acc: 0.9860\n",
      "Epoch 10/10\n",
      "1000/1000 [==============================] - 66s 66ms/step - loss: 0.0347 - acc: 0.9920\n",
      "Training on Epoch  2 batch  5  Files [5] start  10 / 459\n",
      "Epoch 1/10\n",
      "1000/1000 [==============================] - 63s 63ms/step - loss: 0.3208 - acc: 0.8890\n",
      "Epoch 2/10\n",
      "1000/1000 [==============================] - 63s 63ms/step - loss: 0.2244 - acc: 0.9180\n",
      "Epoch 3/10\n",
      "1000/1000 [==============================] - 64s 64ms/step - loss: 0.1640 - acc: 0.9370\n",
      "Epoch 4/10\n",
      "1000/1000 [==============================] - 63s 63ms/step - loss: 0.1199 - acc: 0.9580\n",
      "Epoch 5/10\n",
      "1000/1000 [==============================] - 63s 63ms/step - loss: 0.0958 - acc: 0.9630\n",
      "Epoch 6/10\n",
      "1000/1000 [==============================] - 64s 64ms/step - loss: 0.0779 - acc: 0.9740\n",
      "Epoch 7/10\n",
      "1000/1000 [==============================] - 63s 63ms/step - loss: 0.0645 - acc: 0.9800\n",
      "Epoch 8/10\n",
      "1000/1000 [==============================] - 64s 64ms/step - loss: 0.0554 - acc: 0.9810\n",
      "Epoch 9/10\n",
      "1000/1000 [==============================] - 63s 63ms/step - loss: 0.0482 - acc: 0.9870\n",
      "Epoch 10/10\n",
      "1000/1000 [==============================] - 64s 64ms/step - loss: 0.0420 - acc: 0.9870\n",
      "Training on Epoch  2 batch  5  Files [5] start  15 / 459\n",
      "Epoch 1/10\n",
      "1000/1000 [==============================] - 66s 66ms/step - loss: 0.3871 - acc: 0.8840\n",
      "Epoch 2/10\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000/1000 [==============================] - 68s 68ms/step - loss: 0.3156 - acc: 0.8800\n",
      "Epoch 3/10\n",
      "1000/1000 [==============================] - 69s 69ms/step - loss: 0.2352 - acc: 0.9160\n",
      "Epoch 4/10\n",
      "1000/1000 [==============================] - 69s 69ms/step - loss: 0.1914 - acc: 0.9300\n",
      "Epoch 5/10\n",
      "1000/1000 [==============================] - 67s 67ms/step - loss: 0.1680 - acc: 0.9410\n",
      "Epoch 6/10\n",
      "1000/1000 [==============================] - 67s 67ms/step - loss: 0.1395 - acc: 0.9470\n",
      "Epoch 7/10\n",
      "1000/1000 [==============================] - 68s 68ms/step - loss: 0.1178 - acc: 0.9600\n",
      "Epoch 8/10\n",
      "1000/1000 [==============================] - 66s 66ms/step - loss: 0.1120 - acc: 0.9660\n",
      "Epoch 9/10\n",
      "1000/1000 [==============================] - 66s 66ms/step - loss: 0.0927 - acc: 0.9710\n",
      "Epoch 10/10\n",
      "1000/1000 [==============================] - 66s 66ms/step - loss: 0.0860 - acc: 0.9730\n",
      "Training on Epoch  2 batch  5  Files [5] start  20 / 459\n",
      "Epoch 1/10\n",
      "1000/1000 [==============================] - 62s 62ms/step - loss: 0.3308 - acc: 0.8750\n",
      "Epoch 2/10\n",
      "1000/1000 [==============================] - 65s 65ms/step - loss: 0.2493 - acc: 0.8980\n",
      "Epoch 3/10\n",
      "1000/1000 [==============================] - 65s 65ms/step - loss: 0.1898 - acc: 0.9220\n",
      "Epoch 4/10\n",
      "1000/1000 [==============================] - 64s 64ms/step - loss: 0.1523 - acc: 0.9430\n",
      "Epoch 5/10\n",
      "1000/1000 [==============================] - 65s 65ms/step - loss: 0.1309 - acc: 0.9540\n",
      "Epoch 6/10\n",
      "1000/1000 [==============================] - 61s 61ms/step - loss: 0.1144 - acc: 0.9600\n",
      "Epoch 7/10\n",
      "1000/1000 [==============================] - 65s 65ms/step - loss: 0.1009 - acc: 0.9660\n",
      "Epoch 8/10\n",
      "1000/1000 [==============================] - 67s 67ms/step - loss: 0.0885 - acc: 0.9660\n",
      "Epoch 9/10\n",
      "1000/1000 [==============================] - 64s 64ms/step - loss: 0.0784 - acc: 0.9680\n",
      "Epoch 10/10\n",
      "1000/1000 [==============================] - 66s 66ms/step - loss: 0.0708 - acc: 0.9720\n",
      "Training on Epoch  2 batch  5  Files [5] start  25 / 459\n",
      "Epoch 1/10\n",
      "1000/1000 [==============================] - 68s 68ms/step - loss: 0.3133 - acc: 0.8850\n",
      "Epoch 2/10\n",
      "1000/1000 [==============================] - 68s 68ms/step - loss: 0.2352 - acc: 0.9070\n",
      "Epoch 3/10\n",
      "1000/1000 [==============================] - 71s 71ms/step - loss: 0.1873 - acc: 0.9360\n",
      "Epoch 4/10\n",
      "1000/1000 [==============================] - 69s 69ms/step - loss: 0.1590 - acc: 0.9440\n",
      "Epoch 5/10\n",
      "1000/1000 [==============================] - 68s 68ms/step - loss: 0.1383 - acc: 0.9480\n",
      "Epoch 6/10\n",
      "1000/1000 [==============================] - 67s 67ms/step - loss: 0.1163 - acc: 0.9560\n",
      "Epoch 7/10\n",
      "1000/1000 [==============================] - 68s 68ms/step - loss: 0.1037 - acc: 0.9620\n",
      "Epoch 8/10\n",
      "1000/1000 [==============================] - 65s 65ms/step - loss: 0.0909 - acc: 0.9710\n",
      "Epoch 9/10\n",
      "1000/1000 [==============================] - 66s 66ms/step - loss: 0.0825 - acc: 0.9720\n",
      "Epoch 10/10\n",
      "1000/1000 [==============================] - 66s 66ms/step - loss: 0.0743 - acc: 0.9750\n",
      "Training on Epoch  2 batch  5  Files [5] start  30 / 459\n",
      "Epoch 1/10\n",
      "1000/1000 [==============================] - 62s 62ms/step - loss: 0.3024 - acc: 0.8810\n",
      "Epoch 2/10\n",
      "1000/1000 [==============================] - 62s 62ms/step - loss: 0.2122 - acc: 0.9190\n",
      "Epoch 3/10\n",
      "1000/1000 [==============================] - 62s 62ms/step - loss: 0.1563 - acc: 0.9400\n",
      "Epoch 4/10\n",
      "1000/1000 [==============================] - 62s 62ms/step - loss: 0.1320 - acc: 0.9560\n",
      "Epoch 5/10\n",
      "1000/1000 [==============================] - 62s 62ms/step - loss: 0.1220 - acc: 0.9560\n",
      "Epoch 6/10\n",
      "1000/1000 [==============================] - 63s 63ms/step - loss: 0.1299 - acc: 0.9530\n",
      "Epoch 7/10\n",
      "1000/1000 [==============================] - 62s 62ms/step - loss: 0.1193 - acc: 0.9580\n",
      "Epoch 8/10\n",
      "1000/1000 [==============================] - 62s 62ms/step - loss: 0.1012 - acc: 0.9680\n",
      "Epoch 9/10\n",
      "1000/1000 [==============================] - 62s 62ms/step - loss: 0.0881 - acc: 0.9700\n",
      "Epoch 10/10\n",
      "1000/1000 [==============================] - 62s 62ms/step - loss: 0.0807 - acc: 0.9700\n",
      "Training on Epoch  2 batch  5  Files [5] start  35 / 459\n",
      "Epoch 1/10\n",
      "1000/1000 [==============================] - 67s 67ms/step - loss: 0.2606 - acc: 0.8890\n",
      "Epoch 2/10\n",
      "1000/1000 [==============================] - 62s 62ms/step - loss: 0.2009 - acc: 0.9210\n",
      "Epoch 3/10\n",
      "1000/1000 [==============================] - 64s 64ms/step - loss: 0.1553 - acc: 0.9440\n",
      "Epoch 4/10\n",
      "1000/1000 [==============================] - 61s 61ms/step - loss: 0.1340 - acc: 0.9450\n",
      "Epoch 5/10\n",
      "1000/1000 [==============================] - 60s 60ms/step - loss: 0.1149 - acc: 0.9500\n",
      "Epoch 6/10\n",
      "1000/1000 [==============================] - 61s 61ms/step - loss: 0.1001 - acc: 0.9630\n",
      "Epoch 7/10\n",
      "1000/1000 [==============================] - 61s 61ms/step - loss: 0.0888 - acc: 0.9660\n",
      "Epoch 8/10\n",
      "1000/1000 [==============================] - 61s 61ms/step - loss: 0.0791 - acc: 0.9670\n",
      "Epoch 9/10\n",
      "1000/1000 [==============================] - 62s 62ms/step - loss: 0.0723 - acc: 0.9690\n",
      "Epoch 10/10\n",
      "1000/1000 [==============================] - 62s 62ms/step - loss: 0.0670 - acc: 0.9720\n",
      "Training on Epoch  2 batch  5  Files [5] start  40 / 459\n",
      "Epoch 1/10\n",
      "1000/1000 [==============================] - 60s 60ms/step - loss: 0.2782 - acc: 0.9100\n",
      "Epoch 2/10\n",
      "1000/1000 [==============================] - 60s 60ms/step - loss: 0.1978 - acc: 0.9270\n",
      "Epoch 3/10\n",
      "1000/1000 [==============================] - 60s 60ms/step - loss: 0.1477 - acc: 0.9510\n",
      "Epoch 4/10\n",
      "1000/1000 [==============================] - 61s 61ms/step - loss: 0.1193 - acc: 0.9610\n",
      "Epoch 5/10\n",
      "1000/1000 [==============================] - 60s 60ms/step - loss: 0.1017 - acc: 0.9650\n",
      "Epoch 6/10\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 0.0897 - acc: 0.9660\n",
      "Epoch 7/10\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 0.0800 - acc: 0.9730\n",
      "Epoch 8/10\n",
      "1000/1000 [==============================] - 60s 60ms/step - loss: 0.0716 - acc: 0.9750\n",
      "Epoch 9/10\n",
      "1000/1000 [==============================] - 60s 60ms/step - loss: 0.0648 - acc: 0.9780\n",
      "Epoch 10/10\n",
      "1000/1000 [==============================] - 60s 60ms/step - loss: 0.0577 - acc: 0.9790\n",
      "Training on Epoch  2 batch  5  Files [5] start  45 / 459\n",
      "Epoch 1/10\n",
      "1000/1000 [==============================] - 56s 56ms/step - loss: 0.2731 - acc: 0.9040\n",
      "Epoch 2/10\n",
      "1000/1000 [==============================] - 56s 56ms/step - loss: 0.2143 - acc: 0.9160\n",
      "Epoch 3/10\n",
      "1000/1000 [==============================] - 56s 56ms/step - loss: 0.1577 - acc: 0.9360\n",
      "Epoch 4/10\n",
      "1000/1000 [==============================] - 56s 56ms/step - loss: 0.1284 - acc: 0.9520\n",
      "Epoch 5/10\n",
      "1000/1000 [==============================] - 56s 56ms/step - loss: 0.1133 - acc: 0.9570\n",
      "Epoch 6/10\n",
      "1000/1000 [==============================] - 56s 56ms/step - loss: 0.1016 - acc: 0.9650\n",
      "Epoch 7/10\n",
      "1000/1000 [==============================] - 57s 57ms/step - loss: 0.0927 - acc: 0.9670\n",
      "Epoch 8/10\n",
      "1000/1000 [==============================] - 56s 56ms/step - loss: 0.0853 - acc: 0.9700\n",
      "Epoch 9/10\n",
      "1000/1000 [==============================] - 56s 56ms/step - loss: 0.0788 - acc: 0.9700\n",
      "Epoch 10/10\n",
      "1000/1000 [==============================] - 57s 57ms/step - loss: 0.0734 - acc: 0.9740\n",
      "Training on Epoch  2 batch  5  Files [5] start  50 / 459\n",
      "Epoch 1/10\n",
      "1000/1000 [==============================] - 65s 65ms/step - loss: 0.2816 - acc: 0.8860\n",
      "Epoch 2/10\n",
      "1000/1000 [==============================] - 64s 64ms/step - loss: 0.2269 - acc: 0.9070\n",
      "Epoch 3/10\n",
      "1000/1000 [==============================] - 65s 65ms/step - loss: 0.1862 - acc: 0.9260\n",
      "Epoch 4/10\n",
      "1000/1000 [==============================] - 66s 66ms/step - loss: 0.1574 - acc: 0.9410\n",
      "Epoch 5/10\n",
      "1000/1000 [==============================] - 65s 65ms/step - loss: 0.1350 - acc: 0.9470\n",
      "Epoch 6/10\n",
      "1000/1000 [==============================] - 65s 65ms/step - loss: 0.1180 - acc: 0.9560\n",
      "Epoch 7/10\n",
      "1000/1000 [==============================] - 65s 65ms/step - loss: 0.1062 - acc: 0.9610\n",
      "Epoch 8/10\n",
      "1000/1000 [==============================] - 66s 66ms/step - loss: 0.0983 - acc: 0.9670\n",
      "Epoch 9/10\n",
      "1000/1000 [==============================] - 66s 66ms/step - loss: 0.0924 - acc: 0.9690\n",
      "Epoch 10/10\n",
      "1000/1000 [==============================] - 65s 65ms/step - loss: 0.0856 - acc: 0.9700\n",
      "Training on Epoch  2 batch  5  Files [5] start  55 / 459\n",
      "Epoch 1/10\n",
      "1000/1000 [==============================] - 58s 58ms/step - loss: 0.3506 - acc: 0.8840\n",
      "Epoch 2/10\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 0.2656 - acc: 0.8980\n",
      "Epoch 3/10\n",
      "1000/1000 [==============================] - 60s 60ms/step - loss: 0.2001 - acc: 0.9260\n",
      "Epoch 4/10\n",
      "1000/1000 [==============================] - 61s 61ms/step - loss: 0.1642 - acc: 0.9410\n",
      "Epoch 5/10\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 0.1470 - acc: 0.9570\n",
      "Epoch 6/10\n",
      "1000/1000 [==============================] - 60s 60ms/step - loss: 0.1243 - acc: 0.9610\n",
      "Epoch 7/10\n",
      "1000/1000 [==============================] - 60s 60ms/step - loss: 0.1119 - acc: 0.9640\n",
      "Epoch 8/10\n",
      "1000/1000 [==============================] - 60s 60ms/step - loss: 0.1004 - acc: 0.9670\n",
      "Epoch 9/10\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 0.0905 - acc: 0.9700\n",
      "Epoch 10/10\n",
      "1000/1000 [==============================] - 62s 62ms/step - loss: 0.0812 - acc: 0.9750\n",
      "Training on Epoch  2 batch  5  Files [5] start  60 / 459\n",
      "Epoch 1/10\n",
      "1000/1000 [==============================] - 58s 58ms/step - loss: 0.2613 - acc: 0.8960\n",
      "Epoch 2/10\n",
      "1000/1000 [==============================] - 56s 56ms/step - loss: 0.1959 - acc: 0.9220\n",
      "Epoch 3/10\n",
      "1000/1000 [==============================] - 57s 57ms/step - loss: 0.1509 - acc: 0.9430\n",
      "Epoch 4/10\n",
      "1000/1000 [==============================] - 56s 56ms/step - loss: 0.1264 - acc: 0.9520\n",
      "Epoch 5/10\n",
      "1000/1000 [==============================] - 56s 56ms/step - loss: 0.1090 - acc: 0.9590\n",
      "Epoch 6/10\n",
      "1000/1000 [==============================] - 56s 56ms/step - loss: 0.0932 - acc: 0.9680\n",
      "Epoch 7/10\n",
      "1000/1000 [==============================] - 57s 57ms/step - loss: 0.0848 - acc: 0.9710\n",
      "Epoch 8/10\n",
      "1000/1000 [==============================] - 56s 56ms/step - loss: 0.0780 - acc: 0.9740\n",
      "Epoch 9/10\n",
      "1000/1000 [==============================] - 56s 56ms/step - loss: 0.0726 - acc: 0.9750\n",
      "Epoch 10/10\n",
      "1000/1000 [==============================] - 56s 56ms/step - loss: 0.0685 - acc: 0.9790\n",
      "Training on Epoch  2 batch  5  Files [5] start  65 / 459\n",
      "Epoch 1/10\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 0.3308 - acc: 0.8900\n",
      "Epoch 2/10\n",
      "1000/1000 [==============================] - 58s 58ms/step - loss: 0.2278 - acc: 0.9130\n",
      "Epoch 3/10\n",
      "1000/1000 [==============================] - 58s 58ms/step - loss: 0.1678 - acc: 0.9290\n",
      "Epoch 4/10\n",
      "1000/1000 [==============================] - 58s 58ms/step - loss: 0.1428 - acc: 0.9410\n",
      "Epoch 5/10\n",
      "1000/1000 [==============================] - 58s 58ms/step - loss: 0.1137 - acc: 0.9630\n",
      "Epoch 6/10\n",
      "1000/1000 [==============================] - 58s 58ms/step - loss: 0.0960 - acc: 0.9650\n",
      "Epoch 7/10\n",
      "1000/1000 [==============================] - 58s 58ms/step - loss: 0.0847 - acc: 0.9680\n",
      "Epoch 8/10\n",
      "1000/1000 [==============================] - 58s 58ms/step - loss: 0.0762 - acc: 0.9720\n",
      "Epoch 9/10\n",
      "1000/1000 [==============================] - 58s 58ms/step - loss: 0.0686 - acc: 0.9730\n",
      "Epoch 10/10\n",
      "1000/1000 [==============================] - 58s 58ms/step - loss: 0.0630 - acc: 0.9760\n",
      "Training on Epoch  2 batch  5  Files [5] start  70 / 459\n",
      "Epoch 1/10\n",
      "1000/1000 [==============================] - 58s 58ms/step - loss: 0.3199 - acc: 0.8880\n",
      "Epoch 2/10\n",
      "1000/1000 [==============================] - 58s 58ms/step - loss: 0.2210 - acc: 0.9080\n",
      "Epoch 3/10\n",
      "1000/1000 [==============================] - 60s 60ms/step - loss: 0.1551 - acc: 0.9430\n",
      "Epoch 4/10\n",
      "1000/1000 [==============================] - 58s 58ms/step - loss: 0.1316 - acc: 0.9550\n",
      "Epoch 5/10\n",
      "1000/1000 [==============================] - 58s 58ms/step - loss: 0.1158 - acc: 0.9610\n",
      "Epoch 6/10\n",
      "1000/1000 [==============================] - 58s 58ms/step - loss: 0.0988 - acc: 0.9690\n",
      "Epoch 7/10\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 0.0882 - acc: 0.9710\n",
      "Epoch 8/10\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 0.0787 - acc: 0.9750\n",
      "Epoch 9/10\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 0.0722 - acc: 0.9790\n",
      "Epoch 10/10\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 0.0671 - acc: 0.9810\n",
      "Training on Epoch  2 batch  5  Files [5] start  75 / 459\n",
      "Epoch 1/10\n",
      "1000/1000 [==============================] - 64s 64ms/step - loss: 0.3647 - acc: 0.8740\n",
      "Epoch 2/10\n",
      "1000/1000 [==============================] - 64s 64ms/step - loss: 0.2691 - acc: 0.8960\n",
      "Epoch 3/10\n",
      "1000/1000 [==============================] - 66s 66ms/step - loss: 0.2059 - acc: 0.9210\n",
      "Epoch 4/10\n",
      "1000/1000 [==============================] - 63s 63ms/step - loss: 0.1667 - acc: 0.9270\n",
      "Epoch 5/10\n",
      "1000/1000 [==============================] - 64s 64ms/step - loss: 0.1448 - acc: 0.9410\n",
      "Epoch 6/10\n",
      "1000/1000 [==============================] - 66s 66ms/step - loss: 0.1292 - acc: 0.9430\n",
      "Epoch 7/10\n",
      "1000/1000 [==============================] - 65s 65ms/step - loss: 0.1091 - acc: 0.9560\n",
      "Epoch 8/10\n",
      "1000/1000 [==============================] - 62s 62ms/step - loss: 0.1022 - acc: 0.9570\n",
      "Epoch 9/10\n",
      "1000/1000 [==============================] - 62s 62ms/step - loss: 0.0922 - acc: 0.9700\n",
      "Epoch 10/10\n",
      "1000/1000 [==============================] - 62s 62ms/step - loss: 0.0825 - acc: 0.9680\n",
      "Training on Epoch  2 batch  5  Files [5] start  80 / 459\n",
      "Epoch 1/10\n",
      "1000/1000 [==============================] - 66s 66ms/step - loss: 0.3536 - acc: 0.8720\n",
      "Epoch 2/10\n",
      "1000/1000 [==============================] - 65s 65ms/step - loss: 0.2543 - acc: 0.8940\n",
      "Epoch 3/10\n",
      "1000/1000 [==============================] - 64s 64ms/step - loss: 0.2014 - acc: 0.9150\n",
      "Epoch 4/10\n",
      "1000/1000 [==============================] - 65s 65ms/step - loss: 0.1582 - acc: 0.9340\n",
      "Epoch 5/10\n",
      "1000/1000 [==============================] - 65s 65ms/step - loss: 0.1254 - acc: 0.9510\n",
      "Epoch 6/10\n",
      "1000/1000 [==============================] - 65s 65ms/step - loss: 0.1086 - acc: 0.9600\n",
      "Epoch 7/10\n",
      "1000/1000 [==============================] - 67s 67ms/step - loss: 0.0958 - acc: 0.9660\n",
      "Epoch 8/10\n",
      "1000/1000 [==============================] - 65s 65ms/step - loss: 0.0867 - acc: 0.9670\n",
      "Epoch 9/10\n",
      "1000/1000 [==============================] - 65s 65ms/step - loss: 0.0792 - acc: 0.9740\n",
      "Epoch 10/10\n",
      "1000/1000 [==============================] - 67s 67ms/step - loss: 0.0748 - acc: 0.9680\n",
      "Training on Epoch  2 batch  5  Files [5] start  85 / 459\n",
      "Epoch 1/10\n",
      "1000/1000 [==============================] - 65s 65ms/step - loss: 0.3433 - acc: 0.8790\n",
      "Epoch 2/10\n",
      "1000/1000 [==============================] - 64s 64ms/step - loss: 0.2455 - acc: 0.9050\n",
      "Epoch 3/10\n",
      "1000/1000 [==============================] - 65s 65ms/step - loss: 0.1965 - acc: 0.9170\n",
      "Epoch 4/10\n",
      "1000/1000 [==============================] - 65s 65ms/step - loss: 0.1560 - acc: 0.9330\n",
      "Epoch 5/10\n",
      "1000/1000 [==============================] - 65s 65ms/step - loss: 0.1334 - acc: 0.9420\n",
      "Epoch 6/10\n",
      "1000/1000 [==============================] - 66s 66ms/step - loss: 0.1159 - acc: 0.9520\n",
      "Epoch 7/10\n",
      "1000/1000 [==============================] - 73s 73ms/step - loss: 0.1039 - acc: 0.9570\n",
      "Epoch 8/10\n",
      "1000/1000 [==============================] - 87s 87ms/step - loss: 0.0912 - acc: 0.9650\n",
      "Epoch 9/10\n",
      "1000/1000 [==============================] - 110s 110ms/step - loss: 0.0823 - acc: 0.9700\n",
      "Epoch 10/10\n",
      "1000/1000 [==============================] - 120s 120ms/step - loss: 0.0753 - acc: 0.9710\n",
      "Training on Epoch  2 batch  5  Files [5] start  90 / 459\n",
      "Epoch 1/10\n",
      "1000/1000 [==============================] - 105s 105ms/step - loss: 0.3345 - acc: 0.8810\n",
      "Epoch 2/10\n",
      "1000/1000 [==============================] - 75s 75ms/step - loss: 0.2341 - acc: 0.9160\n",
      "Epoch 3/10\n",
      "1000/1000 [==============================] - 61s 61ms/step - loss: 0.1791 - acc: 0.9450\n",
      "Epoch 4/10\n",
      "1000/1000 [==============================] - 60s 60ms/step - loss: 0.1443 - acc: 0.9540\n",
      "Epoch 5/10\n",
      "1000/1000 [==============================] - 61s 61ms/step - loss: 0.1201 - acc: 0.9650\n",
      "Epoch 6/10\n",
      "1000/1000 [==============================] - 61s 61ms/step - loss: 0.1037 - acc: 0.9670\n",
      "Epoch 7/10\n",
      "1000/1000 [==============================] - 60s 60ms/step - loss: 0.0894 - acc: 0.9720\n",
      "Epoch 8/10\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000/1000 [==============================] - 61s 61ms/step - loss: 0.0796 - acc: 0.9730\n",
      "Epoch 9/10\n",
      "1000/1000 [==============================] - 60s 60ms/step - loss: 0.0720 - acc: 0.9710\n",
      "Epoch 10/10\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 0.0657 - acc: 0.9750\n",
      "Training on Epoch  2 batch  5  Files [5] start  95 / 459\n",
      "Epoch 1/10\n",
      "1000/1000 [==============================] - 70s 70ms/step - loss: 0.3150 - acc: 0.8780\n",
      "Epoch 2/10\n",
      "1000/1000 [==============================] - 69s 69ms/step - loss: 0.2123 - acc: 0.9090\n",
      "Epoch 3/10\n",
      "1000/1000 [==============================] - 70s 70ms/step - loss: 0.1601 - acc: 0.9390\n",
      "Epoch 4/10\n",
      "1000/1000 [==============================] - 89s 89ms/step - loss: 0.1240 - acc: 0.9580\n",
      "Epoch 5/10\n",
      "1000/1000 [==============================] - 89s 89ms/step - loss: 0.1070 - acc: 0.9610\n",
      "Epoch 6/10\n",
      "1000/1000 [==============================] - 93s 93ms/step - loss: 0.0945 - acc: 0.9640\n",
      "Epoch 7/10\n",
      "1000/1000 [==============================] - 114s 114ms/step - loss: 0.0849 - acc: 0.9690\n",
      "Epoch 8/10\n",
      "1000/1000 [==============================] - 116s 116ms/step - loss: 0.0770 - acc: 0.9710\n",
      "Epoch 9/10\n",
      "1000/1000 [==============================] - 71s 71ms/step - loss: 0.0712 - acc: 0.9760\n",
      "Epoch 10/10\n",
      "1000/1000 [==============================] - 66s 66ms/step - loss: 0.0658 - acc: 0.9810\n",
      "Training on Epoch  2 batch  5  Files [5] start  100 / 459\n",
      "Epoch 1/10\n",
      "1000/1000 [==============================] - 60s 60ms/step - loss: 0.2854 - acc: 0.9050\n",
      "Epoch 2/10\n",
      "1000/1000 [==============================] - 59s 59ms/step - loss: 0.1796 - acc: 0.9390\n",
      "Epoch 3/10\n",
      "1000/1000 [==============================] - 58s 58ms/step - loss: 0.1283 - acc: 0.9560\n",
      "Epoch 4/10\n",
      "1000/1000 [==============================] - 57s 57ms/step - loss: 0.1022 - acc: 0.9700\n",
      "Epoch 5/10\n",
      "1000/1000 [==============================] - 58s 58ms/step - loss: 0.0812 - acc: 0.9760\n",
      "Epoch 6/10\n",
      "1000/1000 [==============================] - 58s 58ms/step - loss: 0.0638 - acc: 0.9800\n",
      "Epoch 7/10\n",
      "1000/1000 [==============================] - 57s 57ms/step - loss: 0.0557 - acc: 0.9840\n",
      "Epoch 8/10\n",
      "1000/1000 [==============================] - 58s 58ms/step - loss: 0.0472 - acc: 0.9850\n",
      "Epoch 9/10\n",
      "1000/1000 [==============================] - 58s 58ms/step - loss: 0.0404 - acc: 0.9870\n",
      "Epoch 10/10\n",
      "1000/1000 [==============================] - 58s 58ms/step - loss: 0.0347 - acc: 0.9880\n",
      "Training on Epoch  2 batch  5  Files [5] start  105 / 459\n",
      "Epoch 1/10\n",
      "1000/1000 [==============================] - 66s 66ms/step - loss: 0.2950 - acc: 0.9010\n",
      "Epoch 2/10\n",
      "1000/1000 [==============================] - 65s 65ms/step - loss: 0.1961 - acc: 0.9260\n",
      "Epoch 3/10\n",
      "1000/1000 [==============================] - 67s 67ms/step - loss: 0.1484 - acc: 0.9480\n",
      "Epoch 4/10\n",
      "1000/1000 [==============================] - 69s 69ms/step - loss: 0.1155 - acc: 0.9630\n",
      "Epoch 5/10\n",
      "1000/1000 [==============================] - 67s 67ms/step - loss: 0.0960 - acc: 0.9710\n",
      "Epoch 6/10\n",
      "1000/1000 [==============================] - 65s 65ms/step - loss: 0.0756 - acc: 0.9770\n",
      "Epoch 7/10\n",
      "1000/1000 [==============================] - 158s 158ms/step - loss: 0.0651 - acc: 0.9810\n",
      "Epoch 8/10\n",
      "1000/1000 [==============================] - 165s 165ms/step - loss: 0.0569 - acc: 0.9840\n",
      "Epoch 9/10\n",
      "1000/1000 [==============================] - 158s 158ms/step - loss: 0.0487 - acc: 0.9850\n",
      "Epoch 10/10\n",
      "1000/1000 [==============================] - 145s 145ms/step - loss: 0.0419 - acc: 0.9870\n",
      "Training on Epoch  2 batch  5  Files [5] start  110 / 459\n",
      "Epoch 1/10\n",
      "1000/1000 [==============================] - 67s 67ms/step - loss: 0.3912 - acc: 0.8720\n",
      "Epoch 2/10\n",
      "1000/1000 [==============================] - 69s 69ms/step - loss: 0.2518 - acc: 0.9020\n",
      "Epoch 3/10\n",
      "1000/1000 [==============================] - 68s 68ms/step - loss: 0.1760 - acc: 0.9210\n",
      "Epoch 4/10\n",
      "1000/1000 [==============================] - 68s 68ms/step - loss: 0.1367 - acc: 0.9530\n",
      "Epoch 5/10\n",
      "1000/1000 [==============================] - 68s 68ms/step - loss: 0.1135 - acc: 0.9570\n",
      "Epoch 6/10\n",
      "1000/1000 [==============================] - 67s 67ms/step - loss: 0.0988 - acc: 0.9660\n",
      "Epoch 7/10\n",
      "1000/1000 [==============================] - 68s 68ms/step - loss: 0.0859 - acc: 0.9690\n",
      "Epoch 8/10\n",
      "1000/1000 [==============================] - 166s 166ms/step - loss: 0.0761 - acc: 0.9710\n",
      "Epoch 9/10\n",
      "1000/1000 [==============================] - 195s 195ms/step - loss: 0.0671 - acc: 0.9740\n",
      "Epoch 10/10\n",
      "1000/1000 [==============================] - 171s 171ms/step - loss: 0.0616 - acc: 0.9790\n",
      "Training on Epoch  2 batch  5  Files [5] start  115 / 459\n",
      "Epoch 1/10\n",
      "1000/1000 [==============================] - 127s 127ms/step - loss: 0.3158 - acc: 0.8800\n",
      "Epoch 2/10\n",
      "1000/1000 [==============================] - 142s 142ms/step - loss: 0.2507 - acc: 0.8960\n",
      "Epoch 3/10\n",
      "1000/1000 [==============================] - 219s 219ms/step - loss: 0.1935 - acc: 0.9210\n",
      "Epoch 4/10\n",
      "1000/1000 [==============================] - 227s 227ms/step - loss: 0.1622 - acc: 0.9320\n",
      "Epoch 5/10\n",
      "1000/1000 [==============================] - 201s 201ms/step - loss: 0.1443 - acc: 0.9430\n",
      "Epoch 6/10\n",
      "1000/1000 [==============================] - 168s 168ms/step - loss: 0.1332 - acc: 0.9430\n",
      "Epoch 7/10\n",
      "1000/1000 [==============================] - 114s 114ms/step - loss: 0.1259 - acc: 0.9460\n",
      "Epoch 8/10\n",
      "1000/1000 [==============================] - 84s 84ms/step - loss: 0.1203 - acc: 0.9530\n",
      "Epoch 9/10\n",
      "1000/1000 [==============================] - 77s 77ms/step - loss: 0.1181 - acc: 0.9520\n",
      "Epoch 10/10\n",
      "1000/1000 [==============================] - 69s 69ms/step - loss: 0.1098 - acc: 0.9540\n",
      "Training on Epoch  2 batch  5  Files [5] start  120 / 459\n"
     ]
    },
    {
     "ename": "MemoryError",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mMemoryError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-42-7d4d112c17b2>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     26\u001b[0m                                                                                 \u001b[0mdimOfQuestionVector\u001b[0m  \u001b[1;33m=\u001b[0m \u001b[0ms_DimOfQuestionVector\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     27\u001b[0m                                                                                 \u001b[0mdimOfTripletVector\u001b[0m   \u001b[1;33m=\u001b[0m \u001b[0ms_DimOfTripletVector\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 28\u001b[1;33m                                                                                 dimOfMask            = s_DimOfMask )\n\u001b[0m\u001b[0;32m     29\u001b[0m             \u001b[1;31m# train on this batch\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     30\u001b[0m             \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mquestion_vectors\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mquestion_masks\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtriplet_vectors\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mY\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mepochs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m10\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch_size\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m200\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mshuffle\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-24-5dd086365f27>\u001b[0m in \u001b[0;36mprepare_data\u001b[1;34m(data, question_max_words, triplets_max_numbers, dimOfQuestionVector, dimOfTripletVector, dimOfMask)\u001b[0m\n\u001b[0;32m     51\u001b[0m     \u001b[0mquestion_vectors\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0masarray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mquestion_vectors\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     52\u001b[0m     \u001b[0mquestion_masks\u001b[0m   \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0masarray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mquestion_masks\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 53\u001b[1;33m     \u001b[0mtriplet_vectors\u001b[0m  \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0masarray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtriplet_vectors\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     54\u001b[0m     \u001b[0mY\u001b[0m                \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0masarray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mY\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     55\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mquestion_vectors\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mquestion_masks\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtriplet_vectors\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mY\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mx:\\cs230\\alpha\\.env\\lib\\site-packages\\numpy\\core\\numeric.py\u001b[0m in \u001b[0;36masarray\u001b[1;34m(a, dtype, order)\u001b[0m\n\u001b[0;32m    536\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    537\u001b[0m     \"\"\"\n\u001b[1;32m--> 538\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0marray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ma\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0morder\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0morder\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    539\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    540\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mMemoryError\u001b[0m: "
     ]
    }
   ],
   "source": [
    "for ep in range(0,s_NumEpocs):\n",
    "    if ep != 0:\n",
    "        file_name = \"train_epoch_\" + str(ep-1) + \".save\"\n",
    "        model.load_weights(file_name)\n",
    "    \n",
    "    file_index       = 0\n",
    "    batch_file_index = 0\n",
    "    \n",
    "    data = []\n",
    "    # train on batches of files\n",
    "    for file_index in range(0, file_list_count) :\n",
    "        inputFile = file_list[file_index]\n",
    "        file_index       += 1\n",
    "        batch_file_index += 1\n",
    "        # print(inputFile)\n",
    "        f = open(inputFile, 'rb')\n",
    "        test = pickle.load(f)\n",
    "        data = np.append(data, test)\n",
    "        f.close()\n",
    "    \n",
    "        if batch_file_index == s_NumFilesInBatch or file_index == file_list_count:\n",
    "            print(\"Training on Epoch \", str(ep), \"batch \", str(batch_file_index), \" Files [\" + str(s_NumFilesInBatch) + \"] start \", str(file_index - batch_file_index), \"/\", str(file_list_count) )\n",
    "            question_vectors, question_masks, triplet_vectors, Y = prepare_data(data, \n",
    "                                                                                question_max_words   = s_QuestionMaxWords, \n",
    "                                                                                triplets_max_numbers = s_TripletsMaxNumbers, \n",
    "                                                                                dimOfQuestionVector  = s_DimOfQuestionVector, \n",
    "                                                                                dimOfTripletVector   = s_DimOfTripletVector, \n",
    "                                                                                dimOfMask            = s_DimOfMask )\n",
    "            # train on this batch\n",
    "            model.fit([question_vectors, question_masks, triplet_vectors], Y, epochs = 10, batch_size = 200, shuffle=True)\n",
    "            # rest for next batch\n",
    "            batch_file_index = 0;\n",
    "            data = []\n",
    "            \n",
    "    # save the mode for the epoch\n",
    "    file_name = \"train_epoch_\" + str(ep) + \".save\"\n",
    "    model.save_weights(file_name)\n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from keras.layers import Dense, Input, Dropout, LSTM, Activation, SimpleRNN, GRU, Concatenate, Multiply, Reshape, Flatten, Bidirectional\n",
    "\n",
    "# # layers\n",
    "# s1_bilstm = Bidirectional(GRU(128, return_sequences = True), name = \"s1_bilstm\")\n",
    "# s2_bilstm = Bidirectional(GRU(128, return_sequences = False), name = \"s2_bilstm\")\n",
    "# t_bilstm = Bidirectional(GRU(128, return_sequences = False), name = \"t_bilstm\")\n",
    "# embedding_layer = pretrained_embedding_layer(word_to_vec_map, words_to_index)\n",
    "# unstack_layer = Lambda(lambda xin: myUnstack(xin), name=\"AUnstackLayer\")\n",
    "\n",
    "# # sentence inputs\n",
    "# sentence_indices = Input(shape=(maxWordsPerSentence,), dtype='int32', name=\"sentence_indices\")   \n",
    "# sentence_masks = Input(shape=(2*lstm_dim,), dtype='float32', name=\"sentence_masks\")\n",
    "\n",
    "# # sentence embeddings\n",
    "# sentence_embeddings = embedding_layer(sentence_indices)       \n",
    "# # X_sentence = Reshape((maxWordsPerSentence, -1), name=\"s_reshape\")(sentence_embeddings)\n",
    "# X_sentence = s1_bilstm(sentence_embeddings)\n",
    "# X_sentence = Multiply()([sentence_masks, X_sentence]) # (None, 60, 256)\n",
    "# X_sentence = s2_bilstm(X_sentence)\n",
    "\n",
    "# # triplets\n",
    "# triplets_input = Input(shape=(maxTriplets, maxWordsPerSentence,), dtype='int32', name=\"tripletz\") \n",
    "# triplet_embeddings = embedding_layer(triplets_input)\n",
    "\n",
    "# X_triplets = Reshape((maxTriplets, -1))(triplet_embeddings)\n",
    "# X_triplets = t_bilstm(X_triplets)\n",
    "\n",
    "# X_concatenated = Concatenate()([X_sentence, X_triplets])\n",
    "# X_concatenated = Dense(256, activation='relu', name=\"Dense256\")(X_concatenated)\n",
    "# X_concatenated = Dense(64, activation='relu', name=\"Dense64\")(X_concatenated)\n",
    "# Y_pred = Dense(1, activation='sigmoid', name=\"Dense1\")(X_concatenated)\n",
    "\n",
    "# m.v2 = Model(inputs=[sentence_indices, sentence_masks, triplets_input], outputs=X_concatenated)\n",
    "# print(m.v2.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
